{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "title-cell"
   },
   "source": [
    "# Neural Bandit Algorithm Evaluation Framework\n",
    "\n",
    "## Graduate Research Project\n",
    "**AI & Quantum Computing Laboratory**  \n",
    "**Rochester Institute of Technology**\n",
    "\n",
    "---\n",
    "\n",
    "## Research Framework Overview\n",
    "\n",
    "This comprehensive evaluation framework provides rigorous analysis of neural bandit algorithms with clear categorical distinction between different operational environments:\n",
    "\n",
    "- **Baseline Environment**: Optimal performance benchmark (Oracle)\n",
    "- **Stochastic Environment**: Natural random failures and network noise\n",
    "- **Adversarial Environment**: Strategic intelligent attacks and malicious targeting\n",
    "\n",
    "## Primary Research Questions\n",
    "\n",
    "1. **Algorithm Robustness**: How do neural bandit algorithms perform across different threat models?\n",
    "2. **Comparative Analysis**: Which algorithms demonstrate superior performance in specific scenarios?\n",
    "3. **Quantified Performance**: What are the exact degradation metrics under adversarial conditions?\n",
    "4. **Theoretical Validation**: Do experimental results align with established regret bounds?\n",
    "\n",
    "## Key Research Contributions\n",
    "\n",
    "- **Systematic Environment Categorization**: Clear baseline/stochastic/adversarial taxonomy\n",
    "- **Multi-Algorithm Comparative Testing**: Comprehensive evaluation across 6+ algorithms\n",
    "- **Quantified Robustness Metrics**: Precise performance degradation measurements\n",
    "- **Publication-Ready Analysis**: Academic-quality visualizations and statistical validation\n",
    "\n",
    "## Evaluation Methodology\n",
    "\n",
    "The framework implements standardized testing protocols across three distinct categories:\n",
    "- **Baseline**: Oracle performance establishing theoretical upper bounds\n",
    "- **Stochastic**: Random environmental perturbations modeling realistic conditions  \n",
    "- **Adversarial**: Strategic attack scenarios simulating malicious interference\n",
    "\n",
    "Each algorithm undergoes identical testing conditions enabling direct performance comparison and robustness quantification across all operational environments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "framework-overview"
   },
   "source": [
    "## Threat Model Classification Framework\n",
    "\n",
    "### Systematic Environment Taxonomy\n",
    "\n",
    "This research framework establishes precise categorical distinctions for quantum network evaluation environments, addressing previous ambiguity in threat model classification:\n",
    "\n",
    "### Environmental Categories\n",
    "\n",
    "| Environment | Implementation | Threat Characteristic | Research Application |\n",
    "|-------------|----------------|----------------------|---------------------|\n",
    "| **Baseline** | `none` | Deterministic optimal performance | Theoretical upper bound |\n",
    "| **Stochastic** | `stochastic`/`random` | Natural random failures | Realistic network conditions |\n",
    "| **Adversarial** | `markov` | Oblivious strategic attacks | Pattern-based targeting |\n",
    "| **Adversarial** | `adaptive` | Responsive strategic attacks | Feedback-driven targeting |\n",
    "| **Adversarial** | `onlineadaptive` | Real-time strategic attacks | Dynamic threat adaptation |\n",
    "\n",
    "### Research Contribution\n",
    "\n",
    "This framework addresses a critical gap in existing literature where random network failures were often conflated with intentional adversarial attacks. The systematic categorization enables:\n",
    "\n",
    "- **Precise Robustness Quantification**: Exact performance degradation measurements across threat categories\n",
    "- **Comparative Algorithm Analysis**: Direct performance comparison under identical threat conditions\n",
    "- **Theoretical Validation**: Empirical verification of regret bounds across different adversarial models\n",
    "- **Reproducible Research Standards**: Standardized evaluation protocols for quantum network algorithms\n",
    "\n",
    "### Methodological Significance\n",
    "\n",
    "Previous research often lacked clear distinction between stochastic and adversarial environments, limiting the ability to assess true algorithm robustness under intentional attacks versus natural network degradation. This framework provides the necessary precision for rigorous academic evaluation of quantum routing algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup-cell"
   },
   "source": [
    "## Environment Setup & Library Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 58,
     "status": "ok",
     "timestamp": 1758879388611,
     "user": {
      "displayName": "Piter Garcia",
      "userId": "06279433864365870614"
     },
     "user_tz": 240
    },
    "id": "theoretical-setup",
    "outputId": "a6c0fc57-a152-45e1-9da6-5113e519b8fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: GA-Work\n",
      "Running locally (not in Colab)\n",
      "Changed to project directory: Dynamic_Routing_Eval_Framework\n",
      "Now working from: Dynamic_Routing_Eval_Framework\n",
      "Framework dependencies installed successfully\n",
      "Python version: 3.12.11\n",
      "PyTorch version: 2.8.0\n",
      "NumPy version: 1.26.4\n",
      "NetworkX version: 3.5\n",
      "Matplotlib version: 3.10.6\n",
      "Quantum MAB Models Evaluation Framework - Ready for Paper 7 (QBGP) testing\n",
      "‚ö†Ô∏è Cleanup script not found, skipping...\n",
      "‚úì Deep cleanup complete (memory cleared)\n",
      "‚úì daqr package found successfully\n",
      "PyTorch version: 2.8.0\n",
      "NumPy version: 1.26.4\n",
      "Using device: cpu\n",
      "PyTorch version: 2.8.0\n",
      "NumPy version: 1.26.4\n",
      "Using device: cpu\n",
      "‚úì All modules reloaded successfully (Paper 7 environment ready)\n",
      "PyTorch version: 2.8.0\n",
      "NumPy version: 1.26.4\n",
      "Using device: cpu\n",
      "PyTorch version: 2.8.0\n",
      "NumPy version: 1.26.4\n",
      "Using device: cpu\n",
      "\n",
      "===================== GET LOCAL REGISTRY =====================\n",
      "‚Üí Skipping local cache (force=True or file missing)\n",
      "\n",
      "===================== BUILD LOCAL REGISTRY =====================\n",
      "\n",
      "================================================================================\n",
      "üîç SCANNING LOCAL FILES\n",
      "================================================================================\n",
      "Parameters: load_to_drive=False, force=False\n",
      "\n",
      "üìÇ Checking DRIVE mode: /content/drive/Shareddrives/ai_quantum_computing/quantum_data_lake\n",
      "   ‚ö†Ô∏è  Path does not exist, skipping\n",
      "\n",
      "üìÇ Checking LOCAL mode: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config\n",
      "   ‚úÖ Path exists, starting walk...\n",
      "   üö∂ Walking directory tree: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config\n",
      "\n",
      "   üìÅ Directory: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201\n",
      "      Relative: framework_state/day_20260201\n",
      "      Component: framework_state\n",
      "      Date: day_20260201\n",
      "      üìÑ Processing 2512 files in framework_state/day_20260201\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "      üìä framework_state/day_20260201: 2485/2512 files processed\n",
      "      üìä framework_state/day_20260201: 0/2512 files skipped\n",
      "      üìä framework_state/day_20260201: 27/2512 files conflicted\n",
      "\n",
      "   üìÅ Directory: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/model_state/day_20260201\n",
      "      Relative: model_state/day_20260201\n",
      "      Component: model_state\n",
      "      Date: day_20260201\n",
      "      üìÑ Processing 8842 files in model_state/day_20260201\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "      üìä model_state/day_20260201: 8842/8842 files processed\n",
      "      üìä model_state/day_20260201: 0/8842 files skipped\n",
      "      üìä model_state/day_20260201: 0/8842 files conflicted\n",
      "\n",
      "   üìä Processed 2 directories\n",
      "\n",
      "================================================================================\n",
      "üì¶ BUILDING FINAL REGISTRY\n",
      "================================================================================\n",
      "Components found: ['framework_state', 'model_state']\n",
      "  ‚Ä¢ framework_state: 2485 files\n",
      "  ‚Ä¢ model_state: 8842 files\n",
      "\n",
      "‚úÖ SCAN COMPLETE\n",
      "Modes scanned: 1\n",
      "Total files in registry: 11327\n",
      "================================================================================\n",
      "\n",
      "\t‚Üí Filesystem scan found 11327 files\n",
      "\n",
      "===================== GET DRIVE REGISTRY =====================\n",
      "===================== REGISTRY BUILD COMPLETE =====================\n",
      "\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "\tüì¶ LocalBackupManager Registry Saved Locally in LOCAL\n",
      "BUILDING REGISTRY WITH 0 EXPECTED COMPONENTS KEYS\n",
      "\n",
      "===================== GET LOCAL REGISTRY =====================\n",
      "‚Üí Skipping local cache (force=True or file missing)\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "\tüì¶ LocalBackupManager Registry Saved Locally in LOCAL\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Setup: Quantum MAB Framework (Paper 7 QBGP Testbed)\n",
    "# ============================================================\n",
    "\n",
    "# --- Install Dependencies ---\n",
    "!pip install -q torch torchvision numpy matplotlib seaborn pandas tqdm scipy scikit-learn pmdarima networkx\n",
    "\n",
    "# --- Core Imports ---\n",
    "import os, sys, gc, warnings, importlib, subprocess\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import networkx as nx\n",
    "from pathlib import Path\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- Path Setup ---\n",
    "print(f\"Current working directory: {os.getcwd().split('/')[-1]}\")\n",
    "try:\n",
    "    import google.colab\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    project_dir = '/content/drive/MyDrive/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework'\n",
    "    os.chdir(project_dir)\n",
    "    print(\"Running in Google Colab\")\n",
    "except ImportError:\n",
    "    print(\"Running locally (not in Colab)\")\n",
    "    # Navigate to the correct directory for local execution\n",
    "    current_dir = os.getcwd()\n",
    "    if 'GA-Work' in current_dir and 'Dynamic_Routing_Eval_Framework' not in current_dir:\n",
    "        project_dir = os.path.join(current_dir, 'hybrid_variable_framework', 'Dynamic_Routing_Eval_Framework')\n",
    "        if os.path.exists(project_dir):\n",
    "            os.chdir(project_dir)\n",
    "            print(f\"Changed to project directory: {os.getcwd().split('/')[-1]}\")\n",
    "\n",
    "# Add necessary paths for daqr package discovery\n",
    "sys.path.append(os.path.join(os.getcwd(), 'src'))\n",
    "sys.path.append(os.getcwd())  # Add current directory to find daqr package\n",
    "\n",
    "print(f\"Now working from: {os.getcwd().split('/')[-1]}\")\n",
    "\n",
    "# --- Framework Verification ---\n",
    "print(\"Framework dependencies installed successfully\")\n",
    "print(f\"Python version: {sys.version.split()[0]}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"NetworkX version: {nx.__version__}\")\n",
    "print(f\"Matplotlib version: {plt.matplotlib.__version__}\")\n",
    "print(\"Quantum MAB Models Evaluation Framework - Ready for Paper 7 (QBGP) testing\")\n",
    "\n",
    "# --- Cleanup Script Execution ---\n",
    "root = os.path.abspath(\"../..\")\n",
    "cleanup_script = os.path.join(root, \"cleanup_state_duplicates.py\")\n",
    "if os.path.exists(cleanup_script):\n",
    "    print(f\"\\nüöø Running cleanup script at: {cleanup_script}\\n\")\n",
    "    result = subprocess.run([\"python3\", cleanup_script], text=True, capture_output=True)\n",
    "    print(\"===== CLEANUP STDOUT =====\\n\", result.stdout)\n",
    "    print(\"===== CLEANUP STDERR =====\\n\", result.stderr)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Cleanup script not found, skipping...\")\n",
    "\n",
    "# --- Deep Cleanup ---\n",
    "def deep_cleanup():\n",
    "    to_clear = [\"oracle\", \"gneuralucb\", \"expneuralucb\", \"cpursuitneuralucb\",\n",
    "                \"icpursuitneuralucb\", \"evaluator\", \"results\"]\n",
    "    for name in to_clear:\n",
    "        if name in globals():\n",
    "            obj = globals().get(name)\n",
    "            if hasattr(obj, \"cleanup\"): obj.cleanup(verbose=False)\n",
    "            globals().pop(name, None)\n",
    "    gc.collect()\n",
    "    torch.set_default_dtype(torch.float32)\n",
    "    if torch.cuda.is_available(): torch.cuda.empty_cache()\n",
    "    print(\"‚úì Deep cleanup complete (memory cleared)\")\n",
    "\n",
    "deep_cleanup()\n",
    "\n",
    "# Ensure daqr package is discoverable\n",
    "PARENT_DIR = os.path.abspath(\"..\")\n",
    "if PARENT_DIR not in sys.path:\n",
    "    sys.path.insert(0, PARENT_DIR)\n",
    "    \n",
    "# Verify daqr package can be found\n",
    "try:\n",
    "    import daqr\n",
    "    print(\"‚úì daqr package found successfully\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå daqr package not found: {e}\")\n",
    "    print(f\"Current directory: {os.getcwd()}\")\n",
    "    print(f\"Python path includes: {[p for p in sys.path if 'GA-Work' in p or 'daqr' in p]}\")\n",
    "    print(\"Please ensure you're running from the Dynamic_Routing_Eval_Framework directory\")\n",
    "\n",
    "# --- Final Module Setup ---\n",
    "from daqr.core.quantum_physics              import (MemoryNoiseModel, FullPaper2FidelityCalculator)\n",
    "from daqr.evaluation                        import experiment_runner, multi_run_evaluator, visualizer\n",
    "from daqr.config                            import experiment_config\n",
    "from daqr.algorithms                        import base_bandit, neural_bandits, predictive_bandits\n",
    "from daqr.core                              import network_environment, qubit_allocator\n",
    "from daqr.config.experiment_config          import ExperimentConfiguration\n",
    "from experiments                            import stochastic_evaluation\n",
    "from daqr.core.network_environment          import *\n",
    "from daqr.core.qubit_allocator              import *\n",
    "from daqr.algorithms.base_bandit            import *\n",
    "from daqr.algorithms.neural_bandits         import *\n",
    "from daqr.algorithms.predictive_bandits     import *\n",
    "from daqr.evaluation.multi_run_evaluator    import *\n",
    "from daqr.evaluation.experiment_runner      import *\n",
    "\n",
    "# ============================================================================\n",
    "# PAPER-SPECIFIC IMPORTS\n",
    "# ============================================================================\n",
    "from daqr.core.topology_generator           import Paper2TopologyGenerator\n",
    "from daqr.core.topology_generator           import Paper7ASTopologyGenerator  # üÜï Paper 7\n",
    "from daqr.core.topology_generator           import Paper12WaxmanTopologyGenerator\n",
    "from daqr.core.quantum_physics              import FiberLossNoiseModel\n",
    "from daqr.core.quantum_physics              import FusionNoiseModel, FusionFidelityCalculator\n",
    "from daqr.core.quantum_physics              import Paper12RetryFidelityCalculator\n",
    "from daqr.core.quantum_physics              import Paper7RewardFunction  # üÜï Paper 7\n",
    "from daqr.core                              import attack_strategy\n",
    "\n",
    "print(\"‚úì All modules reloaded successfully (Paper 7 environment ready)\")\n",
    "\n",
    "# --- Config & Model Setup ---\n",
    "for module in [experiment_config, network_environment, qubit_allocator, attack_strategy, base_bandit, \n",
    "               neural_bandits, predictive_bandits, experiment_runner, multi_run_evaluator, visualizer, \n",
    "               stochastic_evaluation]:\n",
    "    importlib.reload(module)\n",
    "\n",
    "config = ExperimentConfiguration()\n",
    "models = config.NEURAL_MODELS\n",
    "\n",
    "# ============================================================================\n",
    "# FRAMEWORK CONFIGURATION (Paper 7 Optimized)\n",
    "# ============================================================================\n",
    "FRAMEWORK_CONFIG = {\n",
    "    'exp_num': 5,\n",
    "    'test_mode': True,\n",
    "    'base_frames': 4000,\n",
    "    'frame_step': 2000,\n",
    "    'models': models,\n",
    "    'intensity': 0.25,\n",
    "    'routing_strategy': 'fixed',\n",
    "    'capacity': 10000,\n",
    "    'main_env': 'stochastic',\n",
    "\n",
    "    # Environment parameters\n",
    "    'env_attrs': {\n",
    "        'intensity': 0.25,\n",
    "        'base_seed': 12345,\n",
    "        'reproducible': True\n",
    "    },\n",
    "\n",
    "    'default': {\n",
    "        'num_paths': 4,\n",
    "        'total_qubits': 35,\n",
    "        'min_qubits_per_route': 2,\n",
    "        'exploration_bonus': 2.0,\n",
    "        'epsilon': 1.0,\n",
    "        'seed': 42\n",
    "    },\n",
    "    \n",
    "    # üéØ Paper #7 (Liu et al. 2024 - QBGP) - PRIMARY TESTBED\n",
    "    'paper7': {\n",
    "        # Topology Configuration\n",
    "        'k': 5,                      # k-shortest paths per ISP pair\n",
    "        'n_qisps': 3,                # Number of quantum ISP nodes\n",
    "        'num_paths': 4,              # Total paths for framework compatibility\n",
    "        'max_nodes': 50,             # AS subgraph size (30-80 for testing, None for full)\n",
    "        'network_scale': 'small',    # 'small' (30-50), 'medium' (100-200), 'large' (full)\n",
    "        'topology_path': '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/core/topology_data/as20000101.txt',\n",
    "        \n",
    "        # Framework Parameters\n",
    "        'total_qubits': 35,\n",
    "        'min_qubits_per_route': 2,\n",
    "        'exploration_bonus': 2.0,\n",
    "        \n",
    "        # Context & Reward Configuration\n",
    "        'use_context_rewards': True,      # Enable context-aware reward function\n",
    "        'reward_mode': 'neg_hop',         # Options: 'neg_hop', 'neg_degree', 'neg_length'\n",
    "        'use_synthetic': False,           # Force synthetic topology (ignore topology_path)\n",
    "        \n",
    "        # Topology Processing\n",
    "        'largest_cc_only': True,          # Use largest connected component\n",
    "        'relabel_to_int': True,           # Relabel nodes to integers\n",
    "        \n",
    "        # Synthetic Fallback (if topology_path fails or use_synthetic=True)\n",
    "        'synthetic_kind': 'barabasi_albert',\n",
    "        'synthetic_params': {\n",
    "            'n': 50,                      # Number of nodes\n",
    "            'm': 3                        # Edges per new node\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    # Paper #2 (Huang et al. - Neural Bandit Work)\n",
    "    'paper2': {\n",
    "        # Topology & Paths\n",
    "        'num_paths': 4,\n",
    "        'num_total_qubits': 35,\n",
    "        'dest_node': 14,\n",
    "        'num_nodes': 15,\n",
    "        'source_node': 1,\n",
    "        \n",
    "        # Base Physics\n",
    "        'p_init': 0.00001,\n",
    "        'total_qubits': 35,\n",
    "        'f_attenuation': 0.05,\n",
    "        \n",
    "        # Stochastic Noise Parameters\n",
    "        'p_BSM': 0.2,\n",
    "        'p_GateErrors': 0.2,\n",
    "        'p_depol': 0.1,\n",
    "\n",
    "        # State Configuration\n",
    "        'testbed': 'paper2',\n",
    "        'initial_state': 'idle',\n",
    "        'state_total_qubits': {'busy': 35, 'idle': 43},\n",
    "        \n",
    "        # Bandit Algorithm\n",
    "        'exploration_bonus': 2.0,\n",
    "        'min_qubits_per_route': 2,\n",
    "        'transition_trigger': True,\n",
    "        'paper2_transition_interval': 50,\n",
    "        'entanglement_success_factor': 4000,\n",
    "        \n",
    "        # Paper2 Features\n",
    "        'use_paper2_rewards': True,\n",
    "        'swap_mode': 'async',\n",
    "        'memory_T2': 5000,\n",
    "        'gate_error_rate': 0.02,\n",
    "        'swap_delay_per_link': 100,\n",
    "        'use_gate_error': True,\n",
    "        'use_memory_decay': True,\n",
    "    },\n",
    "    # Paper #12 (Wang et al. 2024 - QuARC)\n",
    "    # Reference: Clayton et al., ICNP 2024 - \"Efficient Routing on Quantum Networks using Adaptive Clustering\"\n",
    "    # Repository: https://github.com/cbclayton/clustered-quantum-routing\n",
    "    'paper12': {\n",
    "        'testbed': 'paper12',\n",
    "        \n",
    "        # ========== TOPOLOGY CONFIGURATION ==========\n",
    "        'topology_type': 'waxman_qcast',\n",
    "        \n",
    "        # Network parameters (Paper 12 baseline)\n",
    "        'n_nodes': 100,              # ‚úÖ Baseline: 100 nodes\n",
    "        'avg_degree': 6,             # ‚úÖ E_d: Average node degree\n",
    "        'entanglement_prob': 0.6,    # ‚úÖ E_p: Paper 12 ORIGINAL value\n",
    "        'fusion_prob': 0.9,          # ‚úÖ q: Paper 12 ORIGINAL value\n",
    "        \n",
    "        # Waxman topology parameters\n",
    "        'waxman_alpha': 0.4,\n",
    "        'waxman_beta': 0.2,\n",
    "        \n",
    "        # ========== SIMULATION PARAMETERS ==========\n",
    "        'num_sd_pairs': 10,          # ‚úÖ nsd: Concurrent S-D pairs\n",
    "        'epoch_length': 500,         # ‚úÖ T_epoch: QuARC reconfiguration interval\n",
    "        'total_timeslots': 5000,     # ‚úÖ T: Baseline simulation length\n",
    "        'cutoff': 1e9,               # Request timeout\n",
    "        \n",
    "        # ========== QUART PROTOCOL PARAMETERS ==========\n",
    "        'split_constant': 3,         # ‚úÖ k: Number of shortest paths\n",
    "        'enable_clustering': True,   # ‚úÖ Dynamic cluster merge/split\n",
    "        'enable_secondary_fusions': True,  # ‚úÖ Paper 12 fusion protocol\n",
    "        'use_dynamic_thresholding': True,\n",
    "        \n",
    "        # ========== FRAMEWORK ADAPTATION ==========\n",
    "        'num_paths': 4,              # For framework: paths for bandit arms\n",
    "        'total_qubits': 100,         # Estimated: n_nodes * avg_qubits_per_node\n",
    "        'exploration_bonus': 1.5,    # For bandit algorithms\n",
    "        'min_qubits_per_route': 3,   # For framework allocation\n",
    "        'use_fusion_rewards': True,  # Use entanglement success as reward\n",
    "    }\n",
    "}\n",
    "\n",
    "# --- Test Scenarios ---\n",
    "if FRAMEWORK_CONFIG['main_env'] == 'stochastic':\n",
    "    test_scenarios = {\n",
    "        'none': 'Baseline (Optimal Conditions)',\n",
    "        'stochastic': 'Stochastic Random Failures',\n",
    "        'markov': 'Markov Adversarial Attack',\n",
    "        'adaptive': 'Adaptive Adversarial Attack',\n",
    "        'onlineadaptive': 'Online Adaptive Attack'\n",
    "    }\n",
    "    evaluation_type = \"STOCHASTIC-FOCUSED\"\n",
    "else:\n",
    "    test_scenarios = {\n",
    "        'stochastic': 'Stochastic (Natural Network Failures)',\n",
    "        'adaptive': 'Adversarial (Strategic Attacks)'\n",
    "    }\n",
    "    evaluation_type = \"COMPARATIVE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "stochastic-vs-adversarial"
   },
   "source": [
    "## Comparative Analysis Framework: Stochastic versus Adversarial Environments\n",
    "\n",
    "### Research Focus\n",
    "\n",
    "This evaluation constitutes the primary empirical contribution of the research: systematic quantification of algorithm performance across fundamentally different operational conditions that distinguish between natural system failures and intentional strategic attacks.\n",
    "\n",
    "### Environmental Characterization\n",
    "\n",
    "**Stochastic Environment**\n",
    "- **Operational Model**: Natural random failures representing realistic network degradation patterns\n",
    "- **Attack Distribution**: Probabilistic failures following uniform random distribution\n",
    "- **Research Significance**: Establishes baseline performance metrics under standard operational conditions\n",
    "\n",
    "**Adversarial Environment**  \n",
    "- **Operational Model**: Strategic intelligent attacks systematically targeting algorithmic decision-making processes\n",
    "- **Attack Distribution**: Adaptive targeting mechanisms that dynamically respond to observed algorithm behavior\n",
    "- **Research Significance**: Evaluates robustness under worst-case strategic threat scenarios\n",
    "\n",
    "### Experimental Predictions\n",
    "\n",
    "Based on the theoretical analysis and algorithm architecture, the following empirical outcomes are anticipated:\n",
    "\n",
    "**Performance Superiority Hypothesis**\n",
    "EXPNeuralUCB will demonstrate measurably superior performance retention in adversarial environments relative to baseline neural bandit algorithms lacking specialized adversarial robustness mechanisms.\n",
    "\n",
    "**Bounded Degradation Hypothesis**\n",
    "Performance degradation under adversarial conditions will remain within acceptable operational limits, specifically maintaining performance within 85% of stochastic environment baselines.\n",
    "\n",
    "**Stability Hypothesis**\n",
    "Algorithm performance rankings will exhibit stability across varying adversarial attack intensities, indicating consistent robustness characteristics rather than scenario-dependent performance fluctuations.\n",
    "\n",
    "### Research Methodology\n",
    "\n",
    "The comparative analysis employs identical experimental conditions across both environments, enabling precise quantification of performance degradation attributable to adversarial targeting while controlling for environmental variables and maintaining statistical rigor in the evaluation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üîç PAPER 7 QUICK VALIDATION\n",
      "======================================================================\n",
      "üìä Paper7 Topology: Real AS (as20000101.txt)\n",
      "üìä Paper7 Paths: 15 paths from 5-shortest between 3 ISPs\n",
      "üìä Paper7 Contexts: 15 context vectors generated\n",
      "üìä Paper7 Rewards: Context-aware (mode=neg_hop)\n",
      "‚è±Ô∏è  get_physics_params_paper7() time: 3.6 ms\n",
      "‚úÖ Topology: 50 nodes, 141 edges\n",
      "‚úÖ Contexts: 15 paths\n",
      "‚úÖ Rewards: Enabled\n",
      "\n",
      "‚úì Paper 7 integration validated successfully\n",
      "======================================================================\n",
      "\n",
      "üöÄ Ready to run Paper 7 (QBGP) experiments!\n",
      "   Example: PHYSICS_MODELS = ['paper7']\n",
      "            ALLOCATORS = ['ThompsonSampling', 'DynamicUCB']\n",
      "\n",
      "======================================================================\n",
      "üîç PAPER 12 (QuARC) QUICK VALIDATION\n",
      "======================================================================\n",
      "Generated paper12 Waxman topology: 100 nodes, 355 edges, avg degree: 7.10\n",
      "üìä Paper12 Physics: Fusion (prob=0.9)\n",
      "‚úÖ Topology: 100 nodes, 355 edges\n",
      "‚úÖ Contexts: 4 paths\n",
      "‚úÖ Context features per path: (3,)\n",
      "‚úÖ Rewards: 4 reward lists\n",
      "   ‚Üí Path 0 rewards (first 3): ['0.3', '0.6', '0.8']\n",
      "   ‚Üí Total aggregate reward: 13.1\n",
      "   ‚Üí Average per-arm reward: 0.7\n",
      "‚úÖ Fusion probability: 0.9\n",
      "‚úÖ Entanglement probability: 0.6\n",
      "‚úÖ Epoch length: 500 timeslots\n",
      "‚úÖ Total simulation: 5000 timeslots\n",
      "\n",
      "‚úì Paper 12 (QuARC) integration validated successfully\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# PAPER 12 (QUART) HELPER FUNCTIONS\n",
    "# ============================================================================\n",
    "\n",
    "def generate_paper12_paths(topology, num_paths: int, seed: int):\n",
    "    \"\"\"\n",
    "    Generate random source-destination paths for Paper 12 (QuARC).\n",
    "    \n",
    "    Unlike Paper 7's ISP-based selection, Paper 12 uses random S-D pairs\n",
    "    to evaluate adaptive clustering behavior across diverse routing scenarios.\n",
    "    \n",
    "    Args:\n",
    "        topology: NetworkX graph (Waxman topology)\n",
    "        num_paths: Number of paths to generate (typically 4 for framework testing)\n",
    "        seed: Random seed\n",
    "        \n",
    "    Returns:\n",
    "        List of paths (each path is a list of nodes)\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    nodes = list(topology.nodes())\n",
    "    paths = []\n",
    "    attempts = 0\n",
    "    max_attempts = 10 * num_paths\n",
    "    \n",
    "    while len(paths) < num_paths and attempts < max_attempts:\n",
    "        attempts += 1\n",
    "        src, dst = rng.choice(nodes, 2, replace=False)\n",
    "        try:\n",
    "            path = nx.shortest_path(topology, src, dst)\n",
    "            if path not in paths:\n",
    "                paths.append(path)\n",
    "        except nx.NetworkXNoPath:\n",
    "            continue\n",
    "    \n",
    "    if len(paths) < num_paths:\n",
    "        raise RuntimeError(f\"Could not find {num_paths} valid paths in Waxman topology\")\n",
    "    \n",
    "    return paths\n",
    "\n",
    "\n",
    "def generate_paper12_contexts(paths, topology, fusion_prob: float = 0.9):\n",
    "    \"\"\"\n",
    "    Generate context vectors for Paper 12 (QuARC) paths.\n",
    "    \n",
    "    Context features match QuARC protocol state:\n",
    "    - hop_count: Number of quantum hops (links) in path\n",
    "    - normalized_avg_degree: Average node degree normalized by max degree\n",
    "    - fusion_prob: Quantum fusion gate success probability\n",
    "    \n",
    "    Args:\n",
    "        paths: List of paths (each path is a list of nodes)\n",
    "        topology: NetworkX graph\n",
    "        fusion_prob: Fusion gate success probability (q parameter)\n",
    "        \n",
    "    Returns:\n",
    "        List of context arrays (one per path), each with shape [1, 3]\n",
    "    \"\"\"\n",
    "    contexts = []\n",
    "    degrees = dict(topology.degree())\n",
    "    max_degree = max(degrees.values()) if degrees else 1.0\n",
    "    \n",
    "    for path in paths:\n",
    "        # Feature 1: Hop count (number of quantum links)\n",
    "        hop_count = float(len(path) - 1)\n",
    "        \n",
    "        # Feature 2: Average node degree (normalized)\n",
    "        path_degrees = [degrees[n] for n in path]\n",
    "        avg_degree = float(sum(path_degrees) / len(path_degrees)) if path_degrees else 0.0\n",
    "        normalized_avg_degree = avg_degree / max_degree if max_degree > 0 else 0.0\n",
    "        \n",
    "        # Feature 3: Fusion probability (constant per configuration)\n",
    "        fusion_prob_feature = float(fusion_prob)\n",
    "        \n",
    "        # Context vector: [hop_count, normalized_avg_degree, fusion_prob]\n",
    "        context_vector = np.array([hop_count, normalized_avg_degree, fusion_prob_feature], dtype=float)\n",
    "        contexts.append([context_vector])  # Wrap in list for framework compatibility\n",
    "    \n",
    "    return contexts\n",
    "\n",
    "\n",
    "def get_paper12_thresholds(n_nodes: int):\n",
    "    \"\"\"\n",
    "    Get merge/split thresholds for QuARC clustering (Paper 12).\n",
    "    \n",
    "    In Paper 12, thresholds are computed via interpolation based on network size.\n",
    "    This is a simplified version that returns basic thresholds.\n",
    "    \n",
    "    For full Paper 12 alignment, use get_thresholds(n) from quarc/thresholding.py\n",
    "    which computes dynamic thresholds via:\n",
    "        scale_thresholds(n, 16**2, merge_th_16x16_ent_passing, split_th_16x16_ent_passing)\n",
    "    \n",
    "    Args:\n",
    "        n_nodes: Number of nodes in network\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (merge_threshold_func, split_threshold_func)\n",
    "    \"\"\"\n",
    "    # Baseline thresholds from Paper 12 Table 2 / recreate_figs.py\n",
    "    # For n=100, merge_th ‚âà 0.65, split_th ‚âà 0.85 (approximate values)\n",
    "    \n",
    "    # Simplified linear interpolation for now\n",
    "    base_merge = 0.65\n",
    "    base_split = 0.85\n",
    "    \n",
    "    # Scale adjustment based on network size (larger networks = tighter thresholds)\n",
    "    size_factor = min(1.0, 100.0 / max(n_nodes, 1))\n",
    "    \n",
    "    merge_th = base_merge * size_factor\n",
    "    split_th = base_split * size_factor\n",
    "    \n",
    "    # Return functions for compatibility with protocol interface\n",
    "    merge_threshold_func = lambda: merge_th\n",
    "    split_threshold_func = lambda: split_th\n",
    "    \n",
    "    return merge_threshold_func, split_threshold_func\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# PAPER 7 HELPER FUNCTIONS\n",
    "# ============================================================================\n",
    "\n",
    "def generate_paper7_paths(topology, k: int, n_qisps: int, seed: int):\n",
    "    \"\"\"\n",
    "    Generate k-shortest paths between n_qisps quantum ISP nodes.\n",
    "    \n",
    "    Args:\n",
    "        topology: NetworkX graph (AS-level topology)\n",
    "        k: Number of shortest paths per ISP pair\n",
    "        n_qisps: Number of quantum ISP nodes\n",
    "        seed: Random seed\n",
    "        \n",
    "    Returns:\n",
    "        List of paths (each path is a list of nodes)\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    nodes = list(topology.nodes())\n",
    "\n",
    "    if len(nodes) < n_qisps:\n",
    "        raise ValueError(f\"Topology has {len(nodes)} nodes, need {n_qisps} for ISPs\")\n",
    "    \n",
    "    # Select ISP nodes (prefer high-degree nodes like real BGP)\n",
    "    degrees = dict(topology.degree())\n",
    "    sorted_nodes = sorted(nodes, key=lambda n: degrees[n], reverse=True)\n",
    "    isp_nodes = sorted_nodes[:n_qisps]  # Take top-degree nodes\n",
    "    \n",
    "    all_paths = []\n",
    "    for src, dst in itertools.combinations(isp_nodes, 2):\n",
    "        try:\n",
    "            path_generator = nx.shortest_simple_paths(topology, src, dst, weight='distance')\n",
    "            paths = list(itertools.islice(path_generator, k))\n",
    "            all_paths.extend(paths)\n",
    "        except nx.NetworkXNoPath:\n",
    "            continue\n",
    "    \n",
    "    if not all_paths:\n",
    "        raise RuntimeError(f\"Could not find any paths between {n_qisps} ISP nodes\")\n",
    "    \n",
    "    return all_paths\n",
    "\n",
    "\n",
    "def generate_paper7_contexts(paths, topology):\n",
    "    \"\"\"\n",
    "    Generate context vectors for each path: [hop_count, avg_degree, path_length].\n",
    "    \n",
    "    Args:\n",
    "        paths: List of paths (each path is a list of nodes)\n",
    "        topology: NetworkX graph\n",
    "        \n",
    "    Returns:\n",
    "        List of context arrays, one per path (shape: [1, 3])\n",
    "    \"\"\"\n",
    "    contexts = []\n",
    "    \n",
    "    for path in paths:\n",
    "        # Feature 1: Hop count (AS path length)\n",
    "        hop_count = len(path) - 1\n",
    "        \n",
    "        # Feature 2: Average node degree (bottleneck indicator)\n",
    "        degrees = [topology.degree(node) for node in path]\n",
    "        avg_degree = sum(degrees) / len(degrees) if degrees else 0.0\n",
    "\n",
    "        # Feature 3: Physical path length (sum of edge distances)\n",
    "        path_length = 0.0\n",
    "        for i in range(len(path) - 1):\n",
    "            edge_data = topology.get_edge_data(path[i], path[i+1])\n",
    "            path_length += edge_data.get('distance', 1.0)\n",
    "\n",
    "        # Context vector: [hop_count, avg_degree, path_length]\n",
    "        context_vector = np.array([hop_count, avg_degree, path_length], dtype=float)\n",
    "        contexts.append([context_vector])  # Wrap in list for framework compatibility\n",
    "    \n",
    "    return contexts\n",
    "\n",
    "\n",
    "def get_physics_params(\n",
    "    physics_model: str = \"default\",\n",
    "    current_frames: int = 4000,\n",
    "    base_seed: int = 42,\n",
    "    qubit_cap=None,\n",
    "    *,\n",
    "    topology: \"nx.Graph | None\" = None,\n",
    "    topology_model: str | None = None,\n",
    "    topology_path: str | Path | None = None,\n",
    "    topology_max_nodes: int | None = None,\n",
    "    topology_largest_cc_only: bool = True,\n",
    "    topology_relabel_to_int: bool = True,\n",
    "    synthetic_kind: str = \"barabasi_albert\",\n",
    "    synthetic_params: dict | None = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Unified physics parameter generator for all testbeds.\n",
    "    \n",
    "    Returns:\n",
    "        dict: {noise_model, fidelity_calculator, external_topology, \n",
    "               external_contexts, external_rewards}\n",
    "    \"\"\"\n",
    "    \n",
    "    # ============================================================================\n",
    "    # üéØ PAPER 7 (QBGP) - PRIMARY TESTBED\n",
    "    # ============================================================================\n",
    "    if physics_model == \"paper7\":\n",
    "        import time\n",
    "        start_time = time.time()\n",
    "        \n",
    "        paper7_cfg = FRAMEWORK_CONFIG['paper7']\n",
    "        node_num = paper7_cfg.get('max_nodes')\n",
    "\n",
    "        # --- Topology Generation ---\n",
    "        if topology is not None:\n",
    "            final_topology = topology\n",
    "            print(f\"üìä Paper7 Topology: User-provided ({len(topology.nodes())} nodes)\")\n",
    "        else:\n",
    "            # Determine if using synthetic or real AS data\n",
    "            if paper7_cfg.get('use_synthetic', False) or not paper7_cfg.get('topology_path'):\n",
    "                # Synthetic fallback\n",
    "                synth_params = synthetic_params or paper7_cfg.get('synthetic_params', {'n': 50, 'm': 3})\n",
    "                topo_gen = Paper7ASTopologyGenerator(\n",
    "                    edge_list_path=\"dummy_nonexistent.txt\",\n",
    "                    max_nodes=topology_max_nodes or node_num,\n",
    "                    seed=base_seed,\n",
    "                    synthetic_fallback=True,\n",
    "                    synthetic_kind=paper7_cfg.get('synthetic_kind', 'barabasi_albert'),\n",
    "                    synthetic_params=synth_params\n",
    "                )\n",
    "                print(f\"üìä Paper7 Topology: Synthetic ({paper7_cfg.get('synthetic_kind')}, n={synth_params.get('n', 50)})\")\n",
    "            else:\n",
    "                # Real AS topology\n",
    "                topo_gen = Paper7ASTopologyGenerator(\n",
    "                    edge_list_path=paper7_cfg['topology_path'],\n",
    "                    max_nodes=node_num,\n",
    "                    seed=base_seed,\n",
    "                    relabel_to_integers=paper7_cfg.get('relabel_to_int', True),\n",
    "                    largest_cc_only=paper7_cfg.get('largest_cc_only', True),\n",
    "                    synthetic_fallback=True\n",
    "                )\n",
    "                topo_path_short = paper7_cfg['topology_path'].split('/')[-1]\n",
    "                print(f\"üìä Paper7 Topology: Real AS ({topo_path_short})\")\n",
    "            \n",
    "            final_topology = topo_gen.generate()\n",
    "\n",
    "        # --- Path Generation ---\n",
    "        k = paper7_cfg[\"k\"]\n",
    "        n_qisps = paper7_cfg[\"n_qisps\"]\n",
    "        paths = generate_paper7_paths(final_topology, k, n_qisps, base_seed)\n",
    "        contexts = generate_paper7_contexts(paths, final_topology)\n",
    "        \n",
    "        elapsed_ms = (time.time() - start_time) * 1000\n",
    "        print(f\"üìä Paper7 Paths: {len(paths)} paths from {k}-shortest between {n_qisps} ISPs\")\n",
    "        print(f\"üìä Paper7 Contexts: {len(contexts)} context vectors generated\")\n",
    "\n",
    "        # --- Reward Function (Optional) ---\n",
    "        external_rewards = None\n",
    "        if paper7_cfg.get('use_context_rewards', False):\n",
    "            reward_mode = paper7_cfg.get('reward_mode', 'neg_hop')\n",
    "            reward_func = Paper7RewardFunction(mode=reward_mode)\n",
    "            external_rewards = []\n",
    "            for ctx_list in contexts:\n",
    "                path_rewards = [reward_func.compute(ctx) for ctx in ctx_list]\n",
    "                external_rewards.append(path_rewards)\n",
    "            print(f\"üìä Paper7 Rewards: Context-aware (mode={reward_mode})\")\n",
    "        else:\n",
    "            print(f\"üìä Paper7 Rewards: Using default framework rewards\")\n",
    "\n",
    "        print(f\"‚è±Ô∏è  get_physics_params_paper7() time: {elapsed_ms:.1f} ms\")\n",
    "        \n",
    "        return {\n",
    "            \"noise_model\": None,\n",
    "            \"fidelity_calculator\": None,\n",
    "            \"external_topology\": final_topology,\n",
    "            \"external_contexts\": contexts,\n",
    "            \"external_rewards\": external_rewards\n",
    "        }\n",
    "    \n",
    "    # ============================================================================\n",
    "    # PAPER 2 (Huang et al.)\n",
    "    # ============================================================================\n",
    "    elif physics_model == \"paper2\":\n",
    "        p2_config = FRAMEWORK_CONFIG[\"paper2\"]\n",
    "        topo_gen = Paper2TopologyGenerator(num_nodes=p2_config[\"num_nodes\"], seed=base_seed)\n",
    "        topo = topo_gen.generate()\n",
    "        \n",
    "        try:\n",
    "            path_generator = nx.shortest_simple_paths(\n",
    "                topo, p2_config[\"source_node\"], p2_config[\"dest_node\"], weight=\"distance\"\n",
    "            )\n",
    "            paths = list(itertools.islice(path_generator, p2_config[\"num_paths\"]))\n",
    "        except nx.NetworkXNoPath:\n",
    "            paths = [[p2_config[\"source_node\"], p2_config[\"dest_node\"]]] * p2_config[\"num_paths\"]\n",
    "        \n",
    "        # Stochastic noise model\n",
    "        noise_model = FiberLossNoiseModel(\n",
    "            topology=topo,\n",
    "            paths=paths,\n",
    "            p_init=p2_config.get(\"p_init\", 0.00001),\n",
    "            f_attenuation=p2_config.get(\"f_attenuation\", 0.05)\n",
    "        )\n",
    "        \n",
    "        # Fidelity calculator with optional memory decay\n",
    "        if p2_config.get('use_memory_decay', False):\n",
    "            memory_model = MemoryNoiseModel(\n",
    "                T2=p2_config.get(\"memory_T2\", 5000),\n",
    "                swap_delay_per_link=p2_config.get(\"swap_delay_per_link\", 100)\n",
    "            )\n",
    "            if p2_config.get(\"swap_mode\", \"sync\") == \"sync\":\n",
    "                memory_model = None\n",
    "        else:\n",
    "            memory_model = None\n",
    "        \n",
    "        fidelity_calc = FullPaper2FidelityCalculator(\n",
    "            gate_error_rate=p2_config.get(\"gate_error_rate\", 0.02) if p2_config.get('use_gate_error', False) else 0.0,\n",
    "            memory_model=memory_model\n",
    "        )\n",
    "        \n",
    "        print(f\"üìä Paper2 Physics: Fiber Loss + {'Memory Decay' if memory_model else 'No Memory'}\")\n",
    "        \n",
    "        return {\n",
    "            \"noise_model\": noise_model,\n",
    "            \"fidelity_calculator\": fidelity_calc,\n",
    "            \"external_topology\": topo,\n",
    "            \"external_contexts\": None,\n",
    "            \"external_rewards\": None\n",
    "        }\n",
    "\n",
    "    # ============================================================================\n",
    "    # PAPER 12 (Wang et al. - QuARC)\n",
    "    # ============================================================================\n",
    "    # ============================================================================\n",
    "    # PAPER 12 (Wang et al. - QuARC)\n",
    "    # ============================================================================\n",
    "    elif physics_model == 'paper12':\n",
    "        p12config = FRAMEWORK_CONFIG['paper12']\n",
    "        \n",
    "        # Get base Paper12 physics\n",
    "        physics_params = get_physics_params_paper12(p12config, seed=base_seed, qubit_cap=qubit_cap)\n",
    "        base_fidelity_calc = physics_params['fidelity_calculator']\n",
    "        \n",
    "        # Optional retry logic (only if config provides it)\n",
    "        retry_threshold = p12config.get('retry_threshold', None)\n",
    "        if retry_threshold is not None:\n",
    "            max_attempts = p12config.get('max_retry_attempts', 3)\n",
    "            decay_rate = p12config.get('retry_decay_rate', 0.95)\n",
    "            fidelity_calc = Paper12RetryFidelityCalculator(\n",
    "                base_calculator=base_fidelity_calc,\n",
    "                threshold=retry_threshold,\n",
    "                max_attempts=max_attempts,\n",
    "                decay_rate=decay_rate\n",
    "            )\n",
    "            physics_params['fidelity_calculator'] = fidelity_calc\n",
    "            \n",
    "            metadata = {\n",
    "                'paper': 'Wang2024Paper12',\n",
    "                'retry_enabled': True,\n",
    "                'retry_threshold': retry_threshold,\n",
    "                'max_attempts': max_attempts,\n",
    "                'decay_rate': decay_rate,\n",
    "            }\n",
    "            physics_params['metadata'] = metadata\n",
    "            print(f\"üìä Paper12 Physics: Fusion (prob={p12config['fusion_prob']}) + Retry Logic\")\n",
    "        else:\n",
    "            metadata = {\n",
    "                'paper': 'Wang2024Paper12',\n",
    "                'retry_enabled': False,\n",
    "            }\n",
    "            physics_params['metadata'] = metadata\n",
    "            print(f\"üìä Paper12 Physics: Fusion (prob={p12config['fusion_prob']})\")\n",
    "        \n",
    "        return physics_params\n",
    "    \n",
    "    # ============================================================================\n",
    "    # DEFAULT (No special physics)\n",
    "    # ============================================================================\n",
    "    else:\n",
    "        return {\n",
    "            \"noise_model\": None,\n",
    "            \"fidelity_calculator\": None,\n",
    "            \"external_topology\": topology,\n",
    "            \"external_contexts\": None,\n",
    "            \"external_rewards\": None\n",
    "        }\n",
    "\n",
    "\n",
    "def get_physics_params_paper12(config, seed, qubit_cap):\n",
    "    \"\"\"\n",
    "    Paper #12 (QuARC) physics adapter - CORRECTED VERSION.\n",
    "    \n",
    "    Uses Paper 12 standard parameters:\n",
    "    - E_p = 0.6 (entanglement probability)\n",
    "    - q = 0.9 (fusion success probability)\n",
    "    - k = 3 (split constant for Girvan-Newman)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Generate Waxman topology\n",
    "    topology = Paper12WaxmanTopologyGenerator().generate()\n",
    "    \n",
    "    # Generate 4 paths for framework testing\n",
    "    num_paths = 4\n",
    "    nodes = list(topology.nodes())\n",
    "    rng = np.random.default_rng(seed)\n",
    "    \n",
    "    paths = []\n",
    "    attempts = 0\n",
    "    max_attempts = 10 * num_paths\n",
    "    \n",
    "    while len(paths) < num_paths and attempts < max_attempts:\n",
    "        attempts += 1\n",
    "        src, dst = rng.choice(nodes, 2, replace=False)\n",
    "        try:\n",
    "            path = nx.shortest_path(topology, src, dst)\n",
    "            if path not in paths:\n",
    "                paths.append(path)\n",
    "        except nx.NetworkXNoPath:\n",
    "            continue\n",
    "    \n",
    "    if len(paths) < num_paths:\n",
    "        raise RuntimeError(f\"Could not find {num_paths} valid paths\")\n",
    "    \n",
    "    # ‚úÖ CORRECT Paper 12 parameters\n",
    "    fusion_prob = 0.9           # q from Paper 12\n",
    "    entanglement_prob = 0.6     # E_p from Paper 12\n",
    "    \n",
    "    noise_model = FusionNoiseModel(\n",
    "        topology=topology, \n",
    "        paths=paths, \n",
    "        fusion_prob=fusion_prob, \n",
    "        entanglement_prob=entanglement_prob\n",
    "    )\n",
    "    fidelity_calc = FusionFidelityCalculator()\n",
    "    \n",
    "    # ‚úÖ CORRECT: Derive arms from topology\n",
    "    external_contexts = []\n",
    "    external_rewards = []\n",
    "    degrees = dict(topology.degree())\n",
    "    max_degree = max(degrees.values()) if degrees else 1.0\n",
    "    \n",
    "    for path in paths:\n",
    "        # Get qubit capacity for this path\n",
    "        min_qubits = min(topology.nodes[node].get('qubits', 5) for node in path)\n",
    "        num_arms = min_qubits  # Or use k=3 for Paper 12 standard\n",
    "        \n",
    "        # Generate contexts\n",
    "        hop_count = len(path) - 1\n",
    "        path_degrees = [degrees[n] for n in path]\n",
    "        avg_degree = float(sum(path_degrees) / len(path_degrees))\n",
    "        f2_deg_norm = avg_degree / max_degree if max_degree > 0 else 0.0\n",
    "        \n",
    "        ctx = np.full((num_arms, 3), \n",
    "                     [float(hop_count), f2_deg_norm, fusion_prob], \n",
    "                     dtype=float)\n",
    "        external_contexts.append(ctx)\n",
    "        \n",
    "        # ‚úÖ CORRECT: Use actual entanglement physics (no Beta sampling)\n",
    "        path_rewards = []\n",
    "        for q_alloc in range(1, num_arms + 1):\n",
    "            # Per-link success probability with q_alloc qubits\n",
    "            p_link = 1 - (1 - entanglement_prob) ** q_alloc\n",
    "            # End-to-end success (product over hops √ó fusion)\n",
    "            p_path = (p_link ** hop_count) * fusion_prob\n",
    "            # No √ó100 scaling - use actual probability\n",
    "            path_rewards.append(float(p_path))\n",
    "        \n",
    "        external_rewards.append(path_rewards)\n",
    "    \n",
    "    return {\n",
    "        \"external_topology\": topology,\n",
    "        \"external_contexts\": external_contexts,\n",
    "        \"external_rewards\": external_rewards,\n",
    "        \"noise_model\": noise_model,\n",
    "        \"fidelity_calculator\": fidelity_calc,\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "def force_release_resources(evaluator=None, verbose=True):\n",
    "    \"\"\"Force release of ALL resources that could block. Call AFTER each allocator completes.\"\"\"\n",
    "    cleanup_log = []\n",
    "\n",
    "    # 1. Stop logging and close file handles\n",
    "    if evaluator is not None:\n",
    "        try:\n",
    "            if hasattr(evaluator, 'configs') and hasattr(evaluator.configs, 'backup_mgr'):\n",
    "                backup_mgr = evaluator.configs.backup_mgr\n",
    "                if hasattr(backup_mgr, 'stop_logging_redirect'):\n",
    "                    backup_mgr.stop_logging_redirect()\n",
    "                if hasattr(backup_mgr, '_log_file'):\n",
    "                    try:\n",
    "                        backup_mgr._log_file.close()\n",
    "                    except:\n",
    "                        pass\n",
    "                if hasattr(backup_mgr, 'backup_registry'):\n",
    "                    backup_mgr.backup_registry.clear()\n",
    "            cleanup_log.append(\"‚úÖ Backup manager cleaned\")\n",
    "        except Exception as e:\n",
    "            cleanup_log.append(f\"‚ö†Ô∏è Backup cleanup: {e}\")\n",
    "\n",
    "    # 2. Clear environment graphs\n",
    "    if evaluator is not None:\n",
    "        try:\n",
    "            if hasattr(evaluator, 'configs') and hasattr(evaluator.configs, 'environment'):\n",
    "                env = evaluator.configs.environment\n",
    "                if hasattr(env, 'topology') and hasattr(env.topology, 'clear'):\n",
    "                    env.topology.clear()\n",
    "                    del env.topology\n",
    "                if hasattr(env, 'paths'):\n",
    "                    env.paths = []\n",
    "            cleanup_log.append(\"‚úÖ Environment graphs cleared\")\n",
    "        except Exception as e:\n",
    "            cleanup_log.append(f\"‚ö†Ô∏è Environment cleanup: {e}\")\n",
    "\n",
    "    # 3. Break circular references\n",
    "    if evaluator is not None:\n",
    "        try:\n",
    "            if hasattr(evaluator, 'configs'):\n",
    "                if hasattr(evaluator.configs, 'backup_mgr'):\n",
    "                    evaluator.configs.backup_mgr = None\n",
    "                if hasattr(evaluator.configs, 'environment'):\n",
    "                    evaluator.configs.environment = None\n",
    "                evaluator.configs = None\n",
    "            cleanup_log.append(\"‚úÖ Circular references broken\")\n",
    "        except Exception as e:\n",
    "            cleanup_log.append(f\"‚ö†Ô∏è Reference cleanup: {e}\")\n",
    "\n",
    "    # 4. Clear model registries\n",
    "    try:\n",
    "        import sys\n",
    "        for mod_name in list(sys.modules.keys()):\n",
    "            if 'bandit' in mod_name.lower() or 'neural' in mod_name.lower():\n",
    "                mod = sys.modules[mod_name]\n",
    "                if hasattr(mod, '_model_registry'):\n",
    "                    mod._model_registry.clear()\n",
    "                if hasattr(mod, '_global_models'):\n",
    "                    mod._global_models.clear()\n",
    "        cleanup_log.append(\"‚úÖ Model registries cleared\")\n",
    "    except Exception as e:\n",
    "        cleanup_log.append(f\"‚ö†Ô∏è Registry cleanup: {e}\")\n",
    "\n",
    "    # 5. Torch cleanup\n",
    "    try:\n",
    "        import torch\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "            torch.cuda.synchronize()\n",
    "        cleanup_log.append(\"‚úÖ Torch CUDA cleared\")\n",
    "    except Exception as e:\n",
    "        cleanup_log.append(f\"‚ö†Ô∏è Torch cleanup: {e}\")\n",
    "\n",
    "    # 6. Garbage collection\n",
    "    collected = [gc.collect() for _ in range(3)]\n",
    "    cleanup_log.append(f\"‚úÖ GC collected: {sum(collected)} objects\")\n",
    "\n",
    "    # 7. Close file descriptors\n",
    "    try:\n",
    "        import psutil\n",
    "        process = psutil.Process()\n",
    "        for f in process.open_files():\n",
    "            if any(ext in f.path for ext in ['.pkl', '.log', '.csv']):\n",
    "                try:\n",
    "                    os.close(f.fd)\n",
    "                except:\n",
    "                    pass\n",
    "        cleanup_log.append(\"‚úÖ File descriptors closed\")\n",
    "    except Exception as e:\n",
    "        cleanup_log.append(f\"‚ö†Ô∏è FD cleanup: {e}\")\n",
    "\n",
    "    # 8. Delete evaluator and final collection\n",
    "    if evaluator is not None:\n",
    "        del evaluator\n",
    "    gc.collect(2)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"üßπ FORCED RESOURCE RELEASE\")\n",
    "        print(\"=\"*70)\n",
    "        for log in cleanup_log:\n",
    "            print(log)\n",
    "        print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# VALIDATION: Quick Paper 7 Sanity Check\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üîç PAPER 7 QUICK VALIDATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "try:\n",
    "    # Test Paper 7 physics generation\n",
    "    test_params = get_physics_params(\n",
    "        physics_model='paper7',\n",
    "        base_seed=42\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ Topology: {len(test_params['external_topology'].nodes())} nodes, \"\n",
    "          f\"{len(test_params['external_topology'].edges())} edges\")\n",
    "    print(f\"‚úÖ Contexts: {len(test_params['external_contexts'])} paths\")\n",
    "    print(f\"‚úÖ Rewards: {'Enabled' if test_params['external_rewards'] else 'Disabled'}\")\n",
    "    print(\"\\n‚úì Paper 7 integration validated successfully\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Validation failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "print(\"üöÄ Ready to run Paper 7 (QBGP) experiments!\")\n",
    "print(\"   Example: PHYSICS_MODELS = ['paper7']\")\n",
    "print(\"            ALLOCATORS = ['ThompsonSampling', 'DynamicUCB']\")\n",
    "\n",
    "# ============================================================================\n",
    "# VALIDATION: Quick Paper 12 Sanity Check\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üîç PAPER 12 (QuARC) QUICK VALIDATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "try:\n",
    "    # Test Paper 12 physics generation\n",
    "    test_params_p12 = get_physics_params(\n",
    "        physics_model='paper12',\n",
    "        base_seed=42\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ Topology: {len(test_params_p12['external_topology'].nodes())} nodes, \"\n",
    "          f\"{len(test_params_p12['external_topology'].edges())} edges\")\n",
    "    print(f\"‚úÖ Contexts: {len(test_params_p12['external_contexts'])} paths\")\n",
    "    print(f\"‚úÖ Context features per path: {test_params_p12['external_contexts'][0][0].shape}\")\n",
    "    \n",
    "    # Print actual reward values\n",
    "    print(f\"‚úÖ Rewards: {len(test_params_p12['external_rewards'])} reward lists\")\n",
    "    total_rew = sum(sum(r) for r in test_params_p12['external_rewards'])\n",
    "    avg_rew = total_rew / sum(len(r) for r in test_params_p12['external_rewards'])\n",
    "    print(f\"   ‚Üí Path 0 rewards (first 3): {[f'{r:.1f}' for r in test_params_p12['external_rewards'][0][:3]]}\")\n",
    "    print(f\"   ‚Üí Total aggregate reward: {total_rew:.1f}\")\n",
    "    print(f\"   ‚Üí Average per-arm reward: {avg_rew:.1f}\")\n",
    "    \n",
    "    print(f\"‚úÖ Fusion probability: {FRAMEWORK_CONFIG['paper12']['fusion_prob']}\")\n",
    "    print(f\"‚úÖ Entanglement probability: {FRAMEWORK_CONFIG['paper12']['entanglement_prob']}\")\n",
    "    print(f\"‚úÖ Epoch length: {FRAMEWORK_CONFIG['paper12']['epoch_length']} timeslots\")\n",
    "    print(f\"‚úÖ Total simulation: {FRAMEWORK_CONFIG['paper12']['total_timeslots']} timeslots\")\n",
    "    print(\"\\n‚úì Paper 12 (QuARC) integration validated successfully\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Paper 12 validation failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "PAPER #12 (QuARC) - DEFAULT ALLOCATOR\n",
      "======================================================================\n",
      "‚úÖ Testing QuARC with 1500 timeslots\n",
      "‚úÖ Expected reconfigurations: 3\n",
      "‚úÖ Statistical runs: 5\n",
      "\n",
      "======================================================================\n",
      "PAPER 12 ALLOCATOR EVALUATION\n",
      "======================================================================\n",
      "Allocators:                 ['Default']\n",
      "Physics Models:             ['paper12']\n",
      "Attack Scenarios:           ['stochastic']\n",
      "Scales:                     [1, 1.5, 2]\n",
      "Runs per Scale:             [5]\n",
      "Total Frames:               1500\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "RUNNING: Default on Paper 12 (QuARC)\n",
      "======================================================================\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Preparing: Default at scale 1\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üîß Generating physics parameters for model: paper12\n",
      "\n",
      "===================== GET LOCAL REGISTRY =====================\n",
      "‚Üí Skipping local cache (force=True or file missing)\n",
      "\n",
      "===================== BUILD LOCAL REGISTRY =====================\n",
      "\n",
      "================================================================================\n",
      "üîç SCANNING LOCAL FILES\n",
      "================================================================================\n",
      "Parameters: load_to_drive=False, force=False\n",
      "\n",
      "üìÇ Checking DRIVE mode: /content/drive/Shareddrives/ai_quantum_computing/quantum_data_lake\n",
      "   ‚ö†Ô∏è  Path does not exist, skipping\n",
      "\n",
      "üìÇ Checking LOCAL mode: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config\n",
      "   ‚úÖ Path exists, starting walk...\n",
      "   üö∂ Walking directory tree: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config\n",
      "\n",
      "   üìÅ Directory: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201\n",
      "      Relative: framework_state/day_20260201\n",
      "      Component: framework_state\n",
      "      Date: day_20260201\n",
      "      üìÑ Processing 2512 files in framework_state/day_20260201\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "      üìä framework_state/day_20260201: 2485/2512 files processed\n",
      "      üìä framework_state/day_20260201: 0/2512 files skipped\n",
      "      üìä framework_state/day_20260201: 27/2512 files conflicted\n",
      "\n",
      "   üìÅ Directory: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/model_state/day_20260201\n",
      "      Relative: model_state/day_20260201\n",
      "      Component: model_state\n",
      "      Date: day_20260201\n",
      "      üìÑ Processing 8842 files in model_state/day_20260201\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "      üìä model_state/day_20260201: 8842/8842 files processed\n",
      "      üìä model_state/day_20260201: 0/8842 files skipped\n",
      "      üìä model_state/day_20260201: 0/8842 files conflicted\n",
      "\n",
      "   üìä Processed 2 directories\n",
      "\n",
      "================================================================================\n",
      "üì¶ BUILDING FINAL REGISTRY\n",
      "================================================================================\n",
      "Components found: ['framework_state', 'model_state']\n",
      "  ‚Ä¢ framework_state: 2485 files\n",
      "  ‚Ä¢ model_state: 8842 files\n",
      "\n",
      "‚úÖ SCAN COMPLETE\n",
      "Modes scanned: 1\n",
      "Total files in registry: 11327\n",
      "================================================================================\n",
      "\n",
      "\t‚Üí Filesystem scan found 11327 files\n",
      "\n",
      "===================== GET DRIVE REGISTRY =====================\n",
      "===================== REGISTRY BUILD COMPLETE =====================\n",
      "\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "\tüì¶ LocalBackupManager Registry Saved Locally in LOCAL\n",
      "BUILDING REGISTRY WITH 0 EXPECTED COMPONENTS KEYS\n",
      "\n",
      "===================== GET LOCAL REGISTRY =====================\n",
      "‚Üí Skipping local cache (force=True or file missing)\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "\tüì¶ LocalBackupManager Registry Saved Locally in LOCAL\n",
      "\n",
      "======================================================================\n",
      "üéØ AllocatorRunner initialized: Default\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "üöÄ STARTING ALLOCATOR: Default\n",
      "======================================================================\n",
      "\n",
      "üìä Physics Model: paper12\n",
      "\n",
      "üìã Allocator Config:\n",
      "   Type: Default\n",
      "   Testbed: paper12\n",
      "   Paths: 4\n",
      "   Total Qubits: 100\n",
      "   Min per route: 3\n",
      "   Seed: 42\n",
      "‚úÖ Allocator created: (25, 25, 25, 25)\n",
      "‚úì Allocator: QubitAllocator (4 paths)\n",
      "   Initial allocation: (25, 25, 25, 25)\n",
      "Generated paper12 Waxman topology: 100 nodes, 426 edges, avg degree: 8.52\n",
      "üìä Paper12 Physics: Fusion (prob=0.9)\n",
      "\n",
      "======================================================================\n",
      "RUN 1 | Scale: 1 | Exp: 5\n",
      "======================================================================\n",
      "üîÑ Default Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "\n",
      "\tüîÑ Resume: MultiRunEvaluator\n",
      "\n",
      "=====================================================\n",
      "üîç GENERATING EXPECTED KEYS FROM EVALUATOR\n",
      "=====================================================\n",
      "  ‚Ä¢ Evaluator filename: MultiRunEvaluator_1500-Default_All_All-1500_500_5_S1T_paper12.pkl\n",
      "\n",
      "üß© PARSED COMPONENTS\n",
      "  ‚Ä¢ cap_id:        1500\n",
      "  ‚Ä¢ allocator_id:  Default\n",
      "  ‚Ä¢ env_id:        All\n",
      "  ‚Ä¢ attack_id:     All\n",
      "  ‚Ä¢ base_frames:   1500\n",
      "  ‚Ä¢ frame_step:    500\n",
      "  ‚Ä¢ runs_id:       5\n",
      "\n",
      "=====================================================\n",
      "üß™ GENERATING KEYS FOR EACH RUN\n",
      "=====================================================\n",
      "\n",
      "--- Run 1/5 -----------------------\n",
      "\n",
      "=====================================================\n",
      "üì¶ FINAL EXPECTED KEYS\n",
      "=====================================================\n",
      "  ‚Ä¢ Runner keys: 11\n",
      "\n",
      "  ‚Ä¢ Model keys: 50\n",
      "\n",
      "--- Run 2/5 -----------------------\n",
      "\n",
      "=====================================================\n",
      "üì¶ FINAL EXPECTED KEYS\n",
      "=====================================================\n",
      "  ‚Ä¢ Runner keys: 21\n",
      "\n",
      "  ‚Ä¢ Model keys: 100\n",
      "\n",
      "--- Run 3/5 -----------------------\n",
      "\n",
      "=====================================================\n",
      "üì¶ FINAL EXPECTED KEYS\n",
      "=====================================================\n",
      "  ‚Ä¢ Runner keys: 31\n",
      "\n",
      "  ‚Ä¢ Model keys: 150\n",
      "\n",
      "--- Run 4/5 -----------------------\n",
      "\n",
      "=====================================================\n",
      "üì¶ FINAL EXPECTED KEYS\n",
      "=====================================================\n",
      "  ‚Ä¢ Runner keys: 41\n",
      "\n",
      "  ‚Ä¢ Model keys: 200\n",
      "\n",
      "--- Run 5/5 -----------------------\n",
      "\n",
      "=====================================================\n",
      "üì¶ FINAL EXPECTED KEYS\n",
      "=====================================================\n",
      "  ‚Ä¢ Runner keys: 51\n",
      "\n",
      "  ‚Ä¢ Model keys: 250\n",
      "\n",
      "EXPECTED KEY GENERATION COMPLETE\n",
      "\n",
      "RESTORING FROM DRIVE 1\n",
      "RESTORING FROM DRIVE 2\n",
      "\t‚ö†Ô∏è Registry exists ‚Üí aborting restore\n",
      "\t‚úì MultiRunEvaluator Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/MultiRunEvaluator_1500-Default_All_All-1500_500_5_S1T_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/MultiRunEvaluator_1500-Default_All_All-1500_500_5_S1T_paper12.pkl\n",
      "\t   File exists: True, size: 57556294\n",
      "EQUAL METHOD\n",
      "Multi-Run Evaluator Initialized\n",
      "Environment Type: None\n",
      "Frame Range: 1500 -> 3500 (step: 500)\n",
      "quantum_exps-Default(paper12)_alloc-all_envs-5_attacks-1500_500-5_runs-S1T\n",
      "[Logging Redirect Initialized]\n",
      "Log File: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/quantum_logs/quantum_exps-Default(paper12)_alloc-all_envs-5_attacks-1500_500-5_runs-S1T_20260201_log.txt\n",
      "‚öô Running evaluation...\n",
      "======================================================================\n",
      "SCENARIOS MODEL EVALUATION\n",
      "======================================================================\n",
      "Testing algorithm performance against:\n",
      "\t‚Ä¢ Stochastic:  \tNatural quantum decoherence and network failures\n",
      "\t‚Ä¢ Baseline:    \tOptimal conditions for validation\n",
      "======================================================================\n",
      "Models to Test:             \tOracle, GNeuralUCB, EXPNeuralUCB, CPursuitNeuralUCB, iCPursuitNeuralUCB\n",
      "Experiments per Scenario:   \t5\n",
      "======================================================================\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: BASELINE (OPTIMAL CONDITIONS)\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: NONE\n",
      "Category: Baseline (No Attacks)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 1500 frames  <>  SCALED-CAPACITY: 1500 frames (CAPACITY:1500 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=0 ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for NONE Exp 1: (25, 25, 25, 25)\n",
      "üîÑ Default Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 1: Env:Baseline (None), Attack:No, Rate:0.0, Frames:1500, QubitAlloc=Default, SC:1500 (Scale=1 x Cap=1500), Seed: 18010\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_1\n",
      "\t‚úì QuantumExperimentRunner_1 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_1500-Default_Baseline (None)_No-1500_1_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_1500-Default_Baseline (None)_No-1500_1_paper12.pkl\n",
      "\t   File exists: True, size: 709581\n",
      "‚è© SKIPPING EXPERIMENT 1: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 1 GNEURALUCB          : Reward=0582.53, Efficiency=044.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=1500, Threshold=0.582]\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=0592.44, Efficiency=044.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=1500, Threshold=0.628]\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=0529.36, Efficiency=040.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=1500, Threshold=0.634]\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=0575.36, Efficiency=043.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=1500, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP1 Winner:EXPNeuralUCB        (Gap:055.2%) [Env:Baseline (None), Attack:No X Rate:0.25, Frames:1500, SCapacity=1500, Alloc=Default]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 2000 frames  <>  SCALED-CAPACITY: 2000 frames (CAPACITY:2000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=1 ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for NONE Exp 2: (25, 25, 25, 25)\n",
      "üîÑ Default Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 2: Env:Baseline (None), Attack:No, Rate:0.0, Frames:2000, QubitAlloc=Default, SC:2000 (Scale=1 x Cap=2000), Seed: 20078\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_2\n",
      "\t‚úì QuantumExperimentRunner_2 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_2000-Default_Baseline (None)_No-2000_2_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_2000-Default_Baseline (None)_No-2000_2_paper12.pkl\n",
      "\t   File exists: True, size: 930083\n",
      "‚è© SKIPPING EXPERIMENT 2: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 2 GNEURALUCB          : Reward=0808.21, Efficiency=045.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=2000, Threshold=0.582]\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=0757.57, Efficiency=043.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=2000, Threshold=0.628]\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=0792.12, Efficiency=044.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=2000, Threshold=0.634]\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=0779.04, Efficiency=044.2% [Retries=3, Failed=0, < Threshold=3, SCapacity=2000, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP2 Winner:GNeuralUCB          (Gap:054.2%) [Env:Baseline (None), Attack:No X Rate:0.25, Frames:2000, SCapacity=2000, Alloc=Default]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 2500 frames  <>  SCALED-CAPACITY: 2500 frames (CAPACITY:2500 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=2 ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for NONE Exp 3: (25, 25, 25, 25)\n",
      "üîÑ Default Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 3: Env:Baseline (None), Attack:No, Rate:0.0, Frames:2500, QubitAlloc=Default, SC:2500 (Scale=1 x Cap=2500), Seed: 14623\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_3\n",
      "\t‚úì QuantumExperimentRunner_3 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_2500-Default_Baseline (None)_No-2500_3_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_2500-Default_Baseline (None)_No-2500_3_paper12.pkl\n",
      "\t   File exists: True, size: 1152142\n",
      "‚è© SKIPPING EXPERIMENT 3: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 3 GNEURALUCB          : Reward=1042.30, Efficiency=047.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=2500, Threshold=0.582]\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=1020.38, Efficiency=046.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=2500, Threshold=0.628]\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=0981.14, Efficiency=044.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=2500, Threshold=0.634]\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=1029.54, Efficiency=046.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=2500, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP3 Winner:GNeuralUCB          (Gap:052.7%) [Env:Baseline (None), Attack:No X Rate:0.25, Frames:2500, SCapacity=2500, Alloc=Default]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 3000 frames  <>  SCALED-CAPACITY: 3000 frames (CAPACITY:3000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=3 ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for NONE Exp 4: (25, 25, 25, 25)\n",
      "üîÑ Default Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 4: Env:Baseline (None), Attack:No, Rate:0.0, Frames:3000, QubitAlloc=Default, SC:3000 (Scale=1 x Cap=3000), Seed: 20090\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_4\n",
      "\t‚úì QuantumExperimentRunner_4 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_3000-Default_Baseline (None)_No-3000_4_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_3000-Default_Baseline (None)_No-3000_4_paper12.pkl\n",
      "\t   File exists: True, size: 1374169\n",
      "‚è© SKIPPING EXPERIMENT 4: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 4 GNEURALUCB          : Reward=1167.24, Efficiency=044.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.582]\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=1134.30, Efficiency=042.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.628]\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=1146.58, Efficiency=043.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.634]\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=1210.72, Efficiency=045.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP4 Winner:iCPursuitNeuralUCB  (Gap:054.2%) [Env:Baseline (None), Attack:No X Rate:0.25, Frames:3000, SCapacity=3000, Alloc=Default]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 3500 frames  <>  SCALED-CAPACITY: 3500 frames (CAPACITY:3500 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=4 ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for NONE Exp 5: (25, 25, 25, 25)\n",
      "üîÑ Default Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 5: Env:Baseline (None), Attack:No, Rate:0.0, Frames:3500, QubitAlloc=Default, SC:3500 (Scale=1 x Cap=3500), Seed: 12926\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_5\n",
      "\t‚úì QuantumExperimentRunner_5 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_3500-Default_Baseline (None)_No-3500_5_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_3500-Default_Baseline (None)_No-3500_5_paper12.pkl\n",
      "\t   File exists: True, size: 1596237\n",
      "‚è© SKIPPING EXPERIMENT 5: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 5 GNEURALUCB          : Reward=1445.54, Efficiency=046.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=3500, Threshold=0.582]\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=1422.33, Efficiency=046.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=3500, Threshold=0.628]\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=1371.04, Efficiency=044.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=3500, Threshold=0.634]\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=1435.94, Efficiency=046.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=3500, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP5 Winner:GNeuralUCB          (Gap:053.2%) [Env:Baseline (None), Attack:No X Rate:0.25, Frames:3500, SCapacity=3500, Alloc=Default]\n",
      "\n",
      "Total experiment time: 030.1s\n",
      "Experiments completed for none\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: STOCHASTIC RANDOM FAILURES\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: STOCHASTIC\n",
      "Category: Stochastic (Natural Random Failures)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 1500 frames  <>  SCALED-CAPACITY: 1500 frames (CAPACITY:1500 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=0 ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 1: (25, 25, 25, 25)\n",
      "üîÑ Default Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 1: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:1500, QubitAlloc=Default, SC:1500 (Scale=1 x Cap=1500), Seed: 20197\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_1\n",
      "\t‚úì QuantumExperimentRunner_1 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_1500-Default_Stochastic_Random-1500_1_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_1500-Default_Stochastic_Random-1500_1_paper12.pkl\n",
      "\t   File exists: True, size: 708051\n",
      "‚è© SKIPPING EXPERIMENT 1: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 1 GNEURALUCB          : Reward=0557.35, Efficiency=042.2% [Retries=3, Failed=0, < Threshold=3, SCapacity=1500, Threshold=0.582]\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=0554.68, Efficiency=042.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=1500, Threshold=0.628]\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=0548.20, Efficiency=041.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=1500, Threshold=0.634]\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=0561.75, Efficiency=042.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=1500, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP1 Winner:iCPursuitNeuralUCB  (Gap:057.5%) [Env:Stochastic, Attack:Random X Rate:0.25, Frames:1500, SCapacity=1500, Alloc=Default]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 2000 frames  <>  SCALED-CAPACITY: 2000 frames (CAPACITY:2000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=1 ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 2: (25, 25, 25, 25)\n",
      "üîÑ Default Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 2: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:2000, QubitAlloc=Default, SC:2000 (Scale=1 x Cap=2000), Seed: 17474\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_2\n",
      "\t‚úì QuantumExperimentRunner_2 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_2000-Default_Stochastic_Random-2000_2_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_2000-Default_Stochastic_Random-2000_2_paper12.pkl\n",
      "\t   File exists: True, size: 930087\n",
      "‚è© SKIPPING EXPERIMENT 2: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 2 GNEURALUCB          : Reward=0710.87, Efficiency=040.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=2000, Threshold=0.582]\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=0772.03, Efficiency=043.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=2000, Threshold=0.628]\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=0718.13, Efficiency=040.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=2000, Threshold=0.634]\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=0719.20, Efficiency=040.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=2000, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP2 Winner:EXPNeuralUCB        (Gap:056.2%) [Env:Stochastic, Attack:Random X Rate:0.25, Frames:2000, SCapacity=2000, Alloc=Default]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 2500 frames  <>  SCALED-CAPACITY: 2500 frames (CAPACITY:2500 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=2 ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 3: (25, 25, 25, 25)\n",
      "üîÑ Default Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 3: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:2500, QubitAlloc=Default, SC:2500 (Scale=1 x Cap=2500), Seed: 15795\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_3\n",
      "\t‚úì QuantumExperimentRunner_3 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_2500-Default_Stochastic_Random-2500_3_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_2500-Default_Stochastic_Random-2500_3_paper12.pkl\n",
      "\t   File exists: True, size: 1152146\n",
      "‚è© SKIPPING EXPERIMENT 3: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 3 GNEURALUCB          : Reward=0910.57, Efficiency=041.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=2500, Threshold=0.582]\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=1038.24, Efficiency=047.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=2500, Threshold=0.628]\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=0946.94, Efficiency=043.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=2500, Threshold=0.634]\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=0903.32, Efficiency=041.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=2500, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP3 Winner:EXPNeuralUCB        (Gap:052.9%) [Env:Stochastic, Attack:Random X Rate:0.25, Frames:2500, SCapacity=2500, Alloc=Default]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 3000 frames  <>  SCALED-CAPACITY: 3000 frames (CAPACITY:3000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=3 ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 4: (25, 25, 25, 25)\n",
      "üîÑ Default Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 4: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:3000, QubitAlloc=Default, SC:3000 (Scale=1 x Cap=3000), Seed: 17031\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_4\n",
      "\t‚úì QuantumExperimentRunner_4 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_3000-Default_Stochastic_Random-3000_4_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_3000-Default_Stochastic_Random-3000_4_paper12.pkl\n",
      "\t   File exists: True, size: 1374173\n",
      "‚è© SKIPPING EXPERIMENT 4: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 4 GNEURALUCB          : Reward=1128.24, Efficiency=042.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.582]\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=1044.73, Efficiency=039.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.628]\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=1099.85, Efficiency=041.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.634]\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=1149.96, Efficiency=043.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP4 Winner:iCPursuitNeuralUCB  (Gap:056.5%) [Env:Stochastic, Attack:Random X Rate:0.25, Frames:3000, SCapacity=3000, Alloc=Default]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 3500 frames  <>  SCALED-CAPACITY: 3500 frames (CAPACITY:3500 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=4 ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 5: (25, 25, 25, 25)\n",
      "üîÑ Default Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 5: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:3500, QubitAlloc=Default, SC:3500 (Scale=1 x Cap=3500), Seed: 21490\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_5\n",
      "\t‚úì QuantumExperimentRunner_5 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_3500-Default_Stochastic_Random-3500_5_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_3500-Default_Stochastic_Random-3500_5_paper12.pkl\n",
      "\t   File exists: True, size: 1596241\n",
      "‚è© SKIPPING EXPERIMENT 5: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 5 GNEURALUCB          : Reward=1278.12, Efficiency=041.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=3500, Threshold=0.582]\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=1362.89, Efficiency=044.2% [Retries=3, Failed=0, < Threshold=3, SCapacity=3500, Threshold=0.628]\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=1334.30, Efficiency=043.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=3500, Threshold=0.634]\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=1289.64, Efficiency=041.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=3500, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP5 Winner:EXPNeuralUCB        (Gap:055.8%) [Env:Stochastic, Attack:Random X Rate:0.25, Frames:3500, SCapacity=3500, Alloc=Default]\n",
      "\n",
      "Total experiment time: 032.0s\n",
      "Experiments completed for stochastic\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: MARKOV ADVERSARIAL ATTACK\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: MARKOV\n",
      "Category: Structured (Markov Chain Based)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 1500 frames  <>  SCALED-CAPACITY: 1500 frames (CAPACITY:1500 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=0 ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for MARKOV Exp 1: (25, 25, 25, 25)\n",
      "üîÑ Default Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 1: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:1500, QubitAlloc=Default, SC:1500 (Scale=1 x Cap=1500), Seed: 20262\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_1\n",
      "\t‚úì QuantumExperimentRunner_1 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_1500-Default_Adversarial_Markov-1500_1_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_1500-Default_Adversarial_Markov-1500_1_paper12.pkl\n",
      "\t   File exists: True, size: 708049\n",
      "‚è© SKIPPING EXPERIMENT 1: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 1 GNEURALUCB          : Reward=0280.07, Efficiency=022.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=1500, Threshold=0.582]\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=0274.23, Efficiency=022.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=1500, Threshold=0.628]\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=0276.72, Efficiency=022.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=1500, Threshold=0.634]\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=0293.26, Efficiency=023.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=1500, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP1 Winner:iCPursuitNeuralUCB  (Gap:076.1%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:1500, SCapacity=1500, Alloc=Default]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 2000 frames  <>  SCALED-CAPACITY: 2000 frames (CAPACITY:2000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=1 ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for MARKOV Exp 2: (25, 25, 25, 25)\n",
      "üîÑ Default Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 2: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:2000, QubitAlloc=Default, SC:2000 (Scale=1 x Cap=2000), Seed: 15238\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_2\n",
      "\t‚úì QuantumExperimentRunner_2 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_2000-Default_Adversarial_Markov-2000_2_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_2000-Default_Adversarial_Markov-2000_2_paper12.pkl\n",
      "\t   File exists: True, size: 930085\n",
      "‚è© SKIPPING EXPERIMENT 2: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 2 GNEURALUCB          : Reward=0417.91, Efficiency=025.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=2000, Threshold=0.582]\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=0358.50, Efficiency=021.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=2000, Threshold=0.628]\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=0410.63, Efficiency=024.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=2000, Threshold=0.634]\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=0441.04, Efficiency=026.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=2000, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP2 Winner:iCPursuitNeuralUCB  (Gap:073.3%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:2000, SCapacity=2000, Alloc=Default]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 2500 frames  <>  SCALED-CAPACITY: 2500 frames (CAPACITY:2500 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=2 ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for MARKOV Exp 3: (25, 25, 25, 25)\n",
      "üîÑ Default Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 3: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:2500, QubitAlloc=Default, SC:2500 (Scale=1 x Cap=2500), Seed: 15202\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_3\n",
      "\t‚úì QuantumExperimentRunner_3 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_2500-Default_Adversarial_Markov-2500_3_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_2500-Default_Adversarial_Markov-2500_3_paper12.pkl\n",
      "\t   File exists: True, size: 1152144\n",
      "‚è© SKIPPING EXPERIMENT 3: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 3 GNEURALUCB          : Reward=0511.44, Efficiency=024.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=2500, Threshold=0.582]\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=0492.34, Efficiency=024.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=2500, Threshold=0.628]\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=0494.61, Efficiency=024.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=2500, Threshold=0.634]\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=0516.20, Efficiency=025.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=2500, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP3 Winner:iCPursuitNeuralUCB  (Gap:074.9%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:2500, SCapacity=2500, Alloc=Default]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 3000 frames  <>  SCALED-CAPACITY: 3000 frames (CAPACITY:3000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=3 ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for MARKOV Exp 4: (25, 25, 25, 25)\n",
      "üîÑ Default Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 4: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:3000, QubitAlloc=Default, SC:3000 (Scale=1 x Cap=3000), Seed: 19699\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_4\n",
      "\t‚úì QuantumExperimentRunner_4 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_3000-Default_Adversarial_Markov-3000_4_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_3000-Default_Adversarial_Markov-3000_4_paper12.pkl\n",
      "\t   File exists: True, size: 1374171\n",
      "‚è© SKIPPING EXPERIMENT 4: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 4 GNEURALUCB          : Reward=0604.93, Efficiency=024.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.582]\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=0548.05, Efficiency=022.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.628]\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=0615.91, Efficiency=024.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.634]\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=0658.80, Efficiency=026.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP4 Winner:iCPursuitNeuralUCB  (Gap:073.4%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:3000, SCapacity=3000, Alloc=Default]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 3500 frames  <>  SCALED-CAPACITY: 3500 frames (CAPACITY:3500 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=4 ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for MARKOV Exp 5: (25, 25, 25, 25)\n",
      "üîÑ Default Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 5: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:3500, QubitAlloc=Default, SC:3500 (Scale=1 x Cap=3500), Seed: 22085\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_5\n",
      "\t‚úì QuantumExperimentRunner_5 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_3500-Default_Adversarial_Markov-3500_5_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_3500-Default_Adversarial_Markov-3500_5_paper12.pkl\n",
      "\t   File exists: True, size: 1596239\n",
      "‚è© SKIPPING EXPERIMENT 5: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 5 GNEURALUCB          : Reward=0687.62, Efficiency=023.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=3500, Threshold=0.582]\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=0628.21, Efficiency=021.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=3500, Threshold=0.628]\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=0729.78, Efficiency=025.2% [Retries=3, Failed=0, < Threshold=3, SCapacity=3500, Threshold=0.634]\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=0726.81, Efficiency=025.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=3500, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP5 Winner:CPursuitNeuralUCB   (Gap:074.8%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:3500, SCapacity=3500, Alloc=Default]\n",
      "\n",
      "Total experiment time: 034.8s\n",
      "Experiments completed for markov\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: ADAPTIVE ADVERSARIAL ATTACK\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: ADAPTIVE\n",
      "Category: Adaptive (Reactive Strategic)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 1500 frames  <>  SCALED-CAPACITY: 1500 frames (CAPACITY:1500 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=0 ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 1: (25, 25, 25, 25)\n",
      "üîÑ Default Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 1: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:1500, QubitAlloc=Default, SC:1500 (Scale=1 x Cap=1500), Seed: 14115\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_1\n",
      "\t‚úì QuantumExperimentRunner_1 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_1500-Default_Adversarial_Adaptive-1500_1_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_1500-Default_Adversarial_Adaptive-1500_1_paper12.pkl\n",
      "\t   File exists: True, size: 708055\n",
      "‚è© SKIPPING EXPERIMENT 1: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 1 GNEURALUCB          : Reward=0417.32, Efficiency=031.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=1500, Threshold=0.582]\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=0438.15, Efficiency=033.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=1500, Threshold=0.628]\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=0454.88, Efficiency=034.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=1500, Threshold=0.634]\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=0425.86, Efficiency=032.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=1500, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP1 Winner:CPursuitNeuralUCB   (Gap:065.4%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:1500, SCapacity=1500, Alloc=Default]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 2000 frames  <>  SCALED-CAPACITY: 2000 frames (CAPACITY:2000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=1 ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 2: (25, 25, 25, 25)\n",
      "üîÑ Default Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 2: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:2000, QubitAlloc=Default, SC:2000 (Scale=1 x Cap=2000), Seed: 14473\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_2\n",
      "\t‚úì QuantumExperimentRunner_2 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_2000-Default_Adversarial_Adaptive-2000_2_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_2000-Default_Adversarial_Adaptive-2000_2_paper12.pkl\n",
      "\t   File exists: True, size: 930091\n",
      "‚è© SKIPPING EXPERIMENT 2: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 2 GNEURALUCB          : Reward=0546.16, Efficiency=031.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=2000, Threshold=0.582]\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=0627.19, Efficiency=035.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=2000, Threshold=0.628]\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=0607.29, Efficiency=034.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=2000, Threshold=0.634]\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=0576.53, Efficiency=032.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=2000, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP2 Winner:EXPNeuralUCB        (Gap:064.3%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:2000, SCapacity=2000, Alloc=Default]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 2500 frames  <>  SCALED-CAPACITY: 2500 frames (CAPACITY:2500 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=2 ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 3: (25, 25, 25, 25)\n",
      "üîÑ Default Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 3: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:2500, QubitAlloc=Default, SC:2500 (Scale=1 x Cap=2500), Seed: 13973\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_3\n",
      "\t‚úì QuantumExperimentRunner_3 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_2500-Default_Adversarial_Adaptive-2500_3_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_2500-Default_Adversarial_Adaptive-2500_3_paper12.pkl\n",
      "\t   File exists: True, size: 1152150\n",
      "‚è© SKIPPING EXPERIMENT 3: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 3 GNEURALUCB          : Reward=0691.73, Efficiency=031.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=2500, Threshold=0.582]\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=0802.44, Efficiency=036.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=2500, Threshold=0.628]\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=0741.20, Efficiency=033.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=2500, Threshold=0.634]\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=0746.25, Efficiency=034.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=2500, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP3 Winner:EXPNeuralUCB        (Gap:063.4%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:2500, SCapacity=2500, Alloc=Default]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 3000 frames  <>  SCALED-CAPACITY: 3000 frames (CAPACITY:3000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=3 ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 4: (25, 25, 25, 25)\n",
      "üîÑ Default Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 4: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:3000, QubitAlloc=Default, SC:3000 (Scale=1 x Cap=3000), Seed: 16838\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_4\n",
      "\t‚úì QuantumExperimentRunner_4 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_3000-Default_Adversarial_Adaptive-3000_4_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_3000-Default_Adversarial_Adaptive-3000_4_paper12.pkl\n",
      "\t   File exists: True, size: 1374177\n",
      "‚è© SKIPPING EXPERIMENT 4: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 4 GNEURALUCB          : Reward=0893.31, Efficiency=034.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.582]\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=0923.15, Efficiency=035.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.628]\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=0898.77, Efficiency=034.2% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.634]\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=0924.11, Efficiency=035.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP4 Winner:iCPursuitNeuralUCB  (Gap:064.9%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:3000, SCapacity=3000, Alloc=Default]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 3500 frames  <>  SCALED-CAPACITY: 3500 frames (CAPACITY:3500 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=4 ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 5: (25, 25, 25, 25)\n",
      "üîÑ Default Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 5: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:3500, QubitAlloc=Default, SC:3500 (Scale=1 x Cap=3500), Seed: 20582\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_5\n",
      "\t‚úì QuantumExperimentRunner_5 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_3500-Default_Adversarial_Adaptive-3500_5_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_3500-Default_Adversarial_Adaptive-3500_5_paper12.pkl\n",
      "\t   File exists: True, size: 1596245\n",
      "‚è© SKIPPING EXPERIMENT 5: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 5 GNEURALUCB          : Reward=1069.76, Efficiency=034.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=3500, Threshold=0.582]\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=0992.55, Efficiency=032.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=3500, Threshold=0.628]\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=0963.20, Efficiency=031.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=3500, Threshold=0.634]\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=1026.80, Efficiency=033.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=3500, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP5 Winner:GNeuralUCB          (Gap:065.1%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:3500, SCapacity=3500, Alloc=Default]\n",
      "\n",
      "Total experiment time: 037.8s\n",
      "Experiments completed for adaptive\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: ONLINE ADAPTIVE ATTACK\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: ONLINEADAPTIVE\n",
      "Category: Online Adaptive (Real-time Strategic)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 1500 frames  <>  SCALED-CAPACITY: 1500 frames (CAPACITY:1500 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=0 ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 1: (25, 25, 25, 25)\n",
      "üîÑ Default Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:1500, QubitAlloc=Default, SC:1500 (Scale=1 x Cap=1500), Seed: 14103\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_1\n",
      "\t‚úì QuantumExperimentRunner_1 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_1500-Default_Adversarial_OnlineAdaptive-1500_1_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_1500-Default_Adversarial_OnlineAdaptive-1500_1_paper12.pkl\n",
      "\t   File exists: True, size: 708073\n",
      "‚è© SKIPPING EXPERIMENT 1: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 1 GNEURALUCB          : Reward=0436.26, Efficiency=033.2% [Retries=3, Failed=0, < Threshold=3, SCapacity=1500, Threshold=0.582]\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=0473.11, Efficiency=036.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=1500, Threshold=0.628]\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=0439.79, Efficiency=033.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=1500, Threshold=0.634]\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=0452.96, Efficiency=034.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=1500, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP1 Winner:EXPNeuralUCB        (Gap:064.0%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:1500, SCapacity=1500, Alloc=Default]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 2000 frames  <>  SCALED-CAPACITY: 2000 frames (CAPACITY:2000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=1 ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 2: (25, 25, 25, 25)\n",
      "üîÑ Default Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:2000, QubitAlloc=Default, SC:2000 (Scale=1 x Cap=2000), Seed: 22352\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_2\n",
      "\t‚úì QuantumExperimentRunner_2 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_2000-Default_Adversarial_OnlineAdaptive-2000_2_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_2000-Default_Adversarial_OnlineAdaptive-2000_2_paper12.pkl\n",
      "\t   File exists: True, size: 930109\n",
      "‚è© SKIPPING EXPERIMENT 2: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 2 GNEURALUCB          : Reward=0632.00, Efficiency=036.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=2000, Threshold=0.582]\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=0575.97, Efficiency=032.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=2000, Threshold=0.628]\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=0624.44, Efficiency=035.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=2000, Threshold=0.634]\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=0581.05, Efficiency=033.2% [Retries=3, Failed=0, < Threshold=3, SCapacity=2000, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP2 Winner:GNeuralUCB          (Gap:063.9%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:2000, SCapacity=2000, Alloc=Default]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 2500 frames  <>  SCALED-CAPACITY: 2500 frames (CAPACITY:2500 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=2 ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 3: (25, 25, 25, 25)\n",
      "üîÑ Default Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:2500, QubitAlloc=Default, SC:2500 (Scale=1 x Cap=2500), Seed: 14162\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_3\n",
      "\t‚úì QuantumExperimentRunner_3 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_2500-Default_Adversarial_OnlineAdaptive-2500_3_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_2500-Default_Adversarial_OnlineAdaptive-2500_3_paper12.pkl\n",
      "\t   File exists: True, size: 1152168\n",
      "‚è© SKIPPING EXPERIMENT 3: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 3 GNEURALUCB          : Reward=0726.62, Efficiency=033.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=2500, Threshold=0.582]\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=0739.64, Efficiency=033.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=2500, Threshold=0.628]\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=0721.73, Efficiency=032.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=2500, Threshold=0.634]\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=0752.23, Efficiency=034.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=2500, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP3 Winner:iCPursuitNeuralUCB  (Gap:065.7%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:2500, SCapacity=2500, Alloc=Default]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 3000 frames  <>  SCALED-CAPACITY: 3000 frames (CAPACITY:3000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=3 ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 4: (25, 25, 25, 25)\n",
      "üîÑ Default Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:3000, QubitAlloc=Default, SC:3000 (Scale=1 x Cap=3000), Seed: 21587\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_4\n",
      "\t‚úì QuantumExperimentRunner_4 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_3000-Default_Adversarial_OnlineAdaptive-3000_4_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_3000-Default_Adversarial_OnlineAdaptive-3000_4_paper12.pkl\n",
      "\t   File exists: True, size: 1374195\n",
      "‚è© SKIPPING EXPERIMENT 4: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 4 GNEURALUCB          : Reward=0848.09, Efficiency=032.2% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.582]\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=0968.16, Efficiency=036.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.628]\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=0922.21, Efficiency=035.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.634]\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=0855.44, Efficiency=032.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP4 Winner:EXPNeuralUCB        (Gap:063.2%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:3000, SCapacity=3000, Alloc=Default]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 3500 frames  <>  SCALED-CAPACITY: 3500 frames (CAPACITY:3500 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=4 ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 5: (25, 25, 25, 25)\n",
      "üîÑ Default Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:3500, QubitAlloc=Default, SC:3500 (Scale=1 x Cap=3500), Seed: 17102\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_5\n",
      "\t‚úì QuantumExperimentRunner_5 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_3500-Default_Adversarial_OnlineAdaptive-3500_5_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_3500-Default_Adversarial_OnlineAdaptive-3500_5_paper12.pkl\n",
      "\t   File exists: True, size: 1596263\n",
      "‚è© SKIPPING EXPERIMENT 5: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 5 GNEURALUCB          : Reward=1022.27, Efficiency=033.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=3500, Threshold=0.582]\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=0952.93, Efficiency=031.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=3500, Threshold=0.628]\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=1034.83, Efficiency=033.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=3500, Threshold=0.634]\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=1012.68, Efficiency=033.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=3500, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP5 Winner:CPursuitNeuralUCB   (Gap:066.3%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:3500, SCapacity=3500, Alloc=Default]\n",
      "\n",
      "Total experiment time: 041.1s\n",
      "Experiments completed for onlineadaptive\n",
      "‚úì Scenario 'none' evaluation completed.\n",
      "‚úì Scenario 'stochastic' evaluation completed.\n",
      "‚úì Scenario 'markov' evaluation completed.\n",
      "‚úì Scenario 'adaptive' evaluation completed.\n",
      "‚úì Scenario 'onlineadaptive' evaluation completed.\n",
      "\n",
      "======================================================================\n",
      "COMPREHENSIVE SCENARIO PERFORMANCE ANALYSIS\n",
      "======================================================================\n",
      "SCENARIO: NONE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: GNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 2204.16\n",
      "\t‚Ä¢ Winner Avg Gap: 0054.37%\n",
      "\t‚Ä¢ Winner Avg Reward: 1009.16\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0045.63%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 3 wins\n",
      "\t\t- EXPNeuralUCB: 1 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 1 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: NONE\n",
      "======================================================================\n",
      "SCENARIO: \tBASELINE (OPTIMAL CONDITIONS)\n",
      "----------------------------------------\n",
      "Recommended Model: \tGNeuralUCB (Won 3/5 experiments)\n",
      "\tWinner Avg Gap: \t054.4%\n",
      "\tWinner Avg Efficiency: \t045.6%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ GNeuralUCB     : \t045.6% Efficiency \t(Won 3/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t045.3% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t044.6% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t043.4% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: STOCHASTIC\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: EXPNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 2202.70\n",
      "\t‚Ä¢ Winner Avg Gap: 0056.67%\n",
      "\t‚Ä¢ Winner Avg Reward: 0954.51\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0043.33%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 3 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 2 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: STOCHASTIC\n",
      "======================================================================\n",
      "SCENARIO: \tSTOCHASTIC RANDOM FAILURES\n",
      "----------------------------------------\n",
      "Recommended Model: \tEXPNeuralUCB (Won 3/5 experiments)\n",
      "\tWinner Avg Gap: \t056.7%\n",
      "\tWinner Avg Efficiency: \t043.3%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t043.3% Efficiency \t(Won 3/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t042.0% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t041.9% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t041.6% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: MARKOV\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 2060.56\n",
      "\t‚Ä¢ Winner Avg Gap: 0074.51%\n",
      "\t‚Ä¢ Winner Avg Reward: 0527.22\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0025.49%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 1 wins\n",
      "\t\t- iCPursuitNeuralUCB: 4 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: MARKOV\n",
      "======================================================================\n",
      "SCENARIO: \tMARKOV ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 4/5 experiments)\n",
      "\tWinner Avg Gap: \t074.5%\n",
      "\tWinner Avg Efficiency: \t025.5%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t025.5% Efficiency \t(Won 4/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t024.3% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t024.2% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t022.4% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: EXPNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 2191.43\n",
      "\t‚Ä¢ Winner Avg Gap: 0065.37%\n",
      "\t‚Ä¢ Winner Avg Reward: 0756.70\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0034.63%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 1 wins\n",
      "\t\t- EXPNeuralUCB: 2 wins\n",
      "\t\t- CPursuitNeuralUCB: 1 wins\n",
      "\t\t- iCPursuitNeuralUCB: 1 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tADAPTIVE ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tEXPNeuralUCB (Won 2/5 experiments)\n",
      "\tWinner Avg Gap: \t065.4%\n",
      "\tWinner Avg Efficiency: \t034.6%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t034.6% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t033.7% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t033.6% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t032.7% Efficiency \t(Won 1/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ONLINEADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: CPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 2191.23\n",
      "\t‚Ä¢ Winner Avg Gap: 0065.83%\n",
      "\t‚Ä¢ Winner Avg Reward: 0748.60\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0034.17%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 1 wins\n",
      "\t\t- EXPNeuralUCB: 2 wins\n",
      "\t\t- CPursuitNeuralUCB: 1 wins\n",
      "\t\t- iCPursuitNeuralUCB: 1 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ONLINEADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tONLINE ADAPTIVE ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tCPursuitNeuralUCB (Won 1/5 experiments)\n",
      "\tWinner Avg Gap: \t065.8%\n",
      "\tWinner Avg Efficiency: \t034.2%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t034.2% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t034.1% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t033.6% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t033.5% Efficiency \t(Won 1/5 experiments)\n",
      "======================================================================\n",
      "KEY INSIGHTS:\n",
      "Best Performing Model Analysis (EXPNeuralUCB):\n",
      "\t‚Ä¢ Stochastic Performance:    \t954.513\n",
      "\t‚Ä¢ Baseline Performance:      \t1009.162\n",
      "\t‚Ä¢ Performance Retention:     \t094.6%\n",
      "\tGOOD:               \tAcceptable performance under stochastic conditions\n",
      "Statistical Analysis:\n",
      "\t‚Ä¢ Total models evaluated:     \t5\n",
      "\t‚Ä¢ Experiments per environment:\t5\n",
      "\t‚Ä¢ Quantum network simulation: \tComprehensive stochastic modeling\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "COMPREHENSIVE SCENARIO PERFORMANCE ANALYSIS\n",
      "======================================================================\n",
      "SCENARIO: NONE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: GNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 2204.16\n",
      "\t‚Ä¢ Winner Avg Gap: 0054.37%\n",
      "\t‚Ä¢ Winner Avg Reward: 1009.16\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0045.63%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 3 wins\n",
      "\t\t- EXPNeuralUCB: 1 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 1 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: NONE\n",
      "======================================================================\n",
      "SCENARIO: \tBASELINE (OPTIMAL CONDITIONS)\n",
      "----------------------------------------\n",
      "Recommended Model: \tGNeuralUCB (Won 3/5 experiments)\n",
      "\tWinner Avg Gap: \t054.4%\n",
      "\tWinner Avg Efficiency: \t045.6%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ GNeuralUCB     : \t045.6% Efficiency \t(Won 3/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t045.3% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t044.6% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t043.4% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: STOCHASTIC\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: EXPNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 2202.70\n",
      "\t‚Ä¢ Winner Avg Gap: 0056.67%\n",
      "\t‚Ä¢ Winner Avg Reward: 0954.51\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0043.33%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 3 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 2 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: STOCHASTIC\n",
      "======================================================================\n",
      "SCENARIO: \tSTOCHASTIC RANDOM FAILURES\n",
      "----------------------------------------\n",
      "Recommended Model: \tEXPNeuralUCB (Won 3/5 experiments)\n",
      "\tWinner Avg Gap: \t056.7%\n",
      "\tWinner Avg Efficiency: \t043.3%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t043.3% Efficiency \t(Won 3/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t042.0% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t041.9% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t041.6% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: MARKOV\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 2060.56\n",
      "\t‚Ä¢ Winner Avg Gap: 0074.51%\n",
      "\t‚Ä¢ Winner Avg Reward: 0527.22\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0025.49%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 1 wins\n",
      "\t\t- iCPursuitNeuralUCB: 4 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: MARKOV\n",
      "======================================================================\n",
      "SCENARIO: \tMARKOV ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 4/5 experiments)\n",
      "\tWinner Avg Gap: \t074.5%\n",
      "\tWinner Avg Efficiency: \t025.5%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t025.5% Efficiency \t(Won 4/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t024.3% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t024.2% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t022.4% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: EXPNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 2191.43\n",
      "\t‚Ä¢ Winner Avg Gap: 0065.37%\n",
      "\t‚Ä¢ Winner Avg Reward: 0756.70\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0034.63%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 1 wins\n",
      "\t\t- EXPNeuralUCB: 2 wins\n",
      "\t\t- CPursuitNeuralUCB: 1 wins\n",
      "\t\t- iCPursuitNeuralUCB: 1 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tADAPTIVE ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tEXPNeuralUCB (Won 2/5 experiments)\n",
      "\tWinner Avg Gap: \t065.4%\n",
      "\tWinner Avg Efficiency: \t034.6%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t034.6% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t033.7% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t033.6% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t032.7% Efficiency \t(Won 1/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ONLINEADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: CPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 2191.23\n",
      "\t‚Ä¢ Winner Avg Gap: 0065.83%\n",
      "\t‚Ä¢ Winner Avg Reward: 0748.60\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0034.17%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 1 wins\n",
      "\t\t- EXPNeuralUCB: 2 wins\n",
      "\t\t- CPursuitNeuralUCB: 1 wins\n",
      "\t\t- iCPursuitNeuralUCB: 1 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ONLINEADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tONLINE ADAPTIVE ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tCPursuitNeuralUCB (Won 1/5 experiments)\n",
      "\tWinner Avg Gap: \t065.8%\n",
      "\tWinner Avg Efficiency: \t034.2%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t034.2% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t034.1% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t033.6% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t033.5% Efficiency \t(Won 1/5 experiments)\n",
      "======================================================================\n",
      "‚úÖ Evaluation completed!\n",
      "[Logging Redirect Stopped]\n",
      "\n",
      "üßπ Final cleanup for Default\n",
      "\n",
      "======================================================================\n",
      "‚úÖ COMPLETED: Default\n",
      "======================================================================\n",
      "\n",
      "Default COMPLETED SUCCESSFULLY\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Preparing: Default at scale 1.5\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üîß Generating physics parameters for model: paper12\n",
      "\n",
      "===================== GET LOCAL REGISTRY =====================\n",
      "‚Üí Skipping local cache (force=True or file missing)\n",
      "\n",
      "===================== BUILD LOCAL REGISTRY =====================\n",
      "\n",
      "================================================================================\n",
      "üîç SCANNING LOCAL FILES\n",
      "================================================================================\n",
      "Parameters: load_to_drive=False, force=False\n",
      "\n",
      "üìÇ Checking DRIVE mode: /content/drive/Shareddrives/ai_quantum_computing/quantum_data_lake\n",
      "   ‚ö†Ô∏è  Path does not exist, skipping\n",
      "\n",
      "üìÇ Checking LOCAL mode: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config\n",
      "   ‚úÖ Path exists, starting walk...\n",
      "   üö∂ Walking directory tree: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config\n",
      "\n",
      "   üìÅ Directory: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201\n",
      "      Relative: framework_state/day_20260201\n",
      "      Component: framework_state\n",
      "      Date: day_20260201\n",
      "      üìÑ Processing 2512 files in framework_state/day_20260201\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "      üìä framework_state/day_20260201: 2485/2512 files processed\n",
      "      üìä framework_state/day_20260201: 0/2512 files skipped\n",
      "      üìä framework_state/day_20260201: 27/2512 files conflicted\n",
      "\n",
      "   üìÅ Directory: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/model_state/day_20260201\n",
      "      Relative: model_state/day_20260201\n",
      "      Component: model_state\n",
      "      Date: day_20260201\n",
      "      üìÑ Processing 8842 files in model_state/day_20260201\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "      üìä model_state/day_20260201: 8842/8842 files processed\n",
      "      üìä model_state/day_20260201: 0/8842 files skipped\n",
      "      üìä model_state/day_20260201: 0/8842 files conflicted\n",
      "\n",
      "   üìä Processed 2 directories\n",
      "\n",
      "================================================================================\n",
      "üì¶ BUILDING FINAL REGISTRY\n",
      "================================================================================\n",
      "Components found: ['framework_state', 'model_state']\n",
      "  ‚Ä¢ framework_state: 2485 files\n",
      "  ‚Ä¢ model_state: 8842 files\n",
      "\n",
      "‚úÖ SCAN COMPLETE\n",
      "Modes scanned: 1\n",
      "Total files in registry: 11327\n",
      "================================================================================\n",
      "\n",
      "\t‚Üí Filesystem scan found 11327 files\n",
      "\n",
      "===================== GET DRIVE REGISTRY =====================\n",
      "===================== REGISTRY BUILD COMPLETE =====================\n",
      "\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "\tüì¶ LocalBackupManager Registry Saved Locally in LOCAL\n",
      "BUILDING REGISTRY WITH 0 EXPECTED COMPONENTS KEYS\n",
      "\n",
      "===================== GET LOCAL REGISTRY =====================\n",
      "‚Üí Skipping local cache (force=True or file missing)\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "\tüì¶ LocalBackupManager Registry Saved Locally in LOCAL\n",
      "\n",
      "======================================================================\n",
      "üéØ AllocatorRunner initialized: Default\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "üöÄ STARTING ALLOCATOR: Default\n",
      "======================================================================\n",
      "\n",
      "üìä Physics Model: paper12\n",
      "\n",
      "üìã Allocator Config:\n",
      "   Type: Default\n",
      "   Testbed: paper12\n",
      "   Paths: 4\n",
      "   Total Qubits: 100\n",
      "   Min per route: 3\n",
      "   Seed: 42\n",
      "‚úÖ Allocator created: (25, 25, 25, 25)\n",
      "‚úì Allocator: QubitAllocator (4 paths)\n",
      "   Initial allocation: (25, 25, 25, 25)\n",
      "Generated paper12 Waxman topology: 100 nodes, 393 edges, avg degree: 7.86\n",
      "üìä Paper12 Physics: Fusion (prob=0.9)\n",
      "\n",
      "======================================================================\n",
      "RUN 1 | Scale: 1.5 | Exp: 5\n",
      "======================================================================\n",
      "üîÑ Default Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "\n",
      "\tüîÑ Resume: MultiRunEvaluator\n",
      "\n",
      "=====================================================\n",
      "üîç GENERATING EXPECTED KEYS FROM EVALUATOR\n",
      "=====================================================\n",
      "  ‚Ä¢ Evaluator filename: MultiRunEvaluator_2250-Default_All_All-1500_500_5_S1_5T_paper12.pkl\n",
      "\n",
      "üß© PARSED COMPONENTS\n",
      "  ‚Ä¢ cap_id:        2250\n",
      "  ‚Ä¢ allocator_id:  Default\n",
      "  ‚Ä¢ env_id:        All\n",
      "  ‚Ä¢ attack_id:     All\n",
      "  ‚Ä¢ base_frames:   1500\n",
      "  ‚Ä¢ frame_step:    500\n",
      "  ‚Ä¢ runs_id:       5\n",
      "\n",
      "=====================================================\n",
      "üß™ GENERATING KEYS FOR EACH RUN\n",
      "=====================================================\n",
      "\n",
      "--- Run 1/5 -----------------------\n",
      "\n",
      "=====================================================\n",
      "üì¶ FINAL EXPECTED KEYS\n",
      "=====================================================\n",
      "  ‚Ä¢ Runner keys: 11\n",
      "\n",
      "  ‚Ä¢ Model keys: 50\n",
      "\n",
      "--- Run 2/5 -----------------------\n",
      "\n",
      "=====================================================\n",
      "üì¶ FINAL EXPECTED KEYS\n",
      "=====================================================\n",
      "  ‚Ä¢ Runner keys: 21\n",
      "\n",
      "  ‚Ä¢ Model keys: 100\n",
      "\n",
      "--- Run 3/5 -----------------------\n",
      "\n",
      "=====================================================\n",
      "üì¶ FINAL EXPECTED KEYS\n",
      "=====================================================\n",
      "  ‚Ä¢ Runner keys: 31\n",
      "\n",
      "  ‚Ä¢ Model keys: 150\n",
      "\n",
      "--- Run 4/5 -----------------------\n",
      "\n",
      "=====================================================\n",
      "üì¶ FINAL EXPECTED KEYS\n",
      "=====================================================\n",
      "  ‚Ä¢ Runner keys: 41\n",
      "\n",
      "  ‚Ä¢ Model keys: 200\n",
      "\n",
      "--- Run 5/5 -----------------------\n",
      "\n",
      "=====================================================\n",
      "üì¶ FINAL EXPECTED KEYS\n",
      "=====================================================\n",
      "  ‚Ä¢ Runner keys: 51\n",
      "\n",
      "  ‚Ä¢ Model keys: 250\n",
      "\n",
      "EXPECTED KEY GENERATION COMPLETE\n",
      "\n",
      "RESTORING FROM DRIVE 1\n",
      "RESTORING FROM DRIVE 2\n",
      "\t‚ö†Ô∏è Registry exists ‚Üí aborting restore\n",
      "\t‚òÅÔ∏è Attempting Drive download: framework_state/MultiRunEvaluator_2250-Default_All_All-1500_500_5_S1_5T_paper12.pkl\n",
      "\t‚ùå Not found anywhere: framework_state/MultiRunEvaluator_2250-Default_All_All-1500_500_5_S1_5T_paper12.pkl\n",
      "\t‚ùå Not found in registry or fallback locations\n",
      "\t‚òÅÔ∏è Attempting Drive download: framework_state/MultiRunEvaluator_2250-Default_All_All-1500_500_5_S1_5T_paper12.pkl\n",
      "\t‚ùå Not found anywhere: framework_state/MultiRunEvaluator_2250-Default_All_All-1500_500_5_S1_5T_paper12.pkl\n",
      "\t‚ùå Not found in registry or fallback locations\n",
      "[Resume] exact failed ‚Üí Looking for supersets\n",
      "[Resume-Supersets] target_runs=5, backups=dict_keys([])\n",
      "[Resume-Supersets] Trying horizons in size order (largest first): []\n",
      "[Resume-Supersets] ‚ùå No valid supersets found for resume\n",
      "No state found for MultiRunEvaluator, disabling resume for Experiment Runners\n",
      "Multi-Run Evaluator Initialized\n",
      "Environment Type: None\n",
      "Frame Range: 1500 -> 3500 (step: 500)\n",
      "quantum_exps-Default(paper12)_alloc-all_envs-5_attacks-1500_500-5_runs-S1.5T\n",
      "[Logging Redirect Initialized]\n",
      "Log File: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/quantum_logs/quantum_exps-Default(paper12)_alloc-all_envs-5_attacks-1500_500-5_runs-S1.5T_20260201_log.txt\n",
      "‚öô Running evaluation...\n",
      "======================================================================\n",
      "SCENARIOS MODEL EVALUATION\n",
      "======================================================================\n",
      "Testing algorithm performance against:\n",
      "\t‚Ä¢ Stochastic:  \tNatural quantum decoherence and network failures\n",
      "\t‚Ä¢ Baseline:    \tOptimal conditions for validation\n",
      "======================================================================\n",
      "Models to Test:             \tOracle, GNeuralUCB, EXPNeuralUCB, CPursuitNeuralUCB, iCPursuitNeuralUCB\n",
      "Experiments per Scenario:   \t5\n",
      "======================================================================\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: BASELINE (OPTIMAL CONDITIONS)\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: NONE\n",
      "Category: Baseline (No Attacks)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 1500 frames  <>  SCALED-CAPACITY: 2250.0 frames (CAPACITY:1500 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=0 ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for NONE Exp 1: (25, 25, 25, 25)\n",
      "üîÑ Default Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 1: Env:Baseline (None), Attack:No, Rate:0.0, Frames:1500, QubitAlloc=Default, SC:2250 (Scale=1.5 x Cap=1500), Seed: 18010\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 4\n",
      "\t   First reward: [0.1944, 0.5334336, 0.7380232703999999, 0.8326343725056001, 0.8726341491523584], type: <class 'list'>\n",
      "\t   First reward length: 5\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 1: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 GNEURALUCB          : Reward=0799.99, Efficiency=059.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=2250, Threshold=0.582]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 1: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=0602.70, Efficiency=045.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=2250, Threshold=0.628]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 1: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=0830.65, Efficiency=062.2% [Retries=3, Failed=0, < Threshold=3, SCapacity=2250, Threshold=0.634]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 1: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=0781.11, Efficiency=058.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=2250, Threshold=0.712]\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 1: Env:Baseline (None), Attack:No, Rate:0.0, Frames:1500, QubitAlloc=Default, SC:2250 (Scale=1.5 x Cap=1500), Seed: 18010\n",
      "\t-->üèÜ EXP1 Winner:CPursuitNeuralUCB   (Gap:037.8%) [Env:Baseline (None), Attack:No X Rate:0.0, Frames:1500, SCapacity=2250, Alloc=Default]\n",
      "‚úì Experiment 1 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 2000 frames  <>  SCALED-CAPACITY: 3000.0 frames (CAPACITY:2000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=1 ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for NONE Exp 2: (25, 25, 25, 25)\n",
      "üîÑ Default Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 2: Env:Baseline (None), Attack:No, Rate:0.0, Frames:2000, QubitAlloc=Default, SC:3000 (Scale=1.5 x Cap=2000), Seed: 20078\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 4\n",
      "\t   First reward: [0.1944, 0.5334336, 0.7380232703999999, 0.8326343725056001, 0.8726341491523584], type: <class 'list'>\n",
      "\t   First reward length: 5\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 2: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 GNEURALUCB          : Reward=1104.79, Efficiency=062.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=3000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 2: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=0955.59, Efficiency=053.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 2: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=1092.54, Efficiency=061.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 2: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=1126.47, Efficiency=063.2% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.712]\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 2: Env:Baseline (None), Attack:No, Rate:0.0, Frames:2000, QubitAlloc=Default, SC:3000 (Scale=1.5 x Cap=2000), Seed: 20078\n",
      "\t-->üèÜ EXP2 Winner:iCPursuitNeuralUCB  (Gap:036.8%) [Env:Baseline (None), Attack:No X Rate:0.0, Frames:2000, SCapacity=3000, Alloc=Default]\n",
      "‚úì Experiment 2 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 2500 frames  <>  SCALED-CAPACITY: 3750.0 frames (CAPACITY:2500 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=2 ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for NONE Exp 3: (25, 25, 25, 25)\n",
      "üîÑ Default Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 3: Env:Baseline (None), Attack:No, Rate:0.0, Frames:2500, QubitAlloc=Default, SC:3750 (Scale=1.5 x Cap=2500), Seed: 14623\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 4\n",
      "\t   First reward: [0.1944, 0.5334336, 0.7380232703999999, 0.8326343725056001, 0.8726341491523584], type: <class 'list'>\n",
      "\t   First reward length: 5\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 3: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 GNEURALUCB          : Reward=1345.22, Efficiency=060.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=3750, Threshold=0.582]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 3: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=1275.81, Efficiency=057.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=3750, Threshold=0.628]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 3: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=1384.89, Efficiency=062.2% [Retries=3, Failed=0, < Threshold=3, SCapacity=3750, Threshold=0.634]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 3: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=1387.70, Efficiency=062.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=3750, Threshold=0.712]\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 3: Env:Baseline (None), Attack:No, Rate:0.0, Frames:2500, QubitAlloc=Default, SC:3750 (Scale=1.5 x Cap=2500), Seed: 14623\n",
      "\t-->üèÜ EXP3 Winner:iCPursuitNeuralUCB  (Gap:037.7%) [Env:Baseline (None), Attack:No X Rate:0.0, Frames:2500, SCapacity=3750, Alloc=Default]\n",
      "‚úì Experiment 3 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 3000 frames  <>  SCALED-CAPACITY: 4500.0 frames (CAPACITY:3000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=3 ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for NONE Exp 4: (25, 25, 25, 25)\n",
      "üîÑ Default Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 4: Env:Baseline (None), Attack:No, Rate:0.0, Frames:3000, QubitAlloc=Default, SC:4500 (Scale=1.5 x Cap=3000), Seed: 20090\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 4\n",
      "\t   First reward: [0.1944, 0.5334336, 0.7380232703999999, 0.8326343725056001, 0.8726341491523584], type: <class 'list'>\n",
      "\t   First reward length: 5\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 4: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 GNEURALUCB          : Reward=1648.99, Efficiency=061.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=4500, Threshold=0.582]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 4: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=1612.92, Efficiency=060.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=4500, Threshold=0.628]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 4: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=1672.17, Efficiency=062.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=4500, Threshold=0.634]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 4: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=1675.63, Efficiency=062.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=4500, Threshold=0.712]\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 4: Env:Baseline (None), Attack:No, Rate:0.0, Frames:3000, QubitAlloc=Default, SC:4500 (Scale=1.5 x Cap=3000), Seed: 20090\n",
      "\t-->üèÜ EXP4 Winner:iCPursuitNeuralUCB  (Gap:037.3%) [Env:Baseline (None), Attack:No X Rate:0.0, Frames:3000, SCapacity=4500, Alloc=Default]\n",
      "‚úì Experiment 4 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 3500 frames  <>  SCALED-CAPACITY: 5250.0 frames (CAPACITY:3500 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=4 ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for NONE Exp 5: (25, 25, 25, 25)\n",
      "üîÑ Default Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 5: Env:Baseline (None), Attack:No, Rate:0.0, Frames:3500, QubitAlloc=Default, SC:5250 (Scale=1.5 x Cap=3500), Seed: 12926\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 4\n",
      "\t   First reward: [0.1944, 0.5334336, 0.7380232703999999, 0.8326343725056001, 0.8726341491523584], type: <class 'list'>\n",
      "\t   First reward length: 5\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 5: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 GNEURALUCB          : Reward=1964.80, Efficiency=063.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=5250, Threshold=0.582]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 5: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=1918.72, Efficiency=061.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=5250, Threshold=0.628]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 5: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=1949.40, Efficiency=062.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=5250, Threshold=0.634]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 5: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=1901.82, Efficiency=061.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=5250, Threshold=0.712]\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 5: Env:Baseline (None), Attack:No, Rate:0.0, Frames:3500, QubitAlloc=Default, SC:5250 (Scale=1.5 x Cap=3500), Seed: 12926\n",
      "\t-->üèÜ EXP5 Winner:GNeuralUCB          (Gap:037.0%) [Env:Baseline (None), Attack:No X Rate:0.0, Frames:3500, SCapacity=5250, Alloc=Default]\n",
      "‚úì Experiment 5 completed successfully.\n",
      "Total experiment time: 1753.3s\n",
      "Experiments completed for none\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: STOCHASTIC RANDOM FAILURES\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: STOCHASTIC\n",
      "Category: Stochastic (Natural Random Failures)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 1500 frames  <>  SCALED-CAPACITY: 2250.0 frames (CAPACITY:1500 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=0 ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 1: (25, 25, 25, 25)\n",
      "üîÑ Default Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 1: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:1500, QubitAlloc=Default, SC:2250 (Scale=1.5 x Cap=1500), Seed: 20197\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 4\n",
      "\t   First reward: [0.1944, 0.5334336, 0.7380232703999999, 0.8326343725056001, 0.8726341491523584], type: <class 'list'>\n",
      "\t   First reward length: 5\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 1: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 GNEURALUCB          : Reward=0738.22, Efficiency=055.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=2250, Threshold=0.582]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 1: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=0709.96, Efficiency=053.2% [Retries=3, Failed=0, < Threshold=3, SCapacity=2250, Threshold=0.628]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 1: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=0757.09, Efficiency=056.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=2250, Threshold=0.634]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 1: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=0753.50, Efficiency=056.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=2250, Threshold=0.712]\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 1: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:1500, QubitAlloc=Default, SC:2250 (Scale=1.5 x Cap=1500), Seed: 20197\n",
      "\t-->üèÜ EXP1 Winner:CPursuitNeuralUCB   (Gap:043.3%) [Env:Stochastic, Attack:Random X Rate:0.0625, Frames:1500, SCapacity=2250, Alloc=Default]\n",
      "‚úì Experiment 1 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 2000 frames  <>  SCALED-CAPACITY: 3000.0 frames (CAPACITY:2000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=1 ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 2: (25, 25, 25, 25)\n",
      "üîÑ Default Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 2: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:2000, QubitAlloc=Default, SC:3000 (Scale=1.5 x Cap=2000), Seed: 17474\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 4\n",
      "\t   First reward: [0.1944, 0.5334336, 0.7380232703999999, 0.8326343725056001, 0.8726341491523584], type: <class 'list'>\n",
      "\t   First reward length: 5\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 2: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 GNEURALUCB          : Reward=0994.41, Efficiency=055.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 2: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=1091.83, Efficiency=061.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 2: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=0985.35, Efficiency=055.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 2: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=0999.42, Efficiency=056.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.712]\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 2: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:2000, QubitAlloc=Default, SC:3000 (Scale=1.5 x Cap=2000), Seed: 17474\n",
      "\t-->üèÜ EXP2 Winner:EXPNeuralUCB        (Gap:038.7%) [Env:Stochastic, Attack:Random X Rate:0.0625, Frames:2000, SCapacity=3000, Alloc=Default]\n",
      "‚úì Experiment 2 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 2500 frames  <>  SCALED-CAPACITY: 3750.0 frames (CAPACITY:2500 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=2 ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 3: (25, 25, 25, 25)\n",
      "üîÑ Default Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 3: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:2500, QubitAlloc=Default, SC:3750 (Scale=1.5 x Cap=2500), Seed: 15795\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 4\n",
      "\t   First reward: [0.1944, 0.5334336, 0.7380232703999999, 0.8326343725056001, 0.8726341491523584], type: <class 'list'>\n",
      "\t   First reward length: 5\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 3: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 GNEURALUCB          : Reward=1311.26, Efficiency=058.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=3750, Threshold=0.582]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 3: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=1193.99, Efficiency=053.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=3750, Threshold=0.628]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 3: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=1259.38, Efficiency=056.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=3750, Threshold=0.634]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 3: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=1343.93, Efficiency=060.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=3750, Threshold=0.712]\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 3: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:2500, QubitAlloc=Default, SC:3750 (Scale=1.5 x Cap=2500), Seed: 15795\n",
      "\t-->üèÜ EXP3 Winner:iCPursuitNeuralUCB  (Gap:039.6%) [Env:Stochastic, Attack:Random X Rate:0.0625, Frames:2500, SCapacity=3750, Alloc=Default]\n",
      "‚úì Experiment 3 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 3000 frames  <>  SCALED-CAPACITY: 4500.0 frames (CAPACITY:3000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=3 ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 4: (25, 25, 25, 25)\n",
      "üîÑ Default Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 4: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:3000, QubitAlloc=Default, SC:4500 (Scale=1.5 x Cap=3000), Seed: 17031\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 4\n",
      "\t   First reward: [0.1944, 0.5334336, 0.7380232703999999, 0.8326343725056001, 0.8726341491523584], type: <class 'list'>\n",
      "\t   First reward length: 5\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 4: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 GNEURALUCB          : Reward=1533.66, Efficiency=057.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=4500, Threshold=0.582]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 4: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=1556.15, Efficiency=058.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=4500, Threshold=0.628]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 4: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=1564.70, Efficiency=058.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=4500, Threshold=0.634]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 4: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=1541.19, Efficiency=057.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=4500, Threshold=0.712]\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 4: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:3000, QubitAlloc=Default, SC:4500 (Scale=1.5 x Cap=3000), Seed: 17031\n",
      "\t-->üèÜ EXP4 Winner:CPursuitNeuralUCB   (Gap:041.4%) [Env:Stochastic, Attack:Random X Rate:0.0625, Frames:3000, SCapacity=4500, Alloc=Default]\n",
      "‚úì Experiment 4 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 3500 frames  <>  SCALED-CAPACITY: 5250.0 frames (CAPACITY:3500 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=4 ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 5: (25, 25, 25, 25)\n",
      "üîÑ Default Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 5: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:3500, QubitAlloc=Default, SC:5250 (Scale=1.5 x Cap=3500), Seed: 21490\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 4\n",
      "\t   First reward: [0.1944, 0.5334336, 0.7380232703999999, 0.8326343725056001, 0.8726341491523584], type: <class 'list'>\n",
      "\t   First reward length: 5\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 5: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 GNEURALUCB          : Reward=1817.14, Efficiency=058.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=5250, Threshold=0.582]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 5: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=1817.08, Efficiency=058.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=5250, Threshold=0.628]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 5: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=1814.92, Efficiency=058.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=5250, Threshold=0.634]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 5: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=1814.72, Efficiency=058.2% [Retries=3, Failed=0, < Threshold=3, SCapacity=5250, Threshold=0.712]\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 5: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:3500, QubitAlloc=Default, SC:5250 (Scale=1.5 x Cap=3500), Seed: 21490\n",
      "\t-->üèÜ EXP5 Winner:GNeuralUCB          (Gap:041.7%) [Env:Stochastic, Attack:Random X Rate:0.0625, Frames:3500, SCapacity=5250, Alloc=Default]\n",
      "‚úì Experiment 5 completed successfully.\n",
      "Total experiment time: 1237.0s\n",
      "Experiments completed for stochastic\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: MARKOV ADVERSARIAL ATTACK\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: MARKOV\n",
      "Category: Structured (Markov Chain Based)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 1500 frames  <>  SCALED-CAPACITY: 2250.0 frames (CAPACITY:1500 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=0 ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for MARKOV Exp 1: (25, 25, 25, 25)\n",
      "üîÑ Default Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 1: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:1500, QubitAlloc=Default, SC:2250 (Scale=1.5 x Cap=1500), Seed: 20262\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 4\n",
      "\t   First reward: [0.1944, 0.5334336, 0.7380232703999999, 0.8326343725056001, 0.8726341491523584], type: <class 'list'>\n",
      "\t   First reward length: 5\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 1: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 GNEURALUCB          : Reward=0383.24, Efficiency=030.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=2250, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 1: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=0395.30, Efficiency=031.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=2250, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 1: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=0386.14, Efficiency=031.2% [Retries=3, Failed=0, < Threshold=3, SCapacity=2250, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 1: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=0421.36, Efficiency=034.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=2250, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 1: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:1500, QubitAlloc=Default, SC:2250 (Scale=1.5 x Cap=1500), Seed: 20262\n",
      "\t-->üèÜ EXP1 Winner:iCPursuitNeuralUCB  (Gap:066.0%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:1500, SCapacity=2250, Alloc=Default]\n",
      "‚úì Experiment 1 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 2000 frames  <>  SCALED-CAPACITY: 3000.0 frames (CAPACITY:2000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=1 ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for MARKOV Exp 2: (25, 25, 25, 25)\n",
      "üîÑ Default Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 2: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:2000, QubitAlloc=Default, SC:3000 (Scale=1.5 x Cap=2000), Seed: 15238\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 4\n",
      "\t   First reward: [0.1944, 0.5334336, 0.7380232703999999, 0.8326343725056001, 0.8726341491523584], type: <class 'list'>\n",
      "\t   First reward length: 5\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 2: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 GNEURALUCB          : Reward=0500.70, Efficiency=030.2% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 2: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=0542.59, Efficiency=032.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 2: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=0487.88, Efficiency=029.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 2: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=0540.09, Efficiency=032.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 2: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:2000, QubitAlloc=Default, SC:3000 (Scale=1.5 x Cap=2000), Seed: 15238\n",
      "\t-->üèÜ EXP2 Winner:EXPNeuralUCB        (Gap:067.3%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:2000, SCapacity=3000, Alloc=Default]\n",
      "‚úì Experiment 2 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 2500 frames  <>  SCALED-CAPACITY: 3750.0 frames (CAPACITY:2500 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=2 ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for MARKOV Exp 3: (25, 25, 25, 25)\n",
      "üîÑ Default Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 3: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:2500, QubitAlloc=Default, SC:3750 (Scale=1.5 x Cap=2500), Seed: 15202\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 4\n",
      "\t   First reward: [0.1944, 0.5334336, 0.7380232703999999, 0.8326343725056001, 0.8726341491523584], type: <class 'list'>\n",
      "\t   First reward length: 5\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 3: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 GNEURALUCB          : Reward=0650.79, Efficiency=031.2% [Retries=3, Failed=0, < Threshold=3, SCapacity=3750, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 3: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=0636.63, Efficiency=030.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=3750, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 3: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=0650.27, Efficiency=031.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=3750, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 3: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=0719.14, Efficiency=034.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=3750, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 3: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:2500, QubitAlloc=Default, SC:3750 (Scale=1.5 x Cap=2500), Seed: 15202\n",
      "\t-->üèÜ EXP3 Winner:iCPursuitNeuralUCB  (Gap:065.6%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:2500, SCapacity=3750, Alloc=Default]\n",
      "‚úì Experiment 3 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 3000 frames  <>  SCALED-CAPACITY: 4500.0 frames (CAPACITY:3000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=3 ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for MARKOV Exp 4: (25, 25, 25, 25)\n",
      "üîÑ Default Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 4: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:3000, QubitAlloc=Default, SC:4500 (Scale=1.5 x Cap=3000), Seed: 19699\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 4\n",
      "\t   First reward: [0.1944, 0.5334336, 0.7380232703999999, 0.8326343725056001, 0.8726341491523584], type: <class 'list'>\n",
      "\t   First reward length: 5\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 4: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 GNEURALUCB          : Reward=0801.61, Efficiency=032.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=4500, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 4: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=0680.72, Efficiency=027.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=4500, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 4: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=0765.54, Efficiency=031.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=4500, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 4: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=0825.97, Efficiency=033.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=4500, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 4: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:3000, QubitAlloc=Default, SC:4500 (Scale=1.5 x Cap=3000), Seed: 19699\n",
      "\t-->üèÜ EXP4 Winner:iCPursuitNeuralUCB  (Gap:066.6%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:3000, SCapacity=4500, Alloc=Default]\n",
      "‚úì Experiment 4 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 3500 frames  <>  SCALED-CAPACITY: 5250.0 frames (CAPACITY:3500 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=4 ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for MARKOV Exp 5: (25, 25, 25, 25)\n",
      "üîÑ Default Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 5: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:3500, QubitAlloc=Default, SC:5250 (Scale=1.5 x Cap=3500), Seed: 22085\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 4\n",
      "\t   First reward: [0.1944, 0.5334336, 0.7380232703999999, 0.8326343725056001, 0.8726341491523584], type: <class 'list'>\n",
      "\t   First reward length: 5\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 5: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 GNEURALUCB          : Reward=0958.87, Efficiency=033.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=5250, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 5: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=0855.28, Efficiency=029.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=5250, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 5: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=0943.08, Efficiency=032.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=5250, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 5: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=1011.16, Efficiency=034.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=5250, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 5: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:3500, QubitAlloc=Default, SC:5250 (Scale=1.5 x Cap=3500), Seed: 22085\n",
      "\t-->üèÜ EXP5 Winner:iCPursuitNeuralUCB  (Gap:065.1%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:3500, SCapacity=5250, Alloc=Default]\n",
      "‚úì Experiment 5 completed successfully.\n",
      "Total experiment time: 505.2s\n",
      "Experiments completed for markov\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: ADAPTIVE ADVERSARIAL ATTACK\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: ADAPTIVE\n",
      "Category: Adaptive (Reactive Strategic)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 1500 frames  <>  SCALED-CAPACITY: 2250.0 frames (CAPACITY:1500 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=0 ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 1: (25, 25, 25, 25)\n",
      "üîÑ Default Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 1: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:1500, QubitAlloc=Default, SC:2250 (Scale=1.5 x Cap=1500), Seed: 14115\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 4\n",
      "\t   First reward: [0.1944, 0.5334336, 0.7380232703999999, 0.8326343725056001, 0.8726341491523584], type: <class 'list'>\n",
      "\t   First reward length: 5\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 1: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 GNEURALUCB          : Reward=0557.53, Efficiency=041.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=2250, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 1: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=0447.10, Efficiency=033.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=2250, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 1: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=0591.98, Efficiency=044.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=2250, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 1: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=0556.41, Efficiency=041.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=2250, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 1: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:1500, QubitAlloc=Default, SC:2250 (Scale=1.5 x Cap=1500), Seed: 14115\n",
      "\t-->üèÜ EXP1 Winner:CPursuitNeuralUCB   (Gap:055.5%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:1500, SCapacity=2250, Alloc=Default]\n",
      "‚úì Experiment 1 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 2000 frames  <>  SCALED-CAPACITY: 3000.0 frames (CAPACITY:2000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=1 ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 2: (25, 25, 25, 25)\n",
      "üîÑ Default Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 2: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:2000, QubitAlloc=Default, SC:3000 (Scale=1.5 x Cap=2000), Seed: 14473\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 4\n",
      "\t   First reward: [0.1944, 0.5334336, 0.7380232703999999, 0.8326343725056001, 0.8726341491523584], type: <class 'list'>\n",
      "\t   First reward length: 5\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 2: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 GNEURALUCB          : Reward=0810.94, Efficiency=045.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 2: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=0855.74, Efficiency=048.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 2: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=0782.89, Efficiency=044.2% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 2: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=0777.53, Efficiency=043.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 2: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:2000, QubitAlloc=Default, SC:3000 (Scale=1.5 x Cap=2000), Seed: 14473\n",
      "\t-->üèÜ EXP2 Winner:EXPNeuralUCB        (Gap:051.6%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:2000, SCapacity=3000, Alloc=Default]\n",
      "‚úì Experiment 2 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 2500 frames  <>  SCALED-CAPACITY: 3750.0 frames (CAPACITY:2500 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=2 ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 3: (25, 25, 25, 25)\n",
      "üîÑ Default Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 3: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:2500, QubitAlloc=Default, SC:3750 (Scale=1.5 x Cap=2500), Seed: 13973\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 4\n",
      "\t   First reward: [0.1944, 0.5334336, 0.7380232703999999, 0.8326343725056001, 0.8726341491523584], type: <class 'list'>\n",
      "\t   First reward length: 5\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 3: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 GNEURALUCB          : Reward=1007.88, Efficiency=045.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=3750, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 3: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=1029.99, Efficiency=046.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=3750, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 3: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=1001.18, Efficiency=045.2% [Retries=3, Failed=0, < Threshold=3, SCapacity=3750, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 3: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=0993.98, Efficiency=044.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=3750, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 3: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:2500, QubitAlloc=Default, SC:3750 (Scale=1.5 x Cap=2500), Seed: 13973\n",
      "\t-->üèÜ EXP3 Winner:EXPNeuralUCB        (Gap:053.5%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:2500, SCapacity=3750, Alloc=Default]\n",
      "‚úì Experiment 3 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 3000 frames  <>  SCALED-CAPACITY: 4500.0 frames (CAPACITY:3000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=3 ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 4: (25, 25, 25, 25)\n",
      "üîÑ Default Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 4: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:3000, QubitAlloc=Default, SC:4500 (Scale=1.5 x Cap=3000), Seed: 16838\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 4\n",
      "\t   First reward: [0.1944, 0.5334336, 0.7380232703999999, 0.8326343725056001, 0.8726341491523584], type: <class 'list'>\n",
      "\t   First reward length: 5\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 4: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 GNEURALUCB          : Reward=1199.83, Efficiency=045.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=4500, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 4: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=1210.37, Efficiency=045.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=4500, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 4: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=1197.38, Efficiency=045.2% [Retries=3, Failed=0, < Threshold=3, SCapacity=4500, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 4: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=1190.66, Efficiency=045.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=4500, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 4: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:3000, QubitAlloc=Default, SC:4500 (Scale=1.5 x Cap=3000), Seed: 16838\n",
      "\t-->üèÜ EXP4 Winner:EXPNeuralUCB        (Gap:054.3%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:3000, SCapacity=4500, Alloc=Default]\n",
      "‚úì Experiment 4 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 3500 frames  <>  SCALED-CAPACITY: 5250.0 frames (CAPACITY:3500 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=4 ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 5: (25, 25, 25, 25)\n",
      "üîÑ Default Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 5: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:3500, QubitAlloc=Default, SC:5250 (Scale=1.5 x Cap=3500), Seed: 20582\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 4\n",
      "\t   First reward: [0.1944, 0.5334336, 0.7380232703999999, 0.8326343725056001, 0.8726341491523584], type: <class 'list'>\n",
      "\t   First reward length: 5\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 5: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 GNEURALUCB          : Reward=1413.43, Efficiency=045.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=5250, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 5: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=1035.51, Efficiency=033.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=5250, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 5: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=1408.06, Efficiency=045.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=5250, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 5: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=1411.51, Efficiency=045.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=5250, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 5: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:3500, QubitAlloc=Default, SC:5250 (Scale=1.5 x Cap=3500), Seed: 20582\n",
      "\t-->üèÜ EXP5 Winner:GNeuralUCB          (Gap:054.4%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:3500, SCapacity=5250, Alloc=Default]\n",
      "‚úì Experiment 5 completed successfully.\n",
      "Total experiment time: 792.8s\n",
      "Experiments completed for adaptive\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: ONLINE ADAPTIVE ATTACK\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: ONLINEADAPTIVE\n",
      "Category: Online Adaptive (Real-time Strategic)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 1500 frames  <>  SCALED-CAPACITY: 2250.0 frames (CAPACITY:1500 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=0 ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 1: (25, 25, 25, 25)\n",
      "üîÑ Default Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:1500, QubitAlloc=Default, SC:2250 (Scale=1.5 x Cap=1500), Seed: 14103\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 4\n",
      "\t   First reward: [0.1944, 0.5334336, 0.7380232703999999, 0.8326343725056001, 0.8726341491523584], type: <class 'list'>\n",
      "\t   First reward length: 5\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 GNEURALUCB          : Reward=0543.36, Efficiency=040.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=2250, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=0436.95, Efficiency=032.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=2250, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=0540.67, Efficiency=040.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=2250, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=0563.45, Efficiency=042.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=2250, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:1500, QubitAlloc=Default, SC:2250 (Scale=1.5 x Cap=1500), Seed: 14103\n",
      "\t-->üèÜ EXP1 Winner:iCPursuitNeuralUCB  (Gap:057.6%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:1500, SCapacity=2250, Alloc=Default]\n",
      "‚úì Experiment 1 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 2000 frames  <>  SCALED-CAPACITY: 3000.0 frames (CAPACITY:2000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=1 ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 2: (25, 25, 25, 25)\n",
      "üîÑ Default Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:2000, QubitAlloc=Default, SC:3000 (Scale=1.5 x Cap=2000), Seed: 22352\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 4\n",
      "\t   First reward: [0.1944, 0.5334336, 0.7380232703999999, 0.8326343725056001, 0.8726341491523584], type: <class 'list'>\n",
      "\t   First reward length: 5\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 GNEURALUCB          : Reward=0755.88, Efficiency=042.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=0671.75, Efficiency=038.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=0783.51, Efficiency=044.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=0759.13, Efficiency=042.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:2000, QubitAlloc=Default, SC:3000 (Scale=1.5 x Cap=2000), Seed: 22352\n",
      "\t-->üèÜ EXP2 Winner:CPursuitNeuralUCB   (Gap:055.7%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:2000, SCapacity=3000, Alloc=Default]\n",
      "‚úì Experiment 2 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 2500 frames  <>  SCALED-CAPACITY: 3750.0 frames (CAPACITY:2500 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=2 ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 3: (25, 25, 25, 25)\n",
      "üîÑ Default Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:2500, QubitAlloc=Default, SC:3750 (Scale=1.5 x Cap=2500), Seed: 14162\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 4\n",
      "\t   First reward: [0.1944, 0.5334336, 0.7380232703999999, 0.8326343725056001, 0.8726341491523584], type: <class 'list'>\n",
      "\t   First reward length: 5\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 GNEURALUCB          : Reward=0992.77, Efficiency=044.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=3750, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=0829.30, Efficiency=037.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=3750, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=1032.28, Efficiency=046.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=3750, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=0986.92, Efficiency=044.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=3750, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:2500, QubitAlloc=Default, SC:3750 (Scale=1.5 x Cap=2500), Seed: 14162\n",
      "\t-->üèÜ EXP3 Winner:CPursuitNeuralUCB   (Gap:053.3%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:2500, SCapacity=3750, Alloc=Default]\n",
      "‚úì Experiment 3 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 3000 frames  <>  SCALED-CAPACITY: 4500.0 frames (CAPACITY:3000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=3 ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 4: (25, 25, 25, 25)\n",
      "üîÑ Default Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:3000, QubitAlloc=Default, SC:4500 (Scale=1.5 x Cap=3000), Seed: 21587\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 4\n",
      "\t   First reward: [0.1944, 0.5334336, 0.7380232703999999, 0.8326343725056001, 0.8726341491523584], type: <class 'list'>\n",
      "\t   First reward length: 5\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 GNEURALUCB          : Reward=1209.71, Efficiency=045.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=4500, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=1198.08, Efficiency=045.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=4500, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=1234.27, Efficiency=046.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=4500, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=1171.90, Efficiency=044.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=4500, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:3000, QubitAlloc=Default, SC:4500 (Scale=1.5 x Cap=3000), Seed: 21587\n",
      "\t-->üèÜ EXP4 Winner:CPursuitNeuralUCB   (Gap:053.5%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:3000, SCapacity=4500, Alloc=Default]\n",
      "‚úì Experiment 4 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 3500 frames  <>  SCALED-CAPACITY: 5250.0 frames (CAPACITY:3500 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=4 ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 5: (25, 25, 25, 25)\n",
      "üîÑ Default Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:3500, QubitAlloc=Default, SC:5250 (Scale=1.5 x Cap=3500), Seed: 17102\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 4\n",
      "\t   First reward: [0.1944, 0.5334336, 0.7380232703999999, 0.8326343725056001, 0.8726341491523584], type: <class 'list'>\n",
      "\t   First reward length: 5\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 GNEURALUCB          : Reward=1436.64, Efficiency=046.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=5250, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=1528.58, Efficiency=049.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=5250, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=1395.43, Efficiency=045.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=5250, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=1371.78, Efficiency=044.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=5250, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:3500, QubitAlloc=Default, SC:5250 (Scale=1.5 x Cap=3500), Seed: 17102\n",
      "\t-->üèÜ EXP5 Winner:EXPNeuralUCB        (Gap:050.6%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:3500, SCapacity=5250, Alloc=Default]\n",
      "‚úì Experiment 5 completed successfully.\n",
      "Total experiment time: 2963.0s\n",
      "Experiments completed for onlineadaptive\n",
      "‚úì Scenario 'none' evaluation completed.\n",
      "‚úì Scenario 'stochastic' evaluation completed.\n",
      "‚úì Scenario 'markov' evaluation completed.\n",
      "‚úì Scenario 'adaptive' evaluation completed.\n",
      "‚úì Scenario 'onlineadaptive' evaluation completed.\n",
      "\n",
      "======================================================================\n",
      "COMPREHENSIVE SCENARIO PERFORMANCE ANALYSIS\n",
      "======================================================================\n",
      "SCENARIO: NONE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: CPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 2226.96\n",
      "\t‚Ä¢ Winner Avg Gap: 0037.84%\n",
      "\t‚Ä¢ Winner Avg Reward: 1385.93\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0062.16%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 1 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 1 wins\n",
      "\t\t- iCPursuitNeuralUCB: 3 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: NONE\n",
      "======================================================================\n",
      "SCENARIO: \tBASELINE (OPTIMAL CONDITIONS)\n",
      "----------------------------------------\n",
      "Recommended Model: \tCPursuitNeuralUCB (Won 1/5 experiments)\n",
      "\tWinner Avg Gap: \t037.8%\n",
      "\tWinner Avg Efficiency: \t062.2%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t062.2% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t061.5% Efficiency \t(Won 3/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t061.4% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t055.6% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: STOCHASTIC\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 2225.56\n",
      "\t‚Ä¢ Winner Avg Gap: 0042.22%\n",
      "\t‚Ä¢ Winner Avg Reward: 1290.55\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0057.78%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 1 wins\n",
      "\t\t- EXPNeuralUCB: 1 wins\n",
      "\t\t- CPursuitNeuralUCB: 2 wins\n",
      "\t\t- iCPursuitNeuralUCB: 1 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: STOCHASTIC\n",
      "======================================================================\n",
      "SCENARIO: \tSTOCHASTIC RANDOM FAILURES\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 1/5 experiments)\n",
      "\tWinner Avg Gap: \t042.2%\n",
      "\tWinner Avg Efficiency: \t057.8%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t057.8% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t057.2% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t057.1% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t056.9% Efficiency \t(Won 1/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: MARKOV\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 2070.26\n",
      "\t‚Ä¢ Winner Avg Gap: 0066.13%\n",
      "\t‚Ä¢ Winner Avg Reward: 0703.54\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0033.87%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 1 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 4 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: MARKOV\n",
      "======================================================================\n",
      "SCENARIO: \tMARKOV ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 4/5 experiments)\n",
      "\tWinner Avg Gap: \t066.1%\n",
      "\tWinner Avg Efficiency: \t033.9%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t033.9% Efficiency \t(Won 4/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t031.6% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t031.1% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t030.4% Efficiency \t(Won 1/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: CPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 2211.79\n",
      "\t‚Ä¢ Winner Avg Gap: 0055.07%\n",
      "\t‚Ä¢ Winner Avg Reward: 0996.30\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0044.93%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 1 wins\n",
      "\t\t- EXPNeuralUCB: 3 wins\n",
      "\t\t- CPursuitNeuralUCB: 1 wins\n",
      "\t\t- iCPursuitNeuralUCB: 0 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tADAPTIVE ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tCPursuitNeuralUCB (Won 1/5 experiments)\n",
      "\tWinner Avg Gap: \t055.1%\n",
      "\tWinner Avg Efficiency: \t044.9%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t044.9% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t044.8% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t044.2% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t041.5% Efficiency \t(Won 3/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ONLINEADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: CPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 2211.24\n",
      "\t‚Ä¢ Winner Avg Gap: 0055.34%\n",
      "\t‚Ä¢ Winner Avg Reward: 0997.23\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0044.66%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 1 wins\n",
      "\t\t- CPursuitNeuralUCB: 3 wins\n",
      "\t\t- iCPursuitNeuralUCB: 1 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ONLINEADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tONLINE ADAPTIVE ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tCPursuitNeuralUCB (Won 3/5 experiments)\n",
      "\tWinner Avg Gap: \t055.3%\n",
      "\tWinner Avg Efficiency: \t044.7%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t044.7% Efficiency \t(Won 3/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t044.1% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t043.7% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t040.6% Efficiency \t(Won 1/5 experiments)\n",
      "======================================================================\n",
      "KEY INSIGHTS:\n",
      "Best Performing Model Analysis (iCPursuitNeuralUCB):\n",
      "\t‚Ä¢ Stochastic Performance:    \t1290.552\n",
      "\t‚Ä¢ Baseline Performance:      \t1385.928\n",
      "\t‚Ä¢ Performance Retention:     \t093.1%\n",
      "\tGOOD:               \tAcceptable performance under stochastic conditions\n",
      "Statistical Analysis:\n",
      "\t‚Ä¢ Total models evaluated:     \t5\n",
      "\t‚Ä¢ Experiments per environment:\t5\n",
      "\t‚Ä¢ Quantum network simulation: \tComprehensive stochastic modeling\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "COMPREHENSIVE SCENARIO PERFORMANCE ANALYSIS\n",
      "======================================================================\n",
      "SCENARIO: NONE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: CPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 2226.96\n",
      "\t‚Ä¢ Winner Avg Gap: 0037.84%\n",
      "\t‚Ä¢ Winner Avg Reward: 1385.93\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0062.16%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 1 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 1 wins\n",
      "\t\t- iCPursuitNeuralUCB: 3 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: NONE\n",
      "======================================================================\n",
      "SCENARIO: \tBASELINE (OPTIMAL CONDITIONS)\n",
      "----------------------------------------\n",
      "Recommended Model: \tCPursuitNeuralUCB (Won 1/5 experiments)\n",
      "\tWinner Avg Gap: \t037.8%\n",
      "\tWinner Avg Efficiency: \t062.2%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t062.2% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t061.5% Efficiency \t(Won 3/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t061.4% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t055.6% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: STOCHASTIC\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 2225.56\n",
      "\t‚Ä¢ Winner Avg Gap: 0042.22%\n",
      "\t‚Ä¢ Winner Avg Reward: 1290.55\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0057.78%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 1 wins\n",
      "\t\t- EXPNeuralUCB: 1 wins\n",
      "\t\t- CPursuitNeuralUCB: 2 wins\n",
      "\t\t- iCPursuitNeuralUCB: 1 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: STOCHASTIC\n",
      "======================================================================\n",
      "SCENARIO: \tSTOCHASTIC RANDOM FAILURES\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 1/5 experiments)\n",
      "\tWinner Avg Gap: \t042.2%\n",
      "\tWinner Avg Efficiency: \t057.8%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t057.8% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t057.2% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t057.1% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t056.9% Efficiency \t(Won 1/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: MARKOV\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 2070.26\n",
      "\t‚Ä¢ Winner Avg Gap: 0066.13%\n",
      "\t‚Ä¢ Winner Avg Reward: 0703.54\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0033.87%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 1 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 4 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: MARKOV\n",
      "======================================================================\n",
      "SCENARIO: \tMARKOV ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 4/5 experiments)\n",
      "\tWinner Avg Gap: \t066.1%\n",
      "\tWinner Avg Efficiency: \t033.9%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t033.9% Efficiency \t(Won 4/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t031.6% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t031.1% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t030.4% Efficiency \t(Won 1/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: CPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 2211.79\n",
      "\t‚Ä¢ Winner Avg Gap: 0055.07%\n",
      "\t‚Ä¢ Winner Avg Reward: 0996.30\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0044.93%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 1 wins\n",
      "\t\t- EXPNeuralUCB: 3 wins\n",
      "\t\t- CPursuitNeuralUCB: 1 wins\n",
      "\t\t- iCPursuitNeuralUCB: 0 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tADAPTIVE ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tCPursuitNeuralUCB (Won 1/5 experiments)\n",
      "\tWinner Avg Gap: \t055.1%\n",
      "\tWinner Avg Efficiency: \t044.9%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t044.9% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t044.8% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t044.2% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t041.5% Efficiency \t(Won 3/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ONLINEADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: CPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 2211.24\n",
      "\t‚Ä¢ Winner Avg Gap: 0055.34%\n",
      "\t‚Ä¢ Winner Avg Reward: 0997.23\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0044.66%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 1 wins\n",
      "\t\t- CPursuitNeuralUCB: 3 wins\n",
      "\t\t- iCPursuitNeuralUCB: 1 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ONLINEADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tONLINE ADAPTIVE ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tCPursuitNeuralUCB (Won 3/5 experiments)\n",
      "\tWinner Avg Gap: \t055.3%\n",
      "\tWinner Avg Efficiency: \t044.7%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t044.7% Efficiency \t(Won 3/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t044.1% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t043.7% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t040.6% Efficiency \t(Won 1/5 experiments)\n",
      "======================================================================\n",
      "‚úÖ Evaluation completed!\n",
      "[Logging Redirect Stopped]\n",
      "\n",
      "üßπ Final cleanup for Default\n",
      "\n",
      "======================================================================\n",
      "‚úÖ COMPLETED: Default\n",
      "======================================================================\n",
      "\n",
      "Default COMPLETED SUCCESSFULLY\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Preparing: Default at scale 2\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üîß Generating physics parameters for model: paper12\n",
      "\n",
      "===================== GET LOCAL REGISTRY =====================\n",
      "‚Üí Skipping local cache (force=True or file missing)\n",
      "\n",
      "===================== BUILD LOCAL REGISTRY =====================\n",
      "\n",
      "================================================================================\n",
      "üîç SCANNING LOCAL FILES\n",
      "================================================================================\n",
      "Parameters: load_to_drive=False, force=False\n",
      "\n",
      "üìÇ Checking DRIVE mode: /content/drive/Shareddrives/ai_quantum_computing/quantum_data_lake\n",
      "   ‚ö†Ô∏è  Path does not exist, skipping\n",
      "\n",
      "üìÇ Checking LOCAL mode: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config\n",
      "   ‚úÖ Path exists, starting walk...\n",
      "   üö∂ Walking directory tree: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config\n",
      "\n",
      "   üìÅ Directory: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201\n",
      "      Relative: framework_state/day_20260201\n",
      "      Component: framework_state\n",
      "      Date: day_20260201\n",
      "      üìÑ Processing 2524 files in framework_state/day_20260201\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "      üìä framework_state/day_20260201: 2498/2524 files processed\n",
      "      üìä framework_state/day_20260201: 0/2524 files skipped\n",
      "      üìä framework_state/day_20260201: 26/2524 files conflicted\n",
      "\n",
      "   üìÅ Directory: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/model_state/day_20260201\n",
      "      Relative: model_state/day_20260201\n",
      "      Component: model_state\n",
      "      Date: day_20260201\n",
      "      üìÑ Processing 8934 files in model_state/day_20260201\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "      üìä model_state/day_20260201: 8934/8934 files processed\n",
      "      üìä model_state/day_20260201: 0/8934 files skipped\n",
      "      üìä model_state/day_20260201: 0/8934 files conflicted\n",
      "\n",
      "   üìä Processed 2 directories\n",
      "\n",
      "================================================================================\n",
      "üì¶ BUILDING FINAL REGISTRY\n",
      "================================================================================\n",
      "Components found: ['framework_state', 'model_state']\n",
      "  ‚Ä¢ framework_state: 2498 files\n",
      "  ‚Ä¢ model_state: 8934 files\n",
      "\n",
      "‚úÖ SCAN COMPLETE\n",
      "Modes scanned: 1\n",
      "Total files in registry: 11432\n",
      "================================================================================\n",
      "\n",
      "\t‚Üí Filesystem scan found 11432 files\n",
      "\n",
      "===================== GET DRIVE REGISTRY =====================\n",
      "===================== REGISTRY BUILD COMPLETE =====================\n",
      "\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "\tüì¶ LocalBackupManager Registry Saved Locally in LOCAL\n",
      "BUILDING REGISTRY WITH 0 EXPECTED COMPONENTS KEYS\n",
      "\n",
      "===================== GET LOCAL REGISTRY =====================\n",
      "‚Üí Skipping local cache (force=True or file missing)\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "\tüì¶ LocalBackupManager Registry Saved Locally in LOCAL\n",
      "\n",
      "======================================================================\n",
      "üéØ AllocatorRunner initialized: Default\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "üöÄ STARTING ALLOCATOR: Default\n",
      "======================================================================\n",
      "\n",
      "üìä Physics Model: paper12\n",
      "\n",
      "üìã Allocator Config:\n",
      "   Type: Default\n",
      "   Testbed: paper12\n",
      "   Paths: 4\n",
      "   Total Qubits: 100\n",
      "   Min per route: 3\n",
      "   Seed: 42\n",
      "‚úÖ Allocator created: (25, 25, 25, 25)\n",
      "‚úì Allocator: QubitAllocator (4 paths)\n",
      "   Initial allocation: (25, 25, 25, 25)\n",
      "Generated paper12 Waxman topology: 100 nodes, 415 edges, avg degree: 8.30\n",
      "üìä Paper12 Physics: Fusion (prob=0.9)\n",
      "\n",
      "======================================================================\n",
      "RUN 1 | Scale: 2 | Exp: 5\n",
      "======================================================================\n",
      "üîÑ Default Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "\n",
      "\tüîÑ Resume: MultiRunEvaluator\n",
      "\n",
      "=====================================================\n",
      "üîç GENERATING EXPECTED KEYS FROM EVALUATOR\n",
      "=====================================================\n",
      "  ‚Ä¢ Evaluator filename: MultiRunEvaluator_3000-Default_All_All-1500_500_5_S2T_paper12.pkl\n",
      "\n",
      "üß© PARSED COMPONENTS\n",
      "  ‚Ä¢ cap_id:        3000\n",
      "  ‚Ä¢ allocator_id:  Default\n",
      "  ‚Ä¢ env_id:        All\n",
      "  ‚Ä¢ attack_id:     All\n",
      "  ‚Ä¢ base_frames:   1500\n",
      "  ‚Ä¢ frame_step:    500\n",
      "  ‚Ä¢ runs_id:       5\n",
      "\n",
      "=====================================================\n",
      "üß™ GENERATING KEYS FOR EACH RUN\n",
      "=====================================================\n",
      "\n",
      "--- Run 1/5 -----------------------\n",
      "\n",
      "=====================================================\n",
      "üì¶ FINAL EXPECTED KEYS\n",
      "=====================================================\n",
      "  ‚Ä¢ Runner keys: 11\n",
      "\n",
      "  ‚Ä¢ Model keys: 50\n",
      "\n",
      "--- Run 2/5 -----------------------\n",
      "\n",
      "=====================================================\n",
      "üì¶ FINAL EXPECTED KEYS\n",
      "=====================================================\n",
      "  ‚Ä¢ Runner keys: 21\n",
      "\n",
      "  ‚Ä¢ Model keys: 100\n",
      "\n",
      "--- Run 3/5 -----------------------\n",
      "\n",
      "=====================================================\n",
      "üì¶ FINAL EXPECTED KEYS\n",
      "=====================================================\n",
      "  ‚Ä¢ Runner keys: 31\n",
      "\n",
      "  ‚Ä¢ Model keys: 150\n",
      "\n",
      "--- Run 4/5 -----------------------\n",
      "\n",
      "=====================================================\n",
      "üì¶ FINAL EXPECTED KEYS\n",
      "=====================================================\n",
      "  ‚Ä¢ Runner keys: 41\n",
      "\n",
      "  ‚Ä¢ Model keys: 200\n",
      "\n",
      "--- Run 5/5 -----------------------\n",
      "\n",
      "=====================================================\n",
      "üì¶ FINAL EXPECTED KEYS\n",
      "=====================================================\n",
      "  ‚Ä¢ Runner keys: 51\n",
      "\n",
      "  ‚Ä¢ Model keys: 250\n",
      "\n",
      "EXPECTED KEY GENERATION COMPLETE\n",
      "\n",
      "RESTORING FROM DRIVE 1\n",
      "RESTORING FROM DRIVE 2\n",
      "\t‚ö†Ô∏è Registry exists ‚Üí aborting restore\n",
      "\t‚úì MultiRunEvaluator Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/MultiRunEvaluator_3000-Default_All_All-1500_500_5_S2T_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/MultiRunEvaluator_3000-Default_All_All-1500_500_5_S2T_paper12.pkl\n",
      "\t   File exists: True, size: 57179547\n",
      "EQUAL METHOD\n",
      "Multi-Run Evaluator Initialized\n",
      "Environment Type: None\n",
      "Frame Range: 1500 -> 3500 (step: 500)\n",
      "quantum_exps-Default(paper12)_alloc-all_envs-5_attacks-1500_500-5_runs-S2T\n",
      "[Logging Redirect Initialized]\n",
      "Log File: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/quantum_logs/quantum_exps-Default(paper12)_alloc-all_envs-5_attacks-1500_500-5_runs-S2T_20260201_log.txt\n",
      "‚öô Running evaluation...\n",
      "======================================================================\n",
      "SCENARIOS MODEL EVALUATION\n",
      "======================================================================\n",
      "Testing algorithm performance against:\n",
      "\t‚Ä¢ Stochastic:  \tNatural quantum decoherence and network failures\n",
      "\t‚Ä¢ Baseline:    \tOptimal conditions for validation\n",
      "======================================================================\n",
      "Models to Test:             \tOracle, GNeuralUCB, EXPNeuralUCB, CPursuitNeuralUCB, iCPursuitNeuralUCB\n",
      "Experiments per Scenario:   \t5\n",
      "======================================================================\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: BASELINE (OPTIMAL CONDITIONS)\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: NONE\n",
      "Category: Baseline (No Attacks)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 1500 frames  <>  SCALED-CAPACITY: 3000 frames (CAPACITY:1500 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=0 ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for NONE Exp 1: (25, 25, 25, 25)\n",
      "üîÑ Default Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 1: Env:Baseline (None), Attack:No, Rate:0.0, Frames:1500, QubitAlloc=Default, SC:3000 (Scale=2 x Cap=1500), Seed: 18010\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_1\n",
      "\t‚úì QuantumExperimentRunner_1 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_3000-Default_Baseline (None)_No-1500_1_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_3000-Default_Baseline (None)_No-1500_1_paper12.pkl\n",
      "\t   File exists: True, size: 707998\n",
      "‚è© SKIPPING EXPERIMENT 1: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 1 GNEURALUCB          : Reward=0661.98, Efficiency=050.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.582]\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=0630.53, Efficiency=047.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.628]\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=0663.47, Efficiency=050.2% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.634]\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=0666.27, Efficiency=050.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP1 Winner:iCPursuitNeuralUCB  (Gap:049.6%) [Env:Baseline (None), Attack:No X Rate:0.25, Frames:1500, SCapacity=3000, Alloc=Default]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 2000 frames  <>  SCALED-CAPACITY: 4000 frames (CAPACITY:2000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=1 ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for NONE Exp 2: (25, 25, 25, 25)\n",
      "üîÑ Default Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 2: Env:Baseline (None), Attack:No, Rate:0.0, Frames:2000, QubitAlloc=Default, SC:4000 (Scale=2 x Cap=2000), Seed: 20078\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_2\n",
      "\t‚úì QuantumExperimentRunner_2 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_4000-Default_Baseline (None)_No-2000_2_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_4000-Default_Baseline (None)_No-2000_2_paper12.pkl\n",
      "\t   File exists: True, size: 930034\n",
      "‚è© SKIPPING EXPERIMENT 2: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 2 GNEURALUCB          : Reward=0878.41, Efficiency=049.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=4000, Threshold=0.582]\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=0930.26, Efficiency=052.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=4000, Threshold=0.628]\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=0900.58, Efficiency=051.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=4000, Threshold=0.634]\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=0885.71, Efficiency=050.2% [Retries=3, Failed=0, < Threshold=3, SCapacity=4000, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP2 Winner:EXPNeuralUCB        (Gap:047.2%) [Env:Baseline (None), Attack:No X Rate:0.25, Frames:2000, SCapacity=4000, Alloc=Default]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 2500 frames  <>  SCALED-CAPACITY: 5000 frames (CAPACITY:2500 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=2 ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for NONE Exp 3: (25, 25, 25, 25)\n",
      "üîÑ Default Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 3: Env:Baseline (None), Attack:No, Rate:0.0, Frames:2500, QubitAlloc=Default, SC:5000 (Scale=2 x Cap=2500), Seed: 14623\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_3\n",
      "\t‚úì QuantumExperimentRunner_3 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_5000-Default_Baseline (None)_No-2500_3_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_5000-Default_Baseline (None)_No-2500_3_paper12.pkl\n",
      "\t   File exists: True, size: 1152093\n",
      "‚è© SKIPPING EXPERIMENT 3: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 3 GNEURALUCB          : Reward=1099.32, Efficiency=049.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=5000, Threshold=0.582]\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=1103.31, Efficiency=050.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=5000, Threshold=0.628]\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=1095.85, Efficiency=049.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=5000, Threshold=0.634]\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=1120.84, Efficiency=050.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=5000, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP3 Winner:iCPursuitNeuralUCB  (Gap:049.1%) [Env:Baseline (None), Attack:No X Rate:0.25, Frames:2500, SCapacity=5000, Alloc=Default]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 3000 frames  <>  SCALED-CAPACITY: 6000 frames (CAPACITY:3000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=3 ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for NONE Exp 4: (25, 25, 25, 25)\n",
      "üîÑ Default Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 4: Env:Baseline (None), Attack:No, Rate:0.0, Frames:3000, QubitAlloc=Default, SC:6000 (Scale=2 x Cap=3000), Seed: 20090\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_4\n",
      "\t‚úì QuantumExperimentRunner_4 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_6000-Default_Baseline (None)_No-3000_4_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_6000-Default_Baseline (None)_No-3000_4_paper12.pkl\n",
      "\t   File exists: True, size: 1374120\n",
      "‚è© SKIPPING EXPERIMENT 4: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 4 GNEURALUCB          : Reward=1337.49, Efficiency=050.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=6000, Threshold=0.582]\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=1235.25, Efficiency=046.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=6000, Threshold=0.628]\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=1358.68, Efficiency=051.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=6000, Threshold=0.634]\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=1384.60, Efficiency=052.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=6000, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP4 Winner:iCPursuitNeuralUCB  (Gap:047.7%) [Env:Baseline (None), Attack:No X Rate:0.25, Frames:3000, SCapacity=6000, Alloc=Default]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 3500 frames  <>  SCALED-CAPACITY: 7000 frames (CAPACITY:3500 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=4 ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for NONE Exp 5: (25, 25, 25, 25)\n",
      "üîÑ Default Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 5: Env:Baseline (None), Attack:No, Rate:0.0, Frames:3500, QubitAlloc=Default, SC:7000 (Scale=2 x Cap=3500), Seed: 12926\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_5\n",
      "\t‚úì QuantumExperimentRunner_5 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_7000-Default_Baseline (None)_No-3500_5_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_7000-Default_Baseline (None)_No-3500_5_paper12.pkl\n",
      "\t   File exists: True, size: 1596188\n",
      "‚è© SKIPPING EXPERIMENT 5: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 5 GNEURALUCB          : Reward=1541.43, Efficiency=050.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=7000, Threshold=0.582]\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=1522.04, Efficiency=049.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=7000, Threshold=0.628]\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=1570.02, Efficiency=050.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=7000, Threshold=0.634]\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=1582.69, Efficiency=051.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=7000, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP5 Winner:iCPursuitNeuralUCB  (Gap:048.7%) [Env:Baseline (None), Attack:No X Rate:0.25, Frames:3500, SCapacity=7000, Alloc=Default]\n",
      "\n",
      "Total experiment time: 035.4s\n",
      "Experiments completed for none\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: STOCHASTIC RANDOM FAILURES\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: STOCHASTIC\n",
      "Category: Stochastic (Natural Random Failures)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 1500 frames  <>  SCALED-CAPACITY: 3000 frames (CAPACITY:1500 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=0 ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 1: (25, 25, 25, 25)\n",
      "üîÑ Default Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 1: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:1500, QubitAlloc=Default, SC:3000 (Scale=2 x Cap=1500), Seed: 20197\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_1\n",
      "\t‚úì QuantumExperimentRunner_1 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_3000-Default_Stochastic_Random-1500_1_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_3000-Default_Stochastic_Random-1500_1_paper12.pkl\n",
      "\t   File exists: True, size: 708002\n",
      "‚è© SKIPPING EXPERIMENT 1: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 1 GNEURALUCB          : Reward=0619.11, Efficiency=046.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.582]\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=0641.54, Efficiency=048.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.628]\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=0638.23, Efficiency=048.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.634]\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=0609.92, Efficiency=046.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP1 Winner:EXPNeuralUCB        (Gap:051.5%) [Env:Stochastic, Attack:Random X Rate:0.25, Frames:1500, SCapacity=3000, Alloc=Default]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 2000 frames  <>  SCALED-CAPACITY: 4000 frames (CAPACITY:2000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=1 ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 2: (25, 25, 25, 25)\n",
      "üîÑ Default Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 2: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:2000, QubitAlloc=Default, SC:4000 (Scale=2 x Cap=2000), Seed: 17474\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_2\n",
      "\t‚úì QuantumExperimentRunner_2 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_4000-Default_Stochastic_Random-2000_2_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_4000-Default_Stochastic_Random-2000_2_paper12.pkl\n",
      "\t   File exists: True, size: 930038\n",
      "‚è© SKIPPING EXPERIMENT 2: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 2 GNEURALUCB          : Reward=0861.64, Efficiency=048.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=4000, Threshold=0.582]\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=0845.52, Efficiency=048.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=4000, Threshold=0.628]\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=0798.76, Efficiency=045.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=4000, Threshold=0.634]\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=0859.05, Efficiency=048.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=4000, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP2 Winner:GNeuralUCB          (Gap:051.1%) [Env:Stochastic, Attack:Random X Rate:0.25, Frames:2000, SCapacity=4000, Alloc=Default]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 2500 frames  <>  SCALED-CAPACITY: 5000 frames (CAPACITY:2500 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=2 ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 3: (25, 25, 25, 25)\n",
      "üîÑ Default Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 3: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:2500, QubitAlloc=Default, SC:5000 (Scale=2 x Cap=2500), Seed: 15795\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_3\n",
      "\t‚úì QuantumExperimentRunner_3 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_5000-Default_Stochastic_Random-2500_3_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_5000-Default_Stochastic_Random-2500_3_paper12.pkl\n",
      "\t   File exists: True, size: 1152097\n",
      "‚è© SKIPPING EXPERIMENT 3: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 3 GNEURALUCB          : Reward=1032.87, Efficiency=046.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=5000, Threshold=0.582]\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=1021.94, Efficiency=046.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=5000, Threshold=0.628]\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=1032.48, Efficiency=046.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=5000, Threshold=0.634]\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=1029.23, Efficiency=046.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=5000, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP3 Winner:GNeuralUCB          (Gap:053.1%) [Env:Stochastic, Attack:Random X Rate:0.25, Frames:2500, SCapacity=5000, Alloc=Default]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 3000 frames  <>  SCALED-CAPACITY: 6000 frames (CAPACITY:3000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=3 ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 4: (25, 25, 25, 25)\n",
      "üîÑ Default Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 4: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:3000, QubitAlloc=Default, SC:6000 (Scale=2 x Cap=3000), Seed: 17031\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_4\n",
      "\t‚úì QuantumExperimentRunner_4 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_6000-Default_Stochastic_Random-3000_4_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_6000-Default_Stochastic_Random-3000_4_paper12.pkl\n",
      "\t   File exists: True, size: 1374124\n",
      "‚è© SKIPPING EXPERIMENT 4: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 4 GNEURALUCB          : Reward=1269.73, Efficiency=048.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=6000, Threshold=0.582]\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=1213.96, Efficiency=045.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=6000, Threshold=0.628]\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=1174.29, Efficiency=044.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=6000, Threshold=0.634]\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=1279.11, Efficiency=048.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=6000, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP4 Winner:iCPursuitNeuralUCB  (Gap:051.6%) [Env:Stochastic, Attack:Random X Rate:0.25, Frames:3000, SCapacity=6000, Alloc=Default]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 3500 frames  <>  SCALED-CAPACITY: 7000 frames (CAPACITY:3500 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=4 ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 5: (25, 25, 25, 25)\n",
      "üîÑ Default Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 5: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:3500, QubitAlloc=Default, SC:7000 (Scale=2 x Cap=3500), Seed: 21490\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_5\n",
      "\t‚úì QuantumExperimentRunner_5 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_7000-Default_Stochastic_Random-3500_5_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_7000-Default_Stochastic_Random-3500_5_paper12.pkl\n",
      "\t   File exists: True, size: 1596192\n",
      "‚è© SKIPPING EXPERIMENT 5: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 5 GNEURALUCB          : Reward=1449.95, Efficiency=047.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=7000, Threshold=0.582]\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=1506.62, Efficiency=048.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=7000, Threshold=0.628]\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=1492.56, Efficiency=048.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=7000, Threshold=0.634]\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=1506.87, Efficiency=048.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=7000, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP5 Winner:iCPursuitNeuralUCB  (Gap:051.1%) [Env:Stochastic, Attack:Random X Rate:0.25, Frames:3500, SCapacity=7000, Alloc=Default]\n",
      "\n",
      "Total experiment time: 058.3s\n",
      "Experiments completed for stochastic\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: MARKOV ADVERSARIAL ATTACK\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: MARKOV\n",
      "Category: Structured (Markov Chain Based)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 1500 frames  <>  SCALED-CAPACITY: 3000 frames (CAPACITY:1500 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=0 ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for MARKOV Exp 1: (25, 25, 25, 25)\n",
      "üîÑ Default Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 1: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:1500, QubitAlloc=Default, SC:3000 (Scale=2 x Cap=1500), Seed: 20262\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_1\n",
      "\t‚úì QuantumExperimentRunner_1 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_3000-Default_Adversarial_Markov-1500_1_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_3000-Default_Adversarial_Markov-1500_1_paper12.pkl\n",
      "\t   File exists: True, size: 708000\n",
      "‚è© SKIPPING EXPERIMENT 1: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 1 GNEURALUCB          : Reward=0362.46, Efficiency=029.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.582]\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=0305.77, Efficiency=024.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.628]\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=0336.71, Efficiency=027.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.634]\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=0349.91, Efficiency=028.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP1 Winner:GNeuralUCB          (Gap:070.4%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:1500, SCapacity=3000, Alloc=Default]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 2000 frames  <>  SCALED-CAPACITY: 4000 frames (CAPACITY:2000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=1 ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for MARKOV Exp 2: (25, 25, 25, 25)\n",
      "üîÑ Default Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 2: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:2000, QubitAlloc=Default, SC:4000 (Scale=2 x Cap=2000), Seed: 15238\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_2\n",
      "\t‚úì QuantumExperimentRunner_2 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_4000-Default_Adversarial_Markov-2000_2_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_4000-Default_Adversarial_Markov-2000_2_paper12.pkl\n",
      "\t   File exists: True, size: 930036\n",
      "‚è© SKIPPING EXPERIMENT 2: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 2 GNEURALUCB          : Reward=0451.69, Efficiency=027.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=4000, Threshold=0.582]\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=0420.37, Efficiency=025.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=4000, Threshold=0.628]\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=0488.71, Efficiency=029.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=4000, Threshold=0.634]\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=0487.87, Efficiency=029.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=4000, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP2 Winner:CPursuitNeuralUCB   (Gap:070.4%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:2000, SCapacity=4000, Alloc=Default]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 2500 frames  <>  SCALED-CAPACITY: 5000 frames (CAPACITY:2500 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=2 ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for MARKOV Exp 3: (25, 25, 25, 25)\n",
      "üîÑ Default Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 3: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:2500, QubitAlloc=Default, SC:5000 (Scale=2 x Cap=2500), Seed: 15202\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_3\n",
      "\t‚úì QuantumExperimentRunner_3 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_5000-Default_Adversarial_Markov-2500_3_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_5000-Default_Adversarial_Markov-2500_3_paper12.pkl\n",
      "\t   File exists: True, size: 1152095\n",
      "‚è© SKIPPING EXPERIMENT 3: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 3 GNEURALUCB          : Reward=0583.18, Efficiency=028.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=5000, Threshold=0.582]\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=0549.72, Efficiency=026.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=5000, Threshold=0.628]\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=0573.26, Efficiency=028.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=5000, Threshold=0.634]\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=0617.10, Efficiency=030.2% [Retries=3, Failed=0, < Threshold=3, SCapacity=5000, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP3 Winner:iCPursuitNeuralUCB  (Gap:069.8%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:2500, SCapacity=5000, Alloc=Default]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 3000 frames  <>  SCALED-CAPACITY: 6000 frames (CAPACITY:3000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=3 ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for MARKOV Exp 4: (25, 25, 25, 25)\n",
      "üîÑ Default Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 4: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:3000, QubitAlloc=Default, SC:6000 (Scale=2 x Cap=3000), Seed: 19699\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_4\n",
      "\t‚úì QuantumExperimentRunner_4 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_6000-Default_Adversarial_Markov-3000_4_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_6000-Default_Adversarial_Markov-3000_4_paper12.pkl\n",
      "\t   File exists: True, size: 1374122\n",
      "‚è© SKIPPING EXPERIMENT 4: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 4 GNEURALUCB          : Reward=0716.30, Efficiency=028.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=6000, Threshold=0.582]\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=0664.22, Efficiency=026.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=6000, Threshold=0.628]\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=0637.57, Efficiency=025.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=6000, Threshold=0.634]\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=0702.37, Efficiency=028.2% [Retries=3, Failed=0, < Threshold=3, SCapacity=6000, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP4 Winner:GNeuralUCB          (Gap:071.3%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:3000, SCapacity=6000, Alloc=Default]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 3500 frames  <>  SCALED-CAPACITY: 7000 frames (CAPACITY:3500 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=4 ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for MARKOV Exp 5: (25, 25, 25, 25)\n",
      "üîÑ Default Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 5: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:3500, QubitAlloc=Default, SC:7000 (Scale=2 x Cap=3500), Seed: 22085\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_5\n",
      "\t‚úì QuantumExperimentRunner_5 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_7000-Default_Adversarial_Markov-3500_5_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_7000-Default_Adversarial_Markov-3500_5_paper12.pkl\n",
      "\t   File exists: True, size: 1596190\n",
      "‚è© SKIPPING EXPERIMENT 5: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 5 GNEURALUCB          : Reward=0837.93, Efficiency=029.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=7000, Threshold=0.582]\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=0747.23, Efficiency=025.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=7000, Threshold=0.628]\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=0793.31, Efficiency=027.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=7000, Threshold=0.634]\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=0818.16, Efficiency=028.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=7000, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP5 Winner:GNeuralUCB          (Gap:071.0%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:3500, SCapacity=7000, Alloc=Default]\n",
      "\n",
      "Total experiment time: 055.3s\n",
      "Experiments completed for markov\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: ADAPTIVE ADVERSARIAL ATTACK\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: ADAPTIVE\n",
      "Category: Adaptive (Reactive Strategic)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 1500 frames  <>  SCALED-CAPACITY: 3000 frames (CAPACITY:1500 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=0 ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 1: (25, 25, 25, 25)\n",
      "üîÑ Default Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 1: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:1500, QubitAlloc=Default, SC:3000 (Scale=2 x Cap=1500), Seed: 14115\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_1\n",
      "\t‚úì QuantumExperimentRunner_1 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_3000-Default_Adversarial_Adaptive-1500_1_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_3000-Default_Adversarial_Adaptive-1500_1_paper12.pkl\n",
      "\t   File exists: True, size: 708006\n",
      "‚è© SKIPPING EXPERIMENT 1: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 1 GNEURALUCB          : Reward=0460.26, Efficiency=034.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.582]\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=0461.16, Efficiency=035.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.628]\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=0475.60, Efficiency=036.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.634]\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=0496.17, Efficiency=037.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP1 Winner:iCPursuitNeuralUCB  (Gap:062.3%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:1500, SCapacity=3000, Alloc=Default]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 2000 frames  <>  SCALED-CAPACITY: 4000 frames (CAPACITY:2000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=1 ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 2: (25, 25, 25, 25)\n",
      "üîÑ Default Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 2: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:2000, QubitAlloc=Default, SC:4000 (Scale=2 x Cap=2000), Seed: 14473\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_2\n",
      "\t‚úì QuantumExperimentRunner_2 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_4000-Default_Adversarial_Adaptive-2000_2_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_4000-Default_Adversarial_Adaptive-2000_2_paper12.pkl\n",
      "\t   File exists: True, size: 930042\n",
      "‚è© SKIPPING EXPERIMENT 2: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 2 GNEURALUCB          : Reward=0633.31, Efficiency=036.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=4000, Threshold=0.582]\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=0650.37, Efficiency=037.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=4000, Threshold=0.628]\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=0664.83, Efficiency=037.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=4000, Threshold=0.634]\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=0656.96, Efficiency=037.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=4000, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP2 Winner:CPursuitNeuralUCB   (Gap:062.1%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:2000, SCapacity=4000, Alloc=Default]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 2500 frames  <>  SCALED-CAPACITY: 5000 frames (CAPACITY:2500 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=2 ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 3: (25, 25, 25, 25)\n",
      "üîÑ Default Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 3: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:2500, QubitAlloc=Default, SC:5000 (Scale=2 x Cap=2500), Seed: 13973\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_3\n",
      "\t‚úì QuantumExperimentRunner_3 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_5000-Default_Adversarial_Adaptive-2500_3_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_5000-Default_Adversarial_Adaptive-2500_3_paper12.pkl\n",
      "\t   File exists: True, size: 1152101\n",
      "‚è© SKIPPING EXPERIMENT 3: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 3 GNEURALUCB          : Reward=0788.23, Efficiency=036.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=5000, Threshold=0.582]\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=0910.26, Efficiency=041.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=5000, Threshold=0.628]\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=0814.56, Efficiency=037.2% [Retries=3, Failed=0, < Threshold=3, SCapacity=5000, Threshold=0.634]\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=0810.20, Efficiency=037.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=5000, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP3 Winner:EXPNeuralUCB        (Gap:058.4%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:2500, SCapacity=5000, Alloc=Default]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 3000 frames  <>  SCALED-CAPACITY: 6000 frames (CAPACITY:3000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=3 ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 4: (25, 25, 25, 25)\n",
      "üîÑ Default Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 4: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:3000, QubitAlloc=Default, SC:6000 (Scale=2 x Cap=3000), Seed: 16838\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_4\n",
      "\t‚úì QuantumExperimentRunner_4 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_6000-Default_Adversarial_Adaptive-3000_4_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_6000-Default_Adversarial_Adaptive-3000_4_paper12.pkl\n",
      "\t   File exists: True, size: 1374128\n",
      "‚è© SKIPPING EXPERIMENT 4: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 4 GNEURALUCB          : Reward=0944.74, Efficiency=035.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=6000, Threshold=0.582]\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=1004.95, Efficiency=038.2% [Retries=3, Failed=0, < Threshold=3, SCapacity=6000, Threshold=0.628]\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=1004.03, Efficiency=038.2% [Retries=3, Failed=0, < Threshold=3, SCapacity=6000, Threshold=0.634]\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=0974.25, Efficiency=037.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=6000, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP4 Winner:EXPNeuralUCB        (Gap:061.8%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:3000, SCapacity=6000, Alloc=Default]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 3500 frames  <>  SCALED-CAPACITY: 7000 frames (CAPACITY:3500 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=4 ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 5: (25, 25, 25, 25)\n",
      "üîÑ Default Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 5: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:3500, QubitAlloc=Default, SC:7000 (Scale=2 x Cap=3500), Seed: 20582\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_5\n",
      "\t‚úì QuantumExperimentRunner_5 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_7000-Default_Adversarial_Adaptive-3500_5_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_7000-Default_Adversarial_Adaptive-3500_5_paper12.pkl\n",
      "\t   File exists: True, size: 1596196\n",
      "‚è© SKIPPING EXPERIMENT 5: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 5 GNEURALUCB          : Reward=1184.82, Efficiency=038.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=7000, Threshold=0.582]\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=1146.98, Efficiency=037.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=7000, Threshold=0.628]\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=1195.05, Efficiency=039.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=7000, Threshold=0.634]\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=1166.06, Efficiency=038.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=7000, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP5 Winner:CPursuitNeuralUCB   (Gap:061.0%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:3500, SCapacity=7000, Alloc=Default]\n",
      "\n",
      "Total experiment time: 070.6s\n",
      "Experiments completed for adaptive\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: ONLINE ADAPTIVE ATTACK\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: ONLINEADAPTIVE\n",
      "Category: Online Adaptive (Real-time Strategic)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 1500 frames  <>  SCALED-CAPACITY: 3000 frames (CAPACITY:1500 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=0 ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 1: (25, 25, 25, 25)\n",
      "üîÑ Default Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:1500, QubitAlloc=Default, SC:3000 (Scale=2 x Cap=1500), Seed: 14103\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_1\n",
      "\t‚úì QuantumExperimentRunner_1 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_3000-Default_Adversarial_OnlineAdaptive-1500_1_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_3000-Default_Adversarial_OnlineAdaptive-1500_1_paper12.pkl\n",
      "\t   File exists: True, size: 708024\n",
      "‚è© SKIPPING EXPERIMENT 1: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 1 GNEURALUCB          : Reward=0485.05, Efficiency=037.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.582]\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=0501.91, Efficiency=038.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.628]\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=0485.24, Efficiency=037.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.634]\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=0462.72, Efficiency=035.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP1 Winner:EXPNeuralUCB        (Gap:061.7%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:1500, SCapacity=3000, Alloc=Default]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 2000 frames  <>  SCALED-CAPACITY: 4000 frames (CAPACITY:2000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=1 ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 2: (25, 25, 25, 25)\n",
      "üîÑ Default Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:2000, QubitAlloc=Default, SC:4000 (Scale=2 x Cap=2000), Seed: 22352\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_2\n",
      "\t‚úì QuantumExperimentRunner_2 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_4000-Default_Adversarial_OnlineAdaptive-2000_2_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_4000-Default_Adversarial_OnlineAdaptive-2000_2_paper12.pkl\n",
      "\t   File exists: True, size: 930060\n",
      "‚è© SKIPPING EXPERIMENT 2: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 2 GNEURALUCB          : Reward=0651.50, Efficiency=037.2% [Retries=3, Failed=0, < Threshold=3, SCapacity=4000, Threshold=0.582]\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=0672.92, Efficiency=038.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=4000, Threshold=0.628]\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=0657.96, Efficiency=037.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=4000, Threshold=0.634]\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=0619.05, Efficiency=035.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=4000, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP2 Winner:EXPNeuralUCB        (Gap:061.6%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:2000, SCapacity=4000, Alloc=Default]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 2500 frames  <>  SCALED-CAPACITY: 5000 frames (CAPACITY:2500 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=2 ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 3: (25, 25, 25, 25)\n",
      "üîÑ Default Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:2500, QubitAlloc=Default, SC:5000 (Scale=2 x Cap=2500), Seed: 14162\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_3\n",
      "\t‚úì QuantumExperimentRunner_3 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_5000-Default_Adversarial_OnlineAdaptive-2500_3_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_5000-Default_Adversarial_OnlineAdaptive-2500_3_paper12.pkl\n",
      "\t   File exists: True, size: 1152119\n",
      "‚è© SKIPPING EXPERIMENT 3: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 3 GNEURALUCB          : Reward=0855.56, Efficiency=039.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=5000, Threshold=0.582]\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=0746.40, Efficiency=034.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=5000, Threshold=0.628]\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=0806.16, Efficiency=036.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=5000, Threshold=0.634]\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=0824.45, Efficiency=037.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=5000, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP3 Winner:GNeuralUCB          (Gap:060.9%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:2500, SCapacity=5000, Alloc=Default]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 3000 frames  <>  SCALED-CAPACITY: 6000 frames (CAPACITY:3000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=3 ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 4: (25, 25, 25, 25)\n",
      "üîÑ Default Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:3000, QubitAlloc=Default, SC:6000 (Scale=2 x Cap=3000), Seed: 21587\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_4\n",
      "\t‚úì QuantumExperimentRunner_4 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_6000-Default_Adversarial_OnlineAdaptive-3000_4_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_6000-Default_Adversarial_OnlineAdaptive-3000_4_paper12.pkl\n",
      "\t   File exists: True, size: 1374146\n",
      "‚è© SKIPPING EXPERIMENT 4: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 4 GNEURALUCB          : Reward=0970.68, Efficiency=036.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=6000, Threshold=0.582]\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=1022.29, Efficiency=038.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=6000, Threshold=0.628]\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=1013.51, Efficiency=038.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=6000, Threshold=0.634]\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=1017.89, Efficiency=038.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=6000, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP4 Winner:EXPNeuralUCB        (Gap:061.1%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:3000, SCapacity=6000, Alloc=Default]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 3500 frames  <>  SCALED-CAPACITY: 7000 frames (CAPACITY:3500 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=4 ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 5: (25, 25, 25, 25)\n",
      "üîÑ Default Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:3500, QubitAlloc=Default, SC:7000 (Scale=2 x Cap=3500), Seed: 17102\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_5\n",
      "\t‚úì QuantumExperimentRunner_5 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_7000-Default_Adversarial_OnlineAdaptive-3500_5_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_7000-Default_Adversarial_OnlineAdaptive-3500_5_paper12.pkl\n",
      "\t   File exists: True, size: 1596214\n",
      "‚è© SKIPPING EXPERIMENT 5: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 5 GNEURALUCB          : Reward=1168.67, Efficiency=038.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=7000, Threshold=0.582]\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=1224.43, Efficiency=039.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=7000, Threshold=0.628]\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=1175.45, Efficiency=038.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=7000, Threshold=0.634]\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=1186.05, Efficiency=038.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=7000, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP5 Winner:EXPNeuralUCB        (Gap:060.1%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:3500, SCapacity=7000, Alloc=Default]\n",
      "\n",
      "Total experiment time: 065.2s\n",
      "Experiments completed for onlineadaptive\n",
      "‚úì Scenario 'none' evaluation completed.\n",
      "‚úì Scenario 'stochastic' evaluation completed.\n",
      "‚úì Scenario 'markov' evaluation completed.\n",
      "‚úì Scenario 'adaptive' evaluation completed.\n",
      "‚úì Scenario 'onlineadaptive' evaluation completed.\n",
      "\n",
      "======================================================================\n",
      "COMPREHENSIVE SCENARIO PERFORMANCE ANALYSIS\n",
      "======================================================================\n",
      "SCENARIO: NONE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 2204.16\n",
      "\t‚Ä¢ Winner Avg Gap: 0048.98%\n",
      "\t‚Ä¢ Winner Avg Reward: 1128.02\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0051.02%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 1 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 4 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: NONE\n",
      "======================================================================\n",
      "SCENARIO: \tBASELINE (OPTIMAL CONDITIONS)\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 4/5 experiments)\n",
      "\tWinner Avg Gap: \t049.0%\n",
      "\tWinner Avg Efficiency: \t051.0%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t051.0% Efficiency \t(Won 4/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t050.6% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t050.1% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t049.3% Efficiency \t(Won 1/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: STOCHASTIC\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 2202.68\n",
      "\t‚Ä¢ Winner Avg Gap: 0052.22%\n",
      "\t‚Ä¢ Winner Avg Reward: 1056.84\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0047.78%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 2 wins\n",
      "\t\t- EXPNeuralUCB: 1 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 2 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: STOCHASTIC\n",
      "======================================================================\n",
      "SCENARIO: \tSTOCHASTIC RANDOM FAILURES\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 2/5 experiments)\n",
      "\tWinner Avg Gap: \t052.2%\n",
      "\tWinner Avg Efficiency: \t047.8%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t047.8% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t047.5% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t047.5% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t046.7% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: MARKOV\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 2061.84\n",
      "\t‚Ä¢ Winner Avg Gap: 0071.06%\n",
      "\t‚Ä¢ Winner Avg Reward: 0595.08\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0028.94%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 3 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 1 wins\n",
      "\t\t- iCPursuitNeuralUCB: 1 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: MARKOV\n",
      "======================================================================\n",
      "SCENARIO: \tMARKOV ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 1/5 experiments)\n",
      "\tWinner Avg Gap: \t071.1%\n",
      "\tWinner Avg Efficiency: \t028.9%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t028.9% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t028.6% Efficiency \t(Won 3/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t027.6% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t025.9% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: EXPNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 2191.22\n",
      "\t‚Ä¢ Winner Avg Gap: 0062.14%\n",
      "\t‚Ä¢ Winner Avg Reward: 0834.74\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0037.86%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 2 wins\n",
      "\t\t- CPursuitNeuralUCB: 2 wins\n",
      "\t\t- iCPursuitNeuralUCB: 1 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tADAPTIVE ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tEXPNeuralUCB (Won 2/5 experiments)\n",
      "\tWinner Avg Gap: \t062.1%\n",
      "\tWinner Avg Efficiency: \t037.9%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t037.9% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t037.7% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t037.4% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t036.3% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ONLINEADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: EXPNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 2189.96\n",
      "\t‚Ä¢ Winner Avg Gap: 0062.09%\n",
      "\t‚Ä¢ Winner Avg Reward: 0833.59\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0037.91%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 1 wins\n",
      "\t\t- EXPNeuralUCB: 4 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 0 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ONLINEADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tONLINE ADAPTIVE ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tEXPNeuralUCB (Won 4/5 experiments)\n",
      "\tWinner Avg Gap: \t062.1%\n",
      "\tWinner Avg Efficiency: \t037.9%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t037.9% Efficiency \t(Won 4/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t037.7% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t037.6% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t037.1% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "KEY INSIGHTS:\n",
      "Best Performing Model Analysis (iCPursuitNeuralUCB):\n",
      "\t‚Ä¢ Stochastic Performance:    \t1056.839\n",
      "\t‚Ä¢ Baseline Performance:      \t1128.020\n",
      "\t‚Ä¢ Performance Retention:     \t093.7%\n",
      "\tGOOD:               \tAcceptable performance under stochastic conditions\n",
      "Statistical Analysis:\n",
      "\t‚Ä¢ Total models evaluated:     \t5\n",
      "\t‚Ä¢ Experiments per environment:\t5\n",
      "\t‚Ä¢ Quantum network simulation: \tComprehensive stochastic modeling\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "COMPREHENSIVE SCENARIO PERFORMANCE ANALYSIS\n",
      "======================================================================\n",
      "SCENARIO: NONE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 2204.16\n",
      "\t‚Ä¢ Winner Avg Gap: 0048.98%\n",
      "\t‚Ä¢ Winner Avg Reward: 1128.02\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0051.02%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 1 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 4 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: NONE\n",
      "======================================================================\n",
      "SCENARIO: \tBASELINE (OPTIMAL CONDITIONS)\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 4/5 experiments)\n",
      "\tWinner Avg Gap: \t049.0%\n",
      "\tWinner Avg Efficiency: \t051.0%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t051.0% Efficiency \t(Won 4/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t050.6% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t050.1% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t049.3% Efficiency \t(Won 1/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: STOCHASTIC\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 2202.68\n",
      "\t‚Ä¢ Winner Avg Gap: 0052.22%\n",
      "\t‚Ä¢ Winner Avg Reward: 1056.84\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0047.78%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 2 wins\n",
      "\t\t- EXPNeuralUCB: 1 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 2 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: STOCHASTIC\n",
      "======================================================================\n",
      "SCENARIO: \tSTOCHASTIC RANDOM FAILURES\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 2/5 experiments)\n",
      "\tWinner Avg Gap: \t052.2%\n",
      "\tWinner Avg Efficiency: \t047.8%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t047.8% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t047.5% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t047.5% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t046.7% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: MARKOV\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 2061.84\n",
      "\t‚Ä¢ Winner Avg Gap: 0071.06%\n",
      "\t‚Ä¢ Winner Avg Reward: 0595.08\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0028.94%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 3 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 1 wins\n",
      "\t\t- iCPursuitNeuralUCB: 1 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: MARKOV\n",
      "======================================================================\n",
      "SCENARIO: \tMARKOV ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 1/5 experiments)\n",
      "\tWinner Avg Gap: \t071.1%\n",
      "\tWinner Avg Efficiency: \t028.9%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t028.9% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t028.6% Efficiency \t(Won 3/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t027.6% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t025.9% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: EXPNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 2191.22\n",
      "\t‚Ä¢ Winner Avg Gap: 0062.14%\n",
      "\t‚Ä¢ Winner Avg Reward: 0834.74\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0037.86%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 2 wins\n",
      "\t\t- CPursuitNeuralUCB: 2 wins\n",
      "\t\t- iCPursuitNeuralUCB: 1 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tADAPTIVE ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tEXPNeuralUCB (Won 2/5 experiments)\n",
      "\tWinner Avg Gap: \t062.1%\n",
      "\tWinner Avg Efficiency: \t037.9%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t037.9% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t037.7% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t037.4% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t036.3% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ONLINEADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: EXPNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 2189.96\n",
      "\t‚Ä¢ Winner Avg Gap: 0062.09%\n",
      "\t‚Ä¢ Winner Avg Reward: 0833.59\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0037.91%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 1 wins\n",
      "\t\t- EXPNeuralUCB: 4 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 0 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ONLINEADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tONLINE ADAPTIVE ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tEXPNeuralUCB (Won 4/5 experiments)\n",
      "\tWinner Avg Gap: \t062.1%\n",
      "\tWinner Avg Efficiency: \t037.9%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t037.9% Efficiency \t(Won 4/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t037.7% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t037.6% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t037.1% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "‚úÖ Evaluation completed!\n",
      "[Logging Redirect Stopped]\n",
      "\n",
      "üßπ Final cleanup for Default\n",
      "\n",
      "======================================================================\n",
      "‚úÖ COMPLETED: Default\n",
      "======================================================================\n",
      "\n",
      "Default COMPLETED SUCCESSFULLY\n",
      "\n",
      "======================================================================\n",
      "ALL ALLOCATORS COMPLETE!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Cell: Allocator + ExperimentConfiguration for Paper #12\n",
    "# ALLOCATOR: Default (Baseline for Paper 12 QuARC)\n",
    "# ============================================================\n",
    "importlib.reload(qubit_allocator)\n",
    "importlib.reload(experiment_config)\n",
    "importlib.reload(multi_run_evaluator)\n",
    "\n",
    "from daqr.core.quantum_physics              import *\n",
    "from daqr.evaluation.allocator_runner       import AllocatorRunner\n",
    "from daqr.evaluation.multi_run_evaluator    import MultiRunEvaluator\n",
    "from daqr.config.experiment_config          import ExperimentConfiguration\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"PAPER #12 (QuARC) - DEFAULT ALLOCATOR\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# ============================================================================\n",
    "# PAPER 12 EXECUTION FLOW:\n",
    "# ============================================================================\n",
    "# 1. get_physics_params(physics_model='paper12', ...):\n",
    "#    ‚Üí Calls get_physics_params_paper12(config, seed, qubit_cap)\n",
    "#    ‚Üí Generates Waxman topology (fallback) or BlobbedQCastNetwork (.net files)\n",
    "#    ‚Üí Calls generate_paper12_paths() to find 4 S-D paths\n",
    "#    ‚Üí Calls generate_paper12_contexts() to create context vectors\n",
    "#    ‚Üí Computes rewards via FusionNoiseModel (fusion_prob=0.9)\n",
    "#\n",
    "# 2. AllocatorRunner.run():\n",
    "#    ‚Üí Instantiates allocator (Default/Dynamic/ThompsonSampling/Random)\n",
    "#    ‚Üí Iterates through frame_step checkpoints (aligned to epoch_length=500)\n",
    "#    ‚Üí Each checkpoint: allocator.allocate() ‚Üí select qubit distribution\n",
    "#    ‚Üí Rewards update via FusionNoiseModel.get_error_rates(path_idx)\n",
    "#    ‚Üí QuARC protocol checks thresholds at epoch boundaries\n",
    "#\n",
    "# 3. Results aggregated and saved:\n",
    "#    ‚Üí Metadata: paper=Wang2024Paper12, retry_enabled=False\n",
    "#    ‚Üí Topology: Waxman (n=100, E_d=6)\n",
    "#    ‚Üí Physics: E_p=0.6, q=0.9\n",
    "#    ‚Üí Simulation: T=1500ts, epoch=500, 3 epochs\n",
    "# ============================================================================\n",
    "\n",
    "# --- Paper 12 Allocator Configuration ---\n",
    "ALLOCATORS = [\"Default\"]\n",
    "\n",
    "# --- Paper 12 Run Parameters (Aligned with ICNP 2024 spec) ---\n",
    "# Frame configuration aligned to QuARC epoch length\n",
    "epoch_length_ts = FRAMEWORK_CONFIG['paper12']['epoch_length']  # 500 timeslots\n",
    "total_sim_ts = FRAMEWORK_CONFIG['paper12']['total_timeslots']  # 5000 timeslots\n",
    "\n",
    "attack_intensity    = FRAMEWORK_CONFIG['intensity']\n",
    "current_frames      = min(1500, total_sim_ts)  # 3 epochs for testing\n",
    "frame_step          = epoch_length_ts           # Checkpoint every epoch\n",
    "current_experiments = 1\n",
    "last_backup         = True\n",
    "base_cap            = False\n",
    "overwrite           = False\n",
    "\n",
    "RUNS                = [5]               # Acceptable for initial testing\n",
    "SCALES              = [1, 1.5, 2]\n",
    "ATTACK_SCENARIOS    = ['stochastic']    # Start simple\n",
    "print(f\"‚úÖ Testing QuARC with {current_frames} timeslots\")\n",
    "print(f\"‚úÖ Expected reconfigurations: {current_frames // 500}\")\n",
    "print(f\"‚úÖ Statistical runs: {RUNS[0]}\")\n",
    "\n",
    "FRAMEWORK_CONFIG['exp_num']     = current_experiments\n",
    "FRAMEWORK_CONFIG['base_frames'] = current_frames\n",
    "FRAMEWORK_CONFIG['frame_step']  = frame_step\n",
    "\n",
    "# Testbed Configuration\n",
    "PHYSICS_MODELS = ['paper12']  # Paper 12 (QuARC)\n",
    "ATTACK_SCENARIOS = ['stochastic']  # Start simple\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PAPER 12 ALLOCATOR EVALUATION\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Allocators:                 {ALLOCATORS}\")\n",
    "print(f\"Physics Models:             {PHYSICS_MODELS}\")\n",
    "print(f\"Attack Scenarios:           {ATTACK_SCENARIOS}\")\n",
    "print(f\"Scales:                     {SCALES}\")\n",
    "print(f\"Runs per Scale:             {RUNS}\")\n",
    "print(f\"Total Frames:               {current_frames}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for allocator_type in ALLOCATORS:\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"RUNNING: {allocator_type} on Paper 12 (QuARC)\")\n",
    "    print('='*70)\n",
    "\n",
    "    for scale in SCALES:\n",
    "        print(f\"\\n{'-'*70}\")\n",
    "        print(f\"Preparing: {allocator_type} at scale {scale}\")\n",
    "        print(f\"{'-'*70}\")\n",
    "\n",
    "        for physics_model in PHYSICS_MODELS:\n",
    "            print(f\"\\nüîß Generating physics parameters for model: {physics_model}\") \n",
    "            try:\n",
    "                # Create isolated runner instance\n",
    "                custom_config = ExperimentConfiguration(\n",
    "                    env_type=FRAMEWORK_CONFIG['main_env'],\n",
    "                    scenarios=test_scenarios,\n",
    "                    use_last_backup=last_backup,\n",
    "                    models=models,\n",
    "                    attack_intensity=attack_intensity,\n",
    "                    scale=scale,\n",
    "                    base_capacity=base_cap,\n",
    "                    overwrite=overwrite\n",
    "                )\n",
    "\n",
    "                alloc_runner = AllocatorRunner(\n",
    "                    allocator_type=allocator_type,\n",
    "                    physics_models=[physics_model],\n",
    "                    framework_config=FRAMEWORK_CONFIG,\n",
    "                    scales=[scale],\n",
    "                    runs=RUNS,\n",
    "                    models=models,\n",
    "                    test_scenarios=test_scenarios,\n",
    "                    config=custom_config\n",
    "                )\n",
    "\n",
    "                # Run with Paper 12 physics\n",
    "                alloc_runner.run(get_physics_params_func=get_physics_params)\n",
    "                print(f\"\\n{allocator_type} COMPLETED SUCCESSFULLY\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"\\n{allocator_type} FAILED: {e}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ALL ALLOCATORS COMPLETE!\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "robustness-analysis",
    "outputId": "d5bf77ec-ed26-474f-b68b-650ab683fece"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "PAPER #12 (QuARC) QUANTUM ROUTING EVALUATION - ALL ALLOCATORS\n",
      "======================================================================\n",
      "‚úÖ Testing QuARC with 1500 timeslots\n",
      "‚úÖ Expected reconfigurations: 3\n",
      "‚úÖ Statistical runs: 5\n",
      "\n",
      "======================================================================\n",
      "PAPER 12 ALLOCATOR EVALUATION\n",
      "======================================================================\n",
      "Allocators:                 ['Dynamic']\n",
      "Physics Models:             ['paper12']\n",
      "Attack Scenarios:           ['stochastic']\n",
      "Scales:                     [1, 1.5, 2]\n",
      "Runs per Scale:             [5]\n",
      "Total Frames:               1500\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "RUNNING: Dynamic on Paper 12 (QuARC)\n",
      "======================================================================\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Preparing: Dynamic at scale 1\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üîß Generating physics parameters for model: paper12\n",
      "\n",
      "===================== GET LOCAL REGISTRY =====================\n",
      "‚Üí Skipping local cache (force=True or file missing)\n",
      "\n",
      "===================== BUILD LOCAL REGISTRY =====================\n",
      "\n",
      "================================================================================\n",
      "üîç SCANNING LOCAL FILES\n",
      "================================================================================\n",
      "Parameters: load_to_drive=False, force=False\n",
      "\n",
      "üìÇ Checking DRIVE mode: /content/drive/Shareddrives/ai_quantum_computing/quantum_data_lake\n",
      "   ‚ö†Ô∏è  Path does not exist, skipping\n",
      "\n",
      "üìÇ Checking LOCAL mode: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config\n",
      "   ‚úÖ Path exists, starting walk...\n",
      "   üö∂ Walking directory tree: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config\n",
      "\n",
      "   üìÅ Directory: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201\n",
      "      Relative: framework_state/day_20260201\n",
      "      Component: framework_state\n",
      "      Date: day_20260201\n",
      "      üìÑ Processing 2543 files in framework_state/day_20260201\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "      üìä framework_state/day_20260201: 2517/2543 files processed\n",
      "      üìä framework_state/day_20260201: 0/2543 files skipped\n",
      "      üìä framework_state/day_20260201: 26/2543 files conflicted\n",
      "\n",
      "   üìÅ Directory: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/model_state/day_20260201\n",
      "      Relative: model_state/day_20260201\n",
      "      Component: model_state\n",
      "      Date: day_20260201\n",
      "      üìÑ Processing 9137 files in model_state/day_20260201\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "      üìä model_state/day_20260201: 9137/9137 files processed\n",
      "      üìä model_state/day_20260201: 0/9137 files skipped\n",
      "      üìä model_state/day_20260201: 0/9137 files conflicted\n",
      "\n",
      "   üìä Processed 2 directories\n",
      "\n",
      "================================================================================\n",
      "üì¶ BUILDING FINAL REGISTRY\n",
      "================================================================================\n",
      "Components found: ['framework_state', 'model_state']\n",
      "  ‚Ä¢ framework_state: 2517 files\n",
      "  ‚Ä¢ model_state: 9137 files\n",
      "\n",
      "‚úÖ SCAN COMPLETE\n",
      "Modes scanned: 1\n",
      "Total files in registry: 11654\n",
      "================================================================================\n",
      "\n",
      "\t‚Üí Filesystem scan found 11654 files\n",
      "\n",
      "===================== GET DRIVE REGISTRY =====================\n",
      "===================== REGISTRY BUILD COMPLETE =====================\n",
      "\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "\tüì¶ LocalBackupManager Registry Saved Locally in LOCAL\n",
      "BUILDING REGISTRY WITH 0 EXPECTED COMPONENTS KEYS\n",
      "\n",
      "===================== GET LOCAL REGISTRY =====================\n",
      "‚Üí Skipping local cache (force=True or file missing)\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "\tüì¶ LocalBackupManager Registry Saved Locally in LOCAL\n",
      "\n",
      "======================================================================\n",
      "üéØ AllocatorRunner initialized: Dynamic\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "üöÄ STARTING ALLOCATOR: Dynamic\n",
      "======================================================================\n",
      "\n",
      "üìä Physics Model: paper12\n",
      "\n",
      "üìã Allocator Config:\n",
      "   Type: Dynamic\n",
      "   Testbed: paper12\n",
      "   Paths: 4\n",
      "   Total Qubits: 100\n",
      "   Min per route: 3\n",
      "   Seed: 42\n",
      "   Exploration bonus: 1.5\n",
      "‚úÖ Allocator created: (25, 25, 25, 25)\n",
      "‚úì Allocator: DynamicQubitAllocator (4 paths)\n",
      "   Initial allocation: (25, 25, 25, 25)\n",
      "Generated paper12 Waxman topology: 100 nodes, 394 edges, avg degree: 7.88\n",
      "üìä Paper12 Physics: Fusion (prob=0.9)\n",
      "\n",
      "======================================================================\n",
      "RUN 1 | Scale: 1 | Exp: 5\n",
      "======================================================================\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "\n",
      "\tüîÑ Resume: MultiRunEvaluator\n",
      "\n",
      "=====================================================\n",
      "üîç GENERATING EXPECTED KEYS FROM EVALUATOR\n",
      "=====================================================\n",
      "  ‚Ä¢ Evaluator filename: MultiRunEvaluator_1500-Dynamic_All_All-1500_500_5_S1T_paper12.pkl\n",
      "\n",
      "üß© PARSED COMPONENTS\n",
      "  ‚Ä¢ cap_id:        1500\n",
      "  ‚Ä¢ allocator_id:  Dynamic\n",
      "  ‚Ä¢ env_id:        All\n",
      "  ‚Ä¢ attack_id:     All\n",
      "  ‚Ä¢ base_frames:   1500\n",
      "  ‚Ä¢ frame_step:    500\n",
      "  ‚Ä¢ runs_id:       5\n",
      "\n",
      "=====================================================\n",
      "üß™ GENERATING KEYS FOR EACH RUN\n",
      "=====================================================\n",
      "\n",
      "--- Run 1/5 -----------------------\n",
      "\n",
      "=====================================================\n",
      "üì¶ FINAL EXPECTED KEYS\n",
      "=====================================================\n",
      "  ‚Ä¢ Runner keys: 11\n",
      "\n",
      "  ‚Ä¢ Model keys: 50\n",
      "\n",
      "--- Run 2/5 -----------------------\n",
      "\n",
      "=====================================================\n",
      "üì¶ FINAL EXPECTED KEYS\n",
      "=====================================================\n",
      "  ‚Ä¢ Runner keys: 21\n",
      "\n",
      "  ‚Ä¢ Model keys: 100\n",
      "\n",
      "--- Run 3/5 -----------------------\n",
      "\n",
      "=====================================================\n",
      "üì¶ FINAL EXPECTED KEYS\n",
      "=====================================================\n",
      "  ‚Ä¢ Runner keys: 31\n",
      "\n",
      "  ‚Ä¢ Model keys: 150\n",
      "\n",
      "--- Run 4/5 -----------------------\n",
      "\n",
      "=====================================================\n",
      "üì¶ FINAL EXPECTED KEYS\n",
      "=====================================================\n",
      "  ‚Ä¢ Runner keys: 41\n",
      "\n",
      "  ‚Ä¢ Model keys: 200\n",
      "\n",
      "--- Run 5/5 -----------------------\n",
      "\n",
      "=====================================================\n",
      "üì¶ FINAL EXPECTED KEYS\n",
      "=====================================================\n",
      "  ‚Ä¢ Runner keys: 51\n",
      "\n",
      "  ‚Ä¢ Model keys: 250\n",
      "\n",
      "EXPECTED KEY GENERATION COMPLETE\n",
      "\n",
      "RESTORING FROM DRIVE 1\n",
      "RESTORING FROM DRIVE 2\n",
      "\t‚ö†Ô∏è Registry exists ‚Üí aborting restore\n",
      "\t‚úì MultiRunEvaluator Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/MultiRunEvaluator_1500-Dynamic_All_All-1500_500_5_S1T_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/MultiRunEvaluator_1500-Dynamic_All_All-1500_500_5_S1T_paper12.pkl\n",
      "\t   File exists: True, size: 57553569\n",
      "EQUAL METHOD\n",
      "Multi-Run Evaluator Initialized\n",
      "Environment Type: None\n",
      "Frame Range: 1500 -> 3500 (step: 500)\n",
      "quantum_exps-Dynamic(paper12)_alloc-all_envs-5_attacks-1500_500-5_runs-S1T\n",
      "[Logging Redirect Initialized]\n",
      "Log File: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/quantum_logs/quantum_exps-Dynamic(paper12)_alloc-all_envs-5_attacks-1500_500-5_runs-S1T_20260201_log.txt\n",
      "‚öô Running evaluation...\n",
      "======================================================================\n",
      "SCENARIOS MODEL EVALUATION\n",
      "======================================================================\n",
      "Testing algorithm performance against:\n",
      "\t‚Ä¢ Stochastic:  \tNatural quantum decoherence and network failures\n",
      "\t‚Ä¢ Baseline:    \tOptimal conditions for validation\n",
      "======================================================================\n",
      "Models to Test:             \tOracle, GNeuralUCB, EXPNeuralUCB, CPursuitNeuralUCB, iCPursuitNeuralUCB\n",
      "Experiments per Scenario:   \t5\n",
      "======================================================================\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: BASELINE (OPTIMAL CONDITIONS)\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: NONE\n",
      "Category: Baseline (No Attacks)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 1500 frames  <>  SCALED-CAPACITY: 1500 frames (CAPACITY:1500 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=0 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for NONE Exp 1: (25, 25, 25, 25)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 1: Env:Baseline (None), Attack:No, Rate:0.0, Frames:1500, QubitAlloc=Dynamic, SC:1500 (Scale=1 x Cap=1500), Seed: 18010\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_1\n",
      "\t‚úì QuantumExperimentRunner_1 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_1500-Dynamic_Baseline (None)_No-1500_1_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_1500-Dynamic_Baseline (None)_No-1500_1_paper12.pkl\n",
      "\t   File exists: True, size: 705328\n",
      "‚è© SKIPPING EXPERIMENT 1: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 1 GNEURALUCB          : Reward=0804.63, Efficiency=060.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=1500, Threshold=0.582]\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=0794.06, Efficiency=059.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=1500, Threshold=0.628]\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=0797.93, Efficiency=059.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=1500, Threshold=0.634]\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=0832.22, Efficiency=062.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=1500, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP1 Winner:iCPursuitNeuralUCB  (Gap:037.7%) [Env:Baseline (None), Attack:No X Rate:0.25, Frames:1500, SCapacity=1500, Alloc=Dynamic]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 2000 frames  <>  SCALED-CAPACITY: 2000 frames (CAPACITY:2000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=1 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for NONE Exp 2: (25, 25, 25, 25)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 2: Env:Baseline (None), Attack:No, Rate:0.0, Frames:2000, QubitAlloc=Dynamic, SC:2000 (Scale=1 x Cap=2000), Seed: 20078\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_2\n",
      "\t‚úì QuantumExperimentRunner_2 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_2000-Dynamic_Baseline (None)_No-2000_2_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_2000-Dynamic_Baseline (None)_No-2000_2_paper12.pkl\n",
      "\t   File exists: True, size: 927364\n",
      "‚è© SKIPPING EXPERIMENT 2: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 2 GNEURALUCB          : Reward=1087.95, Efficiency=061.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=2000, Threshold=0.582]\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=1081.48, Efficiency=060.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=2000, Threshold=0.628]\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=1123.44, Efficiency=063.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=2000, Threshold=0.634]\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=1079.81, Efficiency=060.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=2000, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP2 Winner:CPursuitNeuralUCB   (Gap:036.9%) [Env:Baseline (None), Attack:No X Rate:0.25, Frames:2000, SCapacity=2000, Alloc=Dynamic]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 2500 frames  <>  SCALED-CAPACITY: 2500 frames (CAPACITY:2500 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=2 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for NONE Exp 3: (25, 25, 25, 25)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 3: Env:Baseline (None), Attack:No, Rate:0.0, Frames:2500, QubitAlloc=Dynamic, SC:2500 (Scale=1 x Cap=2500), Seed: 14623\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_3\n",
      "\t‚úì QuantumExperimentRunner_3 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_2500-Dynamic_Baseline (None)_No-2500_3_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_2500-Dynamic_Baseline (None)_No-2500_3_paper12.pkl\n",
      "\t   File exists: True, size: 1149423\n",
      "‚è© SKIPPING EXPERIMENT 3: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 3 GNEURALUCB          : Reward=1361.87, Efficiency=061.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=2500, Threshold=0.582]\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=1101.74, Efficiency=049.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=2500, Threshold=0.628]\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=1393.15, Efficiency=062.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=2500, Threshold=0.634]\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=1373.50, Efficiency=061.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=2500, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP3 Winner:CPursuitNeuralUCB   (Gap:037.4%) [Env:Baseline (None), Attack:No X Rate:0.25, Frames:2500, SCapacity=2500, Alloc=Dynamic]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 3000 frames  <>  SCALED-CAPACITY: 3000 frames (CAPACITY:3000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=3 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for NONE Exp 4: (25, 25, 25, 25)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 4: Env:Baseline (None), Attack:No, Rate:0.0, Frames:3000, QubitAlloc=Dynamic, SC:3000 (Scale=1 x Cap=3000), Seed: 20090\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_4\n",
      "\t‚úì QuantumExperimentRunner_4 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_3000-Dynamic_Baseline (None)_No-3000_4_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_3000-Dynamic_Baseline (None)_No-3000_4_paper12.pkl\n",
      "\t   File exists: True, size: 1371450\n",
      "‚è© SKIPPING EXPERIMENT 4: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 4 GNEURALUCB          : Reward=1656.45, Efficiency=062.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=3000, Threshold=0.582]\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=1266.20, Efficiency=047.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.628]\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=1668.20, Efficiency=062.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.634]\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=1667.88, Efficiency=062.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP4 Winner:CPursuitNeuralUCB   (Gap:037.6%) [Env:Baseline (None), Attack:No X Rate:0.25, Frames:3000, SCapacity=3000, Alloc=Dynamic]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 3500 frames  <>  SCALED-CAPACITY: 3500 frames (CAPACITY:3500 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=4 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for NONE Exp 5: (25, 25, 25, 25)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 5: Env:Baseline (None), Attack:No, Rate:0.0, Frames:3500, QubitAlloc=Dynamic, SC:3500 (Scale=1 x Cap=3500), Seed: 12926\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_5\n",
      "\t‚úì QuantumExperimentRunner_5 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_3500-Dynamic_Baseline (None)_No-3500_5_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_3500-Dynamic_Baseline (None)_No-3500_5_paper12.pkl\n",
      "\t   File exists: True, size: 1593518\n",
      "‚è© SKIPPING EXPERIMENT 5: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 5 GNEURALUCB          : Reward=1923.67, Efficiency=061.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=3500, Threshold=0.582]\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=1983.27, Efficiency=063.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=3500, Threshold=0.628]\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=1962.53, Efficiency=062.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=3500, Threshold=0.634]\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=2014.17, Efficiency=064.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=3500, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP5 Winner:iCPursuitNeuralUCB  (Gap:035.4%) [Env:Baseline (None), Attack:No X Rate:0.25, Frames:3500, SCapacity=3500, Alloc=Dynamic]\n",
      "\n",
      "Total experiment time: 046.1s\n",
      "Experiments completed for none\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: STOCHASTIC RANDOM FAILURES\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: STOCHASTIC\n",
      "Category: Stochastic (Natural Random Failures)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 1500 frames  <>  SCALED-CAPACITY: 1500 frames (CAPACITY:1500 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=0 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 1: (25, 25, 25, 25)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 1: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:1500, QubitAlloc=Dynamic, SC:1500 (Scale=1 x Cap=1500), Seed: 20197\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_1\n",
      "\t‚úì QuantumExperimentRunner_1 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_1500-Dynamic_Stochastic_Random-1500_1_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_1500-Dynamic_Stochastic_Random-1500_1_paper12.pkl\n",
      "\t   File exists: True, size: 705332\n",
      "‚è© SKIPPING EXPERIMENT 1: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 1 GNEURALUCB          : Reward=0718.69, Efficiency=053.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=1500, Threshold=0.582]\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=0686.35, Efficiency=051.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=1500, Threshold=0.628]\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=0732.90, Efficiency=054.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=1500, Threshold=0.634]\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=0731.40, Efficiency=054.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=1500, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP1 Winner:CPursuitNeuralUCB   (Gap:045.1%) [Env:Stochastic, Attack:Random X Rate:0.25, Frames:1500, SCapacity=1500, Alloc=Dynamic]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 2000 frames  <>  SCALED-CAPACITY: 2000 frames (CAPACITY:2000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=1 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 2: (25, 25, 25, 25)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 2: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:2000, QubitAlloc=Dynamic, SC:2000 (Scale=1 x Cap=2000), Seed: 17474\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_2\n",
      "\t‚úì QuantumExperimentRunner_2 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_2000-Dynamic_Stochastic_Random-2000_2_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_2000-Dynamic_Stochastic_Random-2000_2_paper12.pkl\n",
      "\t   File exists: True, size: 927368\n",
      "‚è© SKIPPING EXPERIMENT 2: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 2 GNEURALUCB          : Reward=1022.46, Efficiency=057.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=2000, Threshold=0.582]\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=0857.40, Efficiency=048.2% [Retries=3, Failed=0, < Threshold=3, SCapacity=2000, Threshold=0.628]\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=1022.38, Efficiency=057.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=2000, Threshold=0.634]\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=1007.23, Efficiency=056.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=2000, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP2 Winner:GNeuralUCB          (Gap:042.6%) [Env:Stochastic, Attack:Random X Rate:0.25, Frames:2000, SCapacity=2000, Alloc=Dynamic]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 2500 frames  <>  SCALED-CAPACITY: 2500 frames (CAPACITY:2500 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=2 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 3: (25, 25, 25, 25)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 3: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:2500, QubitAlloc=Dynamic, SC:2500 (Scale=1 x Cap=2500), Seed: 15795\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_3\n",
      "\t‚úì QuantumExperimentRunner_3 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_2500-Dynamic_Stochastic_Random-2500_3_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_2500-Dynamic_Stochastic_Random-2500_3_paper12.pkl\n",
      "\t   File exists: True, size: 1149427\n",
      "‚è© SKIPPING EXPERIMENT 3: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 3 GNEURALUCB          : Reward=1276.98, Efficiency=057.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=2500, Threshold=0.582]\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=1296.41, Efficiency=058.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=2500, Threshold=0.628]\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=1264.24, Efficiency=056.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=2500, Threshold=0.634]\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=1285.86, Efficiency=057.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=2500, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP3 Winner:EXPNeuralUCB        (Gap:041.7%) [Env:Stochastic, Attack:Random X Rate:0.25, Frames:2500, SCapacity=2500, Alloc=Dynamic]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 3000 frames  <>  SCALED-CAPACITY: 3000 frames (CAPACITY:3000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=3 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 4: (25, 25, 25, 25)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 4: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:3000, QubitAlloc=Dynamic, SC:3000 (Scale=1 x Cap=3000), Seed: 17031\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_4\n",
      "\t‚úì QuantumExperimentRunner_4 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_3000-Dynamic_Stochastic_Random-3000_4_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_3000-Dynamic_Stochastic_Random-3000_4_paper12.pkl\n",
      "\t   File exists: True, size: 1371454\n",
      "‚è© SKIPPING EXPERIMENT 4: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 4 GNEURALUCB          : Reward=1551.92, Efficiency=058.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.582]\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=1278.73, Efficiency=047.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.628]\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=1517.01, Efficiency=056.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.634]\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=1565.75, Efficiency=058.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP4 Winner:iCPursuitNeuralUCB  (Gap:041.4%) [Env:Stochastic, Attack:Random X Rate:0.25, Frames:3000, SCapacity=3000, Alloc=Dynamic]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 3500 frames  <>  SCALED-CAPACITY: 3500 frames (CAPACITY:3500 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=4 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 5: (25, 25, 25, 25)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 5: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:3500, QubitAlloc=Dynamic, SC:3500 (Scale=1 x Cap=3500), Seed: 21490\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_5\n",
      "\t‚úì QuantumExperimentRunner_5 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_3500-Dynamic_Stochastic_Random-3500_5_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_3500-Dynamic_Stochastic_Random-3500_5_paper12.pkl\n",
      "\t   File exists: True, size: 1593522\n",
      "‚è© SKIPPING EXPERIMENT 5: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 5 GNEURALUCB          : Reward=1752.20, Efficiency=056.2% [Retries=3, Failed=0, < Threshold=3, SCapacity=3500, Threshold=0.582]\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=1739.75, Efficiency=055.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=3500, Threshold=0.628]\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=1804.10, Efficiency=057.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=3500, Threshold=0.634]\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=1815.24, Efficiency=058.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=3500, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP5 Winner:iCPursuitNeuralUCB  (Gap:041.7%) [Env:Stochastic, Attack:Random X Rate:0.25, Frames:3500, SCapacity=3500, Alloc=Dynamic]\n",
      "\n",
      "Total experiment time: 051.9s\n",
      "Experiments completed for stochastic\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: MARKOV ADVERSARIAL ATTACK\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: MARKOV\n",
      "Category: Structured (Markov Chain Based)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 1500 frames  <>  SCALED-CAPACITY: 1500 frames (CAPACITY:1500 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=0 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for MARKOV Exp 1: (25, 25, 25, 25)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 1: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:1500, QubitAlloc=Dynamic, SC:1500 (Scale=1 x Cap=1500), Seed: 20262\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_1\n",
      "\t‚úì QuantumExperimentRunner_1 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_1500-Dynamic_Adversarial_Markov-1500_1_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_1500-Dynamic_Adversarial_Markov-1500_1_paper12.pkl\n",
      "\t   File exists: True, size: 705330\n",
      "‚è© SKIPPING EXPERIMENT 1: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 1 GNEURALUCB          : Reward=0386.50, Efficiency=031.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=1500, Threshold=0.582]\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=0299.66, Efficiency=024.2% [Retries=3, Failed=0, < Threshold=3, SCapacity=1500, Threshold=0.628]\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=0376.00, Efficiency=030.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=1500, Threshold=0.634]\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=0406.42, Efficiency=032.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=1500, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP1 Winner:iCPursuitNeuralUCB  (Gap:067.1%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:1500, SCapacity=1500, Alloc=Dynamic]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 2000 frames  <>  SCALED-CAPACITY: 2000 frames (CAPACITY:2000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=1 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for MARKOV Exp 2: (25, 25, 25, 25)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 2: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:2000, QubitAlloc=Dynamic, SC:2000 (Scale=1 x Cap=2000), Seed: 15238\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_2\n",
      "\t‚úì QuantumExperimentRunner_2 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_2000-Dynamic_Adversarial_Markov-2000_2_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_2000-Dynamic_Adversarial_Markov-2000_2_paper12.pkl\n",
      "\t   File exists: True, size: 927366\n",
      "‚è© SKIPPING EXPERIMENT 2: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 2 GNEURALUCB          : Reward=0545.55, Efficiency=032.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=2000, Threshold=0.582]\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=0527.57, Efficiency=031.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=2000, Threshold=0.628]\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=0514.88, Efficiency=030.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=2000, Threshold=0.634]\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=0592.10, Efficiency=035.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=2000, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP2 Winner:iCPursuitNeuralUCB  (Gap:064.5%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:2000, SCapacity=2000, Alloc=Dynamic]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 2500 frames  <>  SCALED-CAPACITY: 2500 frames (CAPACITY:2500 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=2 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for MARKOV Exp 3: (25, 25, 25, 25)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 3: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:2500, QubitAlloc=Dynamic, SC:2500 (Scale=1 x Cap=2500), Seed: 15202\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_3\n",
      "\t‚úì QuantumExperimentRunner_3 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_2500-Dynamic_Adversarial_Markov-2500_3_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_2500-Dynamic_Adversarial_Markov-2500_3_paper12.pkl\n",
      "\t   File exists: True, size: 1149425\n",
      "‚è© SKIPPING EXPERIMENT 3: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 3 GNEURALUCB          : Reward=0657.96, Efficiency=031.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=2500, Threshold=0.582]\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=0655.01, Efficiency=031.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=2500, Threshold=0.628]\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=0619.23, Efficiency=029.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=2500, Threshold=0.634]\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=0675.43, Efficiency=032.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=2500, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP3 Winner:iCPursuitNeuralUCB  (Gap:067.3%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:2500, SCapacity=2500, Alloc=Dynamic]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 3000 frames  <>  SCALED-CAPACITY: 3000 frames (CAPACITY:3000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=3 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for MARKOV Exp 4: (25, 25, 25, 25)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 4: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:3000, QubitAlloc=Dynamic, SC:3000 (Scale=1 x Cap=3000), Seed: 19699\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_4\n",
      "\t‚úì QuantumExperimentRunner_4 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_3000-Dynamic_Adversarial_Markov-3000_4_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_3000-Dynamic_Adversarial_Markov-3000_4_paper12.pkl\n",
      "\t   File exists: True, size: 1371452\n",
      "‚è© SKIPPING EXPERIMENT 4: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 4 GNEURALUCB          : Reward=0791.91, Efficiency=031.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.582]\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=0783.65, Efficiency=031.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.628]\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=0829.29, Efficiency=033.2% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.634]\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=0870.96, Efficiency=034.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP4 Winner:iCPursuitNeuralUCB  (Gap:065.1%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:3000, SCapacity=3000, Alloc=Dynamic]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 3500 frames  <>  SCALED-CAPACITY: 3500 frames (CAPACITY:3500 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=4 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for MARKOV Exp 5: (25, 25, 25, 25)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 5: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:3500, QubitAlloc=Dynamic, SC:3500 (Scale=1 x Cap=3500), Seed: 22085\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_5\n",
      "\t‚úì QuantumExperimentRunner_5 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_3500-Dynamic_Adversarial_Markov-3500_5_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_3500-Dynamic_Adversarial_Markov-3500_5_paper12.pkl\n",
      "\t   File exists: True, size: 1593520\n",
      "‚è© SKIPPING EXPERIMENT 5: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 5 GNEURALUCB          : Reward=0940.25, Efficiency=032.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=3500, Threshold=0.582]\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=0881.45, Efficiency=030.2% [Retries=3, Failed=0, < Threshold=3, SCapacity=3500, Threshold=0.628]\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=0938.43, Efficiency=032.2% [Retries=3, Failed=0, < Threshold=3, SCapacity=3500, Threshold=0.634]\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=0993.88, Efficiency=034.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=3500, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP5 Winner:iCPursuitNeuralUCB  (Gap:065.9%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:3500, SCapacity=3500, Alloc=Dynamic]\n",
      "\n",
      "Total experiment time: 037.1s\n",
      "Experiments completed for markov\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: ADAPTIVE ADVERSARIAL ATTACK\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: ADAPTIVE\n",
      "Category: Adaptive (Reactive Strategic)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 1500 frames  <>  SCALED-CAPACITY: 1500 frames (CAPACITY:1500 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=0 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 1: (25, 25, 25, 25)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 1: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:1500, QubitAlloc=Dynamic, SC:1500 (Scale=1 x Cap=1500), Seed: 14115\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_1\n",
      "\t‚úì QuantumExperimentRunner_1 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_1500-Dynamic_Adversarial_Adaptive-1500_1_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_1500-Dynamic_Adversarial_Adaptive-1500_1_paper12.pkl\n",
      "\t   File exists: True, size: 705336\n",
      "‚è© SKIPPING EXPERIMENT 1: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 1 GNEURALUCB          : Reward=0557.49, Efficiency=042.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=1500, Threshold=0.582]\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=0565.64, Efficiency=042.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=1500, Threshold=0.628]\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=0601.64, Efficiency=045.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=1500, Threshold=0.634]\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=0582.63, Efficiency=043.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=1500, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP1 Winner:CPursuitNeuralUCB   (Gap:054.7%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:1500, SCapacity=1500, Alloc=Dynamic]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 2000 frames  <>  SCALED-CAPACITY: 2000 frames (CAPACITY:2000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=1 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 2: (25, 25, 25, 25)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 2: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:2000, QubitAlloc=Dynamic, SC:2000 (Scale=1 x Cap=2000), Seed: 14473\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_2\n",
      "\t‚úì QuantumExperimentRunner_2 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_2000-Dynamic_Adversarial_Adaptive-2000_2_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_2000-Dynamic_Adversarial_Adaptive-2000_2_paper12.pkl\n",
      "\t   File exists: True, size: 927372\n",
      "‚è© SKIPPING EXPERIMENT 2: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 2 GNEURALUCB          : Reward=0798.99, Efficiency=045.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=2000, Threshold=0.582]\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=0839.18, Efficiency=047.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=2000, Threshold=0.628]\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=0799.32, Efficiency=045.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=2000, Threshold=0.634]\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=0784.62, Efficiency=044.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=2000, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP2 Winner:EXPNeuralUCB        (Gap:052.7%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:2000, SCapacity=2000, Alloc=Dynamic]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 2500 frames  <>  SCALED-CAPACITY: 2500 frames (CAPACITY:2500 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=2 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 3: (25, 25, 25, 25)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 3: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:2500, QubitAlloc=Dynamic, SC:2500 (Scale=1 x Cap=2500), Seed: 13973\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_3\n",
      "\t‚úì QuantumExperimentRunner_3 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_2500-Dynamic_Adversarial_Adaptive-2500_3_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_2500-Dynamic_Adversarial_Adaptive-2500_3_paper12.pkl\n",
      "\t   File exists: True, size: 1149431\n",
      "‚è© SKIPPING EXPERIMENT 3: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 3 GNEURALUCB          : Reward=0974.05, Efficiency=044.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=2500, Threshold=0.582]\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=1106.89, Efficiency=050.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=2500, Threshold=0.628]\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=0989.58, Efficiency=044.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=2500, Threshold=0.634]\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=0974.26, Efficiency=044.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=2500, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP3 Winner:EXPNeuralUCB        (Gap:050.0%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:2500, SCapacity=2500, Alloc=Dynamic]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 3000 frames  <>  SCALED-CAPACITY: 3000 frames (CAPACITY:3000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=3 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 4: (25, 25, 25, 25)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 4: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:3000, QubitAlloc=Dynamic, SC:3000 (Scale=1 x Cap=3000), Seed: 16838\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_4\n",
      "\t‚úì QuantumExperimentRunner_4 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_3000-Dynamic_Adversarial_Adaptive-3000_4_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_3000-Dynamic_Adversarial_Adaptive-3000_4_paper12.pkl\n",
      "\t   File exists: True, size: 1371458\n",
      "‚è© SKIPPING EXPERIMENT 4: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 4 GNEURALUCB          : Reward=1218.19, Efficiency=045.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.582]\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=1095.48, Efficiency=041.2% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.628]\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=1230.32, Efficiency=046.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.634]\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=1207.23, Efficiency=045.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP4 Winner:CPursuitNeuralUCB   (Gap:053.7%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:3000, SCapacity=3000, Alloc=Dynamic]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 3500 frames  <>  SCALED-CAPACITY: 3500 frames (CAPACITY:3500 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=4 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 5: (25, 25, 25, 25)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 5: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:3500, QubitAlloc=Dynamic, SC:3500 (Scale=1 x Cap=3500), Seed: 20582\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_5\n",
      "\t‚úì QuantumExperimentRunner_5 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_3500-Dynamic_Adversarial_Adaptive-3500_5_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_3500-Dynamic_Adversarial_Adaptive-3500_5_paper12.pkl\n",
      "\t   File exists: True, size: 1593526\n",
      "‚è© SKIPPING EXPERIMENT 5: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 5 GNEURALUCB          : Reward=1405.49, Efficiency=045.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=3500, Threshold=0.582]\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=1081.74, Efficiency=035.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=3500, Threshold=0.628]\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=1441.08, Efficiency=046.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=3500, Threshold=0.634]\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=1399.00, Efficiency=045.2% [Retries=3, Failed=0, < Threshold=3, SCapacity=3500, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP5 Winner:CPursuitNeuralUCB   (Gap:053.4%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:3500, SCapacity=3500, Alloc=Dynamic]\n",
      "\n",
      "Total experiment time: 057.9s\n",
      "Experiments completed for adaptive\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: ONLINE ADAPTIVE ATTACK\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: ONLINEADAPTIVE\n",
      "Category: Online Adaptive (Real-time Strategic)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 1500 frames  <>  SCALED-CAPACITY: 1500 frames (CAPACITY:1500 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=0 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 1: (25, 25, 25, 25)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:1500, QubitAlloc=Dynamic, SC:1500 (Scale=1 x Cap=1500), Seed: 14103\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_1\n",
      "\t‚úì QuantumExperimentRunner_1 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_1500-Dynamic_Adversarial_OnlineAdaptive-1500_1_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_1500-Dynamic_Adversarial_OnlineAdaptive-1500_1_paper12.pkl\n",
      "\t   File exists: True, size: 705354\n",
      "‚è© SKIPPING EXPERIMENT 1: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 1 GNEURALUCB          : Reward=0597.89, Efficiency=045.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=1500, Threshold=0.582]\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=0546.99, Efficiency=041.2% [Retries=3, Failed=0, < Threshold=3, SCapacity=1500, Threshold=0.628]\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=0578.35, Efficiency=043.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=1500, Threshold=0.634]\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=0581.50, Efficiency=043.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=1500, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP1 Winner:GNeuralUCB          (Gap:055.0%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:1500, SCapacity=1500, Alloc=Dynamic]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 2000 frames  <>  SCALED-CAPACITY: 2000 frames (CAPACITY:2000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=1 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 2: (25, 25, 25, 25)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:2000, QubitAlloc=Dynamic, SC:2000 (Scale=1 x Cap=2000), Seed: 22352\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_2\n",
      "\t‚úì QuantumExperimentRunner_2 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_2000-Dynamic_Adversarial_OnlineAdaptive-2000_2_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_2000-Dynamic_Adversarial_OnlineAdaptive-2000_2_paper12.pkl\n",
      "\t   File exists: True, size: 927390\n",
      "‚è© SKIPPING EXPERIMENT 2: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 2 GNEURALUCB          : Reward=0759.77, Efficiency=043.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=2000, Threshold=0.582]\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=0831.88, Efficiency=047.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=2000, Threshold=0.628]\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=0767.69, Efficiency=043.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=2000, Threshold=0.634]\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=0755.46, Efficiency=042.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=2000, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP2 Winner:EXPNeuralUCB        (Gap:052.9%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:2000, SCapacity=2000, Alloc=Dynamic]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 2500 frames  <>  SCALED-CAPACITY: 2500 frames (CAPACITY:2500 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=2 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 3: (25, 25, 25, 25)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:2500, QubitAlloc=Dynamic, SC:2500 (Scale=1 x Cap=2500), Seed: 14162\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_3\n",
      "\t‚úì QuantumExperimentRunner_3 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_2500-Dynamic_Adversarial_OnlineAdaptive-2500_3_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_2500-Dynamic_Adversarial_OnlineAdaptive-2500_3_paper12.pkl\n",
      "\t   File exists: True, size: 1149449\n",
      "‚è© SKIPPING EXPERIMENT 3: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 3 GNEURALUCB          : Reward=0975.26, Efficiency=044.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=2500, Threshold=0.582]\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=0833.01, Efficiency=037.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=2500, Threshold=0.628]\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=0994.97, Efficiency=044.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=2500, Threshold=0.634]\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=0975.16, Efficiency=044.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=2500, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP3 Winner:CPursuitNeuralUCB   (Gap:055.1%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:2500, SCapacity=2500, Alloc=Dynamic]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 3000 frames  <>  SCALED-CAPACITY: 3000 frames (CAPACITY:3000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=3 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 4: (25, 25, 25, 25)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:3000, QubitAlloc=Dynamic, SC:3000 (Scale=1 x Cap=3000), Seed: 21587\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_4\n",
      "\t‚úì QuantumExperimentRunner_4 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_3000-Dynamic_Adversarial_OnlineAdaptive-3000_4_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_3000-Dynamic_Adversarial_OnlineAdaptive-3000_4_paper12.pkl\n",
      "\t   File exists: True, size: 1371476\n",
      "‚è© SKIPPING EXPERIMENT 4: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 4 GNEURALUCB          : Reward=1185.56, Efficiency=044.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.582]\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=1316.13, Efficiency=049.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.628]\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=1230.01, Efficiency=046.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.634]\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=1193.27, Efficiency=044.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP4 Winner:EXPNeuralUCB        (Gap:050.5%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:3000, SCapacity=3000, Alloc=Dynamic]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 3500 frames  <>  SCALED-CAPACITY: 3500 frames (CAPACITY:3500 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=4 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 5: (25, 25, 25, 25)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:3500, QubitAlloc=Dynamic, SC:3500 (Scale=1 x Cap=3500), Seed: 17102\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_5\n",
      "\t‚úì QuantumExperimentRunner_5 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_3500-Dynamic_Adversarial_OnlineAdaptive-3500_5_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_3500-Dynamic_Adversarial_OnlineAdaptive-3500_5_paper12.pkl\n",
      "\t   File exists: True, size: 1593544\n",
      "‚è© SKIPPING EXPERIMENT 5: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 5 GNEURALUCB          : Reward=1410.12, Efficiency=045.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=3500, Threshold=0.582]\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=1585.62, Efficiency=051.2% [Retries=3, Failed=0, < Threshold=3, SCapacity=3500, Threshold=0.628]\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=1419.75, Efficiency=045.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=3500, Threshold=0.634]\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=1441.59, Efficiency=046.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=3500, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP5 Winner:EXPNeuralUCB        (Gap:048.8%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:3500, SCapacity=3500, Alloc=Dynamic]\n",
      "\n",
      "Total experiment time: 055.4s\n",
      "Experiments completed for onlineadaptive\n",
      "‚úì Scenario 'none' evaluation completed.\n",
      "‚úì Scenario 'stochastic' evaluation completed.\n",
      "‚úì Scenario 'markov' evaluation completed.\n",
      "‚úì Scenario 'adaptive' evaluation completed.\n",
      "‚úì Scenario 'onlineadaptive' evaluation completed.\n",
      "\n",
      "======================================================================\n",
      "COMPREHENSIVE SCENARIO PERFORMANCE ANALYSIS\n",
      "======================================================================\n",
      "SCENARIO: NONE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 2226.96\n",
      "\t‚Ä¢ Winner Avg Gap: 0037.68%\n",
      "\t‚Ä¢ Winner Avg Reward: 1393.52\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0062.32%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 3 wins\n",
      "\t\t- iCPursuitNeuralUCB: 2 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: NONE\n",
      "======================================================================\n",
      "SCENARIO: \tBASELINE (OPTIMAL CONDITIONS)\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 2/5 experiments)\n",
      "\tWinner Avg Gap: \t037.7%\n",
      "\tWinner Avg Efficiency: \t062.3%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t062.3% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t062.1% Efficiency \t(Won 3/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t061.2% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t056.1% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: STOCHASTIC\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 2225.42\n",
      "\t‚Ä¢ Winner Avg Gap: 0042.79%\n",
      "\t‚Ä¢ Winner Avg Reward: 1281.10\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0057.21%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 1 wins\n",
      "\t\t- EXPNeuralUCB: 1 wins\n",
      "\t\t- CPursuitNeuralUCB: 1 wins\n",
      "\t\t- iCPursuitNeuralUCB: 2 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: STOCHASTIC\n",
      "======================================================================\n",
      "SCENARIO: \tSTOCHASTIC RANDOM FAILURES\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 2/5 experiments)\n",
      "\tWinner Avg Gap: \t042.8%\n",
      "\tWinner Avg Efficiency: \t057.2%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t057.2% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t056.8% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t056.6% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t052.3% Efficiency \t(Won 1/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: MARKOV\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 2076.50\n",
      "\t‚Ä¢ Winner Avg Gap: 0065.99%\n",
      "\t‚Ä¢ Winner Avg Reward: 0707.76\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0034.01%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 5 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: MARKOV\n",
      "======================================================================\n",
      "SCENARIO: \tMARKOV ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 5/5 experiments)\n",
      "\tWinner Avg Gap: \t066.0%\n",
      "\tWinner Avg Efficiency: \t034.0%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t034.0% Efficiency \t(Won 5/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t032.0% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t031.3% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t029.8% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: CPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 2212.73\n",
      "\t‚Ä¢ Winner Avg Gap: 0054.40%\n",
      "\t‚Ä¢ Winner Avg Reward: 1012.39\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0045.60%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 2 wins\n",
      "\t\t- CPursuitNeuralUCB: 3 wins\n",
      "\t\t- iCPursuitNeuralUCB: 0 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tADAPTIVE ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tCPursuitNeuralUCB (Won 3/5 experiments)\n",
      "\tWinner Avg Gap: \t054.4%\n",
      "\tWinner Avg Efficiency: \t045.6%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t045.6% Efficiency \t(Won 3/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t044.6% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t044.5% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t043.2% Efficiency \t(Won 2/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ONLINEADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: EXPNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 2212.52\n",
      "\t‚Ä¢ Winner Avg Gap: 0054.67%\n",
      "\t‚Ä¢ Winner Avg Reward: 1022.73\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0045.33%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 1 wins\n",
      "\t\t- EXPNeuralUCB: 3 wins\n",
      "\t\t- CPursuitNeuralUCB: 1 wins\n",
      "\t\t- iCPursuitNeuralUCB: 0 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ONLINEADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tONLINE ADAPTIVE ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tEXPNeuralUCB (Won 3/5 experiments)\n",
      "\tWinner Avg Gap: \t054.7%\n",
      "\tWinner Avg Efficiency: \t045.3%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t045.3% Efficiency \t(Won 3/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t044.8% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t044.4% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t044.4% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "KEY INSIGHTS:\n",
      "Best Performing Model Analysis (iCPursuitNeuralUCB):\n",
      "\t‚Ä¢ Stochastic Performance:    \t1281.097\n",
      "\t‚Ä¢ Baseline Performance:      \t1393.516\n",
      "\t‚Ä¢ Performance Retention:     \t091.9%\n",
      "\tGOOD:               \tAcceptable performance under stochastic conditions\n",
      "Statistical Analysis:\n",
      "\t‚Ä¢ Total models evaluated:     \t5\n",
      "\t‚Ä¢ Experiments per environment:\t5\n",
      "\t‚Ä¢ Quantum network simulation: \tComprehensive stochastic modeling\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "COMPREHENSIVE SCENARIO PERFORMANCE ANALYSIS\n",
      "======================================================================\n",
      "SCENARIO: NONE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 2226.96\n",
      "\t‚Ä¢ Winner Avg Gap: 0037.68%\n",
      "\t‚Ä¢ Winner Avg Reward: 1393.52\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0062.32%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 3 wins\n",
      "\t\t- iCPursuitNeuralUCB: 2 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: NONE\n",
      "======================================================================\n",
      "SCENARIO: \tBASELINE (OPTIMAL CONDITIONS)\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 2/5 experiments)\n",
      "\tWinner Avg Gap: \t037.7%\n",
      "\tWinner Avg Efficiency: \t062.3%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t062.3% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t062.1% Efficiency \t(Won 3/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t061.2% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t056.1% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: STOCHASTIC\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 2225.42\n",
      "\t‚Ä¢ Winner Avg Gap: 0042.79%\n",
      "\t‚Ä¢ Winner Avg Reward: 1281.10\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0057.21%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 1 wins\n",
      "\t\t- EXPNeuralUCB: 1 wins\n",
      "\t\t- CPursuitNeuralUCB: 1 wins\n",
      "\t\t- iCPursuitNeuralUCB: 2 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: STOCHASTIC\n",
      "======================================================================\n",
      "SCENARIO: \tSTOCHASTIC RANDOM FAILURES\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 2/5 experiments)\n",
      "\tWinner Avg Gap: \t042.8%\n",
      "\tWinner Avg Efficiency: \t057.2%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t057.2% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t056.8% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t056.6% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t052.3% Efficiency \t(Won 1/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: MARKOV\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 2076.50\n",
      "\t‚Ä¢ Winner Avg Gap: 0065.99%\n",
      "\t‚Ä¢ Winner Avg Reward: 0707.76\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0034.01%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 5 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: MARKOV\n",
      "======================================================================\n",
      "SCENARIO: \tMARKOV ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 5/5 experiments)\n",
      "\tWinner Avg Gap: \t066.0%\n",
      "\tWinner Avg Efficiency: \t034.0%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t034.0% Efficiency \t(Won 5/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t032.0% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t031.3% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t029.8% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: CPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 2212.73\n",
      "\t‚Ä¢ Winner Avg Gap: 0054.40%\n",
      "\t‚Ä¢ Winner Avg Reward: 1012.39\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0045.60%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 2 wins\n",
      "\t\t- CPursuitNeuralUCB: 3 wins\n",
      "\t\t- iCPursuitNeuralUCB: 0 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tADAPTIVE ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tCPursuitNeuralUCB (Won 3/5 experiments)\n",
      "\tWinner Avg Gap: \t054.4%\n",
      "\tWinner Avg Efficiency: \t045.6%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t045.6% Efficiency \t(Won 3/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t044.6% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t044.5% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t043.2% Efficiency \t(Won 2/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ONLINEADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: EXPNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 2212.52\n",
      "\t‚Ä¢ Winner Avg Gap: 0054.67%\n",
      "\t‚Ä¢ Winner Avg Reward: 1022.73\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0045.33%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 1 wins\n",
      "\t\t- EXPNeuralUCB: 3 wins\n",
      "\t\t- CPursuitNeuralUCB: 1 wins\n",
      "\t\t- iCPursuitNeuralUCB: 0 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ONLINEADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tONLINE ADAPTIVE ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tEXPNeuralUCB (Won 3/5 experiments)\n",
      "\tWinner Avg Gap: \t054.7%\n",
      "\tWinner Avg Efficiency: \t045.3%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t045.3% Efficiency \t(Won 3/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t044.8% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t044.4% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t044.4% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "‚úÖ Evaluation completed!\n",
      "[Logging Redirect Stopped]\n",
      "\n",
      "üßπ Final cleanup for Dynamic\n",
      "\n",
      "======================================================================\n",
      "‚úÖ COMPLETED: Dynamic\n",
      "======================================================================\n",
      "\n",
      "Dynamic COMPLETED SUCCESSFULLY\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Preparing: Dynamic at scale 1.5\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üîß Generating physics parameters for model: paper12\n",
      "\n",
      "===================== GET LOCAL REGISTRY =====================\n",
      "‚Üí Skipping local cache (force=True or file missing)\n",
      "\n",
      "===================== BUILD LOCAL REGISTRY =====================\n",
      "\n",
      "================================================================================\n",
      "üîç SCANNING LOCAL FILES\n",
      "================================================================================\n",
      "Parameters: load_to_drive=False, force=False\n",
      "\n",
      "üìÇ Checking DRIVE mode: /content/drive/Shareddrives/ai_quantum_computing/quantum_data_lake\n",
      "   ‚ö†Ô∏è  Path does not exist, skipping\n",
      "\n",
      "üìÇ Checking LOCAL mode: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config\n",
      "   ‚úÖ Path exists, starting walk...\n",
      "   üö∂ Walking directory tree: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config\n",
      "\n",
      "   üìÅ Directory: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201\n",
      "      Relative: framework_state/day_20260201\n",
      "      Component: framework_state\n",
      "      Date: day_20260201\n",
      "      üìÑ Processing 2544 files in framework_state/day_20260201\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "      üìä framework_state/day_20260201: 2518/2544 files processed\n",
      "      üìä framework_state/day_20260201: 0/2544 files skipped\n",
      "      üìä framework_state/day_20260201: 26/2544 files conflicted\n",
      "\n",
      "   üìÅ Directory: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/model_state/day_20260201\n",
      "      Relative: model_state/day_20260201\n",
      "      Component: model_state\n",
      "      Date: day_20260201\n",
      "      üìÑ Processing 9160 files in model_state/day_20260201\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "      üìä model_state/day_20260201: 9160/9160 files processed\n",
      "      üìä model_state/day_20260201: 0/9160 files skipped\n",
      "      üìä model_state/day_20260201: 0/9160 files conflicted\n",
      "\n",
      "   üìä Processed 2 directories\n",
      "\n",
      "================================================================================\n",
      "üì¶ BUILDING FINAL REGISTRY\n",
      "================================================================================\n",
      "Components found: ['framework_state', 'model_state']\n",
      "  ‚Ä¢ framework_state: 2518 files\n",
      "  ‚Ä¢ model_state: 9160 files\n",
      "\n",
      "‚úÖ SCAN COMPLETE\n",
      "Modes scanned: 1\n",
      "Total files in registry: 11678\n",
      "================================================================================\n",
      "\n",
      "\t‚Üí Filesystem scan found 11678 files\n",
      "\n",
      "===================== GET DRIVE REGISTRY =====================\n",
      "===================== REGISTRY BUILD COMPLETE =====================\n",
      "\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "\tüì¶ LocalBackupManager Registry Saved Locally in LOCAL\n",
      "BUILDING REGISTRY WITH 0 EXPECTED COMPONENTS KEYS\n",
      "\n",
      "===================== GET LOCAL REGISTRY =====================\n",
      "‚Üí Skipping local cache (force=True or file missing)\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "\tüì¶ LocalBackupManager Registry Saved Locally in LOCAL\n",
      "\n",
      "======================================================================\n",
      "üéØ AllocatorRunner initialized: Dynamic\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "üöÄ STARTING ALLOCATOR: Dynamic\n",
      "======================================================================\n",
      "\n",
      "üìä Physics Model: paper12\n",
      "\n",
      "üìã Allocator Config:\n",
      "   Type: Dynamic\n",
      "   Testbed: paper12\n",
      "   Paths: 4\n",
      "   Total Qubits: 100\n",
      "   Min per route: 3\n",
      "   Seed: 42\n",
      "   Exploration bonus: 1.5\n",
      "‚úÖ Allocator created: (25, 25, 25, 25)\n",
      "‚úì Allocator: DynamicQubitAllocator (4 paths)\n",
      "   Initial allocation: (25, 25, 25, 25)\n",
      "Generated paper12 Waxman topology: 100 nodes, 375 edges, avg degree: 7.50\n",
      "üìä Paper12 Physics: Fusion (prob=0.9)\n",
      "\n",
      "======================================================================\n",
      "RUN 1 | Scale: 1.5 | Exp: 5\n",
      "======================================================================\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "\n",
      "\tüîÑ Resume: MultiRunEvaluator\n",
      "\n",
      "=====================================================\n",
      "üîç GENERATING EXPECTED KEYS FROM EVALUATOR\n",
      "=====================================================\n",
      "  ‚Ä¢ Evaluator filename: MultiRunEvaluator_2250-Dynamic_All_All-1500_500_5_S1_5T_paper12.pkl\n",
      "\n",
      "üß© PARSED COMPONENTS\n",
      "  ‚Ä¢ cap_id:        2250\n",
      "  ‚Ä¢ allocator_id:  Dynamic\n",
      "  ‚Ä¢ env_id:        All\n",
      "  ‚Ä¢ attack_id:     All\n",
      "  ‚Ä¢ base_frames:   1500\n",
      "  ‚Ä¢ frame_step:    500\n",
      "  ‚Ä¢ runs_id:       5\n",
      "\n",
      "=====================================================\n",
      "üß™ GENERATING KEYS FOR EACH RUN\n",
      "=====================================================\n",
      "\n",
      "--- Run 1/5 -----------------------\n",
      "\n",
      "=====================================================\n",
      "üì¶ FINAL EXPECTED KEYS\n",
      "=====================================================\n",
      "  ‚Ä¢ Runner keys: 11\n",
      "\n",
      "  ‚Ä¢ Model keys: 50\n",
      "\n",
      "--- Run 2/5 -----------------------\n",
      "\n",
      "=====================================================\n",
      "üì¶ FINAL EXPECTED KEYS\n",
      "=====================================================\n",
      "  ‚Ä¢ Runner keys: 21\n",
      "\n",
      "  ‚Ä¢ Model keys: 100\n",
      "\n",
      "--- Run 3/5 -----------------------\n",
      "\n",
      "=====================================================\n",
      "üì¶ FINAL EXPECTED KEYS\n",
      "=====================================================\n",
      "  ‚Ä¢ Runner keys: 31\n",
      "\n",
      "  ‚Ä¢ Model keys: 150\n",
      "\n",
      "--- Run 4/5 -----------------------\n",
      "\n",
      "=====================================================\n",
      "üì¶ FINAL EXPECTED KEYS\n",
      "=====================================================\n",
      "  ‚Ä¢ Runner keys: 41\n",
      "\n",
      "  ‚Ä¢ Model keys: 200\n",
      "\n",
      "--- Run 5/5 -----------------------\n",
      "\n",
      "=====================================================\n",
      "üì¶ FINAL EXPECTED KEYS\n",
      "=====================================================\n",
      "  ‚Ä¢ Runner keys: 51\n",
      "\n",
      "  ‚Ä¢ Model keys: 250\n",
      "\n",
      "EXPECTED KEY GENERATION COMPLETE\n",
      "\n",
      "RESTORING FROM DRIVE 1\n",
      "RESTORING FROM DRIVE 2\n",
      "\t‚ö†Ô∏è Registry exists ‚Üí aborting restore\n",
      "\t‚úì MultiRunEvaluator Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/MultiRunEvaluator_2250-Dynamic_All_All-1500_500_5_S1_5T_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/MultiRunEvaluator_2250-Dynamic_All_All-1500_500_5_S1_5T_paper12.pkl\n",
      "\t   File exists: True, size: 57179767\n",
      "EQUAL METHOD\n",
      "Multi-Run Evaluator Initialized\n",
      "Environment Type: None\n",
      "Frame Range: 1500 -> 3500 (step: 500)\n",
      "quantum_exps-Dynamic(paper12)_alloc-all_envs-5_attacks-1500_500-5_runs-S1.5T\n",
      "[Logging Redirect Initialized]\n",
      "Log File: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/quantum_logs/quantum_exps-Dynamic(paper12)_alloc-all_envs-5_attacks-1500_500-5_runs-S1.5T_20260201_log.txt\n",
      "‚öô Running evaluation...\n",
      "======================================================================\n",
      "SCENARIOS MODEL EVALUATION\n",
      "======================================================================\n",
      "Testing algorithm performance against:\n",
      "\t‚Ä¢ Stochastic:  \tNatural quantum decoherence and network failures\n",
      "\t‚Ä¢ Baseline:    \tOptimal conditions for validation\n",
      "======================================================================\n",
      "Models to Test:             \tOracle, GNeuralUCB, EXPNeuralUCB, CPursuitNeuralUCB, iCPursuitNeuralUCB\n",
      "Experiments per Scenario:   \t5\n",
      "======================================================================\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: BASELINE (OPTIMAL CONDITIONS)\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: NONE\n",
      "Category: Baseline (No Attacks)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 1500 frames  <>  SCALED-CAPACITY: 2250.0 frames (CAPACITY:1500 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=0 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for NONE Exp 1: (25, 25, 25, 25)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 1: Env:Baseline (None), Attack:No, Rate:0.0, Frames:1500, QubitAlloc=Dynamic, SC:2250 (Scale=1.5 x Cap=1500), Seed: 18010\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_1\n",
      "\t‚úì QuantumExperimentRunner_1 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_2250-Dynamic_Baseline (None)_No-1500_1_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_2250-Dynamic_Baseline (None)_No-1500_1_paper12.pkl\n",
      "\t   File exists: True, size: 708206\n",
      "‚è© SKIPPING EXPERIMENT 1: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 1 GNEURALUCB          : Reward=0812.69, Efficiency=060.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=2250.0, Threshold=0.582]\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=0807.25, Efficiency=060.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=2250.0, Threshold=0.628]\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=0802.96, Efficiency=060.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=2250.0, Threshold=0.634]\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=0802.76, Efficiency=060.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=2250.0, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP1 Winner:GNeuralUCB          (Gap:039.2%) [Env:Baseline (None), Attack:No X Rate:0.25, Frames:1500, SCapacity=2250.0, Alloc=Dynamic]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 2000 frames  <>  SCALED-CAPACITY: 3000.0 frames (CAPACITY:2000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=1 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for NONE Exp 2: (25, 25, 25, 25)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 2: Env:Baseline (None), Attack:No, Rate:0.0, Frames:2000, QubitAlloc=Dynamic, SC:3000 (Scale=1.5 x Cap=2000), Seed: 20078\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_2\n",
      "\t‚úì QuantumExperimentRunner_2 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_3000-Dynamic_Baseline (None)_No-2000_2_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_3000-Dynamic_Baseline (None)_No-2000_2_paper12.pkl\n",
      "\t   File exists: True, size: 930242\n",
      "‚è© SKIPPING EXPERIMENT 2: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 2 GNEURALUCB          : Reward=1128.68, Efficiency=063.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=3000.0, Threshold=0.582]\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=1110.57, Efficiency=062.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000.0, Threshold=0.628]\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=1067.68, Efficiency=059.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000.0, Threshold=0.634]\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=1095.68, Efficiency=061.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000.0, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP2 Winner:GNeuralUCB          (Gap:036.6%) [Env:Baseline (None), Attack:No X Rate:0.25, Frames:2000, SCapacity=3000.0, Alloc=Dynamic]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 2500 frames  <>  SCALED-CAPACITY: 3750.0 frames (CAPACITY:2500 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=2 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for NONE Exp 3: (25, 25, 25, 25)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 3: Env:Baseline (None), Attack:No, Rate:0.0, Frames:2500, QubitAlloc=Dynamic, SC:3750 (Scale=1.5 x Cap=2500), Seed: 14623\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_3\n",
      "\t‚úì QuantumExperimentRunner_3 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_3750-Dynamic_Baseline (None)_No-2500_3_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_3750-Dynamic_Baseline (None)_No-2500_3_paper12.pkl\n",
      "\t   File exists: True, size: 1152301\n",
      "‚è© SKIPPING EXPERIMENT 3: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 3 GNEURALUCB          : Reward=1356.60, Efficiency=060.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=3750.0, Threshold=0.582]\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=1379.52, Efficiency=061.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=3750.0, Threshold=0.628]\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=1393.15, Efficiency=062.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=3750.0, Threshold=0.634]\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=1351.88, Efficiency=060.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=3750.0, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP3 Winner:CPursuitNeuralUCB   (Gap:037.4%) [Env:Baseline (None), Attack:No X Rate:0.25, Frames:2500, SCapacity=3750.0, Alloc=Dynamic]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 3000 frames  <>  SCALED-CAPACITY: 4500.0 frames (CAPACITY:3000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=3 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for NONE Exp 4: (25, 25, 25, 25)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 4: Env:Baseline (None), Attack:No, Rate:0.0, Frames:3000, QubitAlloc=Dynamic, SC:4500 (Scale=1.5 x Cap=3000), Seed: 20090\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_4\n",
      "\t‚úì QuantumExperimentRunner_4 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_4500-Dynamic_Baseline (None)_No-3000_4_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_4500-Dynamic_Baseline (None)_No-3000_4_paper12.pkl\n",
      "\t   File exists: True, size: 1374328\n",
      "‚è© SKIPPING EXPERIMENT 4: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 4 GNEURALUCB          : Reward=1656.37, Efficiency=062.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=4500.0, Threshold=0.582]\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=1762.90, Efficiency=066.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=4500.0, Threshold=0.628]\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=1669.56, Efficiency=062.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=4500.0, Threshold=0.634]\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=1649.21, Efficiency=061.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=4500.0, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP4 Winner:EXPNeuralUCB        (Gap:034.0%) [Env:Baseline (None), Attack:No X Rate:0.25, Frames:3000, SCapacity=4500.0, Alloc=Dynamic]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 3500 frames  <>  SCALED-CAPACITY: 5250.0 frames (CAPACITY:3500 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=4 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for NONE Exp 5: (25, 25, 25, 25)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 5: Env:Baseline (None), Attack:No, Rate:0.0, Frames:3500, QubitAlloc=Dynamic, SC:5250 (Scale=1.5 x Cap=3500), Seed: 12926\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_5\n",
      "\t‚úì QuantumExperimentRunner_5 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_5250-Dynamic_Baseline (None)_No-3500_5_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_5250-Dynamic_Baseline (None)_No-3500_5_paper12.pkl\n",
      "\t   File exists: True, size: 1596396\n",
      "‚è© SKIPPING EXPERIMENT 5: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 5 GNEURALUCB          : Reward=1941.29, Efficiency=062.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=5250.0, Threshold=0.582]\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=2046.04, Efficiency=065.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=5250.0, Threshold=0.628]\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=1896.11, Efficiency=060.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=5250.0, Threshold=0.634]\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=1941.30, Efficiency=062.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=5250.0, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP5 Winner:EXPNeuralUCB        (Gap:034.4%) [Env:Baseline (None), Attack:No X Rate:0.25, Frames:3500, SCapacity=5250.0, Alloc=Dynamic]\n",
      "\n",
      "Total experiment time: 036.9s\n",
      "Experiments completed for none\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: STOCHASTIC RANDOM FAILURES\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: STOCHASTIC\n",
      "Category: Stochastic (Natural Random Failures)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 1500 frames  <>  SCALED-CAPACITY: 2250.0 frames (CAPACITY:1500 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=0 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 1: (25, 25, 25, 25)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 1: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:1500, QubitAlloc=Dynamic, SC:2250 (Scale=1.5 x Cap=1500), Seed: 20197\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_1\n",
      "\t‚úì QuantumExperimentRunner_1 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_2250-Dynamic_Stochastic_Random-1500_1_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_2250-Dynamic_Stochastic_Random-1500_1_paper12.pkl\n",
      "\t   File exists: True, size: 708210\n",
      "‚è© SKIPPING EXPERIMENT 1: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 1 GNEURALUCB          : Reward=0722.45, Efficiency=054.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=2250.0, Threshold=0.582]\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=0809.08, Efficiency=060.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=2250.0, Threshold=0.628]\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=0727.30, Efficiency=054.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=2250.0, Threshold=0.634]\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=0759.88, Efficiency=056.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=2250.0, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP1 Winner:EXPNeuralUCB        (Gap:039.4%) [Env:Stochastic, Attack:Random X Rate:0.25, Frames:1500, SCapacity=2250.0, Alloc=Dynamic]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 2000 frames  <>  SCALED-CAPACITY: 3000.0 frames (CAPACITY:2000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=1 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 2: (25, 25, 25, 25)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 2: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:2000, QubitAlloc=Dynamic, SC:3000 (Scale=1.5 x Cap=2000), Seed: 17474\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_2\n",
      "\t‚úì QuantumExperimentRunner_2 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_3000-Dynamic_Stochastic_Random-2000_2_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_3000-Dynamic_Stochastic_Random-2000_2_paper12.pkl\n",
      "\t   File exists: True, size: 930246\n",
      "‚è© SKIPPING EXPERIMENT 2: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 2 GNEURALUCB          : Reward=1004.10, Efficiency=056.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000.0, Threshold=0.582]\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=0807.43, Efficiency=045.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000.0, Threshold=0.628]\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=1036.68, Efficiency=058.2% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000.0, Threshold=0.634]\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=1000.91, Efficiency=056.2% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000.0, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP2 Winner:CPursuitNeuralUCB   (Gap:041.8%) [Env:Stochastic, Attack:Random X Rate:0.25, Frames:2000, SCapacity=3000.0, Alloc=Dynamic]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 2500 frames  <>  SCALED-CAPACITY: 3750.0 frames (CAPACITY:2500 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=2 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 3: (25, 25, 25, 25)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 3: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:2500, QubitAlloc=Dynamic, SC:3750 (Scale=1.5 x Cap=2500), Seed: 15795\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_3\n",
      "\t‚úì QuantumExperimentRunner_3 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_3750-Dynamic_Stochastic_Random-2500_3_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_3750-Dynamic_Stochastic_Random-2500_3_paper12.pkl\n",
      "\t   File exists: True, size: 1152305\n",
      "‚è© SKIPPING EXPERIMENT 3: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 3 GNEURALUCB          : Reward=1244.94, Efficiency=055.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=3750.0, Threshold=0.582]\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=1248.36, Efficiency=056.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=3750.0, Threshold=0.628]\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=1239.48, Efficiency=055.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=3750.0, Threshold=0.634]\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=1242.40, Efficiency=055.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=3750.0, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP3 Winner:EXPNeuralUCB        (Gap:043.9%) [Env:Stochastic, Attack:Random X Rate:0.25, Frames:2500, SCapacity=3750.0, Alloc=Dynamic]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 3000 frames  <>  SCALED-CAPACITY: 4500.0 frames (CAPACITY:3000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=3 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 4: (25, 25, 25, 25)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 4: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:3000, QubitAlloc=Dynamic, SC:4500 (Scale=1.5 x Cap=3000), Seed: 17031\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_4\n",
      "\t‚úì QuantumExperimentRunner_4 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_4500-Dynamic_Stochastic_Random-3000_4_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_4500-Dynamic_Stochastic_Random-3000_4_paper12.pkl\n",
      "\t   File exists: True, size: 1374332\n",
      "‚è© SKIPPING EXPERIMENT 4: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 4 GNEURALUCB          : Reward=1543.48, Efficiency=057.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=4500.0, Threshold=0.582]\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=1276.66, Efficiency=047.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=4500.0, Threshold=0.628]\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=1528.85, Efficiency=057.2% [Retries=3, Failed=0, < Threshold=3, SCapacity=4500.0, Threshold=0.634]\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=1513.08, Efficiency=056.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=4500.0, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP4 Winner:GNeuralUCB          (Gap:042.2%) [Env:Stochastic, Attack:Random X Rate:0.25, Frames:3000, SCapacity=4500.0, Alloc=Dynamic]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 3500 frames  <>  SCALED-CAPACITY: 5250.0 frames (CAPACITY:3500 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=4 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 5: (25, 25, 25, 25)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 5: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:3500, QubitAlloc=Dynamic, SC:5250 (Scale=1.5 x Cap=3500), Seed: 21490\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_5\n",
      "\t‚úì QuantumExperimentRunner_5 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_5250-Dynamic_Stochastic_Random-3500_5_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_5250-Dynamic_Stochastic_Random-3500_5_paper12.pkl\n",
      "\t   File exists: True, size: 1596400\n",
      "‚è© SKIPPING EXPERIMENT 5: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 5 GNEURALUCB          : Reward=1796.78, Efficiency=057.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=5250.0, Threshold=0.582]\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=1628.80, Efficiency=052.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=5250.0, Threshold=0.628]\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=1838.75, Efficiency=059.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=5250.0, Threshold=0.634]\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=1869.06, Efficiency=060.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=5250.0, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP5 Winner:iCPursuitNeuralUCB  (Gap:040.0%) [Env:Stochastic, Attack:Random X Rate:0.25, Frames:3500, SCapacity=5250.0, Alloc=Dynamic]\n",
      "\n",
      "Total experiment time: 040.9s\n",
      "Experiments completed for stochastic\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: MARKOV ADVERSARIAL ATTACK\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: MARKOV\n",
      "Category: Structured (Markov Chain Based)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 1500 frames  <>  SCALED-CAPACITY: 2250.0 frames (CAPACITY:1500 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=0 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for MARKOV Exp 1: (25, 25, 25, 25)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 1: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:1500, QubitAlloc=Dynamic, SC:2250 (Scale=1.5 x Cap=1500), Seed: 20262\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_1\n",
      "\t‚úì QuantumExperimentRunner_1 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_2250-Dynamic_Adversarial_Markov-1500_1_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_2250-Dynamic_Adversarial_Markov-1500_1_paper12.pkl\n",
      "\t   File exists: True, size: 708208\n",
      "‚è© SKIPPING EXPERIMENT 1: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 1 GNEURALUCB          : Reward=0384.78, Efficiency=031.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=2250.0, Threshold=0.582]\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=0419.09, Efficiency=033.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=2250.0, Threshold=0.628]\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=0390.88, Efficiency=031.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=2250.0, Threshold=0.634]\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=0418.76, Efficiency=033.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=2250.0, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP1 Winner:EXPNeuralUCB        (Gap:066.2%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:1500, SCapacity=2250.0, Alloc=Dynamic]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 2000 frames  <>  SCALED-CAPACITY: 3000.0 frames (CAPACITY:2000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=1 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for MARKOV Exp 2: (25, 25, 25, 25)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 2: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:2000, QubitAlloc=Dynamic, SC:3000 (Scale=1.5 x Cap=2000), Seed: 15238\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_2\n",
      "\t‚úì QuantumExperimentRunner_2 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_3000-Dynamic_Adversarial_Markov-2000_2_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_3000-Dynamic_Adversarial_Markov-2000_2_paper12.pkl\n",
      "\t   File exists: True, size: 930244\n",
      "‚è© SKIPPING EXPERIMENT 2: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 2 GNEURALUCB          : Reward=0542.70, Efficiency=032.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000.0, Threshold=0.582]\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=0543.16, Efficiency=032.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000.0, Threshold=0.628]\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=0544.22, Efficiency=032.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000.0, Threshold=0.634]\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=0589.82, Efficiency=035.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000.0, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP2 Winner:iCPursuitNeuralUCB  (Gap:064.7%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:2000, SCapacity=3000.0, Alloc=Dynamic]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 2500 frames  <>  SCALED-CAPACITY: 3750.0 frames (CAPACITY:2500 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=2 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for MARKOV Exp 3: (25, 25, 25, 25)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 3: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:2500, QubitAlloc=Dynamic, SC:3750 (Scale=1.5 x Cap=2500), Seed: 15202\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_3\n",
      "\t‚úì QuantumExperimentRunner_3 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_3750-Dynamic_Adversarial_Markov-2500_3_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_3750-Dynamic_Adversarial_Markov-2500_3_paper12.pkl\n",
      "\t   File exists: True, size: 1152303\n",
      "‚è© SKIPPING EXPERIMENT 3: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 3 GNEURALUCB          : Reward=0653.68, Efficiency=031.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=3750.0, Threshold=0.582]\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=0601.46, Efficiency=029.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=3750.0, Threshold=0.628]\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=0679.90, Efficiency=032.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=3750.0, Threshold=0.634]\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=0715.64, Efficiency=034.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=3750.0, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP3 Winner:iCPursuitNeuralUCB  (Gap:065.5%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:2500, SCapacity=3750.0, Alloc=Dynamic]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 3000 frames  <>  SCALED-CAPACITY: 4500.0 frames (CAPACITY:3000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=3 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for MARKOV Exp 4: (25, 25, 25, 25)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 4: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:3000, QubitAlloc=Dynamic, SC:4500 (Scale=1.5 x Cap=3000), Seed: 19699\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_4\n",
      "\t‚úì QuantumExperimentRunner_4 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_4500-Dynamic_Adversarial_Markov-3000_4_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_4500-Dynamic_Adversarial_Markov-3000_4_paper12.pkl\n",
      "\t   File exists: True, size: 1374330\n",
      "‚è© SKIPPING EXPERIMENT 4: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 4 GNEURALUCB          : Reward=0816.55, Efficiency=032.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=4500.0, Threshold=0.582]\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=0640.33, Efficiency=025.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=4500.0, Threshold=0.628]\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=0795.81, Efficiency=031.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=4500.0, Threshold=0.634]\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=0839.70, Efficiency=033.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=4500.0, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP4 Winner:iCPursuitNeuralUCB  (Gap:066.4%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:3000, SCapacity=4500.0, Alloc=Dynamic]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 3500 frames  <>  SCALED-CAPACITY: 5250.0 frames (CAPACITY:3500 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=4 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for MARKOV Exp 5: (25, 25, 25, 25)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 5: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:3500, QubitAlloc=Dynamic, SC:5250 (Scale=1.5 x Cap=3500), Seed: 22085\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_5\n",
      "\t‚úì QuantumExperimentRunner_5 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_5250-Dynamic_Adversarial_Markov-3500_5_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_5250-Dynamic_Adversarial_Markov-3500_5_paper12.pkl\n",
      "\t   File exists: True, size: 1596398\n",
      "‚è© SKIPPING EXPERIMENT 5: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 5 GNEURALUCB          : Reward=0920.09, Efficiency=031.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=5250.0, Threshold=0.582]\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=0855.42, Efficiency=029.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=5250.0, Threshold=0.628]\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=0929.82, Efficiency=031.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=5250.0, Threshold=0.634]\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=0984.60, Efficiency=033.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=5250.0, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP5 Winner:iCPursuitNeuralUCB  (Gap:066.3%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:3500, SCapacity=5250.0, Alloc=Dynamic]\n",
      "\n",
      "Total experiment time: 049.3s\n",
      "Experiments completed for markov\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: ADAPTIVE ADVERSARIAL ATTACK\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: ADAPTIVE\n",
      "Category: Adaptive (Reactive Strategic)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 1500 frames  <>  SCALED-CAPACITY: 2250.0 frames (CAPACITY:1500 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=0 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 1: (25, 25, 25, 25)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 1: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:1500, QubitAlloc=Dynamic, SC:2250 (Scale=1.5 x Cap=1500), Seed: 14115\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_1\n",
      "\t‚úì QuantumExperimentRunner_1 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_2250-Dynamic_Adversarial_Adaptive-1500_1_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_2250-Dynamic_Adversarial_Adaptive-1500_1_paper12.pkl\n",
      "\t   File exists: True, size: 708214\n",
      "‚è© SKIPPING EXPERIMENT 1: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 1 GNEURALUCB          : Reward=0619.41, Efficiency=046.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=2250.0, Threshold=0.582]\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=0636.45, Efficiency=047.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=2250.0, Threshold=0.628]\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=0629.71, Efficiency=047.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=2250.0, Threshold=0.634]\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=0612.16, Efficiency=046.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=2250.0, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP1 Winner:EXPNeuralUCB        (Gap:052.1%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:1500, SCapacity=2250.0, Alloc=Dynamic]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 2000 frames  <>  SCALED-CAPACITY: 3000.0 frames (CAPACITY:2000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=1 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 2: (25, 25, 25, 25)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 2: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:2000, QubitAlloc=Dynamic, SC:3000 (Scale=1.5 x Cap=2000), Seed: 14473\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_2\n",
      "\t‚úì QuantumExperimentRunner_2 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_3000-Dynamic_Adversarial_Adaptive-2000_2_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_3000-Dynamic_Adversarial_Adaptive-2000_2_paper12.pkl\n",
      "\t   File exists: True, size: 930250\n",
      "‚è© SKIPPING EXPERIMENT 2: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 2 GNEURALUCB          : Reward=0780.41, Efficiency=044.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000.0, Threshold=0.582]\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=0866.01, Efficiency=048.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000.0, Threshold=0.628]\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=0767.91, Efficiency=043.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000.0, Threshold=0.634]\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=0769.72, Efficiency=043.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000.0, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP2 Winner:EXPNeuralUCB        (Gap:051.2%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:2000, SCapacity=3000.0, Alloc=Dynamic]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 2500 frames  <>  SCALED-CAPACITY: 3750.0 frames (CAPACITY:2500 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=2 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 3: (25, 25, 25, 25)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 3: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:2500, QubitAlloc=Dynamic, SC:3750 (Scale=1.5 x Cap=2500), Seed: 13973\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_3\n",
      "\t‚úì QuantumExperimentRunner_3 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_3750-Dynamic_Adversarial_Adaptive-2500_3_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_3750-Dynamic_Adversarial_Adaptive-2500_3_paper12.pkl\n",
      "\t   File exists: True, size: 1152309\n",
      "‚è© SKIPPING EXPERIMENT 3: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 3 GNEURALUCB          : Reward=0973.71, Efficiency=044.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=3750.0, Threshold=0.582]\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=1020.31, Efficiency=046.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=3750.0, Threshold=0.628]\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=1005.61, Efficiency=045.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=3750.0, Threshold=0.634]\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=0980.61, Efficiency=044.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=3750.0, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP3 Winner:EXPNeuralUCB        (Gap:053.9%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:2500, SCapacity=3750.0, Alloc=Dynamic]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 3000 frames  <>  SCALED-CAPACITY: 4500.0 frames (CAPACITY:3000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=3 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 4: (25, 25, 25, 25)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 4: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:3000, QubitAlloc=Dynamic, SC:4500 (Scale=1.5 x Cap=3000), Seed: 16838\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_4\n",
      "\t‚úì QuantumExperimentRunner_4 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_4500-Dynamic_Adversarial_Adaptive-3000_4_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_4500-Dynamic_Adversarial_Adaptive-3000_4_paper12.pkl\n",
      "\t   File exists: True, size: 1374336\n",
      "‚è© SKIPPING EXPERIMENT 4: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 4 GNEURALUCB          : Reward=1203.93, Efficiency=045.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=4500.0, Threshold=0.582]\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=1007.28, Efficiency=037.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=4500.0, Threshold=0.628]\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=1239.89, Efficiency=046.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=4500.0, Threshold=0.634]\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=1177.68, Efficiency=044.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=4500.0, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP4 Winner:CPursuitNeuralUCB   (Gap:053.4%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:3000, SCapacity=4500.0, Alloc=Dynamic]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 3500 frames  <>  SCALED-CAPACITY: 5250.0 frames (CAPACITY:3500 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=4 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 5: (25, 25, 25, 25)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 5: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:3500, QubitAlloc=Dynamic, SC:5250 (Scale=1.5 x Cap=3500), Seed: 20582\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_5\n",
      "\t‚úì QuantumExperimentRunner_5 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_5250-Dynamic_Adversarial_Adaptive-3500_5_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_5250-Dynamic_Adversarial_Adaptive-3500_5_paper12.pkl\n",
      "\t   File exists: True, size: 1596404\n",
      "‚è© SKIPPING EXPERIMENT 5: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 5 GNEURALUCB          : Reward=1421.87, Efficiency=045.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=5250.0, Threshold=0.582]\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=1455.62, Efficiency=047.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=5250.0, Threshold=0.628]\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=1407.76, Efficiency=045.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=5250.0, Threshold=0.634]\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=1370.66, Efficiency=044.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=5250.0, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP5 Winner:EXPNeuralUCB        (Gap:053.0%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:3500, SCapacity=5250.0, Alloc=Dynamic]\n",
      "\n",
      "Total experiment time: 061.8s\n",
      "Experiments completed for adaptive\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: ONLINE ADAPTIVE ATTACK\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: ONLINEADAPTIVE\n",
      "Category: Online Adaptive (Real-time Strategic)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 1500 frames  <>  SCALED-CAPACITY: 2250.0 frames (CAPACITY:1500 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=0 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 1: (25, 25, 25, 25)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:1500, QubitAlloc=Dynamic, SC:2250 (Scale=1.5 x Cap=1500), Seed: 14103\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_1\n",
      "\t‚úì QuantumExperimentRunner_1 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_2250-Dynamic_Adversarial_OnlineAdaptive-1500_1_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_2250-Dynamic_Adversarial_OnlineAdaptive-1500_1_paper12.pkl\n",
      "\t   File exists: True, size: 708232\n",
      "‚è© SKIPPING EXPERIMENT 1: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 1 GNEURALUCB          : Reward=0581.20, Efficiency=043.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=2250.0, Threshold=0.582]\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=0549.21, Efficiency=041.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=2250.0, Threshold=0.628]\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=0570.96, Efficiency=043.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=2250.0, Threshold=0.634]\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=0577.87, Efficiency=043.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=2250.0, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP1 Winner:GNeuralUCB          (Gap:056.2%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:1500, SCapacity=2250.0, Alloc=Dynamic]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 2000 frames  <>  SCALED-CAPACITY: 3000.0 frames (CAPACITY:2000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=1 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 2: (25, 25, 25, 25)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:2000, QubitAlloc=Dynamic, SC:3000 (Scale=1.5 x Cap=2000), Seed: 22352\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_2\n",
      "\t‚úì QuantumExperimentRunner_2 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_3000-Dynamic_Adversarial_OnlineAdaptive-2000_2_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_3000-Dynamic_Adversarial_OnlineAdaptive-2000_2_paper12.pkl\n",
      "\t   File exists: True, size: 930268\n",
      "‚è© SKIPPING EXPERIMENT 2: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 2 GNEURALUCB          : Reward=0781.12, Efficiency=044.2% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000.0, Threshold=0.582]\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=0705.73, Efficiency=039.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000.0, Threshold=0.628]\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=0745.96, Efficiency=042.2% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000.0, Threshold=0.634]\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=0770.49, Efficiency=043.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000.0, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP2 Winner:GNeuralUCB          (Gap:055.8%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:2000, SCapacity=3000.0, Alloc=Dynamic]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 2500 frames  <>  SCALED-CAPACITY: 3750.0 frames (CAPACITY:2500 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=2 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 3: (25, 25, 25, 25)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:2500, QubitAlloc=Dynamic, SC:3750 (Scale=1.5 x Cap=2500), Seed: 14162\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_3\n",
      "\t‚úì QuantumExperimentRunner_3 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_3750-Dynamic_Adversarial_OnlineAdaptive-2500_3_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_3750-Dynamic_Adversarial_OnlineAdaptive-2500_3_paper12.pkl\n",
      "\t   File exists: True, size: 1152327\n",
      "‚è© SKIPPING EXPERIMENT 3: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 3 GNEURALUCB          : Reward=1022.15, Efficiency=046.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=3750.0, Threshold=0.582]\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=0838.20, Efficiency=037.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=3750.0, Threshold=0.628]\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=0997.86, Efficiency=045.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=3750.0, Threshold=0.634]\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=0987.24, Efficiency=044.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=3750.0, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP3 Winner:GNeuralUCB          (Gap:053.9%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:2500, SCapacity=3750.0, Alloc=Dynamic]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 3000 frames  <>  SCALED-CAPACITY: 4500.0 frames (CAPACITY:3000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=3 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 4: (25, 25, 25, 25)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:3000, QubitAlloc=Dynamic, SC:4500 (Scale=1.5 x Cap=3000), Seed: 21587\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_4\n",
      "\t‚úì QuantumExperimentRunner_4 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_4500-Dynamic_Adversarial_OnlineAdaptive-3000_4_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_4500-Dynamic_Adversarial_OnlineAdaptive-3000_4_paper12.pkl\n",
      "\t   File exists: True, size: 1374354\n",
      "‚è© SKIPPING EXPERIMENT 4: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 4 GNEURALUCB          : Reward=1172.07, Efficiency=044.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=4500.0, Threshold=0.582]\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=1153.43, Efficiency=043.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=4500.0, Threshold=0.628]\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=1279.95, Efficiency=048.2% [Retries=3, Failed=0, < Threshold=3, SCapacity=4500.0, Threshold=0.634]\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=1231.11, Efficiency=046.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=4500.0, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP4 Winner:CPursuitNeuralUCB   (Gap:051.8%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:3000, SCapacity=4500.0, Alloc=Dynamic]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 3500 frames  <>  SCALED-CAPACITY: 5250.0 frames (CAPACITY:3500 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=4 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 5: (25, 25, 25, 25)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:3500, QubitAlloc=Dynamic, SC:5250 (Scale=1.5 x Cap=3500), Seed: 17102\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_5\n",
      "\t‚úì QuantumExperimentRunner_5 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_5250-Dynamic_Adversarial_OnlineAdaptive-3500_5_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_5250-Dynamic_Adversarial_OnlineAdaptive-3500_5_paper12.pkl\n",
      "\t   File exists: True, size: 1596422\n",
      "‚è© SKIPPING EXPERIMENT 5: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 5 GNEURALUCB          : Reward=1449.03, Efficiency=046.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=5250.0, Threshold=0.582]\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=1096.51, Efficiency=035.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=5250.0, Threshold=0.628]\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=1415.34, Efficiency=045.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=5250.0, Threshold=0.634]\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=1407.97, Efficiency=045.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=5250.0, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP5 Winner:GNeuralUCB          (Gap:053.2%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:3500, SCapacity=5250.0, Alloc=Dynamic]\n",
      "\n",
      "Total experiment time: 067.5s\n",
      "Experiments completed for onlineadaptive\n",
      "‚úì Scenario 'none' evaluation completed.\n",
      "‚úì Scenario 'stochastic' evaluation completed.\n",
      "‚úì Scenario 'markov' evaluation completed.\n",
      "‚úì Scenario 'adaptive' evaluation completed.\n",
      "‚úì Scenario 'onlineadaptive' evaluation completed.\n",
      "\n",
      "======================================================================\n",
      "COMPREHENSIVE SCENARIO PERFORMANCE ANALYSIS\n",
      "======================================================================\n",
      "SCENARIO: NONE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: EXPNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 2226.96\n",
      "\t‚Ä¢ Winner Avg Gap: 0036.74%\n",
      "\t‚Ä¢ Winner Avg Reward: 1421.26\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0063.26%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 2 wins\n",
      "\t\t- EXPNeuralUCB: 2 wins\n",
      "\t\t- CPursuitNeuralUCB: 1 wins\n",
      "\t\t- iCPursuitNeuralUCB: 0 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: NONE\n",
      "======================================================================\n",
      "SCENARIO: \tBASELINE (OPTIMAL CONDITIONS)\n",
      "----------------------------------------\n",
      "Recommended Model: \tEXPNeuralUCB (Won 2/5 experiments)\n",
      "\tWinner Avg Gap: \t036.7%\n",
      "\tWinner Avg Efficiency: \t063.3%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t063.3% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t061.9% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t061.3% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t061.2% Efficiency \t(Won 1/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: STOCHASTIC\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 2225.47\n",
      "\t‚Ä¢ Winner Avg Gap: 0042.88%\n",
      "\t‚Ä¢ Winner Avg Reward: 1277.07\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0057.12%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 1 wins\n",
      "\t\t- EXPNeuralUCB: 2 wins\n",
      "\t\t- CPursuitNeuralUCB: 1 wins\n",
      "\t\t- iCPursuitNeuralUCB: 1 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: STOCHASTIC\n",
      "======================================================================\n",
      "SCENARIO: \tSTOCHASTIC RANDOM FAILURES\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 1/5 experiments)\n",
      "\tWinner Avg Gap: \t042.9%\n",
      "\tWinner Avg Efficiency: \t057.1%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t057.1% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t056.9% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t056.4% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t052.4% Efficiency \t(Won 2/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: MARKOV\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 2080.48\n",
      "\t‚Ä¢ Winner Avg Gap: 0065.81%\n",
      "\t‚Ä¢ Winner Avg Reward: 0709.70\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0034.19%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 1 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 4 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: MARKOV\n",
      "======================================================================\n",
      "SCENARIO: \tMARKOV ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 4/5 experiments)\n",
      "\tWinner Avg Gap: \t065.8%\n",
      "\tWinner Avg Efficiency: \t034.2%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t034.2% Efficiency \t(Won 4/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t032.1% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t031.8% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t030.1% Efficiency \t(Won 1/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: CPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 2214.01\n",
      "\t‚Ä¢ Winner Avg Gap: 0054.36%\n",
      "\t‚Ä¢ Winner Avg Reward: 1010.17\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0045.64%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 4 wins\n",
      "\t\t- CPursuitNeuralUCB: 1 wins\n",
      "\t\t- iCPursuitNeuralUCB: 0 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tADAPTIVE ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tCPursuitNeuralUCB (Won 1/5 experiments)\n",
      "\tWinner Avg Gap: \t054.4%\n",
      "\tWinner Avg Efficiency: \t045.6%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t045.6% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t045.5% Efficiency \t(Won 4/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t045.2% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t044.5% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ONLINEADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: GNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 2213.63\n",
      "\t‚Ä¢ Winner Avg Gap: 0055.01%\n",
      "\t‚Ä¢ Winner Avg Reward: 1001.11\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0044.99%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 4 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 1 wins\n",
      "\t\t- iCPursuitNeuralUCB: 0 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ONLINEADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tONLINE ADAPTIVE ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tGNeuralUCB (Won 4/5 experiments)\n",
      "\tWinner Avg Gap: \t055.0%\n",
      "\tWinner Avg Efficiency: \t045.0%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ GNeuralUCB     : \t045.0% Efficiency \t(Won 4/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t044.8% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t044.7% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t039.6% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "KEY INSIGHTS:\n",
      "Best Performing Model Analysis (iCPursuitNeuralUCB):\n",
      "\t‚Ä¢ Stochastic Performance:    \t1277.067\n",
      "\t‚Ä¢ Baseline Performance:      \t1421.255\n",
      "\t‚Ä¢ Performance Retention:     \t089.9%\n",
      "\tGOOD:               \tAcceptable performance under stochastic conditions\n",
      "Statistical Analysis:\n",
      "\t‚Ä¢ Total models evaluated:     \t5\n",
      "\t‚Ä¢ Experiments per environment:\t5\n",
      "\t‚Ä¢ Quantum network simulation: \tComprehensive stochastic modeling\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "COMPREHENSIVE SCENARIO PERFORMANCE ANALYSIS\n",
      "======================================================================\n",
      "SCENARIO: NONE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: EXPNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 2226.96\n",
      "\t‚Ä¢ Winner Avg Gap: 0036.74%\n",
      "\t‚Ä¢ Winner Avg Reward: 1421.26\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0063.26%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 2 wins\n",
      "\t\t- EXPNeuralUCB: 2 wins\n",
      "\t\t- CPursuitNeuralUCB: 1 wins\n",
      "\t\t- iCPursuitNeuralUCB: 0 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: NONE\n",
      "======================================================================\n",
      "SCENARIO: \tBASELINE (OPTIMAL CONDITIONS)\n",
      "----------------------------------------\n",
      "Recommended Model: \tEXPNeuralUCB (Won 2/5 experiments)\n",
      "\tWinner Avg Gap: \t036.7%\n",
      "\tWinner Avg Efficiency: \t063.3%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t063.3% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t061.9% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t061.3% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t061.2% Efficiency \t(Won 1/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: STOCHASTIC\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 2225.47\n",
      "\t‚Ä¢ Winner Avg Gap: 0042.88%\n",
      "\t‚Ä¢ Winner Avg Reward: 1277.07\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0057.12%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 1 wins\n",
      "\t\t- EXPNeuralUCB: 2 wins\n",
      "\t\t- CPursuitNeuralUCB: 1 wins\n",
      "\t\t- iCPursuitNeuralUCB: 1 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: STOCHASTIC\n",
      "======================================================================\n",
      "SCENARIO: \tSTOCHASTIC RANDOM FAILURES\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 1/5 experiments)\n",
      "\tWinner Avg Gap: \t042.9%\n",
      "\tWinner Avg Efficiency: \t057.1%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t057.1% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t056.9% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t056.4% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t052.4% Efficiency \t(Won 2/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: MARKOV\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 2080.48\n",
      "\t‚Ä¢ Winner Avg Gap: 0065.81%\n",
      "\t‚Ä¢ Winner Avg Reward: 0709.70\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0034.19%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 1 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 4 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: MARKOV\n",
      "======================================================================\n",
      "SCENARIO: \tMARKOV ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 4/5 experiments)\n",
      "\tWinner Avg Gap: \t065.8%\n",
      "\tWinner Avg Efficiency: \t034.2%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t034.2% Efficiency \t(Won 4/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t032.1% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t031.8% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t030.1% Efficiency \t(Won 1/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: CPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 2214.01\n",
      "\t‚Ä¢ Winner Avg Gap: 0054.36%\n",
      "\t‚Ä¢ Winner Avg Reward: 1010.17\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0045.64%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 4 wins\n",
      "\t\t- CPursuitNeuralUCB: 1 wins\n",
      "\t\t- iCPursuitNeuralUCB: 0 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tADAPTIVE ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tCPursuitNeuralUCB (Won 1/5 experiments)\n",
      "\tWinner Avg Gap: \t054.4%\n",
      "\tWinner Avg Efficiency: \t045.6%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t045.6% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t045.5% Efficiency \t(Won 4/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t045.2% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t044.5% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ONLINEADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: GNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 2213.63\n",
      "\t‚Ä¢ Winner Avg Gap: 0055.01%\n",
      "\t‚Ä¢ Winner Avg Reward: 1001.11\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0044.99%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 4 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 1 wins\n",
      "\t\t- iCPursuitNeuralUCB: 0 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ONLINEADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tONLINE ADAPTIVE ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tGNeuralUCB (Won 4/5 experiments)\n",
      "\tWinner Avg Gap: \t055.0%\n",
      "\tWinner Avg Efficiency: \t045.0%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ GNeuralUCB     : \t045.0% Efficiency \t(Won 4/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t044.8% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t044.7% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t039.6% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "‚úÖ Evaluation completed!\n",
      "[Logging Redirect Stopped]\n",
      "\n",
      "üßπ Final cleanup for Dynamic\n",
      "\n",
      "======================================================================\n",
      "‚úÖ COMPLETED: Dynamic\n",
      "======================================================================\n",
      "\n",
      "Dynamic COMPLETED SUCCESSFULLY\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Preparing: Dynamic at scale 2\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üîß Generating physics parameters for model: paper12\n",
      "\n",
      "===================== GET LOCAL REGISTRY =====================\n",
      "‚Üí Skipping local cache (force=True or file missing)\n",
      "\n",
      "===================== BUILD LOCAL REGISTRY =====================\n",
      "\n",
      "================================================================================\n",
      "üîç SCANNING LOCAL FILES\n",
      "================================================================================\n",
      "Parameters: load_to_drive=False, force=False\n",
      "\n",
      "üìÇ Checking DRIVE mode: /content/drive/Shareddrives/ai_quantum_computing/quantum_data_lake\n",
      "   ‚ö†Ô∏è  Path does not exist, skipping\n",
      "\n",
      "üìÇ Checking LOCAL mode: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config\n",
      "   ‚úÖ Path exists, starting walk...\n",
      "   üö∂ Walking directory tree: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config\n",
      "\n",
      "   üìÅ Directory: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201\n",
      "      Relative: framework_state/day_20260201\n",
      "      Component: framework_state\n",
      "      Date: day_20260201\n",
      "      üìÑ Processing 2546 files in framework_state/day_20260201\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "      üìä framework_state/day_20260201: 2520/2546 files processed\n",
      "      üìä framework_state/day_20260201: 0/2546 files skipped\n",
      "      üìä framework_state/day_20260201: 26/2546 files conflicted\n",
      "\n",
      "   üìÅ Directory: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/model_state/day_20260201\n",
      "      Relative: model_state/day_20260201\n",
      "      Component: model_state\n",
      "      Date: day_20260201\n",
      "      üìÑ Processing 9198 files in model_state/day_20260201\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "      üìä model_state/day_20260201: 9198/9198 files processed\n",
      "      üìä model_state/day_20260201: 0/9198 files skipped\n",
      "      üìä model_state/day_20260201: 0/9198 files conflicted\n",
      "\n",
      "   üìä Processed 2 directories\n",
      "\n",
      "================================================================================\n",
      "üì¶ BUILDING FINAL REGISTRY\n",
      "================================================================================\n",
      "Components found: ['framework_state', 'model_state']\n",
      "  ‚Ä¢ framework_state: 2520 files\n",
      "  ‚Ä¢ model_state: 9198 files\n",
      "\n",
      "‚úÖ SCAN COMPLETE\n",
      "Modes scanned: 1\n",
      "Total files in registry: 11718\n",
      "================================================================================\n",
      "\n",
      "\t‚Üí Filesystem scan found 11718 files\n",
      "\n",
      "===================== GET DRIVE REGISTRY =====================\n",
      "===================== REGISTRY BUILD COMPLETE =====================\n",
      "\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "\tüì¶ LocalBackupManager Registry Saved Locally in LOCAL\n",
      "BUILDING REGISTRY WITH 0 EXPECTED COMPONENTS KEYS\n",
      "\n",
      "===================== GET LOCAL REGISTRY =====================\n",
      "‚Üí Skipping local cache (force=True or file missing)\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "\tüì¶ LocalBackupManager Registry Saved Locally in LOCAL\n",
      "\n",
      "======================================================================\n",
      "üéØ AllocatorRunner initialized: Dynamic\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "üöÄ STARTING ALLOCATOR: Dynamic\n",
      "======================================================================\n",
      "\n",
      "üìä Physics Model: paper12\n",
      "\n",
      "üìã Allocator Config:\n",
      "   Type: Dynamic\n",
      "   Testbed: paper12\n",
      "   Paths: 4\n",
      "   Total Qubits: 100\n",
      "   Min per route: 3\n",
      "   Seed: 42\n",
      "   Exploration bonus: 1.5\n",
      "‚úÖ Allocator created: (25, 25, 25, 25)\n",
      "‚úì Allocator: DynamicQubitAllocator (4 paths)\n",
      "   Initial allocation: (25, 25, 25, 25)\n",
      "Generated paper12 Waxman topology: 100 nodes, 416 edges, avg degree: 8.32\n",
      "üìä Paper12 Physics: Fusion (prob=0.9)\n",
      "\n",
      "======================================================================\n",
      "RUN 1 | Scale: 2 | Exp: 5\n",
      "======================================================================\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "\n",
      "\tüîÑ Resume: MultiRunEvaluator\n",
      "\n",
      "=====================================================\n",
      "üîç GENERATING EXPECTED KEYS FROM EVALUATOR\n",
      "=====================================================\n",
      "  ‚Ä¢ Evaluator filename: MultiRunEvaluator_3000-Dynamic_All_All-1500_500_5_S2T_paper12.pkl\n",
      "\n",
      "üß© PARSED COMPONENTS\n",
      "  ‚Ä¢ cap_id:        3000\n",
      "  ‚Ä¢ allocator_id:  Dynamic\n",
      "  ‚Ä¢ env_id:        All\n",
      "  ‚Ä¢ attack_id:     All\n",
      "  ‚Ä¢ base_frames:   1500\n",
      "  ‚Ä¢ frame_step:    500\n",
      "  ‚Ä¢ runs_id:       5\n",
      "\n",
      "=====================================================\n",
      "üß™ GENERATING KEYS FOR EACH RUN\n",
      "=====================================================\n",
      "\n",
      "--- Run 1/5 -----------------------\n",
      "\n",
      "=====================================================\n",
      "üì¶ FINAL EXPECTED KEYS\n",
      "=====================================================\n",
      "  ‚Ä¢ Runner keys: 11\n",
      "\n",
      "  ‚Ä¢ Model keys: 50\n",
      "\n",
      "--- Run 2/5 -----------------------\n",
      "\n",
      "=====================================================\n",
      "üì¶ FINAL EXPECTED KEYS\n",
      "=====================================================\n",
      "  ‚Ä¢ Runner keys: 21\n",
      "\n",
      "  ‚Ä¢ Model keys: 100\n",
      "\n",
      "--- Run 3/5 -----------------------\n",
      "\n",
      "=====================================================\n",
      "üì¶ FINAL EXPECTED KEYS\n",
      "=====================================================\n",
      "  ‚Ä¢ Runner keys: 31\n",
      "\n",
      "  ‚Ä¢ Model keys: 150\n",
      "\n",
      "--- Run 4/5 -----------------------\n",
      "\n",
      "=====================================================\n",
      "üì¶ FINAL EXPECTED KEYS\n",
      "=====================================================\n",
      "  ‚Ä¢ Runner keys: 41\n",
      "\n",
      "  ‚Ä¢ Model keys: 200\n",
      "\n",
      "--- Run 5/5 -----------------------\n",
      "\n",
      "=====================================================\n",
      "üì¶ FINAL EXPECTED KEYS\n",
      "=====================================================\n",
      "  ‚Ä¢ Runner keys: 51\n",
      "\n",
      "  ‚Ä¢ Model keys: 250\n",
      "\n",
      "EXPECTED KEY GENERATION COMPLETE\n",
      "\n",
      "RESTORING FROM DRIVE 1\n",
      "RESTORING FROM DRIVE 2\n",
      "\t‚ö†Ô∏è Registry exists ‚Üí aborting restore\n",
      "\t‚úì MultiRunEvaluator Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/MultiRunEvaluator_3000-Dynamic_All_All-1500_500_5_S2T_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/MultiRunEvaluator_3000-Dynamic_All_All-1500_500_5_S2T_paper12.pkl\n",
      "\t   File exists: True, size: 57176831\n",
      "EQUAL METHOD\n",
      "Multi-Run Evaluator Initialized\n",
      "Environment Type: None\n",
      "Frame Range: 1500 -> 3500 (step: 500)\n",
      "quantum_exps-Dynamic(paper12)_alloc-all_envs-5_attacks-1500_500-5_runs-S2T\n",
      "[Logging Redirect Initialized]\n",
      "Log File: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/quantum_logs/quantum_exps-Dynamic(paper12)_alloc-all_envs-5_attacks-1500_500-5_runs-S2T_20260201_log.txt\n",
      "‚öô Running evaluation...\n",
      "======================================================================\n",
      "SCENARIOS MODEL EVALUATION\n",
      "======================================================================\n",
      "Testing algorithm performance against:\n",
      "\t‚Ä¢ Stochastic:  \tNatural quantum decoherence and network failures\n",
      "\t‚Ä¢ Baseline:    \tOptimal conditions for validation\n",
      "======================================================================\n",
      "Models to Test:             \tOracle, GNeuralUCB, EXPNeuralUCB, CPursuitNeuralUCB, iCPursuitNeuralUCB\n",
      "Experiments per Scenario:   \t5\n",
      "======================================================================\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: BASELINE (OPTIMAL CONDITIONS)\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: NONE\n",
      "Category: Baseline (No Attacks)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 1500 frames  <>  SCALED-CAPACITY: 3000 frames (CAPACITY:1500 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=0 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for NONE Exp 1: (25, 25, 25, 25)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 1: Env:Baseline (None), Attack:No, Rate:0.0, Frames:1500, QubitAlloc=Dynamic, SC:3000 (Scale=2 x Cap=1500), Seed: 18010\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_1\n",
      "\t‚úì QuantumExperimentRunner_1 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_3000-Dynamic_Baseline (None)_No-1500_1_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_3000-Dynamic_Baseline (None)_No-1500_1_paper12.pkl\n",
      "\t   File exists: True, size: 705279\n",
      "‚è© SKIPPING EXPERIMENT 1: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 1 GNEURALUCB          : Reward=0875.40, Efficiency=065.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=3000, Threshold=0.582]\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=0806.08, Efficiency=060.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.628]\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=0845.26, Efficiency=063.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.634]\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=0857.53, Efficiency=064.2% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP1 Winner:GNeuralUCB          (Gap:034.5%) [Env:Baseline (None), Attack:No X Rate:0.25, Frames:1500, SCapacity=3000, Alloc=Dynamic]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 2000 frames  <>  SCALED-CAPACITY: 4000 frames (CAPACITY:2000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=1 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for NONE Exp 2: (25, 25, 25, 25)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 2: Env:Baseline (None), Attack:No, Rate:0.0, Frames:2000, QubitAlloc=Dynamic, SC:4000 (Scale=2 x Cap=2000), Seed: 20078\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_2\n",
      "\t‚úì QuantumExperimentRunner_2 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_4000-Dynamic_Baseline (None)_No-2000_2_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_4000-Dynamic_Baseline (None)_No-2000_2_paper12.pkl\n",
      "\t   File exists: True, size: 927315\n",
      "‚è© SKIPPING EXPERIMENT 2: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 2 GNEURALUCB          : Reward=1142.23, Efficiency=064.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=4000, Threshold=0.582]\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=1144.94, Efficiency=064.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=4000, Threshold=0.628]\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=1158.64, Efficiency=065.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=4000, Threshold=0.634]\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=1152.83, Efficiency=064.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=4000, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP2 Winner:CPursuitNeuralUCB   (Gap:035.0%) [Env:Baseline (None), Attack:No X Rate:0.25, Frames:2000, SCapacity=4000, Alloc=Dynamic]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 2500 frames  <>  SCALED-CAPACITY: 5000 frames (CAPACITY:2500 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=2 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for NONE Exp 3: (25, 25, 25, 25)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 3: Env:Baseline (None), Attack:No, Rate:0.0, Frames:2500, QubitAlloc=Dynamic, SC:5000 (Scale=2 x Cap=2500), Seed: 14623\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_3\n",
      "\t‚úì QuantumExperimentRunner_3 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_5000-Dynamic_Baseline (None)_No-2500_3_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_5000-Dynamic_Baseline (None)_No-2500_3_paper12.pkl\n",
      "\t   File exists: True, size: 1149374\n",
      "‚è© SKIPPING EXPERIMENT 3: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 3 GNEURALUCB          : Reward=1451.77, Efficiency=065.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=5000, Threshold=0.582]\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=1456.77, Efficiency=065.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=5000, Threshold=0.628]\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=1470.28, Efficiency=066.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=5000, Threshold=0.634]\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=1462.87, Efficiency=065.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=5000, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP3 Winner:CPursuitNeuralUCB   (Gap:034.0%) [Env:Baseline (None), Attack:No X Rate:0.25, Frames:2500, SCapacity=5000, Alloc=Dynamic]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 3000 frames  <>  SCALED-CAPACITY: 6000 frames (CAPACITY:3000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=3 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for NONE Exp 4: (25, 25, 25, 25)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 4: Env:Baseline (None), Attack:No, Rate:0.0, Frames:3000, QubitAlloc=Dynamic, SC:6000 (Scale=2 x Cap=3000), Seed: 20090\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_4\n",
      "\t‚úì QuantumExperimentRunner_4 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_6000-Dynamic_Baseline (None)_No-3000_4_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_6000-Dynamic_Baseline (None)_No-3000_4_paper12.pkl\n",
      "\t   File exists: True, size: 1371401\n",
      "‚è© SKIPPING EXPERIMENT 4: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 4 GNEURALUCB          : Reward=1768.73, Efficiency=066.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.582]\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=1412.80, Efficiency=052.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=6000, Threshold=0.628]\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=1817.49, Efficiency=068.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.634]\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=1775.81, Efficiency=066.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=6000, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP4 Winner:CPursuitNeuralUCB   (Gap:032.0%) [Env:Baseline (None), Attack:No X Rate:0.25, Frames:3000, SCapacity=6000, Alloc=Dynamic]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 3500 frames  <>  SCALED-CAPACITY: 7000 frames (CAPACITY:3500 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=4 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for NONE Exp 5: (25, 25, 25, 25)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 5: Env:Baseline (None), Attack:No, Rate:0.0, Frames:3500, QubitAlloc=Dynamic, SC:7000 (Scale=2 x Cap=3500), Seed: 12926\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_5\n",
      "\t‚úì QuantumExperimentRunner_5 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_7000-Dynamic_Baseline (None)_No-3500_5_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_7000-Dynamic_Baseline (None)_No-3500_5_paper12.pkl\n",
      "\t   File exists: True, size: 1593469\n",
      "‚è© SKIPPING EXPERIMENT 5: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 5 GNEURALUCB          : Reward=2070.53, Efficiency=066.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=7000, Threshold=0.582]\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=1648.91, Efficiency=052.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=7000, Threshold=0.628]\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=2006.54, Efficiency=064.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=7000, Threshold=0.634]\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=2111.34, Efficiency=067.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=7000, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP5 Winner:iCPursuitNeuralUCB  (Gap:032.3%) [Env:Baseline (None), Attack:No X Rate:0.25, Frames:3500, SCapacity=7000, Alloc=Dynamic]\n",
      "\n",
      "Total experiment time: 050.3s\n",
      "Experiments completed for none\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: STOCHASTIC RANDOM FAILURES\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: STOCHASTIC\n",
      "Category: Stochastic (Natural Random Failures)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 1500 frames  <>  SCALED-CAPACITY: 3000 frames (CAPACITY:1500 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=0 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 1: (25, 25, 25, 25)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 1: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:1500, QubitAlloc=Dynamic, SC:3000 (Scale=2 x Cap=1500), Seed: 20197\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_1\n",
      "\t‚úì QuantumExperimentRunner_1 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_3000-Dynamic_Stochastic_Random-1500_1_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_3000-Dynamic_Stochastic_Random-1500_1_paper12.pkl\n",
      "\t   File exists: True, size: 705283\n",
      "‚è© SKIPPING EXPERIMENT 1: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 1 GNEURALUCB          : Reward=0804.16, Efficiency=060.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=3000, Threshold=0.582]\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=0671.20, Efficiency=050.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.628]\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=0772.01, Efficiency=057.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.634]\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=0755.65, Efficiency=056.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP1 Winner:GNeuralUCB          (Gap:039.8%) [Env:Stochastic, Attack:Random X Rate:0.25, Frames:1500, SCapacity=3000, Alloc=Dynamic]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 2000 frames  <>  SCALED-CAPACITY: 4000 frames (CAPACITY:2000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=1 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 2: (25, 25, 25, 25)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 2: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:2000, QubitAlloc=Dynamic, SC:4000 (Scale=2 x Cap=2000), Seed: 17474\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_2\n",
      "\t‚úì QuantumExperimentRunner_2 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_4000-Dynamic_Stochastic_Random-2000_2_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_4000-Dynamic_Stochastic_Random-2000_2_paper12.pkl\n",
      "\t   File exists: True, size: 927319\n",
      "‚è© SKIPPING EXPERIMENT 2: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 2 GNEURALUCB          : Reward=1087.96, Efficiency=061.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=4000, Threshold=0.582]\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=1024.23, Efficiency=057.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=4000, Threshold=0.628]\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=1065.87, Efficiency=059.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=4000, Threshold=0.634]\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=1077.69, Efficiency=060.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=4000, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP2 Winner:GNeuralUCB          (Gap:038.9%) [Env:Stochastic, Attack:Random X Rate:0.25, Frames:2000, SCapacity=4000, Alloc=Dynamic]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 2500 frames  <>  SCALED-CAPACITY: 5000 frames (CAPACITY:2500 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=2 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 3: (25, 25, 25, 25)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 3: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:2500, QubitAlloc=Dynamic, SC:5000 (Scale=2 x Cap=2500), Seed: 15795\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_3\n",
      "\t‚úì QuantumExperimentRunner_3 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_5000-Dynamic_Stochastic_Random-2500_3_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_5000-Dynamic_Stochastic_Random-2500_3_paper12.pkl\n",
      "\t   File exists: True, size: 1149378\n",
      "‚è© SKIPPING EXPERIMENT 3: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 3 GNEURALUCB          : Reward=1383.49, Efficiency=062.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=5000, Threshold=0.582]\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=1296.20, Efficiency=058.2% [Retries=3, Failed=0, < Threshold=3, SCapacity=5000, Threshold=0.628]\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=1345.51, Efficiency=060.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=5000, Threshold=0.634]\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=1341.18, Efficiency=060.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=5000, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP3 Winner:GNeuralUCB          (Gap:037.8%) [Env:Stochastic, Attack:Random X Rate:0.25, Frames:2500, SCapacity=5000, Alloc=Dynamic]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 3000 frames  <>  SCALED-CAPACITY: 6000 frames (CAPACITY:3000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=3 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 4: (25, 25, 25, 25)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 4: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:3000, QubitAlloc=Dynamic, SC:6000 (Scale=2 x Cap=3000), Seed: 17031\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_4\n",
      "\t‚úì QuantumExperimentRunner_4 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_6000-Dynamic_Stochastic_Random-3000_4_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_6000-Dynamic_Stochastic_Random-3000_4_paper12.pkl\n",
      "\t   File exists: True, size: 1371405\n",
      "‚è© SKIPPING EXPERIMENT 4: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 4 GNEURALUCB          : Reward=1647.39, Efficiency=061.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.582]\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=1548.68, Efficiency=058.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=6000, Threshold=0.628]\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=1616.46, Efficiency=060.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=6000, Threshold=0.634]\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=1663.70, Efficiency=062.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=6000, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP4 Winner:iCPursuitNeuralUCB  (Gap:037.7%) [Env:Stochastic, Attack:Random X Rate:0.25, Frames:3000, SCapacity=6000, Alloc=Dynamic]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 3500 frames  <>  SCALED-CAPACITY: 7000 frames (CAPACITY:3500 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=4 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 5: (25, 25, 25, 25)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 5: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:3500, QubitAlloc=Dynamic, SC:7000 (Scale=2 x Cap=3500), Seed: 21490\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_5\n",
      "\t‚úì QuantumExperimentRunner_5 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_7000-Dynamic_Stochastic_Random-3500_5_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_7000-Dynamic_Stochastic_Random-3500_5_paper12.pkl\n",
      "\t   File exists: True, size: 1593473\n",
      "‚è© SKIPPING EXPERIMENT 5: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 5 GNEURALUCB          : Reward=1904.68, Efficiency=061.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=7000, Threshold=0.582]\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=1926.75, Efficiency=061.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=7000, Threshold=0.628]\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=1882.67, Efficiency=060.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=7000, Threshold=0.634]\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=1919.66, Efficiency=061.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=7000, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP5 Winner:EXPNeuralUCB        (Gap:038.2%) [Env:Stochastic, Attack:Random X Rate:0.25, Frames:3500, SCapacity=7000, Alloc=Dynamic]\n",
      "\n",
      "Total experiment time: 052.4s\n",
      "Experiments completed for stochastic\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: MARKOV ADVERSARIAL ATTACK\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: MARKOV\n",
      "Category: Structured (Markov Chain Based)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 1500 frames  <>  SCALED-CAPACITY: 3000 frames (CAPACITY:1500 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=0 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for MARKOV Exp 1: (25, 25, 25, 25)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 1: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:1500, QubitAlloc=Dynamic, SC:3000 (Scale=2 x Cap=1500), Seed: 20262\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_1\n",
      "\t‚úì QuantumExperimentRunner_1 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_3000-Dynamic_Adversarial_Markov-1500_1_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_3000-Dynamic_Adversarial_Markov-1500_1_paper12.pkl\n",
      "\t   File exists: True, size: 705281\n",
      "‚è© SKIPPING EXPERIMENT 1: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 1 GNEURALUCB          : Reward=0433.35, Efficiency=035.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.582]\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=0421.05, Efficiency=034.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.628]\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=0445.65, Efficiency=036.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.634]\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=0458.24, Efficiency=037.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP1 Winner:iCPursuitNeuralUCB  (Gap:062.9%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:1500, SCapacity=3000, Alloc=Dynamic]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 2000 frames  <>  SCALED-CAPACITY: 4000 frames (CAPACITY:2000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=1 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for MARKOV Exp 2: (25, 25, 25, 25)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 2: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:2000, QubitAlloc=Dynamic, SC:4000 (Scale=2 x Cap=2000), Seed: 15238\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_2\n",
      "\t‚úì QuantumExperimentRunner_2 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_4000-Dynamic_Adversarial_Markov-2000_2_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_4000-Dynamic_Adversarial_Markov-2000_2_paper12.pkl\n",
      "\t   File exists: True, size: 927317\n",
      "‚è© SKIPPING EXPERIMENT 2: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 2 GNEURALUCB          : Reward=0578.40, Efficiency=034.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=4000, Threshold=0.582]\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=0538.84, Efficiency=032.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=4000, Threshold=0.628]\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=0552.13, Efficiency=033.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=4000, Threshold=0.634]\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=0631.18, Efficiency=037.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=4000, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP2 Winner:iCPursuitNeuralUCB  (Gap:062.1%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:2000, SCapacity=4000, Alloc=Dynamic]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 2500 frames  <>  SCALED-CAPACITY: 5000 frames (CAPACITY:2500 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=2 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for MARKOV Exp 3: (25, 25, 25, 25)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 3: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:2500, QubitAlloc=Dynamic, SC:5000 (Scale=2 x Cap=2500), Seed: 15202\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_3\n",
      "\t‚úì QuantumExperimentRunner_3 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_5000-Dynamic_Adversarial_Markov-2500_3_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_5000-Dynamic_Adversarial_Markov-2500_3_paper12.pkl\n",
      "\t   File exists: True, size: 1149376\n",
      "‚è© SKIPPING EXPERIMENT 3: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 3 GNEURALUCB          : Reward=0733.70, Efficiency=035.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=5000, Threshold=0.582]\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=0740.63, Efficiency=035.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=5000, Threshold=0.628]\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=0710.20, Efficiency=034.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=5000, Threshold=0.634]\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=0752.53, Efficiency=036.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=5000, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP3 Winner:iCPursuitNeuralUCB  (Gap:063.5%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:2500, SCapacity=5000, Alloc=Dynamic]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 3000 frames  <>  SCALED-CAPACITY: 6000 frames (CAPACITY:3000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=3 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for MARKOV Exp 4: (25, 25, 25, 25)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 4: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:3000, QubitAlloc=Dynamic, SC:6000 (Scale=2 x Cap=3000), Seed: 19699\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_4\n",
      "\t‚úì QuantumExperimentRunner_4 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_6000-Dynamic_Adversarial_Markov-3000_4_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_6000-Dynamic_Adversarial_Markov-3000_4_paper12.pkl\n",
      "\t   File exists: True, size: 1371403\n",
      "‚è© SKIPPING EXPERIMENT 4: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 4 GNEURALUCB          : Reward=0868.90, Efficiency=034.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=6000, Threshold=0.582]\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=0753.04, Efficiency=030.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=6000, Threshold=0.628]\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=0822.98, Efficiency=032.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=6000, Threshold=0.634]\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=0885.84, Efficiency=035.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=6000, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP4 Winner:iCPursuitNeuralUCB  (Gap:064.7%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:3000, SCapacity=6000, Alloc=Dynamic]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 3500 frames  <>  SCALED-CAPACITY: 7000 frames (CAPACITY:3500 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=4 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for MARKOV Exp 5: (25, 25, 25, 25)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 5: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:3500, QubitAlloc=Dynamic, SC:7000 (Scale=2 x Cap=3500), Seed: 22085\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_5\n",
      "\t‚úì QuantumExperimentRunner_5 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_7000-Dynamic_Adversarial_Markov-3500_5_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_7000-Dynamic_Adversarial_Markov-3500_5_paper12.pkl\n",
      "\t   File exists: True, size: 1593471\n",
      "‚è© SKIPPING EXPERIMENT 5: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 5 GNEURALUCB          : Reward=0961.32, Efficiency=033.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=7000, Threshold=0.582]\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=1034.28, Efficiency=035.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=7000, Threshold=0.628]\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=0978.39, Efficiency=033.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=7000, Threshold=0.634]\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=1043.75, Efficiency=035.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=7000, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP5 Winner:iCPursuitNeuralUCB  (Gap:064.2%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:3500, SCapacity=7000, Alloc=Dynamic]\n",
      "\n",
      "Total experiment time: 054.6s\n",
      "Experiments completed for markov\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: ADAPTIVE ADVERSARIAL ATTACK\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: ADAPTIVE\n",
      "Category: Adaptive (Reactive Strategic)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 1500 frames  <>  SCALED-CAPACITY: 3000 frames (CAPACITY:1500 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=0 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 1: (25, 25, 25, 25)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 1: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:1500, QubitAlloc=Dynamic, SC:3000 (Scale=2 x Cap=1500), Seed: 14115\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_1\n",
      "\t‚úì QuantumExperimentRunner_1 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_3000-Dynamic_Adversarial_Adaptive-1500_1_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_3000-Dynamic_Adversarial_Adaptive-1500_1_paper12.pkl\n",
      "\t   File exists: True, size: 705287\n",
      "‚è© SKIPPING EXPERIMENT 1: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 1 GNEURALUCB          : Reward=0605.92, Efficiency=045.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.582]\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=0519.51, Efficiency=039.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.628]\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=0606.41, Efficiency=045.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.634]\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=0627.97, Efficiency=047.2% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP1 Winner:iCPursuitNeuralUCB  (Gap:052.8%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:1500, SCapacity=3000, Alloc=Dynamic]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 2000 frames  <>  SCALED-CAPACITY: 4000 frames (CAPACITY:2000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=1 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 2: (25, 25, 25, 25)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 2: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:2000, QubitAlloc=Dynamic, SC:4000 (Scale=2 x Cap=2000), Seed: 14473\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_2\n",
      "\t‚úì QuantumExperimentRunner_2 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_4000-Dynamic_Adversarial_Adaptive-2000_2_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_4000-Dynamic_Adversarial_Adaptive-2000_2_paper12.pkl\n",
      "\t   File exists: True, size: 927323\n",
      "‚è© SKIPPING EXPERIMENT 2: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 2 GNEURALUCB          : Reward=0808.83, Efficiency=045.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=4000, Threshold=0.582]\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=0796.95, Efficiency=045.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=4000, Threshold=0.628]\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=0818.65, Efficiency=046.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=4000, Threshold=0.634]\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=0850.69, Efficiency=048.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=4000, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP2 Winner:iCPursuitNeuralUCB  (Gap:051.9%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:2000, SCapacity=4000, Alloc=Dynamic]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 2500 frames  <>  SCALED-CAPACITY: 5000 frames (CAPACITY:2500 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=2 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 3: (25, 25, 25, 25)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 3: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:2500, QubitAlloc=Dynamic, SC:5000 (Scale=2 x Cap=2500), Seed: 13973\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_3\n",
      "\t‚úì QuantumExperimentRunner_3 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_5000-Dynamic_Adversarial_Adaptive-2500_3_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_5000-Dynamic_Adversarial_Adaptive-2500_3_paper12.pkl\n",
      "\t   File exists: True, size: 1149382\n",
      "‚è© SKIPPING EXPERIMENT 3: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 3 GNEURALUCB          : Reward=1103.93, Efficiency=049.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=5000, Threshold=0.582]\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=1131.62, Efficiency=051.2% [Retries=3, Failed=0, < Threshold=3, SCapacity=5000, Threshold=0.628]\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=1091.57, Efficiency=049.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=5000, Threshold=0.634]\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=1093.23, Efficiency=049.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=5000, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP3 Winner:EXPNeuralUCB        (Gap:048.8%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:2500, SCapacity=5000, Alloc=Dynamic]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 3000 frames  <>  SCALED-CAPACITY: 6000 frames (CAPACITY:3000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=3 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 4: (25, 25, 25, 25)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 4: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:3000, QubitAlloc=Dynamic, SC:6000 (Scale=2 x Cap=3000), Seed: 16838\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_4\n",
      "\t‚úì QuantumExperimentRunner_4 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_6000-Dynamic_Adversarial_Adaptive-3000_4_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_6000-Dynamic_Adversarial_Adaptive-3000_4_paper12.pkl\n",
      "\t   File exists: True, size: 1371409\n",
      "‚è© SKIPPING EXPERIMENT 4: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 4 GNEURALUCB          : Reward=1172.54, Efficiency=044.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=6000, Threshold=0.582]\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=1282.51, Efficiency=048.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=6000, Threshold=0.628]\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=1346.12, Efficiency=050.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=6000, Threshold=0.634]\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=1263.06, Efficiency=047.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=6000, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP4 Winner:CPursuitNeuralUCB   (Gap:049.3%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:3000, SCapacity=6000, Alloc=Dynamic]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 3500 frames  <>  SCALED-CAPACITY: 7000 frames (CAPACITY:3500 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=4 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 5: (25, 25, 25, 25)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 5: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:3500, QubitAlloc=Dynamic, SC:7000 (Scale=2 x Cap=3500), Seed: 20582\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_5\n",
      "\t‚úì QuantumExperimentRunner_5 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_7000-Dynamic_Adversarial_Adaptive-3500_5_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_7000-Dynamic_Adversarial_Adaptive-3500_5_paper12.pkl\n",
      "\t   File exists: True, size: 1593477\n",
      "‚è© SKIPPING EXPERIMENT 5: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 5 GNEURALUCB          : Reward=1489.41, Efficiency=048.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=7000, Threshold=0.582]\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=1605.83, Efficiency=051.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=7000, Threshold=0.628]\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=1514.05, Efficiency=048.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=7000, Threshold=0.634]\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=1537.50, Efficiency=049.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=7000, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP5 Winner:EXPNeuralUCB        (Gap:048.1%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:3500, SCapacity=7000, Alloc=Dynamic]\n",
      "\n",
      "Total experiment time: 049.0s\n",
      "Experiments completed for adaptive\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: ONLINE ADAPTIVE ATTACK\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: ONLINEADAPTIVE\n",
      "Category: Online Adaptive (Real-time Strategic)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 1500 frames  <>  SCALED-CAPACITY: 3000 frames (CAPACITY:1500 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=0 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 1: (25, 25, 25, 25)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:1500, QubitAlloc=Dynamic, SC:3000 (Scale=2 x Cap=1500), Seed: 14103\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_1\n",
      "\t‚úì QuantumExperimentRunner_1 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_3000-Dynamic_Adversarial_OnlineAdaptive-1500_1_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_3000-Dynamic_Adversarial_OnlineAdaptive-1500_1_paper12.pkl\n",
      "\t   File exists: True, size: 705305\n",
      "‚è© SKIPPING EXPERIMENT 1: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 1 GNEURALUCB          : Reward=0634.48, Efficiency=047.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.582]\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=0612.55, Efficiency=046.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.628]\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=0613.63, Efficiency=046.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.634]\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=0617.63, Efficiency=046.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP1 Winner:GNeuralUCB          (Gap:052.1%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:1500, SCapacity=3000, Alloc=Dynamic]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 2000 frames  <>  SCALED-CAPACITY: 4000 frames (CAPACITY:2000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=1 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 2: (25, 25, 25, 25)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:2000, QubitAlloc=Dynamic, SC:4000 (Scale=2 x Cap=2000), Seed: 22352\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_2\n",
      "\t‚úì QuantumExperimentRunner_2 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_4000-Dynamic_Adversarial_OnlineAdaptive-2000_2_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_4000-Dynamic_Adversarial_OnlineAdaptive-2000_2_paper12.pkl\n",
      "\t   File exists: True, size: 927341\n",
      "‚è© SKIPPING EXPERIMENT 2: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 2 GNEURALUCB          : Reward=0814.56, Efficiency=046.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=4000, Threshold=0.582]\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=0673.40, Efficiency=038.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=4000, Threshold=0.628]\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=0826.57, Efficiency=046.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=4000, Threshold=0.634]\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=0839.94, Efficiency=047.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=4000, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP2 Winner:iCPursuitNeuralUCB  (Gap:052.5%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:2000, SCapacity=4000, Alloc=Dynamic]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 2500 frames  <>  SCALED-CAPACITY: 5000 frames (CAPACITY:2500 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=2 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 3: (25, 25, 25, 25)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:2500, QubitAlloc=Dynamic, SC:5000 (Scale=2 x Cap=2500), Seed: 14162\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_3\n",
      "\t‚úì QuantumExperimentRunner_3 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_5000-Dynamic_Adversarial_OnlineAdaptive-2500_3_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_5000-Dynamic_Adversarial_OnlineAdaptive-2500_3_paper12.pkl\n",
      "\t   File exists: True, size: 1149400\n",
      "‚è© SKIPPING EXPERIMENT 3: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 3 GNEURALUCB          : Reward=1095.02, Efficiency=049.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=5000, Threshold=0.582]\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=0915.92, Efficiency=041.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=5000, Threshold=0.628]\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=1068.05, Efficiency=048.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=5000, Threshold=0.634]\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=1073.15, Efficiency=048.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=5000, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP3 Winner:GNeuralUCB          (Gap:050.5%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:2500, SCapacity=5000, Alloc=Dynamic]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 3000 frames  <>  SCALED-CAPACITY: 6000 frames (CAPACITY:3000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=3 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 4: (25, 25, 25, 25)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:3000, QubitAlloc=Dynamic, SC:6000 (Scale=2 x Cap=3000), Seed: 21587\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_4\n",
      "\t‚úì QuantumExperimentRunner_4 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_6000-Dynamic_Adversarial_OnlineAdaptive-3000_4_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_6000-Dynamic_Adversarial_OnlineAdaptive-3000_4_paper12.pkl\n",
      "\t   File exists: True, size: 1371427\n",
      "‚è© SKIPPING EXPERIMENT 4: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 4 GNEURALUCB          : Reward=1312.77, Efficiency=049.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=6000, Threshold=0.582]\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=1472.72, Efficiency=055.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=6000, Threshold=0.628]\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=1296.68, Efficiency=048.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=6000, Threshold=0.634]\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=1359.43, Efficiency=051.2% [Retries=3, Failed=0, < Threshold=3, SCapacity=6000, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP4 Winner:EXPNeuralUCB        (Gap:044.5%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:3000, SCapacity=6000, Alloc=Dynamic]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 3500 frames  <>  SCALED-CAPACITY: 7000 frames (CAPACITY:3500 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=4 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 5: (25, 25, 25, 25)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:3500, QubitAlloc=Dynamic, SC:7000 (Scale=2 x Cap=3500), Seed: 17102\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_5\n",
      "\t‚úì QuantumExperimentRunner_5 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_7000-Dynamic_Adversarial_OnlineAdaptive-3500_5_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_7000-Dynamic_Adversarial_OnlineAdaptive-3500_5_paper12.pkl\n",
      "\t   File exists: True, size: 1593495\n",
      "‚è© SKIPPING EXPERIMENT 5: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 5 GNEURALUCB          : Reward=1520.17, Efficiency=049.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=7000, Threshold=0.582]\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=1511.12, Efficiency=048.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=7000, Threshold=0.628]\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=1521.07, Efficiency=049.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=7000, Threshold=0.634]\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=1524.48, Efficiency=049.2% [Retries=3, Failed=0, < Threshold=3, SCapacity=7000, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP5 Winner:iCPursuitNeuralUCB  (Gap:050.8%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:3500, SCapacity=7000, Alloc=Dynamic]\n",
      "\n",
      "Total experiment time: 054.1s\n",
      "Experiments completed for onlineadaptive\n",
      "‚úì Scenario 'none' evaluation completed.\n",
      "‚úì Scenario 'stochastic' evaluation completed.\n",
      "‚úì Scenario 'markov' evaluation completed.\n",
      "‚úì Scenario 'adaptive' evaluation completed.\n",
      "‚úì Scenario 'onlineadaptive' evaluation completed.\n",
      "\n",
      "======================================================================\n",
      "COMPREHENSIVE SCENARIO PERFORMANCE ANALYSIS\n",
      "======================================================================\n",
      "SCENARIO: NONE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 2226.96\n",
      "\t‚Ä¢ Winner Avg Gap: 0034.25%\n",
      "\t‚Ä¢ Winner Avg Reward: 1472.07\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0065.75%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 1 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 3 wins\n",
      "\t\t- iCPursuitNeuralUCB: 1 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: NONE\n",
      "======================================================================\n",
      "SCENARIO: \tBASELINE (OPTIMAL CONDITIONS)\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 1/5 experiments)\n",
      "\tWinner Avg Gap: \t034.3%\n",
      "\tWinner Avg Efficiency: \t065.7%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t065.7% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t065.5% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t065.3% Efficiency \t(Won 3/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t059.2% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: STOCHASTIC\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: GNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 2225.41\n",
      "\t‚Ä¢ Winner Avg Gap: 0038.73%\n",
      "\t‚Ä¢ Winner Avg Reward: 1365.54\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0061.27%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 3 wins\n",
      "\t\t- EXPNeuralUCB: 1 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 1 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: STOCHASTIC\n",
      "======================================================================\n",
      "SCENARIO: \tSTOCHASTIC RANDOM FAILURES\n",
      "----------------------------------------\n",
      "Recommended Model: \tGNeuralUCB (Won 3/5 experiments)\n",
      "\tWinner Avg Gap: \t038.7%\n",
      "\tWinner Avg Efficiency: \t061.3%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ GNeuralUCB     : \t061.3% Efficiency \t(Won 3/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t060.3% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t059.8% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t057.2% Efficiency \t(Won 1/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: MARKOV\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 2077.34\n",
      "\t‚Ä¢ Winner Avg Gap: 0063.48%\n",
      "\t‚Ä¢ Winner Avg Reward: 0754.31\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0036.52%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 5 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: MARKOV\n",
      "======================================================================\n",
      "SCENARIO: \tMARKOV ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 5/5 experiments)\n",
      "\tWinner Avg Gap: \t063.5%\n",
      "\tWinner Avg Efficiency: \t036.5%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t036.5% Efficiency \t(Won 5/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t034.6% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t034.0% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t033.6% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 2212.50\n",
      "\t‚Ä¢ Winner Avg Gap: 0051.61%\n",
      "\t‚Ä¢ Winner Avg Reward: 1074.49\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0048.39%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 2 wins\n",
      "\t\t- CPursuitNeuralUCB: 1 wins\n",
      "\t\t- iCPursuitNeuralUCB: 2 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tADAPTIVE ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 2/5 experiments)\n",
      "\tWinner Avg Gap: \t051.6%\n",
      "\tWinner Avg Efficiency: \t048.4%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t048.4% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t048.2% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t047.1% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t046.7% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ONLINEADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 2211.22\n",
      "\t‚Ä¢ Winner Avg Gap: 0051.38%\n",
      "\t‚Ä¢ Winner Avg Reward: 1082.93\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0048.62%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 2 wins\n",
      "\t\t- EXPNeuralUCB: 1 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 2 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ONLINEADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tONLINE ADAPTIVE ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 2/5 experiments)\n",
      "\tWinner Avg Gap: \t051.4%\n",
      "\tWinner Avg Efficiency: \t048.6%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t048.6% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t048.4% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t047.9% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t046.0% Efficiency \t(Won 1/5 experiments)\n",
      "======================================================================\n",
      "KEY INSIGHTS:\n",
      "Best Performing Model Analysis (GNeuralUCB):\n",
      "\t‚Ä¢ Stochastic Performance:    \t1365.538\n",
      "\t‚Ä¢ Baseline Performance:      \t1472.075\n",
      "\t‚Ä¢ Performance Retention:     \t092.8%\n",
      "\tGOOD:               \tAcceptable performance under stochastic conditions\n",
      "Statistical Analysis:\n",
      "\t‚Ä¢ Total models evaluated:     \t5\n",
      "\t‚Ä¢ Experiments per environment:\t5\n",
      "\t‚Ä¢ Quantum network simulation: \tComprehensive stochastic modeling\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "COMPREHENSIVE SCENARIO PERFORMANCE ANALYSIS\n",
      "======================================================================\n",
      "SCENARIO: NONE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 2226.96\n",
      "\t‚Ä¢ Winner Avg Gap: 0034.25%\n",
      "\t‚Ä¢ Winner Avg Reward: 1472.07\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0065.75%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 1 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 3 wins\n",
      "\t\t- iCPursuitNeuralUCB: 1 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: NONE\n",
      "======================================================================\n",
      "SCENARIO: \tBASELINE (OPTIMAL CONDITIONS)\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 1/5 experiments)\n",
      "\tWinner Avg Gap: \t034.3%\n",
      "\tWinner Avg Efficiency: \t065.7%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t065.7% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t065.5% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t065.3% Efficiency \t(Won 3/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t059.2% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: STOCHASTIC\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: GNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 2225.41\n",
      "\t‚Ä¢ Winner Avg Gap: 0038.73%\n",
      "\t‚Ä¢ Winner Avg Reward: 1365.54\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0061.27%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 3 wins\n",
      "\t\t- EXPNeuralUCB: 1 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 1 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: STOCHASTIC\n",
      "======================================================================\n",
      "SCENARIO: \tSTOCHASTIC RANDOM FAILURES\n",
      "----------------------------------------\n",
      "Recommended Model: \tGNeuralUCB (Won 3/5 experiments)\n",
      "\tWinner Avg Gap: \t038.7%\n",
      "\tWinner Avg Efficiency: \t061.3%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ GNeuralUCB     : \t061.3% Efficiency \t(Won 3/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t060.3% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t059.8% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t057.2% Efficiency \t(Won 1/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: MARKOV\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 2077.34\n",
      "\t‚Ä¢ Winner Avg Gap: 0063.48%\n",
      "\t‚Ä¢ Winner Avg Reward: 0754.31\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0036.52%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 5 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: MARKOV\n",
      "======================================================================\n",
      "SCENARIO: \tMARKOV ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 5/5 experiments)\n",
      "\tWinner Avg Gap: \t063.5%\n",
      "\tWinner Avg Efficiency: \t036.5%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t036.5% Efficiency \t(Won 5/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t034.6% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t034.0% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t033.6% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 2212.50\n",
      "\t‚Ä¢ Winner Avg Gap: 0051.61%\n",
      "\t‚Ä¢ Winner Avg Reward: 1074.49\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0048.39%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 2 wins\n",
      "\t\t- CPursuitNeuralUCB: 1 wins\n",
      "\t\t- iCPursuitNeuralUCB: 2 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tADAPTIVE ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 2/5 experiments)\n",
      "\tWinner Avg Gap: \t051.6%\n",
      "\tWinner Avg Efficiency: \t048.4%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t048.4% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t048.2% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t047.1% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t046.7% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ONLINEADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 2211.22\n",
      "\t‚Ä¢ Winner Avg Gap: 0051.38%\n",
      "\t‚Ä¢ Winner Avg Reward: 1082.93\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0048.62%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 2 wins\n",
      "\t\t- EXPNeuralUCB: 1 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 2 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ONLINEADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tONLINE ADAPTIVE ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 2/5 experiments)\n",
      "\tWinner Avg Gap: \t051.4%\n",
      "\tWinner Avg Efficiency: \t048.6%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t048.6% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t048.4% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t047.9% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t046.0% Efficiency \t(Won 1/5 experiments)\n",
      "======================================================================\n",
      "‚úÖ Evaluation completed!\n",
      "[Logging Redirect Stopped]\n",
      "\n",
      "üßπ Final cleanup for Dynamic\n",
      "\n",
      "======================================================================\n",
      "‚úÖ COMPLETED: Dynamic\n",
      "======================================================================\n",
      "\n",
      "Dynamic COMPLETED SUCCESSFULLY\n",
      "\n",
      "======================================================================\n",
      "ALL ALLOCATORS COMPLETE!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Cell: Allocator + ExperimentConfiguration for Paper #12\n",
    "# ============================================================\n",
    "importlib.reload(qubit_allocator)\n",
    "importlib.reload(experiment_config)\n",
    "importlib.reload(multi_run_evaluator)\n",
    "\n",
    "from daqr.core.quantum_physics              import *\n",
    "from daqr.evaluation.allocator_runner       import AllocatorRunner\n",
    "from daqr.evaluation.multi_run_evaluator    import MultiRunEvaluator\n",
    "from daqr.config.experiment_config          import ExperimentConfiguration\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"PAPER #12 (QuARC) QUANTUM ROUTING EVALUATION - ALL ALLOCATORS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1) Allocator Selection\n",
    "# ------------------------------------------------------------\n",
    "ALLOCATORS = [\"Dynamic\"]\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2) Run Parameters\n",
    "# ------------------------------------------------------------\n",
    "# CORRECTED Paper 12 Evaluation\n",
    "attack_intensity    = FRAMEWORK_CONFIG['intensity']\n",
    "current_frames      = 1500      # 3 reconfiguration cycles\n",
    "frame_step          = 500       # Epoch-aligned checkpoints\n",
    "current_experiments = 1\n",
    "last_backup         = True\n",
    "base_cap            = False\n",
    "overwrite           = False\n",
    "\n",
    "RUNS                = [5]               # Acceptable for initial testing\n",
    "SCALES              = [1, 1.5, 2]\n",
    "ATTACK_SCENARIOS    = ['stochastic']    # Start simple\n",
    "print(f\"‚úÖ Testing QuARC with {current_frames} timeslots\")\n",
    "print(f\"‚úÖ Expected reconfigurations: {current_frames // 500}\")\n",
    "print(f\"‚úÖ Statistical runs: {RUNS[0]}\")\n",
    "\n",
    "FRAMEWORK_CONFIG['exp_num']     = current_experiments\n",
    "FRAMEWORK_CONFIG['base_frames'] = current_frames\n",
    "FRAMEWORK_CONFIG['frame_step']  = frame_step\n",
    "\n",
    "# Testbed Configuration\n",
    "PHYSICS_MODELS = ['paper12']  # Paper 12 (QuARC)\n",
    "ATTACK_SCENARIOS = ['stochastic']  # Start simple\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PAPER 12 ALLOCATOR EVALUATION\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Allocators:                 {ALLOCATORS}\")\n",
    "print(f\"Physics Models:             {PHYSICS_MODELS}\")\n",
    "print(f\"Attack Scenarios:           {ATTACK_SCENARIOS}\")\n",
    "print(f\"Scales:                     {SCALES}\")\n",
    "print(f\"Runs per Scale:             {RUNS}\")\n",
    "print(f\"Total Frames:               {current_frames}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "\n",
    "for allocator_type in ALLOCATORS:\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"RUNNING: {allocator_type} on Paper 12 (QuARC)\")\n",
    "    print('='*70)\n",
    "\n",
    "    for scale in SCALES:\n",
    "        print(f\"\\n{'-'*70}\")\n",
    "        print(f\"Preparing: {allocator_type} at scale {scale}\")\n",
    "        print(f\"{'-'*70}\")\n",
    "\n",
    "        for physics_model in PHYSICS_MODELS:\n",
    "            print(f\"\\nüîß Generating physics parameters for model: {physics_model}\") \n",
    "            try:\n",
    "                # Create isolated runner instance\n",
    "                custom_config = ExperimentConfiguration(\n",
    "                    env_type=FRAMEWORK_CONFIG['main_env'],\n",
    "                    scenarios=test_scenarios,\n",
    "                    use_last_backup=last_backup,\n",
    "                    models=models,\n",
    "                    attack_intensity=attack_intensity,\n",
    "                    scale=scale,\n",
    "                    base_capacity=base_cap,\n",
    "                    overwrite=overwrite\n",
    "                )\n",
    "\n",
    "                alloc_runner = AllocatorRunner(\n",
    "                    allocator_type=allocator_type,\n",
    "                    physics_models=[physics_model],\n",
    "                    framework_config=FRAMEWORK_CONFIG,\n",
    "                    scales=[scale],\n",
    "                    runs=RUNS,\n",
    "                    models=models,\n",
    "                    test_scenarios=test_scenarios,\n",
    "                    config=custom_config\n",
    "                )\n",
    "\n",
    "                # Run with Paper 12 physics\n",
    "                alloc_runner.run(get_physics_params_func=get_physics_params)\n",
    "                print(f\"\\n{allocator_type} COMPLETED SUCCESSFULLY\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"\\n{allocator_type} FAILED: {e}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ALL ALLOCATORS COMPLETE!\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "PAPER #12 (QuARC) QUANTUM ROUTING EVALUATION - ALL ALLOCATORS\n",
      "======================================================================\n",
      "‚úÖ Testing QuARC with 1500 timeslots\n",
      "‚úÖ Expected reconfigurations: 3\n",
      "‚úÖ Statistical runs: 5\n",
      "\n",
      "======================================================================\n",
      "PAPER 12 ALLOCATOR EVALUATION\n",
      "======================================================================\n",
      "Allocators:                 ['ThompsonSampling']\n",
      "Physics Models:             ['paper12']\n",
      "Attack Scenarios:           ['stochastic']\n",
      "Scales:                     [1, 1.5, 2]\n",
      "Runs per Scale:             [5]\n",
      "Total Frames:               1500\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "RUNNING: ThompsonSampling on Paper 12 (QuARC)\n",
      "======================================================================\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Preparing: ThompsonSampling at scale 1\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üîß Generating physics parameters for model: paper12\n",
      "\n",
      "===================== GET LOCAL REGISTRY =====================\n",
      "‚Üí Skipping local cache (force=True or file missing)\n",
      "\n",
      "===================== BUILD LOCAL REGISTRY =====================\n",
      "\n",
      "================================================================================\n",
      "üîç SCANNING LOCAL FILES\n",
      "================================================================================\n",
      "Parameters: load_to_drive=False, force=False\n",
      "\n",
      "üìÇ Checking DRIVE mode: /content/drive/Shareddrives/ai_quantum_computing/quantum_data_lake\n",
      "   ‚ö†Ô∏è  Path does not exist, skipping\n",
      "\n",
      "üìÇ Checking LOCAL mode: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config\n",
      "   ‚úÖ Path exists, starting walk...\n",
      "   üö∂ Walking directory tree: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config\n",
      "\n",
      "   üìÅ Directory: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201\n",
      "      Relative: framework_state/day_20260201\n",
      "      Component: framework_state\n",
      "      Date: day_20260201\n",
      "      üìÑ Processing 2570 files in framework_state/day_20260201\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "      üìä framework_state/day_20260201: 2544/2570 files processed\n",
      "      üìä framework_state/day_20260201: 0/2570 files skipped\n",
      "      üìä framework_state/day_20260201: 26/2570 files conflicted\n",
      "\n",
      "   üìÅ Directory: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/model_state/day_20260201\n",
      "      Relative: model_state/day_20260201\n",
      "      Component: model_state\n",
      "      Date: day_20260201\n",
      "      üìÑ Processing 9320 files in model_state/day_20260201\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "      üìä model_state/day_20260201: 9320/9320 files processed\n",
      "      üìä model_state/day_20260201: 0/9320 files skipped\n",
      "      üìä model_state/day_20260201: 0/9320 files conflicted\n",
      "\n",
      "   üìä Processed 2 directories\n",
      "\n",
      "================================================================================\n",
      "üì¶ BUILDING FINAL REGISTRY\n",
      "================================================================================\n",
      "Components found: ['framework_state', 'model_state']\n",
      "  ‚Ä¢ framework_state: 2544 files\n",
      "  ‚Ä¢ model_state: 9320 files\n",
      "\n",
      "‚úÖ SCAN COMPLETE\n",
      "Modes scanned: 1\n",
      "Total files in registry: 11864\n",
      "================================================================================\n",
      "\n",
      "\t‚Üí Filesystem scan found 11864 files\n",
      "\n",
      "===================== GET DRIVE REGISTRY =====================\n",
      "===================== REGISTRY BUILD COMPLETE =====================\n",
      "\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "\tüì¶ LocalBackupManager Registry Saved Locally in LOCAL\n",
      "BUILDING REGISTRY WITH 0 EXPECTED COMPONENTS KEYS\n",
      "\n",
      "===================== GET LOCAL REGISTRY =====================\n",
      "‚Üí Skipping local cache (force=True or file missing)\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "\tüì¶ LocalBackupManager Registry Saved Locally in LOCAL\n",
      "\n",
      "======================================================================\n",
      "üéØ AllocatorRunner initialized: ThompsonSampling\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "üöÄ STARTING ALLOCATOR: ThompsonSampling\n",
      "======================================================================\n",
      "\n",
      "üìä Physics Model: paper12\n",
      "\n",
      "üìã Allocator Config:\n",
      "   Type: ThompsonSampling\n",
      "   Testbed: paper12\n",
      "   Paths: 4\n",
      "   Total Qubits: 100\n",
      "   Min per route: 3\n",
      "   Seed: 42\n",
      "   Priors: Œ±=1.0, Œ≤=1.0\n",
      "‚úÖ Allocator created: (25, 25, 25, 25)\n",
      "‚úì Allocator: ThompsonSamplingAllocator (4 paths)\n",
      "   Initial allocation: (25, 25, 25, 25)\n",
      "Generated paper12 Waxman topology: 100 nodes, 404 edges, avg degree: 8.08\n",
      "üìä Paper12 Physics: Fusion (prob=0.9)\n",
      "\n",
      "======================================================================\n",
      "RUN 1 | Scale: 1 | Exp: 5\n",
      "======================================================================\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "\n",
      "\tüîÑ Resume: MultiRunEvaluator\n",
      "\n",
      "=====================================================\n",
      "üîç GENERATING EXPECTED KEYS FROM EVALUATOR\n",
      "=====================================================\n",
      "  ‚Ä¢ Evaluator filename: MultiRunEvaluator_1500-ThompsonSampling_All_All-1500_500_5_S1T_paper12.pkl\n",
      "\n",
      "üß© PARSED COMPONENTS\n",
      "  ‚Ä¢ cap_id:        1500\n",
      "  ‚Ä¢ allocator_id:  ThompsonSampling\n",
      "  ‚Ä¢ env_id:        All\n",
      "  ‚Ä¢ attack_id:     All\n",
      "  ‚Ä¢ base_frames:   1500\n",
      "  ‚Ä¢ frame_step:    500\n",
      "  ‚Ä¢ runs_id:       5\n",
      "\n",
      "=====================================================\n",
      "üß™ GENERATING KEYS FOR EACH RUN\n",
      "=====================================================\n",
      "\n",
      "--- Run 1/5 -----------------------\n",
      "\n",
      "=====================================================\n",
      "üì¶ FINAL EXPECTED KEYS\n",
      "=====================================================\n",
      "  ‚Ä¢ Runner keys: 11\n",
      "\n",
      "  ‚Ä¢ Model keys: 50\n",
      "\n",
      "--- Run 2/5 -----------------------\n",
      "\n",
      "=====================================================\n",
      "üì¶ FINAL EXPECTED KEYS\n",
      "=====================================================\n",
      "  ‚Ä¢ Runner keys: 21\n",
      "\n",
      "  ‚Ä¢ Model keys: 100\n",
      "\n",
      "--- Run 3/5 -----------------------\n",
      "\n",
      "=====================================================\n",
      "üì¶ FINAL EXPECTED KEYS\n",
      "=====================================================\n",
      "  ‚Ä¢ Runner keys: 31\n",
      "\n",
      "  ‚Ä¢ Model keys: 150\n",
      "\n",
      "--- Run 4/5 -----------------------\n",
      "\n",
      "=====================================================\n",
      "üì¶ FINAL EXPECTED KEYS\n",
      "=====================================================\n",
      "  ‚Ä¢ Runner keys: 41\n",
      "\n",
      "  ‚Ä¢ Model keys: 200\n",
      "\n",
      "--- Run 5/5 -----------------------\n",
      "\n",
      "=====================================================\n",
      "üì¶ FINAL EXPECTED KEYS\n",
      "=====================================================\n",
      "  ‚Ä¢ Runner keys: 51\n",
      "\n",
      "  ‚Ä¢ Model keys: 250\n",
      "\n",
      "EXPECTED KEY GENERATION COMPLETE\n",
      "\n",
      "RESTORING FROM DRIVE 1\n",
      "RESTORING FROM DRIVE 2\n",
      "\t‚ö†Ô∏è Registry exists ‚Üí aborting restore\n",
      "\t‚úì MultiRunEvaluator Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/MultiRunEvaluator_1500-ThompsonSampling_All_All-1500_500_5_S1T_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/MultiRunEvaluator_1500-ThompsonSampling_All_All-1500_500_5_S1T_paper12.pkl\n",
      "\t   File exists: True, size: 57178537\n",
      "EQUAL METHOD\n",
      "Multi-Run Evaluator Initialized\n",
      "Environment Type: None\n",
      "Frame Range: 1500 -> 3500 (step: 500)\n",
      "quantum_exps-ThompsonSampling(paper12)_alloc-all_envs-5_attacks-1500_500-5_runs-S1T\n",
      "[Logging Redirect Initialized]\n",
      "Log File: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/quantum_logs/quantum_exps-ThompsonSampling(paper12)_alloc-all_envs-5_attacks-1500_500-5_runs-S1T_20260201_log.txt\n",
      "‚öô Running evaluation...\n",
      "======================================================================\n",
      "SCENARIOS MODEL EVALUATION\n",
      "======================================================================\n",
      "Testing algorithm performance against:\n",
      "\t‚Ä¢ Stochastic:  \tNatural quantum decoherence and network failures\n",
      "\t‚Ä¢ Baseline:    \tOptimal conditions for validation\n",
      "======================================================================\n",
      "Models to Test:             \tOracle, GNeuralUCB, EXPNeuralUCB, CPursuitNeuralUCB, iCPursuitNeuralUCB\n",
      "Experiments per Scenario:   \t5\n",
      "======================================================================\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: BASELINE (OPTIMAL CONDITIONS)\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: NONE\n",
      "Category: Baseline (No Attacks)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 1500 frames  <>  SCALED-CAPACITY: 1500 frames (CAPACITY:1500 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=0 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for NONE Exp 1: (25, 25, 25, 25)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 1: Env:Baseline (None), Attack:No, Rate:0.0, Frames:1500, QubitAlloc=ThompsonSampling, SC:1500 (Scale=1 x Cap=1500), Seed: 18010\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_1\n",
      "\t‚úì QuantumExperimentRunner_1 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_1500-ThompsonSampling_Baseline (None)_No-1500_1_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_1500-ThompsonSampling_Baseline (None)_No-1500_1_paper12.pkl\n",
      "\t   File exists: True, size: 706985\n",
      "‚è© SKIPPING EXPERIMENT 1: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 1 GNEURALUCB          : Reward=0610.90, Efficiency=046.2% [Retries=3, Failed=0, < Threshold=3, SCapacity=1500, Threshold=0.582]\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=0632.24, Efficiency=047.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=1500, Threshold=0.628]\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=0601.49, Efficiency=045.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=1500, Threshold=0.634]\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=0628.39, Efficiency=047.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=1500, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP1 Winner:EXPNeuralUCB        (Gap:052.2%) [Env:Baseline (None), Attack:No X Rate:0.25, Frames:1500, SCapacity=1500, Alloc=ThompsonSampling]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 2000 frames  <>  SCALED-CAPACITY: 2000 frames (CAPACITY:2000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=1 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for NONE Exp 2: (25, 25, 25, 25)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 2: Env:Baseline (None), Attack:No, Rate:0.0, Frames:2000, QubitAlloc=ThompsonSampling, SC:2000 (Scale=1 x Cap=2000), Seed: 20078\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_2\n",
      "\t‚úì QuantumExperimentRunner_2 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_2000-ThompsonSampling_Baseline (None)_No-2000_2_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_2000-ThompsonSampling_Baseline (None)_No-2000_2_paper12.pkl\n",
      "\t   File exists: True, size: 929021\n",
      "‚è© SKIPPING EXPERIMENT 2: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 2 GNEURALUCB          : Reward=0855.65, Efficiency=048.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=2000, Threshold=0.582]\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=0829.50, Efficiency=047.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=2000, Threshold=0.628]\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=0871.53, Efficiency=049.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=2000, Threshold=0.634]\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=0852.19, Efficiency=048.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=2000, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP2 Winner:CPursuitNeuralUCB   (Gap:050.6%) [Env:Baseline (None), Attack:No X Rate:0.25, Frames:2000, SCapacity=2000, Alloc=ThompsonSampling]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 2500 frames  <>  SCALED-CAPACITY: 2500 frames (CAPACITY:2500 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=2 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for NONE Exp 3: (25, 25, 25, 25)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 3: Env:Baseline (None), Attack:No, Rate:0.0, Frames:2500, QubitAlloc=ThompsonSampling, SC:2500 (Scale=1 x Cap=2500), Seed: 14623\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_3\n",
      "\t‚úì QuantumExperimentRunner_3 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_2500-ThompsonSampling_Baseline (None)_No-2500_3_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_2500-ThompsonSampling_Baseline (None)_No-2500_3_paper12.pkl\n",
      "\t   File exists: True, size: 1151080\n",
      "‚è© SKIPPING EXPERIMENT 3: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 3 GNEURALUCB          : Reward=1087.89, Efficiency=049.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=2500, Threshold=0.582]\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=1033.54, Efficiency=046.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=2500, Threshold=0.628]\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=1094.48, Efficiency=049.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=2500, Threshold=0.634]\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=1093.18, Efficiency=049.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=2500, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP3 Winner:CPursuitNeuralUCB   (Gap:050.3%) [Env:Baseline (None), Attack:No X Rate:0.25, Frames:2500, SCapacity=2500, Alloc=ThompsonSampling]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 3000 frames  <>  SCALED-CAPACITY: 3000 frames (CAPACITY:3000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=3 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for NONE Exp 4: (25, 25, 25, 25)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 4: Env:Baseline (None), Attack:No, Rate:0.0, Frames:3000, QubitAlloc=ThompsonSampling, SC:3000 (Scale=1 x Cap=3000), Seed: 20090\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_4\n",
      "\t‚úì QuantumExperimentRunner_4 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_3000-ThompsonSampling_Baseline (None)_No-3000_4_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_3000-ThompsonSampling_Baseline (None)_No-3000_4_paper12.pkl\n",
      "\t   File exists: True, size: 1373107\n",
      "‚è© SKIPPING EXPERIMENT 4: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 4 GNEURALUCB          : Reward=1329.41, Efficiency=050.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.582]\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=1389.95, Efficiency=052.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.628]\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=1264.00, Efficiency=047.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.634]\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=1297.93, Efficiency=049.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP4 Winner:EXPNeuralUCB        (Gap:047.4%) [Env:Baseline (None), Attack:No X Rate:0.25, Frames:3000, SCapacity=3000, Alloc=ThompsonSampling]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 3500 frames  <>  SCALED-CAPACITY: 3500 frames (CAPACITY:3500 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=4 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for NONE Exp 5: (25, 25, 25, 25)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 5: Env:Baseline (None), Attack:No, Rate:0.0, Frames:3500, QubitAlloc=ThompsonSampling, SC:3500 (Scale=1 x Cap=3500), Seed: 12926\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_5\n",
      "\t‚úì QuantumExperimentRunner_5 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_3500-ThompsonSampling_Baseline (None)_No-3500_5_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_3500-ThompsonSampling_Baseline (None)_No-3500_5_paper12.pkl\n",
      "\t   File exists: True, size: 1595175\n",
      "‚è© SKIPPING EXPERIMENT 5: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 5 GNEURALUCB          : Reward=1459.41, Efficiency=047.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=3500, Threshold=0.582]\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=1580.57, Efficiency=051.2% [Retries=3, Failed=0, < Threshold=3, SCapacity=3500, Threshold=0.628]\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=1471.72, Efficiency=047.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=3500, Threshold=0.634]\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=1541.85, Efficiency=050.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=3500, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP5 Winner:EXPNeuralUCB        (Gap:048.8%) [Env:Baseline (None), Attack:No X Rate:0.25, Frames:3500, SCapacity=3500, Alloc=ThompsonSampling]\n",
      "\n",
      "Total experiment time: 048.9s\n",
      "Experiments completed for none\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: STOCHASTIC RANDOM FAILURES\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: STOCHASTIC\n",
      "Category: Stochastic (Natural Random Failures)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 1500 frames  <>  SCALED-CAPACITY: 1500 frames (CAPACITY:1500 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=0 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 1: (25, 25, 25, 25)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 1: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:1500, QubitAlloc=ThompsonSampling, SC:1500 (Scale=1 x Cap=1500), Seed: 20197\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_1\n",
      "\t‚úì QuantumExperimentRunner_1 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_1500-ThompsonSampling_Stochastic_Random-1500_1_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_1500-ThompsonSampling_Stochastic_Random-1500_1_paper12.pkl\n",
      "\t   File exists: True, size: 706989\n",
      "‚è© SKIPPING EXPERIMENT 1: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 1 GNEURALUCB          : Reward=0598.36, Efficiency=045.2% [Retries=3, Failed=0, < Threshold=3, SCapacity=1500, Threshold=0.582]\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=0534.93, Efficiency=040.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=1500, Threshold=0.628]\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=0570.20, Efficiency=043.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=1500, Threshold=0.634]\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=0580.28, Efficiency=043.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=1500, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP1 Winner:GNeuralUCB          (Gap:054.8%) [Env:Stochastic, Attack:Random X Rate:0.25, Frames:1500, SCapacity=1500, Alloc=ThompsonSampling]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 2000 frames  <>  SCALED-CAPACITY: 2000 frames (CAPACITY:2000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=1 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 2: (25, 25, 25, 25)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 2: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:2000, QubitAlloc=ThompsonSampling, SC:2000 (Scale=1 x Cap=2000), Seed: 17474\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_2\n",
      "\t‚úì QuantumExperimentRunner_2 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_2000-ThompsonSampling_Stochastic_Random-2000_2_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_2000-ThompsonSampling_Stochastic_Random-2000_2_paper12.pkl\n",
      "\t   File exists: True, size: 929025\n",
      "‚è© SKIPPING EXPERIMENT 2: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 2 GNEURALUCB          : Reward=0785.14, Efficiency=044.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=2000, Threshold=0.582]\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=0815.13, Efficiency=046.2% [Retries=3, Failed=0, < Threshold=3, SCapacity=2000, Threshold=0.628]\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=0802.54, Efficiency=045.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=2000, Threshold=0.634]\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=0815.03, Efficiency=046.2% [Retries=3, Failed=0, < Threshold=3, SCapacity=2000, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP2 Winner:EXPNeuralUCB        (Gap:053.8%) [Env:Stochastic, Attack:Random X Rate:0.25, Frames:2000, SCapacity=2000, Alloc=ThompsonSampling]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 2500 frames  <>  SCALED-CAPACITY: 2500 frames (CAPACITY:2500 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=2 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 3: (25, 25, 25, 25)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 3: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:2500, QubitAlloc=ThompsonSampling, SC:2500 (Scale=1 x Cap=2500), Seed: 15795\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_3\n",
      "\t‚úì QuantumExperimentRunner_3 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_2500-ThompsonSampling_Stochastic_Random-2500_3_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_2500-ThompsonSampling_Stochastic_Random-2500_3_paper12.pkl\n",
      "\t   File exists: True, size: 1151084\n",
      "‚è© SKIPPING EXPERIMENT 3: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 3 GNEURALUCB          : Reward=0988.10, Efficiency=044.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=2500, Threshold=0.582]\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=1031.77, Efficiency=046.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=2500, Threshold=0.628]\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=0978.19, Efficiency=044.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=2500, Threshold=0.634]\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=1013.32, Efficiency=046.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=2500, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP3 Winner:EXPNeuralUCB        (Gap:053.2%) [Env:Stochastic, Attack:Random X Rate:0.25, Frames:2500, SCapacity=2500, Alloc=ThompsonSampling]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 3000 frames  <>  SCALED-CAPACITY: 3000 frames (CAPACITY:3000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=3 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 4: (25, 25, 25, 25)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 4: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:3000, QubitAlloc=ThompsonSampling, SC:3000 (Scale=1 x Cap=3000), Seed: 17031\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_4\n",
      "\t‚úì QuantumExperimentRunner_4 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_3000-ThompsonSampling_Stochastic_Random-3000_4_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_3000-ThompsonSampling_Stochastic_Random-3000_4_paper12.pkl\n",
      "\t   File exists: True, size: 1373111\n",
      "‚è© SKIPPING EXPERIMENT 4: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 4 GNEURALUCB          : Reward=1230.83, Efficiency=046.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.582]\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=1232.84, Efficiency=046.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.628]\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=1176.09, Efficiency=044.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.634]\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=1207.42, Efficiency=045.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP4 Winner:EXPNeuralUCB        (Gap:053.4%) [Env:Stochastic, Attack:Random X Rate:0.25, Frames:3000, SCapacity=3000, Alloc=ThompsonSampling]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 3500 frames  <>  SCALED-CAPACITY: 3500 frames (CAPACITY:3500 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=4 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 5: (25, 25, 25, 25)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 5: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:3500, QubitAlloc=ThompsonSampling, SC:3500 (Scale=1 x Cap=3500), Seed: 21490\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_5\n",
      "\t‚úì QuantumExperimentRunner_5 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_3500-ThompsonSampling_Stochastic_Random-3500_5_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_3500-ThompsonSampling_Stochastic_Random-3500_5_paper12.pkl\n",
      "\t   File exists: True, size: 1595179\n",
      "‚è© SKIPPING EXPERIMENT 5: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 5 GNEURALUCB          : Reward=1385.52, Efficiency=044.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=3500, Threshold=0.582]\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=1399.53, Efficiency=045.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=3500, Threshold=0.628]\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=1436.62, Efficiency=046.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=3500, Threshold=0.634]\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=1417.33, Efficiency=045.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=3500, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP5 Winner:CPursuitNeuralUCB   (Gap:053.4%) [Env:Stochastic, Attack:Random X Rate:0.25, Frames:3500, SCapacity=3500, Alloc=ThompsonSampling]\n",
      "\n",
      "Total experiment time: 052.6s\n",
      "Experiments completed for stochastic\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: MARKOV ADVERSARIAL ATTACK\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: MARKOV\n",
      "Category: Structured (Markov Chain Based)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 1500 frames  <>  SCALED-CAPACITY: 1500 frames (CAPACITY:1500 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=0 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for MARKOV Exp 1: (25, 25, 25, 25)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 1: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:1500, QubitAlloc=ThompsonSampling, SC:1500 (Scale=1 x Cap=1500), Seed: 20262\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_1\n",
      "\t‚úì QuantumExperimentRunner_1 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_1500-ThompsonSampling_Adversarial_Markov-1500_1_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_1500-ThompsonSampling_Adversarial_Markov-1500_1_paper12.pkl\n",
      "\t   File exists: True, size: 706987\n",
      "‚è© SKIPPING EXPERIMENT 1: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 1 GNEURALUCB          : Reward=0317.67, Efficiency=025.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=1500, Threshold=0.582]\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=0317.81, Efficiency=025.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=1500, Threshold=0.628]\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=0340.99, Efficiency=027.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=1500, Threshold=0.634]\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=0332.70, Efficiency=027.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=1500, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP1 Winner:CPursuitNeuralUCB   (Gap:072.3%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:1500, SCapacity=1500, Alloc=ThompsonSampling]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 2000 frames  <>  SCALED-CAPACITY: 2000 frames (CAPACITY:2000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=1 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for MARKOV Exp 2: (25, 25, 25, 25)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 2: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:2000, QubitAlloc=ThompsonSampling, SC:2000 (Scale=1 x Cap=2000), Seed: 15238\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_2\n",
      "\t‚úì QuantumExperimentRunner_2 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_2000-ThompsonSampling_Adversarial_Markov-2000_2_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_2000-ThompsonSampling_Adversarial_Markov-2000_2_paper12.pkl\n",
      "\t   File exists: True, size: 929023\n",
      "‚è© SKIPPING EXPERIMENT 2: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 2 GNEURALUCB          : Reward=0455.10, Efficiency=027.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=2000, Threshold=0.582]\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=0422.75, Efficiency=025.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=2000, Threshold=0.628]\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=0466.56, Efficiency=028.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=2000, Threshold=0.634]\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=0478.02, Efficiency=028.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=2000, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP2 Winner:iCPursuitNeuralUCB  (Gap:071.2%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:2000, SCapacity=2000, Alloc=ThompsonSampling]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 2500 frames  <>  SCALED-CAPACITY: 2500 frames (CAPACITY:2500 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=2 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for MARKOV Exp 3: (25, 25, 25, 25)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 3: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:2500, QubitAlloc=ThompsonSampling, SC:2500 (Scale=1 x Cap=2500), Seed: 15202\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_3\n",
      "\t‚úì QuantumExperimentRunner_3 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_2500-ThompsonSampling_Adversarial_Markov-2500_3_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_2500-ThompsonSampling_Adversarial_Markov-2500_3_paper12.pkl\n",
      "\t   File exists: True, size: 1151082\n",
      "‚è© SKIPPING EXPERIMENT 3: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 3 GNEURALUCB          : Reward=0532.77, Efficiency=025.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=2500, Threshold=0.582]\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=0511.40, Efficiency=024.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=2500, Threshold=0.628]\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=0538.17, Efficiency=026.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=2500, Threshold=0.634]\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=0590.87, Efficiency=028.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=2500, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP3 Winner:iCPursuitNeuralUCB  (Gap:071.3%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:2500, SCapacity=2500, Alloc=ThompsonSampling]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 3000 frames  <>  SCALED-CAPACITY: 3000 frames (CAPACITY:3000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=3 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for MARKOV Exp 4: (25, 25, 25, 25)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 4: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:3000, QubitAlloc=ThompsonSampling, SC:3000 (Scale=1 x Cap=3000), Seed: 19699\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_4\n",
      "\t‚úì QuantumExperimentRunner_4 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_3000-ThompsonSampling_Adversarial_Markov-3000_4_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_3000-ThompsonSampling_Adversarial_Markov-3000_4_paper12.pkl\n",
      "\t   File exists: True, size: 1373109\n",
      "‚è© SKIPPING EXPERIMENT 4: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 4 GNEURALUCB          : Reward=0632.15, Efficiency=025.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.582]\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=0578.57, Efficiency=023.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.628]\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=0654.48, Efficiency=026.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.634]\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=0717.02, Efficiency=028.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP4 Winner:iCPursuitNeuralUCB  (Gap:071.2%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:3000, SCapacity=3000, Alloc=ThompsonSampling]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 3500 frames  <>  SCALED-CAPACITY: 3500 frames (CAPACITY:3500 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=4 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for MARKOV Exp 5: (25, 25, 25, 25)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 5: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:3500, QubitAlloc=ThompsonSampling, SC:3500 (Scale=1 x Cap=3500), Seed: 22085\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_5\n",
      "\t‚úì QuantumExperimentRunner_5 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_3500-ThompsonSampling_Adversarial_Markov-3500_5_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_3500-ThompsonSampling_Adversarial_Markov-3500_5_paper12.pkl\n",
      "\t   File exists: True, size: 1595177\n",
      "‚è© SKIPPING EXPERIMENT 5: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 5 GNEURALUCB          : Reward=0762.30, Efficiency=026.2% [Retries=3, Failed=0, < Threshold=3, SCapacity=3500, Threshold=0.582]\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=0725.43, Efficiency=025.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=3500, Threshold=0.628]\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=0826.69, Efficiency=028.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=3500, Threshold=0.634]\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=0835.00, Efficiency=028.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=3500, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP5 Winner:iCPursuitNeuralUCB  (Gap:071.2%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:3500, SCapacity=3500, Alloc=ThompsonSampling]\n",
      "\n",
      "Total experiment time: 063.6s\n",
      "Experiments completed for markov\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: ADAPTIVE ADVERSARIAL ATTACK\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: ADAPTIVE\n",
      "Category: Adaptive (Reactive Strategic)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 1500 frames  <>  SCALED-CAPACITY: 1500 frames (CAPACITY:1500 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=0 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 1: (25, 25, 25, 25)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 1: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:1500, QubitAlloc=ThompsonSampling, SC:1500 (Scale=1 x Cap=1500), Seed: 14115\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_1\n",
      "\t‚úì QuantumExperimentRunner_1 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_1500-ThompsonSampling_Adversarial_Adaptive-1500_1_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_1500-ThompsonSampling_Adversarial_Adaptive-1500_1_paper12.pkl\n",
      "\t   File exists: True, size: 706993\n",
      "‚è© SKIPPING EXPERIMENT 1: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 1 GNEURALUCB          : Reward=0463.70, Efficiency=035.2% [Retries=3, Failed=0, < Threshold=3, SCapacity=1500, Threshold=0.582]\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=0465.95, Efficiency=035.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=1500, Threshold=0.628]\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=0471.31, Efficiency=035.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=1500, Threshold=0.634]\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=0466.82, Efficiency=035.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=1500, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP1 Winner:CPursuitNeuralUCB   (Gap:064.3%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:1500, SCapacity=1500, Alloc=ThompsonSampling]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 2000 frames  <>  SCALED-CAPACITY: 2000 frames (CAPACITY:2000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=1 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 2: (25, 25, 25, 25)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 2: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:2000, QubitAlloc=ThompsonSampling, SC:2000 (Scale=1 x Cap=2000), Seed: 14473\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_2\n",
      "\t‚úì QuantumExperimentRunner_2 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_2000-ThompsonSampling_Adversarial_Adaptive-2000_2_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_2000-ThompsonSampling_Adversarial_Adaptive-2000_2_paper12.pkl\n",
      "\t   File exists: True, size: 929029\n",
      "‚è© SKIPPING EXPERIMENT 2: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 2 GNEURALUCB          : Reward=0634.93, Efficiency=036.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=2000, Threshold=0.582]\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=0627.19, Efficiency=035.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=2000, Threshold=0.628]\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=0617.02, Efficiency=035.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=2000, Threshold=0.634]\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=0615.95, Efficiency=035.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=2000, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP2 Winner:GNeuralUCB          (Gap:063.9%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:2000, SCapacity=2000, Alloc=ThompsonSampling]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 2500 frames  <>  SCALED-CAPACITY: 2500 frames (CAPACITY:2500 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=2 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 3: (25, 25, 25, 25)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 3: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:2500, QubitAlloc=ThompsonSampling, SC:2500 (Scale=1 x Cap=2500), Seed: 13973\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_3\n",
      "\t‚úì QuantumExperimentRunner_3 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_2500-ThompsonSampling_Adversarial_Adaptive-2500_3_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_2500-ThompsonSampling_Adversarial_Adaptive-2500_3_paper12.pkl\n",
      "\t   File exists: True, size: 1151088\n",
      "‚è© SKIPPING EXPERIMENT 3: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 3 GNEURALUCB          : Reward=0808.23, Efficiency=036.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=2500, Threshold=0.582]\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=0793.79, Efficiency=036.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=2500, Threshold=0.628]\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=0788.65, Efficiency=035.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=2500, Threshold=0.634]\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=0806.97, Efficiency=036.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=2500, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP3 Winner:GNeuralUCB          (Gap:063.2%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:2500, SCapacity=2500, Alloc=ThompsonSampling]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 3000 frames  <>  SCALED-CAPACITY: 3000 frames (CAPACITY:3000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=3 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 4: (25, 25, 25, 25)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 4: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:3000, QubitAlloc=ThompsonSampling, SC:3000 (Scale=1 x Cap=3000), Seed: 16838\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_4\n",
      "\t‚úì QuantumExperimentRunner_4 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_3000-ThompsonSampling_Adversarial_Adaptive-3000_4_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_3000-ThompsonSampling_Adversarial_Adaptive-3000_4_paper12.pkl\n",
      "\t   File exists: True, size: 1373115\n",
      "‚è© SKIPPING EXPERIMENT 4: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 4 GNEURALUCB          : Reward=0963.02, Efficiency=036.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.582]\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=0987.14, Efficiency=037.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.628]\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=0962.11, Efficiency=036.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.634]\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=0963.65, Efficiency=036.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP4 Winner:EXPNeuralUCB        (Gap:062.6%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:3000, SCapacity=3000, Alloc=ThompsonSampling]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 3500 frames  <>  SCALED-CAPACITY: 3500 frames (CAPACITY:3500 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=4 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 5: (25, 25, 25, 25)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 5: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:3500, QubitAlloc=ThompsonSampling, SC:3500 (Scale=1 x Cap=3500), Seed: 20582\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_5\n",
      "\t‚úì QuantumExperimentRunner_5 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_3500-ThompsonSampling_Adversarial_Adaptive-3500_5_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_3500-ThompsonSampling_Adversarial_Adaptive-3500_5_paper12.pkl\n",
      "\t   File exists: True, size: 1595183\n",
      "‚è© SKIPPING EXPERIMENT 5: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 5 GNEURALUCB          : Reward=1120.67, Efficiency=036.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=3500, Threshold=0.582]\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=1181.17, Efficiency=038.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=3500, Threshold=0.628]\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=1082.40, Efficiency=035.2% [Retries=3, Failed=0, < Threshold=3, SCapacity=3500, Threshold=0.634]\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=1122.67, Efficiency=036.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=3500, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP5 Winner:EXPNeuralUCB        (Gap:061.6%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:3500, SCapacity=3500, Alloc=ThompsonSampling]\n",
      "\n",
      "Total experiment time: 067.7s\n",
      "Experiments completed for adaptive\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: ONLINE ADAPTIVE ATTACK\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: ONLINEADAPTIVE\n",
      "Category: Online Adaptive (Real-time Strategic)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 1500 frames  <>  SCALED-CAPACITY: 1500 frames (CAPACITY:1500 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=0 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 1: (25, 25, 25, 25)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:1500, QubitAlloc=ThompsonSampling, SC:1500 (Scale=1 x Cap=1500), Seed: 14103\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_1\n",
      "\t‚úì QuantumExperimentRunner_1 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_1500-ThompsonSampling_Adversarial_OnlineAdaptive-1500_1_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_1500-ThompsonSampling_Adversarial_OnlineAdaptive-1500_1_paper12.pkl\n",
      "\t   File exists: True, size: 707011\n",
      "‚è© SKIPPING EXPERIMENT 1: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 1 GNEURALUCB          : Reward=0469.27, Efficiency=035.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=1500, Threshold=0.582]\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=0506.76, Efficiency=038.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=1500, Threshold=0.628]\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=0471.57, Efficiency=035.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=1500, Threshold=0.634]\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=0482.03, Efficiency=036.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=1500, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP1 Winner:EXPNeuralUCB        (Gap:061.5%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:1500, SCapacity=1500, Alloc=ThompsonSampling]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 2000 frames  <>  SCALED-CAPACITY: 2000 frames (CAPACITY:2000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=1 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 2: (25, 25, 25, 25)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:2000, QubitAlloc=ThompsonSampling, SC:2000 (Scale=1 x Cap=2000), Seed: 22352\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_2\n",
      "\t‚úì QuantumExperimentRunner_2 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_2000-ThompsonSampling_Adversarial_OnlineAdaptive-2000_2_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_2000-ThompsonSampling_Adversarial_OnlineAdaptive-2000_2_paper12.pkl\n",
      "\t   File exists: True, size: 929047\n",
      "‚è© SKIPPING EXPERIMENT 2: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 2 GNEURALUCB          : Reward=0629.16, Efficiency=035.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=2000, Threshold=0.582]\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=0655.68, Efficiency=037.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=2000, Threshold=0.628]\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=0623.56, Efficiency=035.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=2000, Threshold=0.634]\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=0593.37, Efficiency=033.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=2000, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP2 Winner:EXPNeuralUCB        (Gap:062.6%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:2000, SCapacity=2000, Alloc=ThompsonSampling]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 2500 frames  <>  SCALED-CAPACITY: 2500 frames (CAPACITY:2500 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=2 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 3: (25, 25, 25, 25)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:2500, QubitAlloc=ThompsonSampling, SC:2500 (Scale=1 x Cap=2500), Seed: 14162\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_3\n",
      "\t‚úì QuantumExperimentRunner_3 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_2500-ThompsonSampling_Adversarial_OnlineAdaptive-2500_3_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_2500-ThompsonSampling_Adversarial_OnlineAdaptive-2500_3_paper12.pkl\n",
      "\t   File exists: True, size: 1151106\n",
      "‚è© SKIPPING EXPERIMENT 3: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 3 GNEURALUCB          : Reward=0789.42, Efficiency=035.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=2500, Threshold=0.582]\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=0811.42, Efficiency=036.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=2500, Threshold=0.628]\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=0821.60, Efficiency=037.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=2500, Threshold=0.634]\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=0784.22, Efficiency=035.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=2500, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP3 Winner:CPursuitNeuralUCB   (Gap:062.6%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:2500, SCapacity=2500, Alloc=ThompsonSampling]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 3000 frames  <>  SCALED-CAPACITY: 3000 frames (CAPACITY:3000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=3 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 4: (25, 25, 25, 25)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:3000, QubitAlloc=ThompsonSampling, SC:3000 (Scale=1 x Cap=3000), Seed: 21587\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_4\n",
      "\t‚úì QuantumExperimentRunner_4 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_3000-ThompsonSampling_Adversarial_OnlineAdaptive-3000_4_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_3000-ThompsonSampling_Adversarial_OnlineAdaptive-3000_4_paper12.pkl\n",
      "\t   File exists: True, size: 1373133\n",
      "‚è© SKIPPING EXPERIMENT 4: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 4 GNEURALUCB          : Reward=0965.48, Efficiency=036.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.582]\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=0862.75, Efficiency=032.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.628]\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=0974.93, Efficiency=037.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.634]\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=0929.52, Efficiency=035.2% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP4 Winner:CPursuitNeuralUCB   (Gap:063.0%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:3000, SCapacity=3000, Alloc=ThompsonSampling]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 3500 frames  <>  SCALED-CAPACITY: 3500 frames (CAPACITY:3500 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=4 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 5: (25, 25, 25, 25)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:3500, QubitAlloc=ThompsonSampling, SC:3500 (Scale=1 x Cap=3500), Seed: 17102\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_5\n",
      "\t‚úì QuantumExperimentRunner_5 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_3500-ThompsonSampling_Adversarial_OnlineAdaptive-3500_5_paper12.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_3500-ThompsonSampling_Adversarial_OnlineAdaptive-3500_5_paper12.pkl\n",
      "\t   File exists: True, size: 1595201\n",
      "‚è© SKIPPING EXPERIMENT 5: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 5 GNEURALUCB          : Reward=1151.84, Efficiency=037.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=3500, Threshold=0.582]\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=1081.36, Efficiency=035.2% [Retries=3, Failed=0, < Threshold=3, SCapacity=3500, Threshold=0.628]\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=1087.01, Efficiency=035.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=3500, Threshold=0.634]\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=1115.08, Efficiency=036.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=3500, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP5 Winner:GNeuralUCB          (Gap:062.5%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:3500, SCapacity=3500, Alloc=ThompsonSampling]\n",
      "\n",
      "Total experiment time: 079.1s\n",
      "Experiments completed for onlineadaptive\n",
      "‚úì Scenario 'none' evaluation completed.\n",
      "‚úì Scenario 'stochastic' evaluation completed.\n",
      "‚úì Scenario 'markov' evaluation completed.\n",
      "‚úì Scenario 'adaptive' evaluation completed.\n",
      "‚úì Scenario 'onlineadaptive' evaluation completed.\n",
      "\n",
      "======================================================================\n",
      "COMPREHENSIVE SCENARIO PERFORMANCE ANALYSIS\n",
      "======================================================================\n",
      "SCENARIO: NONE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: EXPNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 2204.16\n",
      "\t‚Ä¢ Winner Avg Gap: 0050.90%\n",
      "\t‚Ä¢ Winner Avg Reward: 1093.16\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0049.10%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 3 wins\n",
      "\t\t- CPursuitNeuralUCB: 2 wins\n",
      "\t\t- iCPursuitNeuralUCB: 0 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: NONE\n",
      "======================================================================\n",
      "SCENARIO: \tBASELINE (OPTIMAL CONDITIONS)\n",
      "----------------------------------------\n",
      "Recommended Model: \tEXPNeuralUCB (Won 3/5 experiments)\n",
      "\tWinner Avg Gap: \t050.9%\n",
      "\tWinner Avg Efficiency: \t049.1%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t049.1% Efficiency \t(Won 3/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t048.9% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t048.3% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t048.0% Efficiency \t(Won 2/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: STOCHASTIC\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 2204.15\n",
      "\t‚Ä¢ Winner Avg Gap: 0054.47%\n",
      "\t‚Ä¢ Winner Avg Reward: 1006.68\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0045.53%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 1 wins\n",
      "\t\t- EXPNeuralUCB: 3 wins\n",
      "\t\t- CPursuitNeuralUCB: 1 wins\n",
      "\t\t- iCPursuitNeuralUCB: 0 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: STOCHASTIC\n",
      "======================================================================\n",
      "SCENARIO: \tSTOCHASTIC RANDOM FAILURES\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 0/5 experiments)\n",
      "\tWinner Avg Gap: \t054.5%\n",
      "\tWinner Avg Efficiency: \t045.5%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t045.5% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t045.2% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t045.1% Efficiency \t(Won 3/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t044.8% Efficiency \t(Won 1/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: MARKOV\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 2069.14\n",
      "\t‚Ä¢ Winner Avg Gap: 0071.59%\n",
      "\t‚Ä¢ Winner Avg Reward: 0590.72\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0028.41%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 1 wins\n",
      "\t\t- iCPursuitNeuralUCB: 4 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: MARKOV\n",
      "======================================================================\n",
      "SCENARIO: \tMARKOV ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 4/5 experiments)\n",
      "\tWinner Avg Gap: \t071.6%\n",
      "\tWinner Avg Efficiency: \t028.4%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t028.4% Efficiency \t(Won 4/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t027.3% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t026.1% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t024.9% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: EXPNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 2196.81\n",
      "\t‚Ä¢ Winner Avg Gap: 0063.40%\n",
      "\t‚Ä¢ Winner Avg Reward: 0811.05\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0036.60%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 2 wins\n",
      "\t\t- EXPNeuralUCB: 2 wins\n",
      "\t\t- CPursuitNeuralUCB: 1 wins\n",
      "\t\t- iCPursuitNeuralUCB: 0 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tADAPTIVE ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tEXPNeuralUCB (Won 2/5 experiments)\n",
      "\tWinner Avg Gap: \t063.4%\n",
      "\tWinner Avg Efficiency: \t036.6%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t036.6% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t036.2% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t036.0% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t035.7% Efficiency \t(Won 1/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ONLINEADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: GNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 2196.52\n",
      "\t‚Ä¢ Winner Avg Gap: 0063.71%\n",
      "\t‚Ä¢ Winner Avg Reward: 0801.04\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0036.29%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 1 wins\n",
      "\t\t- EXPNeuralUCB: 2 wins\n",
      "\t\t- CPursuitNeuralUCB: 2 wins\n",
      "\t\t- iCPursuitNeuralUCB: 0 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ONLINEADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tONLINE ADAPTIVE ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tGNeuralUCB (Won 1/5 experiments)\n",
      "\tWinner Avg Gap: \t063.7%\n",
      "\tWinner Avg Efficiency: \t036.3%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ GNeuralUCB     : \t036.3% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t036.2% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t036.1% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t035.5% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "KEY INSIGHTS:\n",
      "Best Performing Model Analysis (iCPursuitNeuralUCB):\n",
      "\t‚Ä¢ Stochastic Performance:    \t1006.679\n",
      "\t‚Ä¢ Baseline Performance:      \t1093.160\n",
      "\t‚Ä¢ Performance Retention:     \t092.1%\n",
      "\tGOOD:               \tAcceptable performance under stochastic conditions\n",
      "Statistical Analysis:\n",
      "\t‚Ä¢ Total models evaluated:     \t5\n",
      "\t‚Ä¢ Experiments per environment:\t5\n",
      "\t‚Ä¢ Quantum network simulation: \tComprehensive stochastic modeling\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "COMPREHENSIVE SCENARIO PERFORMANCE ANALYSIS\n",
      "======================================================================\n",
      "SCENARIO: NONE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: EXPNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 2204.16\n",
      "\t‚Ä¢ Winner Avg Gap: 0050.90%\n",
      "\t‚Ä¢ Winner Avg Reward: 1093.16\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0049.10%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 3 wins\n",
      "\t\t- CPursuitNeuralUCB: 2 wins\n",
      "\t\t- iCPursuitNeuralUCB: 0 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: NONE\n",
      "======================================================================\n",
      "SCENARIO: \tBASELINE (OPTIMAL CONDITIONS)\n",
      "----------------------------------------\n",
      "Recommended Model: \tEXPNeuralUCB (Won 3/5 experiments)\n",
      "\tWinner Avg Gap: \t050.9%\n",
      "\tWinner Avg Efficiency: \t049.1%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t049.1% Efficiency \t(Won 3/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t048.9% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t048.3% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t048.0% Efficiency \t(Won 2/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: STOCHASTIC\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 2204.15\n",
      "\t‚Ä¢ Winner Avg Gap: 0054.47%\n",
      "\t‚Ä¢ Winner Avg Reward: 1006.68\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0045.53%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 1 wins\n",
      "\t\t- EXPNeuralUCB: 3 wins\n",
      "\t\t- CPursuitNeuralUCB: 1 wins\n",
      "\t\t- iCPursuitNeuralUCB: 0 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: STOCHASTIC\n",
      "======================================================================\n",
      "SCENARIO: \tSTOCHASTIC RANDOM FAILURES\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 0/5 experiments)\n",
      "\tWinner Avg Gap: \t054.5%\n",
      "\tWinner Avg Efficiency: \t045.5%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t045.5% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t045.2% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t045.1% Efficiency \t(Won 3/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t044.8% Efficiency \t(Won 1/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: MARKOV\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 2069.14\n",
      "\t‚Ä¢ Winner Avg Gap: 0071.59%\n",
      "\t‚Ä¢ Winner Avg Reward: 0590.72\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0028.41%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 1 wins\n",
      "\t\t- iCPursuitNeuralUCB: 4 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: MARKOV\n",
      "======================================================================\n",
      "SCENARIO: \tMARKOV ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 4/5 experiments)\n",
      "\tWinner Avg Gap: \t071.6%\n",
      "\tWinner Avg Efficiency: \t028.4%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t028.4% Efficiency \t(Won 4/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t027.3% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t026.1% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t024.9% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: EXPNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 2196.81\n",
      "\t‚Ä¢ Winner Avg Gap: 0063.40%\n",
      "\t‚Ä¢ Winner Avg Reward: 0811.05\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0036.60%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 2 wins\n",
      "\t\t- EXPNeuralUCB: 2 wins\n",
      "\t\t- CPursuitNeuralUCB: 1 wins\n",
      "\t\t- iCPursuitNeuralUCB: 0 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tADAPTIVE ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tEXPNeuralUCB (Won 2/5 experiments)\n",
      "\tWinner Avg Gap: \t063.4%\n",
      "\tWinner Avg Efficiency: \t036.6%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t036.6% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t036.2% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t036.0% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t035.7% Efficiency \t(Won 1/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ONLINEADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: GNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 2196.52\n",
      "\t‚Ä¢ Winner Avg Gap: 0063.71%\n",
      "\t‚Ä¢ Winner Avg Reward: 0801.04\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0036.29%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 1 wins\n",
      "\t\t- EXPNeuralUCB: 2 wins\n",
      "\t\t- CPursuitNeuralUCB: 2 wins\n",
      "\t\t- iCPursuitNeuralUCB: 0 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ONLINEADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tONLINE ADAPTIVE ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tGNeuralUCB (Won 1/5 experiments)\n",
      "\tWinner Avg Gap: \t063.7%\n",
      "\tWinner Avg Efficiency: \t036.3%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ GNeuralUCB     : \t036.3% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t036.2% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t036.1% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t035.5% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "‚úÖ Evaluation completed!\n",
      "[Logging Redirect Stopped]\n",
      "\n",
      "üßπ Final cleanup for ThompsonSampling\n",
      "\n",
      "======================================================================\n",
      "‚úÖ COMPLETED: ThompsonSampling\n",
      "======================================================================\n",
      "\n",
      "ThompsonSampling COMPLETED SUCCESSFULLY\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Preparing: ThompsonSampling at scale 1.5\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üîß Generating physics parameters for model: paper12\n",
      "\n",
      "===================== GET LOCAL REGISTRY =====================\n",
      "‚Üí Skipping local cache (force=True or file missing)\n",
      "\n",
      "===================== BUILD LOCAL REGISTRY =====================\n",
      "\n",
      "================================================================================\n",
      "üîç SCANNING LOCAL FILES\n",
      "================================================================================\n",
      "Parameters: load_to_drive=False, force=False\n",
      "\n",
      "üìÇ Checking DRIVE mode: /content/drive/Shareddrives/ai_quantum_computing/quantum_data_lake\n",
      "   ‚ö†Ô∏è  Path does not exist, skipping\n",
      "\n",
      "üìÇ Checking LOCAL mode: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config\n",
      "   ‚úÖ Path exists, starting walk...\n",
      "   üö∂ Walking directory tree: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config\n",
      "\n",
      "   üìÅ Directory: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201\n",
      "      Relative: framework_state/day_20260201\n",
      "      Component: framework_state\n",
      "      Date: day_20260201\n",
      "      üìÑ Processing 2574 files in framework_state/day_20260201\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "      üìä framework_state/day_20260201: 2548/2574 files processed\n",
      "      üìä framework_state/day_20260201: 0/2574 files skipped\n",
      "      üìä framework_state/day_20260201: 26/2574 files conflicted\n",
      "\n",
      "   üìÅ Directory: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/model_state/day_20260201\n",
      "      Relative: model_state/day_20260201\n",
      "      Component: model_state\n",
      "      Date: day_20260201\n",
      "      üìÑ Processing 9369 files in model_state/day_20260201\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "      üìä model_state/day_20260201: 9369/9369 files processed\n",
      "      üìä model_state/day_20260201: 0/9369 files skipped\n",
      "      üìä model_state/day_20260201: 0/9369 files conflicted\n",
      "\n",
      "   üìä Processed 2 directories\n",
      "\n",
      "================================================================================\n",
      "üì¶ BUILDING FINAL REGISTRY\n",
      "================================================================================\n",
      "Components found: ['framework_state', 'model_state']\n",
      "  ‚Ä¢ framework_state: 2548 files\n",
      "  ‚Ä¢ model_state: 9369 files\n",
      "\n",
      "‚úÖ SCAN COMPLETE\n",
      "Modes scanned: 1\n",
      "Total files in registry: 11917\n",
      "================================================================================\n",
      "\n",
      "\t‚Üí Filesystem scan found 11917 files\n",
      "\n",
      "===================== GET DRIVE REGISTRY =====================\n",
      "===================== REGISTRY BUILD COMPLETE =====================\n",
      "\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "\tüì¶ LocalBackupManager Registry Saved Locally in LOCAL\n",
      "BUILDING REGISTRY WITH 0 EXPECTED COMPONENTS KEYS\n",
      "\n",
      "===================== GET LOCAL REGISTRY =====================\n",
      "‚Üí Skipping local cache (force=True or file missing)\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "\tüì¶ LocalBackupManager Registry Saved Locally in LOCAL\n",
      "\n",
      "======================================================================\n",
      "üéØ AllocatorRunner initialized: ThompsonSampling\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "üöÄ STARTING ALLOCATOR: ThompsonSampling\n",
      "======================================================================\n",
      "\n",
      "üìä Physics Model: paper12\n",
      "\n",
      "üìã Allocator Config:\n",
      "   Type: ThompsonSampling\n",
      "   Testbed: paper12\n",
      "   Paths: 4\n",
      "   Total Qubits: 100\n",
      "   Min per route: 3\n",
      "   Seed: 42\n",
      "   Priors: Œ±=1.0, Œ≤=1.0\n",
      "‚úÖ Allocator created: (25, 25, 25, 25)\n",
      "‚úì Allocator: ThompsonSamplingAllocator (4 paths)\n",
      "   Initial allocation: (25, 25, 25, 25)\n",
      "Generated paper12 Waxman topology: 100 nodes, 388 edges, avg degree: 7.76\n",
      "üìä Paper12 Physics: Fusion (prob=0.9)\n",
      "\n",
      "======================================================================\n",
      "RUN 1 | Scale: 1.5 | Exp: 5\n",
      "======================================================================\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "\n",
      "\tüîÑ Resume: MultiRunEvaluator\n",
      "\n",
      "=====================================================\n",
      "üîç GENERATING EXPECTED KEYS FROM EVALUATOR\n",
      "=====================================================\n",
      "  ‚Ä¢ Evaluator filename: MultiRunEvaluator_2250-ThompsonSampling_All_All-1500_500_5_S1_5T_paper12.pkl\n",
      "\n",
      "üß© PARSED COMPONENTS\n",
      "  ‚Ä¢ cap_id:        2250\n",
      "  ‚Ä¢ allocator_id:  ThompsonSampling\n",
      "  ‚Ä¢ env_id:        All\n",
      "  ‚Ä¢ attack_id:     All\n",
      "  ‚Ä¢ base_frames:   1500\n",
      "  ‚Ä¢ frame_step:    500\n",
      "  ‚Ä¢ runs_id:       5\n",
      "\n",
      "=====================================================\n",
      "üß™ GENERATING KEYS FOR EACH RUN\n",
      "=====================================================\n",
      "\n",
      "--- Run 1/5 -----------------------\n",
      "\n",
      "=====================================================\n",
      "üì¶ FINAL EXPECTED KEYS\n",
      "=====================================================\n",
      "  ‚Ä¢ Runner keys: 11\n",
      "\n",
      "  ‚Ä¢ Model keys: 50\n",
      "\n",
      "--- Run 2/5 -----------------------\n",
      "\n",
      "=====================================================\n",
      "üì¶ FINAL EXPECTED KEYS\n",
      "=====================================================\n",
      "  ‚Ä¢ Runner keys: 21\n",
      "\n",
      "  ‚Ä¢ Model keys: 100\n",
      "\n",
      "--- Run 3/5 -----------------------\n",
      "\n",
      "=====================================================\n",
      "üì¶ FINAL EXPECTED KEYS\n",
      "=====================================================\n",
      "  ‚Ä¢ Runner keys: 31\n",
      "\n",
      "  ‚Ä¢ Model keys: 150\n",
      "\n",
      "--- Run 4/5 -----------------------\n",
      "\n",
      "=====================================================\n",
      "üì¶ FINAL EXPECTED KEYS\n",
      "=====================================================\n",
      "  ‚Ä¢ Runner keys: 41\n",
      "\n",
      "  ‚Ä¢ Model keys: 200\n",
      "\n",
      "--- Run 5/5 -----------------------\n",
      "\n",
      "=====================================================\n",
      "üì¶ FINAL EXPECTED KEYS\n",
      "=====================================================\n",
      "  ‚Ä¢ Runner keys: 51\n",
      "\n",
      "  ‚Ä¢ Model keys: 250\n",
      "\n",
      "EXPECTED KEY GENERATION COMPLETE\n",
      "\n",
      "RESTORING FROM DRIVE 1\n",
      "RESTORING FROM DRIVE 2\n",
      "\t‚ö†Ô∏è Registry exists ‚Üí aborting restore\n",
      "\t‚òÅÔ∏è Attempting Drive download: framework_state/MultiRunEvaluator_2250-ThompsonSampling_All_All-1500_500_5_S1_5T_paper12.pkl\n",
      "\t‚ùå Not found anywhere: framework_state/MultiRunEvaluator_2250-ThompsonSampling_All_All-1500_500_5_S1_5T_paper12.pkl\n",
      "\t‚ùå Not found in registry or fallback locations\n",
      "\t‚òÅÔ∏è Attempting Drive download: framework_state/MultiRunEvaluator_2250-ThompsonSampling_All_All-1500_500_5_S1_5T_paper12.pkl\n",
      "\t‚ùå Not found anywhere: framework_state/MultiRunEvaluator_2250-ThompsonSampling_All_All-1500_500_5_S1_5T_paper12.pkl\n",
      "\t‚ùå Not found in registry or fallback locations\n",
      "[Resume] exact failed ‚Üí Looking for supersets\n",
      "[Resume-Supersets] target_runs=5, backups=dict_keys([])\n",
      "[Resume-Supersets] Trying horizons in size order (largest first): []\n",
      "[Resume-Supersets] ‚ùå No valid supersets found for resume\n",
      "No state found for MultiRunEvaluator, disabling resume for Experiment Runners\n",
      "Multi-Run Evaluator Initialized\n",
      "Environment Type: None\n",
      "Frame Range: 1500 -> 3500 (step: 500)\n",
      "quantum_exps-ThompsonSampling(paper12)_alloc-all_envs-5_attacks-1500_500-5_runs-S1.5T\n",
      "[Logging Redirect Initialized]\n",
      "Log File: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/quantum_logs/quantum_exps-ThompsonSampling(paper12)_alloc-all_envs-5_attacks-1500_500-5_runs-S1.5T_20260201_log.txt\n",
      "‚öô Running evaluation...\n",
      "======================================================================\n",
      "SCENARIOS MODEL EVALUATION\n",
      "======================================================================\n",
      "Testing algorithm performance against:\n",
      "\t‚Ä¢ Stochastic:  \tNatural quantum decoherence and network failures\n",
      "\t‚Ä¢ Baseline:    \tOptimal conditions for validation\n",
      "======================================================================\n",
      "Models to Test:             \tOracle, GNeuralUCB, EXPNeuralUCB, CPursuitNeuralUCB, iCPursuitNeuralUCB\n",
      "Experiments per Scenario:   \t5\n",
      "======================================================================\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: BASELINE (OPTIMAL CONDITIONS)\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: NONE\n",
      "Category: Baseline (No Attacks)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 1500 frames  <>  SCALED-CAPACITY: 2250.0 frames (CAPACITY:1500 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=0 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for NONE Exp 1: (25, 25, 25, 25)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 1: Env:Baseline (None), Attack:No, Rate:0.0, Frames:1500, QubitAlloc=ThompsonSampling, SC:2250 (Scale=1.5 x Cap=1500), Seed: 18010\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 4\n",
      "\t   First reward: [0.1944, 0.5334336, 0.7380232703999999, 0.8326343725056001, 0.8726341491523584], type: <class 'list'>\n",
      "\t   First reward length: 5\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 1: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 GNEURALUCB          : Reward=0622.10, Efficiency=047.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=2250, Threshold=0.582]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 1: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=0579.14, Efficiency=043.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=2250, Threshold=0.628]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 1: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=0615.38, Efficiency=046.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=2250, Threshold=0.634]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 1: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=0643.04, Efficiency=048.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=2250, Threshold=0.712]\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 1: Env:Baseline (None), Attack:No, Rate:0.0, Frames:1500, QubitAlloc=ThompsonSampling, SC:2250 (Scale=1.5 x Cap=1500), Seed: 18010\n",
      "\t-->üèÜ EXP1 Winner:iCPursuitNeuralUCB  (Gap:051.4%) [Env:Baseline (None), Attack:No X Rate:0.0, Frames:1500, SCapacity=2250, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 1 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 2000 frames  <>  SCALED-CAPACITY: 3000.0 frames (CAPACITY:2000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=1 (uniform init) ‚Üí allocation=(25, 25, 25, 25)\n",
      "üîß Allocated qubits for NONE Exp 2: (25, 25, 25, 25)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (25, 25, 25, 25)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 2: Env:Baseline (None), Attack:No, Rate:0.0, Frames:2000, QubitAlloc=ThompsonSampling, SC:3000 (Scale=1.5 x Cap=2000), Seed: 20078\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 4\n",
      "\t   First reward: [0.1944, 0.5334336, 0.7380232703999999, 0.8326343725056001, 0.8726341491523584], type: <class 'list'>\n",
      "\t   First reward length: 5\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 2: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 GNEURALUCB          : Reward=0853.28, Efficiency=048.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 2: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=0848.69, Efficiency=048.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=3000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 2: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Cell: Allocator + ExperimentConfiguration for Paper #12\n",
    "# ============================================================\n",
    "importlib.reload(qubit_allocator)\n",
    "importlib.reload(experiment_config)\n",
    "importlib.reload(multi_run_evaluator)\n",
    "\n",
    "from daqr.core.quantum_physics              import *\n",
    "from daqr.evaluation.allocator_runner       import AllocatorRunner\n",
    "from daqr.evaluation.multi_run_evaluator    import MultiRunEvaluator\n",
    "from daqr.config.experiment_config          import ExperimentConfiguration\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"PAPER #12 (QuARC) QUANTUM ROUTING EVALUATION - ALL ALLOCATORS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1) Allocator Selection\n",
    "# ------------------------------------------------------------\n",
    "ALLOCATORS = [\"ThompsonSampling\"]\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2) Run Parameters\n",
    "# ------------------------------------------------------------\n",
    "# CORRECTED Paper 12 Evaluation\n",
    "attack_intensity    = FRAMEWORK_CONFIG['intensity']\n",
    "current_frames      = 1500      # 3 reconfiguration cycles\n",
    "frame_step          = 500       # Epoch-aligned checkpoints\n",
    "current_experiments = 1\n",
    "last_backup         = True\n",
    "base_cap            = False\n",
    "overwrite           = False\n",
    "\n",
    "RUNS                = [5]               # Acceptable for initial testing\n",
    "SCALES              = [1, 1.5, 2]\n",
    "ATTACK_SCENARIOS    = ['stochastic']    # Start simple\n",
    "print(f\"‚úÖ Testing QuARC with {current_frames} timeslots\")\n",
    "print(f\"‚úÖ Expected reconfigurations: {current_frames // 500}\")\n",
    "print(f\"‚úÖ Statistical runs: {RUNS[0]}\")\n",
    "\n",
    "FRAMEWORK_CONFIG['exp_num']     = current_experiments\n",
    "FRAMEWORK_CONFIG['base_frames'] = current_frames\n",
    "FRAMEWORK_CONFIG['frame_step']  = frame_step\n",
    "\n",
    "\n",
    "# Testbed Configuration\n",
    "PHYSICS_MODELS = ['paper12']  # Paper 12 (QuARC)\n",
    "ATTACK_SCENARIOS = ['stochastic']  # Start simple\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PAPER 12 ALLOCATOR EVALUATION\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Allocators:                 {ALLOCATORS}\")\n",
    "print(f\"Physics Models:             {PHYSICS_MODELS}\")\n",
    "print(f\"Attack Scenarios:           {ATTACK_SCENARIOS}\")\n",
    "print(f\"Scales:                     {SCALES}\")\n",
    "print(f\"Runs per Scale:             {RUNS}\")\n",
    "print(f\"Total Frames:               {current_frames}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "\n",
    "for allocator_type in ALLOCATORS:\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"RUNNING: {allocator_type} on Paper 12 (QuARC)\")\n",
    "    print('='*70)\n",
    "\n",
    "    for scale in SCALES:\n",
    "        print(f\"\\n{'-'*70}\")\n",
    "        print(f\"Preparing: {allocator_type} at scale {scale}\")\n",
    "        print(f\"{'-'*70}\")\n",
    "\n",
    "        for physics_model in PHYSICS_MODELS:\n",
    "            print(f\"\\nüîß Generating physics parameters for model: {physics_model}\") \n",
    "            try:\n",
    "                # Create isolated runner instance\n",
    "                custom_config = ExperimentConfiguration(\n",
    "                    env_type=FRAMEWORK_CONFIG['main_env'],\n",
    "                    scenarios=test_scenarios,\n",
    "                    use_last_backup=last_backup,\n",
    "                    models=models,\n",
    "                    attack_intensity=attack_intensity,\n",
    "                    scale=scale,\n",
    "                    base_capacity=base_cap,\n",
    "                    overwrite=overwrite\n",
    "                )\n",
    "\n",
    "                alloc_runner = AllocatorRunner(\n",
    "                    allocator_type=allocator_type,\n",
    "                    physics_models=[physics_model],\n",
    "                    framework_config=FRAMEWORK_CONFIG,\n",
    "                    scales=[scale],\n",
    "                    runs=RUNS,\n",
    "                    models=models,\n",
    "                    test_scenarios=test_scenarios,\n",
    "                    config=custom_config\n",
    "                )\n",
    "\n",
    "                # Run with Paper 12 physics\n",
    "                alloc_runner.run(get_physics_params_func=get_physics_params)\n",
    "                print(f\"\\n{allocator_type} COMPLETED SUCCESSFULLY\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"\\n{allocator_type} FAILED: {e}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ALL ALLOCATORS COMPLETE!\")\n",
    "print(\"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Cell: Allocator + ExperimentConfiguration for Paper #12\n",
    "# ============================================================\n",
    "importlib.reload(qubit_allocator)\n",
    "importlib.reload(experiment_config)\n",
    "importlib.reload(multi_run_evaluator)\n",
    "\n",
    "from daqr.core.quantum_physics              import *\n",
    "from daqr.evaluation.allocator_runner       import AllocatorRunner\n",
    "from daqr.evaluation.multi_run_evaluator    import MultiRunEvaluator\n",
    "from daqr.config.experiment_config          import ExperimentConfiguration\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"PAPER #12 (QuARC) QUANTUM ROUTING EVALUATION - ALL ALLOCATORS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1) Allocator Selection\n",
    "# ------------------------------------------------------------\n",
    "ALLOCATORS = [\"Random\"]\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2) Run Parameters\n",
    "# ------------------------------------------------------------\n",
    "# CORRECTED Paper 12 Evaluation\n",
    "attack_intensity    = FRAMEWORK_CONFIG['intensity']\n",
    "current_frames      = 1500      # 3 reconfiguration cycles\n",
    "frame_step          = 500       # Epoch-aligned checkpoints\n",
    "current_experiments = 1\n",
    "last_backup         = True\n",
    "base_cap            = False\n",
    "overwrite           = False\n",
    "\n",
    "RUNS                = [5]               # Acceptable for initial testing\n",
    "SCALES              = [1, 1.5, 2]\n",
    "ATTACK_SCENARIOS    = ['stochastic']    # Start simple\n",
    "print(f\"‚úÖ Testing QuARC with {current_frames} timeslots\")\n",
    "print(f\"‚úÖ Expected reconfigurations: {current_frames // 500}\")\n",
    "print(f\"‚úÖ Statistical runs: {RUNS[0]}\")\n",
    "\n",
    "FRAMEWORK_CONFIG['exp_num']     = current_experiments\n",
    "FRAMEWORK_CONFIG['base_frames'] = current_frames\n",
    "FRAMEWORK_CONFIG['frame_step']  = frame_step\n",
    "\n",
    "# Testbed Configuration\n",
    "PHYSICS_MODELS = ['paper12']  # Paper 12 (QuARC)\n",
    "ATTACK_SCENARIOS = ['stochastic']  # Start simple\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PAPER 12 ALLOCATOR EVALUATION\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Allocators:                 {ALLOCATORS}\")\n",
    "print(f\"Physics Models:             {PHYSICS_MODELS}\")\n",
    "print(f\"Attack Scenarios:           {ATTACK_SCENARIOS}\")\n",
    "print(f\"Scales:                     {SCALES}\")\n",
    "print(f\"Runs per Scale:             {RUNS}\")\n",
    "print(f\"Total Frames:               {current_frames}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "\n",
    "for allocator_type in ALLOCATORS:\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"RUNNING: {allocator_type} on Paper 12 (QuARC)\")\n",
    "    print('='*70)\n",
    "\n",
    "    for scale in SCALES:\n",
    "        print(f\"\\n{'-'*70}\")\n",
    "        print(f\"Preparing: {allocator_type} at scale {scale}\")\n",
    "        print(f\"{'-'*70}\")\n",
    "\n",
    "        for physics_model in PHYSICS_MODELS:\n",
    "            print(f\"\\nüîß Generating physics parameters for model: {physics_model}\") \n",
    "            try:\n",
    "                # Create isolated runner instance\n",
    "                custom_config = ExperimentConfiguration(\n",
    "                    env_type=FRAMEWORK_CONFIG['main_env'],\n",
    "                    scenarios=test_scenarios,\n",
    "                    use_last_backup=last_backup,\n",
    "                    models=models,\n",
    "                    attack_intensity=attack_intensity,\n",
    "                    scale=scale,\n",
    "                    base_capacity=base_cap,\n",
    "                    overwrite=overwrite\n",
    "                )\n",
    "\n",
    "                alloc_runner = AllocatorRunner(\n",
    "                    allocator_type=allocator_type,\n",
    "                    physics_models=[physics_model],\n",
    "                    framework_config=FRAMEWORK_CONFIG,\n",
    "                    scales=[scale],\n",
    "                    runs=RUNS,\n",
    "                    models=models,\n",
    "                    test_scenarios=test_scenarios,\n",
    "                    config=custom_config\n",
    "                )\n",
    "\n",
    "                # Run with Paper 12 physics\n",
    "                alloc_runner.run(get_physics_params_func=get_physics_params)\n",
    "                print(f\"\\n{allocator_type} COMPLETED SUCCESSFULLY\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"\\n{allocator_type} FAILED: {e}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ALL ALLOCATORS COMPLETE!\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paper 12 (QuARC) - Clustered Quantum Routing\n",
    "\n",
    "## Quantum Adaptive Routing Using Clusters (QuARC)\n",
    "\n",
    "**Reference**: Clayton et al., 2024 - \"Efficient Routing on Quantum Networks using Adaptive Clustering\" (ICNP 2024)\n",
    "\n",
    "**Repository**: https://github.com/cbclayton/clustered-quantum-routing\n",
    "\n",
    "### Key Features\n",
    "\n",
    "- **Adaptive Clustering**: Dynamic network partitioning into clusters (blobs) based on entanglement generation success\n",
    "- **Merge/Split Protocol**: Clusters merge when success rate drops below threshold, split when exceeds threshold\n",
    "- **Fusion Management**: Handles n-way quantum state fusion within clusters with noise modeling\n",
    "- **Waxman Topology**: Realistic topological model with spatial characteristics\n",
    "- **Adaptive Thresholding**: Merge/split thresholds scale dynamically with cluster size\n",
    "\n",
    "### Implementation Strategy\n",
    "\n",
    "Our framework integrates Paper12's QuARC concepts into the neural bandit testbed:\n",
    "\n",
    "1. **Cluster Representation**: Map QuARC \"blobs\" to multi-armed bandit paths\n",
    "2. **Fusion as Actions**: Different cluster sizes = different action arms per path\n",
    "3. **Context Features**: [cluster_size, fusion_prob, avg_entanglement_rate]\n",
    "4. **Reward Function**: Entanglement success rate normalized to [0, 1]\n",
    "5. **Adaptive Allocation**: Neural bandits learn optimal cluster size selection per network state\n",
    "\n",
    "### Testbed Parameters\n",
    "\n",
    "- **Topology**: Waxman random geometric (100-800 nodes)\n",
    "- **Edge Success Probability (E_p)**: 0.6 (60% quantum state fidelity)\n",
    "- **Fusion Success Probability (q)**: 0.9 (90% fusion gate fidelity)\n",
    "- **Average Degree (E_d)**: 6 neighbors per node\n",
    "- **Channel Width**: 3 quantum channels per edge\n",
    "- **Number of SD Pairs**: 10 source-destination pairs per evaluation\n",
    "- **Qubits per Node**: Variable based on cluster configuration\n",
    "- **Request Generation**: Random or bimodal distance distribution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "comprehensive-evaluation"
   },
   "source": [
    "## Multi-Environment Performance Analysis\n",
    "\n",
    "### Complete Evaluation Matrix\n",
    "\n",
    "This research extends beyond the primary stochastic-adversarial comparison to provide comprehensive algorithm assessment across the complete spectrum of operational environments, establishing a thorough empirical foundation for robustness evaluation.\n",
    "\n",
    "### Environmental Test Framework\n",
    "\n",
    "| Environment | Classification | Threat Characteristics | Analytical Purpose |\n",
    "|-------------|---------------|----------------------|-------------------|\n",
    "| `none` | Baseline | Deterministic optimal conditions | Theoretical performance ceiling |\n",
    "| `stochastic` | Probabilistic | Uniform random failures | Standard operational baseline |\n",
    "| `markov` | Adversarial | Memory-dependent strategic attacks | Oblivious adversarial model |\n",
    "| `adaptive` | Adversarial | Feedback-driven strategic attacks | Responsive adversarial model |\n",
    "| `onlineadaptive` | Adversarial | Real-time adaptive strategic attacks | Sophisticated adversarial model |\n",
    "\n",
    "### Research Contributions\n",
    "\n",
    "**Comprehensive Threat Model Coverage**\n",
    "The evaluation framework addresses the complete spectrum of operational conditions, from optimal deterministic environments through increasingly sophisticated adversarial scenarios, providing unprecedented coverage of realistic deployment conditions.\n",
    "\n",
    "**Graduated Adversarial Complexity Analysis**  \n",
    "The systematic progression from oblivious to sophisticated adversarial models enables precise quantification of algorithm performance degradation as threat sophistication increases, revealing critical robustness thresholds.\n",
    "\n",
    "**Cross-Environment Validation Protocol**\n",
    "Consistent algorithm ranking across multiple environments validates robustness claims and identifies algorithms with stable performance characteristics independent of operational conditions.\n",
    "\n",
    "**Empirical Robustness Quantification**\n",
    "The multi-environment approach enables precise measurement of performance degradation rates, establishing quantitative robustness metrics that support theoretical predictions and practical deployment decisions.\n",
    "\n",
    "### Methodological Significance\n",
    "\n",
    "This comprehensive evaluation protocol addresses limitations in existing literature where algorithm assessment often focuses on narrow operational scenarios, providing the empirical foundation necessary for robust algorithm deployment in practical quantum network environments."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1rknAIThhNzWIoGwNHJR_N0F6hBb7T3e-",
     "timestamp": 1759053280580
    }
   ]
  },
  "kernelspec": {
   "display_name": ".quantum (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
