{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick verification: Check if the probability clamping fix is loaded\n",
    "import inspect\n",
    "from daqr.algorithms.neural_bandits import EXPNeuralUCB\n",
    "\n",
    "source = inspect.getsource(EXPNeuralUCB.run)\n",
    "if 'np.clip(base_reward, 0.0, 1.0)' in source:\n",
    "    print(\"‚úÖ PROBABILITY CLAMPING FIX LOADED: np.clip detected in run() method\")\n",
    "else:\n",
    "    print(\"‚ùå PROBABILITY CLAMPING FIX NOT FOUND: np.clip NOT in run() method\")\n",
    "    \n",
    "if 'base_reward_prob' in source:\n",
    "    print(\"‚úÖ PROBABILITY RENAMING FIX LOADED: base_reward_prob variable detected\")\n",
    "else:\n",
    "    print(\"‚ùå PROBABILITY RENAMING FIX NOT FOUND: base_reward_prob NOT in run() method\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "title-cell"
   },
   "source": [
    "# Neural Bandit Algorithm Evaluation Framework\n",
    "\n",
    "## Graduate Research Project\n",
    "**AI & Quantum Computing Laboratory**  \n",
    "**Rochester Institute of Technology**\n",
    "\n",
    "---\n",
    "\n",
    "## Research Framework Overview\n",
    "\n",
    "This comprehensive evaluation framework provides rigorous analysis of neural bandit algorithms with clear categorical distinction between different operational environments:\n",
    "\n",
    "- **Baseline Environment**: Optimal performance benchmark (Oracle)\n",
    "- **Stochastic Environment**: Natural random failures and network noise\n",
    "- **Adversarial Environment**: Strategic intelligent attacks and malicious targeting\n",
    "\n",
    "## Primary Research Questions\n",
    "\n",
    "1. **Algorithm Robustness**: How do neural bandit algorithms perform across different threat models?\n",
    "2. **Comparative Analysis**: Which algorithms demonstrate superior performance in specific scenarios?\n",
    "3. **Quantified Performance**: What are the exact degradation metrics under adversarial conditions?\n",
    "4. **Theoretical Validation**: Do experimental results align with established regret bounds?\n",
    "\n",
    "## Key Research Contributions\n",
    "\n",
    "- **Systematic Environment Categorization**: Clear baseline/stochastic/adversarial taxonomy\n",
    "- **Multi-Algorithm Comparative Testing**: Comprehensive evaluation across 6+ algorithms\n",
    "- **Quantified Robustness Metrics**: Precise performance degradation measurements\n",
    "- **Publication-Ready Analysis**: Academic-quality visualizations and statistical validation\n",
    "\n",
    "## Evaluation Methodology\n",
    "\n",
    "The framework implements standardized testing protocols across three distinct categories:\n",
    "- **Baseline**: Oracle performance establishing theoretical upper bounds\n",
    "- **Stochastic**: Random environmental perturbations modeling realistic conditions  \n",
    "- **Adversarial**: Strategic attack scenarios simulating malicious interference\n",
    "\n",
    "Each algorithm undergoes identical testing conditions enabling direct performance comparison and robustness quantification across all operational environments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "framework-overview"
   },
   "source": [
    "## Threat Model Classification Framework\n",
    "\n",
    "### Systematic Environment Taxonomy\n",
    "\n",
    "This research framework establishes precise categorical distinctions for quantum network evaluation environments, addressing previous ambiguity in threat model classification:\n",
    "\n",
    "### Environmental Categories\n",
    "\n",
    "| Environment | Implementation | Threat Characteristic | Research Application |\n",
    "|-------------|----------------|----------------------|---------------------|\n",
    "| **Baseline** | `none` | Deterministic optimal performance | Theoretical upper bound |\n",
    "| **Stochastic** | `stochastic`/`random` | Natural random failures | Realistic network conditions |\n",
    "| **Adversarial** | `markov` | Oblivious strategic attacks | Pattern-based targeting |\n",
    "| **Adversarial** | `adaptive` | Responsive strategic attacks | Feedback-driven targeting |\n",
    "| **Adversarial** | `onlineadaptive` | Real-time strategic attacks | Dynamic threat adaptation |\n",
    "\n",
    "### Research Contribution\n",
    "\n",
    "This framework addresses a critical gap in existing literature where random network failures were often conflated with intentional adversarial attacks. The systematic categorization enables:\n",
    "\n",
    "- **Precise Robustness Quantification**: Exact performance degradation measurements across threat categories\n",
    "- **Comparative Algorithm Analysis**: Direct performance comparison under identical threat conditions\n",
    "- **Theoretical Validation**: Empirical verification of regret bounds across different adversarial models\n",
    "- **Reproducible Research Standards**: Standardized evaluation protocols for quantum network algorithms\n",
    "\n",
    "### Methodological Significance\n",
    "\n",
    "Previous research often lacked clear distinction between stochastic and adversarial environments, limiting the ability to assess true algorithm robustness under intentional attacks versus natural network degradation. This framework provides the necessary precision for rigorous academic evaluation of quantum routing algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup-cell"
   },
   "source": [
    "## Environment Setup & Library Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 58,
     "status": "ok",
     "timestamp": 1758879388611,
     "user": {
      "displayName": "Piter Garcia",
      "userId": "06279433864365870614"
     },
     "user_tz": 240
    },
    "id": "theoretical-setup",
    "outputId": "a6c0fc57-a152-45e1-9da6-5113e519b8fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: notebooks\n",
      "Running locally (not in Colab)\n",
      "Now working from: notebooks\n",
      "Framework dependencies installed successfully\n",
      "Python version: 3.12.11\n",
      "PyTorch version: 2.8.0\n",
      "NumPy version: 1.26.4\n",
      "Matplotlib version: 3.10.6\n",
      "Quantum MAB Models Evaluation Framework - Ready for model testing\n",
      "\n",
      "üöø Running cleanup script at: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/cleanup_state_duplicates.py\n",
      "\n",
      "===== CLEANUP STDOUT =====\n",
      " Script dir: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework\n",
      "Project root: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework\n",
      "\n",
      "State roots:\n",
      "  ‚úÖ /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state\n",
      "  ‚úÖ /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/model_state\n",
      "  ‚ùå /content/drive/Shareddrives/ai_quantum_computing/quantum_data_lake/framework_state\n",
      "  ‚ùå /content/drive/Shareddrives/ai_quantum_computing/quantum_data_lake/model_state\n",
      "\n",
      "========== STARTING CLEANUP ==========\n",
      "\n",
      "[CLEANUP] Removing .0 float artifacts from filenames...\n",
      "[‚úì] Float artifacts fixed: 0\n",
      "\n",
      "--- Cleaning: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state ---\n",
      "[CLEAN] /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state\n",
      "[‚úì] /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state: removed 3 duplicates\n",
      "\n",
      "--- Cleaning: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/model_state ---\n",
      "[CLEAN] /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/model_state\n",
      "[‚úì] /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/model_state: removed 2 duplicates\n",
      "\n",
      "--- Cleaning: /content/drive/Shareddrives/ai_quantum_computing/quantum_data_lake/framework_state ---\n",
      "[SKIP] Missing path ‚Üí /content/drive/Shareddrives/ai_quantum_computing/quantum_data_lake/framework_state\n",
      "\n",
      "--- Cleaning: /content/drive/Shareddrives/ai_quantum_computing/quantum_data_lake/model_state ---\n",
      "[SKIP] Missing path ‚Üí /content/drive/Shareddrives/ai_quantum_computing/quantum_data_lake/model_state\n",
      "\n",
      "\n",
      "========== CONSOLIDATION: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state ==========\n",
      "Target date directory: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260128\n",
      "[‚úì] Consolidation finished for /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state: moved 1847 files, removed 1 directories.\n",
      "\n",
      "\n",
      "========== CONSOLIDATION: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/model_state ==========\n",
      "Target date directory: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/model_state/day_20260128\n",
      "[‚úì] Consolidation finished for /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/model_state: moved 5438 files, removed 1 directories.\n",
      "[SKIP] Missing path ‚Üí /content/drive/Shareddrives/ai_quantum_computing/quantum_data_lake/framework_state\n",
      "[SKIP] Missing path ‚Üí /content/drive/Shareddrives/ai_quantum_computing/quantum_data_lake/model_state\n",
      "\n",
      "[UPDATE] Updating registry: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/local_backup_registry.json\n",
      "[DEBUG] State roots passed in:\n",
      "        - /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state  (exists=True)\n",
      "        - /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/model_state  (exists=True)\n",
      "\n",
      "[DEBUG] COMPONENT: framework_state\n",
      "        root = /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state\n",
      "[SKIP]     Not a directory: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/.DS_Store\n",
      "[SKIP]     Not a directory: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/Icon\n",
      "\n",
      "[DEBUG] COMPONENT: model_state\n",
      "        root = /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/model_state\n",
      "[SKIP]     Not a directory: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/model_state/.DS_Store\n",
      "[SKIP]     Not a directory: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/model_state/Icon\n",
      "[‚úì] Registry updated: 7588 corrected, 0 added\n",
      "\n",
      "[UPDATE] Updating registry: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/drive_backup_registry.json\n",
      "[DEBUG] State roots passed in:\n",
      "        - /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state  (exists=True)\n",
      "        - /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/model_state  (exists=True)\n",
      "\n",
      "[DEBUG] COMPONENT: framework_state\n",
      "        root = /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state\n",
      "[SKIP]     Not a directory: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/.DS_Store\n",
      "[SKIP]     Not a directory: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/Icon\n",
      "\n",
      "[DEBUG] COMPONENT: model_state\n",
      "        root = /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/model_state\n",
      "[SKIP]     Not a directory: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/model_state/.DS_Store\n",
      "[SKIP]     Not a directory: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/model_state/Icon\n",
      "[‚úì] Registry updated: 7588 corrected, 0 added\n",
      "[INFO] Registry not found, skipping update: /content/drive/Shareddrives/ai_quantum_computing/quantum_data_lake/backup_registry.json\n",
      "\n",
      "========== DONE ==========\n",
      "\n",
      "\n",
      "===== CLEANUP STDERR =====\n",
      " /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/cleanup_state_duplicates.py:1338: SyntaxWarning: invalid escape sequence '\\('\n",
      "  \"scenario_cat\": re.split(\"\\(|\\)\", scenario_cat)[-2],\n",
      "\n",
      "‚úì Deep cleanup complete (memory cleared)\n",
      "PyTorch version: 2.8.0\n",
      "NumPy version: 1.26.4\n",
      "Using device: cpu\n",
      "PyTorch version: 2.8.0\n",
      "NumPy version: 1.26.4\n",
      "Using device: cpu\n",
      "‚úì All modules reloaded successfully (fresh environment ready)\n",
      "PyTorch version: 2.8.0\n",
      "NumPy version: 1.26.4\n",
      "Using device: cpu\n",
      "PyTorch version: 2.8.0\n",
      "NumPy version: 1.26.4\n",
      "Using device: cpu\n",
      "\n",
      "===================== GET LOCAL REGISTRY =====================\n",
      "‚Üí Skipping local cache (force=True or file missing)\n",
      "\n",
      "===================== BUILD LOCAL REGISTRY =====================\n",
      "\n",
      "================================================================================\n",
      "üîç SCANNING LOCAL FILES\n",
      "================================================================================\n",
      "Parameters: load_to_drive=False, force=False\n",
      "\n",
      "üìÇ Checking DRIVE mode: /content/drive/Shareddrives/ai_quantum_computing/quantum_data_lake\n",
      "   ‚ö†Ô∏è  Path does not exist, skipping\n",
      "\n",
      "üìÇ Checking LOCAL mode: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config\n",
      "   ‚úÖ Path exists, starting walk...\n",
      "   üö∂ Walking directory tree: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config\n",
      "\n",
      "   üìÅ Directory: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260128\n",
      "      Relative: framework_state/day_20260128\n",
      "      Component: framework_state\n",
      "      Date: day_20260128\n",
      "      üìÑ Processing 1900 files in framework_state/day_20260128\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "      üìä framework_state/day_20260128: 1772/1900 files processed\n",
      "      üìä framework_state/day_20260128: 0/1900 files skipped\n",
      "      üìä framework_state/day_20260128: 128/1900 files conflicted\n",
      "\n",
      "   üìÅ Directory: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/model_state/day_20260128\n",
      "      Relative: model_state/day_20260128\n",
      "      Component: model_state\n",
      "      Date: day_20260128\n",
      "      üìÑ Processing 5688 files in model_state/day_20260128\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "      üìä model_state/day_20260128: 5677/5688 files processed\n",
      "      üìä model_state/day_20260128: 0/5688 files skipped\n",
      "      üìä model_state/day_20260128: 11/5688 files conflicted\n",
      "\n",
      "   üìä Processed 2 directories\n",
      "\n",
      "================================================================================\n",
      "üì¶ BUILDING FINAL REGISTRY\n",
      "================================================================================\n",
      "Components found: ['framework_state', 'model_state']\n",
      "  ‚Ä¢ framework_state: 1772 files\n",
      "  ‚Ä¢ model_state: 5677 files\n",
      "\n",
      "‚úÖ SCAN COMPLETE\n",
      "Modes scanned: 1\n",
      "Total files in registry: 7449\n",
      "================================================================================\n",
      "\n",
      "\t‚Üí Filesystem scan found 7449 files\n",
      "\n",
      "===================== GET DRIVE REGISTRY =====================\n",
      "===================== REGISTRY BUILD COMPLETE =====================\n",
      "\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "\tüì¶ LocalBackupManager Registry Saved Locally in LOCAL\n",
      "BUILDING REGISTRY WITH 0 EXPECTED COMPONENTS KEYS\n",
      "\n",
      "===================== GET LOCAL REGISTRY =====================\n",
      "‚Üí Skipping local cache (force=True or file missing)\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "\tüì¶ LocalBackupManager Registry Saved Locally in LOCAL\n",
      "======================================================================\n",
      "Models to evaluate: 5 total\n",
      "DYNAMIC ROUTING EVALUATION FRAMEWORK - CONFIGURATION\n",
      "\n",
      "‚úì Configuration loaded successfully - Ready for model evaluation\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Setup: Quantum MAB Framework (Clean Testbed Notebook)\n",
    "# ============================================================\n",
    "\n",
    "# --- Install Dependencies ---\n",
    "!pip install -q torch torchvision numpy matplotlib seaborn pandas tqdm scipy scikit-learn pmdarima\n",
    "\n",
    "# --- Core Imports ---\n",
    "import os, sys, gc, warnings, importlib, subprocess\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- Path Setup ---\n",
    "print(f\"Current working directory: {os.getcwd().split('/')[-1]}\")\n",
    "try:\n",
    "    import google.colab\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    project_dir = '/content/drive/MyDrive/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework'\n",
    "    os.chdir(project_dir)\n",
    "    print(\"Running in Google Colab\")\n",
    "except ImportError:\n",
    "    print(\"Running locally (not in Colab)\")\n",
    "\n",
    "sys.path.append(os.path.join(os.getcwd(), 'src'))\n",
    "print(f\"Now working from: {os.getcwd().split('/')[-1]}\")\n",
    "\n",
    "# --- Framework Verification ---\n",
    "print(\"Framework dependencies installed successfully\")\n",
    "print(f\"Python version: {sys.version.split()[0]}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Matplotlib version: {plt.matplotlib.__version__}\")\n",
    "print(\"Quantum MAB Models Evaluation Framework - Ready for model testing\")\n",
    "\n",
    "\n",
    "# --- Cleanup Script Execution ---\n",
    "root = os.path.abspath(\"../..\")\n",
    "cleanup_script = os.path.join(root, \"cleanup_state_duplicates.py\")\n",
    "print(f\"\\nüöø Running cleanup script at: {cleanup_script}\\n\")\n",
    "result = subprocess.run([\"python3\", cleanup_script], text=True, capture_output=True)\n",
    "print(\"===== CLEANUP STDOUT =====\\n\", result.stdout)\n",
    "print(\"===== CLEANUP STDERR =====\\n\", result.stderr)\n",
    "\n",
    "# --- Deep Cleanup ---\n",
    "def deep_cleanup():\n",
    "    to_clear = [\"oracle\", \"gneuralucb\", \"expneuralucb\", \"cpursuitneuralucb\",\n",
    "                \"icpursuitneuralucb\", \"evaluator\", \"results\"]\n",
    "    for name in to_clear:\n",
    "        if name in globals():\n",
    "            obj = globals().get(name)\n",
    "            if hasattr(obj, \"cleanup\"): obj.cleanup(verbose=False)\n",
    "            globals().pop(name, None)\n",
    "    gc.collect()\n",
    "    torch.set_default_dtype(torch.float32)\n",
    "    if torch.cuda.is_available(): torch.cuda.empty_cache()\n",
    "    print(\"‚úì Deep cleanup complete (memory cleared)\")\n",
    "\n",
    "deep_cleanup()\n",
    "\n",
    "# Ensure daqr package is discoverable\n",
    "PARENT_DIR = os.path.abspath(\"..\")\n",
    "if PARENT_DIR not in sys.path:\n",
    "    sys.path.insert(0, PARENT_DIR)\n",
    "\n",
    "# --- Final Module Setup ---\n",
    "from daqr.core.qubit_allocator              import (QubitAllocator, RandomQubitAllocator, DynamicQubitAllocator, ThompsonSamplingAllocator)\n",
    "from daqr.core.quantum_physics              import (MemoryNoiseModel, FullPaper2FidelityCalculator, Paper2RewardFunction)\n",
    "from daqr.evaluation                        import experiment_runner, multi_run_evaluator, visualizer, allocator_runner\n",
    "from daqr.config                            import experiment_config, gd_backup_manager, local_backup_manager\n",
    "from daqr.algorithms                        import base_bandit, neural_bandits, predictive_bandits\n",
    "from daqr.core                              import network_environment, qubit_allocator\n",
    "from daqr.evaluation.visualizer             import QuantumEvaluatorVisualizer\n",
    "from daqr.config.gd_backup_manager          import GoogleDriveBackupManager\n",
    "from daqr.config.experiment_config          import ExperimentConfiguration\n",
    "from experiments                       import stochastic_evaluation\n",
    "from daqr.config.local_backup_manager       import LocalBackupManager\n",
    "from daqr.core.network_environment          import *\n",
    "from daqr.core.qubit_allocator              import *\n",
    "from daqr.algorithms.base_bandit            import *\n",
    "from daqr.algorithms.neural_bandits         import *\n",
    "from daqr.algorithms.predictive_bandits     import *\n",
    "from daqr.evaluation.multi_run_evaluator    import *\n",
    "from daqr.evaluation.experiment_runner      import *\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 3: CLEAN MODULE RELOAD\n",
    "# ============================================================================\n",
    "from daqr.core.topology_generator           import Paper2TopologyGenerator\n",
    "from daqr.core.topology_generator           import Paper7ASTopologyGenerator\n",
    "from daqr.core.topology_generator           import Paper12WaxmanTopologyGenerator\n",
    "from daqr.core.quantum_physics              import FiberLossNoiseModel, CascadedFidelityCalculator\n",
    "from daqr.core.quantum_physics              import FusionNoiseModel, FusionFidelityCalculator, QuARCRewardFunction\n",
    "\n",
    "# ==================== PAPER-SPECIFIC IMPORTS ====================\n",
    "from daqr.core.quantum_physics              import Paper12RetryFidelityCalculator\n",
    "from daqr.core.quantum_physics              import Paper7RewardFunction\n",
    "from daqr.core                              import attack_strategy\n",
    "\n",
    "print(\"‚úì All modules reloaded successfully (fresh environment ready)\")\n",
    "\n",
    "# --- Config & Model Setup ---\n",
    "# UPDATED: Add attack_strategy to reload list\n",
    "for module in [experiment_config, network_environment, qubit_allocator, attack_strategy, base_bandit, neural_bandits, predictive_bandits, experiment_runner, multi_run_evaluator, visualizer, stochastic_evaluation]:  importlib.reload(module)\n",
    "\n",
    "config = ExperimentConfiguration()\n",
    "models = config.NEURAL_MODELS\n",
    "\n",
    "FRAMEWORK_CONFIG = {\n",
    "    'exp_num': 5,\n",
    "    'test_mode': True,\n",
    "    'base_frames': 4000,\n",
    "    'frame_step': 2000,\n",
    "    'models': models,\n",
    "    'intensity': 0.25,\n",
    "    'routing_strategy': 'fixed',\n",
    "    'capacity': 10000,\n",
    "    'main_env': 'stochastic',\n",
    "\n",
    "    # Environment parameters\n",
    "    'env_attrs': {\n",
    "        'intensity': 0.25,  # Natural failure rate for stochastic\n",
    "        'base_seed': 12345,\n",
    "        'reproducible': True\n",
    "    },\n",
    "\n",
    "    'default': {\n",
    "        'num_paths': 4,\n",
    "        'total_qubits': 35,\n",
    "        'min_qubits_per_route': 2,\n",
    "        'exploration_bonus': 2.0,\n",
    "        'epsilon': 1.0,\n",
    "        'seed': 42\n",
    "    },\n",
    "    \n",
    "    # Paper #2 (Huang et al. - Your Neural Bandit Work)\n",
    "    'paper2': {\n",
    "        # Topology & Paths\n",
    "        'num_paths': 4,\n",
    "        'num_total_qubits': 35,\n",
    "        'dest_node': 14,\n",
    "        'num_nodes': 15,\n",
    "        'source_node': 1,\n",
    "        \n",
    "        # Base Physics\n",
    "        'p_init': 0.00001,\n",
    "        'total_qubits': 35,\n",
    "        'f_attenuation': 0.05,\n",
    "        \n",
    "        # Stochastic Noise Parameters\n",
    "        'p_BSM': 0.2,\n",
    "        'p_GateErrors': 0.2,\n",
    "        'p_depol': 0.1,\n",
    "\n",
    "        # üÜï NEW: Paper2 State Configuration\n",
    "        'testbed': 'paper2',\n",
    "        'initial_state': 'idle',\n",
    "        'state_total_qubits': {'busy': 35, 'idle': 43},\n",
    "        \n",
    "        # Bandit Algorithm\n",
    "        'exploration_bonus': 2.0,\n",
    "        'min_qubits_per_route': 2,\n",
    "        'transition_trigger': True,  # Keep existing key name\n",
    "        'paper2_transition_interval': 50,\n",
    "        'entanglement_success_factor': 4000,\n",
    "        \n",
    "        # Paper2 Features\n",
    "        'use_paper2_rewards': True,\n",
    "        'swap_mode': 'async',\n",
    "        'memory_T2': 5000,\n",
    "        'gate_error_rate': 0.02,\n",
    "        'swap_delay_per_link': 100,\n",
    "        'use_gate_error': True,\n",
    "        'use_memory_decay': True,\n",
    "    },\n",
    "\n",
    "    # Paper #7 (Liu et al. 2024 - QBGP)\n",
    "    'paper7': {\n",
    "        'k': 5,                      # k-shortest paths per ISP pair\n",
    "        'n_qisps': 3,                # Number of ISP nodes\n",
    "        'num_paths': 4,              # Total paths (NOT 8)\n",
    "        'max_nodes': None,           # Use all 342 nodes from file\n",
    "        'total_qubits': 35,          # Your framework default\n",
    "        'network_scale': 'small',\n",
    "        'min_qubits_per_route': 2,\n",
    "        'reward_mode': 'neg_hop',    # or 'neg_length', etc.\n",
    "        'topology_path': '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/core/topology_data/as20000101.txt',\n",
    "\n",
    "\n",
    "        # üÜï NEW: Feature toggles\n",
    "        'use_context_rewards': True,      # Enable context-aware reward function\n",
    "        # 'reward_mode': 'neg_hop',         # 'neg_hop', 'neg_degree', 'neg_length', 'custom'\n",
    "        'use_synthetic': False,           # Force synthetic topology (ignore \n",
    "    },\n",
    "    \n",
    "    # Paper #12 (Wang et al. 2024 - QuARC)\n",
    "    'paper12': {\n",
    "        # Topology\n",
    "        'n_nodes': 100,              # Vary: 100-800\n",
    "        'avg_degree': 6,             # Ed (average degree)\n",
    "        'waxman_beta': 0.2,\n",
    "        'waxman_alpha': 0.4,\n",
    "        'topology_type': 'waxman',\n",
    "        \n",
    "        # Physical parameters\n",
    "        'channel_width': 3,          # Links per edge\n",
    "        'fusion_prob': 0.9,          # q (fusion success)\n",
    "        'qubits_per_node': 12,       # Memory capacity\n",
    "        'entanglement_prob': 0.6,    # Ep (average p)\n",
    "        \n",
    "        # Simulation parameters\n",
    "        'num_sd_pairs': 10,          # nsd (concurrent requests)\n",
    "        'epoch_length': 500,         # Reconfiguration interval\n",
    "        'total_timeslots': 7000,     # T\n",
    "        \n",
    "        # QuARC-specific\n",
    "        'split_constant': 4,         # k (Girvan-Newman)\n",
    "        'enable_clustering': True,\n",
    "        'enable_secondary_fusions': True,\n",
    "        \n",
    "        # Framework mapping\n",
    "        'num_paths': 4,              # For bandit comparison\n",
    "        'total_qubits': 120,         # 12 qubits/node √ó 10 nodes (estimated)\n",
    "        'exploration_bonus': 1.5,    # Lower for clustering\n",
    "        'min_qubits_per_route': 3,   # Higher for fusion-based\n",
    "        'use_fusion_rewards': True,\n",
    "\n",
    "        'time_decay_physics': {\n",
    "            'memory_lifetime': 0.5\n",
    "        },\n",
    "\n",
    "\n",
    "        # NEW: Paper12 retry parameters\n",
    "        'retry_threshold': 0.7,\n",
    "        'max_retry_attempts': 3,\n",
    "        'retry_decay_rate': 0.95,\n",
    "        'enable_retry_logging': True,\n",
    "        'retry_cost_per_attempt': 0.1,\n",
    "    }\n",
    "}\n",
    "\n",
    "# --- Test Scenarios ---\n",
    "if FRAMEWORK_CONFIG['main_env'] == 'stochastic':\n",
    "    test_scenarios = {\n",
    "        'stochastic': 'Stochastic Random Failures',\n",
    "        'markov': 'Markov Adversarial Attack',\n",
    "        'adaptive': 'Adaptive Adversarial Attack',\n",
    "        'onlineadaptive': 'Online Adaptive Attack',\n",
    "        'none': 'Baseline (Optimal Conditions)'\n",
    "    }\n",
    "    evaluation_type = \"STOCHASTIC-FOCUSED\"\n",
    "else:\n",
    "    test_scenarios = {'stochastic': 'Stochastic (Natural Network Failures)', 'adaptive': 'Adversarial (Strategic Attacks)'}\n",
    "    evaluation_type = \"COMPARATIVE\"\n",
    "\n",
    "# --- Display Configuration ---\n",
    "print(\"=\" * 70)\n",
    "print(f\"Models to evaluate: {len(models)} total\")\n",
    "print(\"DYNAMIC ROUTING EVALUATION FRAMEWORK - CONFIGURATION\")\n",
    "print(\"\\n‚úì Configuration loaded successfully - Ready for model evaluation\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "stochastic-vs-adversarial"
   },
   "source": [
    "## Comparative Analysis Framework: Stochastic versus Adversarial Environments\n",
    "\n",
    "### Research Focus\n",
    "\n",
    "This evaluation constitutes the primary empirical contribution of the research: systematic quantification of algorithm performance across fundamentally different operational conditions that distinguish between natural system failures and intentional strategic attacks.\n",
    "\n",
    "### Environmental Characterization\n",
    "\n",
    "**Stochastic Environment**\n",
    "- **Operational Model**: Natural random failures representing realistic network degradation patterns\n",
    "- **Attack Distribution**: Probabilistic failures following uniform random distribution\n",
    "- **Research Significance**: Establishes baseline performance metrics under standard operational conditions\n",
    "\n",
    "**Adversarial Environment**  \n",
    "- **Operational Model**: Strategic intelligent attacks systematically targeting algorithmic decision-making processes\n",
    "- **Attack Distribution**: Adaptive targeting mechanisms that dynamically respond to observed algorithm behavior\n",
    "- **Research Significance**: Evaluates robustness under worst-case strategic threat scenarios\n",
    "\n",
    "### Experimental Predictions\n",
    "\n",
    "Based on the theoretical analysis and algorithm architecture, the following empirical outcomes are anticipated:\n",
    "\n",
    "**Performance Superiority Hypothesis**\n",
    "EXPNeuralUCB will demonstrate measurably superior performance retention in adversarial environments relative to baseline neural bandit algorithms lacking specialized adversarial robustness mechanisms.\n",
    "\n",
    "**Bounded Degradation Hypothesis**\n",
    "Performance degradation under adversarial conditions will remain within acceptable operational limits, specifically maintaining performance within 85% of stochastic environment baselines.\n",
    "\n",
    "**Stability Hypothesis**\n",
    "Algorithm performance rankings will exhibit stability across varying adversarial attack intensities, indicating consistent robustness characteristics rather than scenario-dependent performance fluctuations.\n",
    "\n",
    "### Research Methodology\n",
    "\n",
    "The comparative analysis employs identical experimental conditions across both environments, enabling precise quantification of performance degradation attributable to adversarial targeting while controlling for environmental variables and maintaining statistical rigor in the evaluation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PAPER 7 HELPER FUNCTIONS\n",
    "# ============================================================================\n",
    "def generate_paper7_paths(topology, k: int, n_qisps: int, seed: int):\n",
    "    \"\"\"Generate k-shortest paths between n_qisps ISP nodes.\"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    nodes = list(topology.nodes())\n",
    "\n",
    "    if len(nodes) < n_qisps: raise ValueError(f\"Topology has {len(nodes)} nodes, need {n_qisps} for ISPs\")\n",
    "    isp_nodes = rng.choice(nodes, size=n_qisps, replace=False)\n",
    "    all_paths = []\n",
    "\n",
    "    for src, dst in itertools.combinations(isp_nodes, 2):\n",
    "        try:\n",
    "            path_generator = nx.shortest_simple_paths(topology, src, dst, weight='distance')\n",
    "            paths = list(itertools.islice(path_generator, k))\n",
    "            all_paths.extend(paths)\n",
    "        except nx.NetworkXNoPath:   continue\n",
    "    return all_paths\n",
    "\n",
    "\n",
    "def generate_paper7_contexts(paths, topology):\n",
    "    \"\"\"Generate context vectors for each path (hop_count, avg_degree, path_length).\"\"\"\n",
    "    contexts = []\n",
    "    \n",
    "    for path in paths:\n",
    "        hop_count = len(path) - 1\n",
    "        degrees = [topology.degree(node) for node in path]\n",
    "        avg_degree = sum(degrees) / len(degrees) if degrees else 0.0\n",
    "\n",
    "        path_length = 0.0\n",
    "        for i in range(len(path) - 1):\n",
    "            edge_data = topology.get_edge_data(path[i], path[i+1])\n",
    "            path_length += edge_data.get('distance', 1.0)\n",
    "\n",
    "        context_vector = np.array([hop_count, avg_degree, path_length])\n",
    "        contexts.append([context_vector])\n",
    "    return contexts\n",
    "\n",
    "\n",
    "def get_physics_params_paper12(config, seed, qubit_cap):\n",
    "    \"\"\"\n",
    "    Paper #12 (Waxman + QuARC) physics adapter.\n",
    "    Returns: {external_topology, external_contexts, external_rewards, noise_model, fidelity_calculator}\n",
    "    \"\"\"\n",
    "    topology = Paper12WaxmanTopologyGenerator().generate()\n",
    "    num_paths = 4\n",
    "    nodes = list(topology.nodes())\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    # Find 4 paths\n",
    "    paths = []\n",
    "    attempts = 0\n",
    "    max_attempts = 10 * num_paths\n",
    "    \n",
    "    while len(paths) < num_paths and attempts < max_attempts:\n",
    "        attempts += 1\n",
    "        src, dst = rng.choice(nodes, 2, replace=False)\n",
    "        try:\n",
    "            path = nx.shortest_path(topology, src, dst)\n",
    "            if path not in paths:   paths.append(path)\n",
    "        except nx.NetworkXNoPath:   continue\n",
    "    if len(paths) < num_paths:  raise RuntimeError(f\"Could not find {num_paths} valid paths in Waxman topology\")\n",
    "\n",
    "    # Physics models\n",
    "    fusion_prob = float(config.get(\"fusion_prob\", 0.9))\n",
    "    entanglement_prob = float(config.get(\"entanglement_prob\", 0.6))\n",
    "    noise_model = FusionNoiseModel(topology=topology, paths=paths, fusion_prob=fusion_prob, entanglement_prob=entanglement_prob)\n",
    "    fidelity_calc = FusionFidelityCalculator()\n",
    "    reward_func = QuARCRewardFunction()\n",
    "\n",
    "    # Contexts: 4 arrays with shapes (8,3), (10,3), (8,3), (9,3)\n",
    "    external_contexts = []\n",
    "    arms_per_path = [8, 10, 8, 9]\n",
    "    degrees = dict(topology.degree())\n",
    "    max_degree = max(degrees.values()) if degrees else 1.0\n",
    "\n",
    "    for p_idx, K in enumerate(arms_per_path):\n",
    "        path = paths[p_idx]\n",
    "        hop_count = len(path) - 1\n",
    "        path_degrees = [degrees[n] for n in path]\n",
    "        avg_degree = float(sum(path_degrees) / len(path_degrees))\n",
    "        f2_deg_norm = avg_degree / max_degree if max_degree > 0 else 0.0\n",
    "        ctx = np.full((K, 3), [float(hop_count), f2_deg_norm, fusion_prob], dtype=float)\n",
    "        external_contexts.append(ctx)\n",
    "\n",
    "    # Rewards: 4 lists with lengths [8,10,8,9]\n",
    "    external_rewards = []\n",
    "    for p_idx, K in enumerate(arms_per_path):\n",
    "        path = paths[p_idx]\n",
    "        err_info = noise_model.get_error_rates(p_idx)\n",
    "        base_fidelity = fidelity_calc.compute_path_fidelity(err_info, context=None, fusion_prob=fusion_prob)\n",
    "        base_fidelity = float(np.clip(base_fidelity, 0.0, 1.0))\n",
    "\n",
    "        path_rewards = []\n",
    "        for _ in range(K):\n",
    "            success = rng.random() < base_fidelity\n",
    "            r = reward_func.compute_reward(success=success, aggregate_throughput=1)\n",
    "            path_rewards.append(float(r))\n",
    "        \n",
    "        external_rewards.append(path_rewards)\n",
    "    return {\n",
    "        \"external_topology\": topology, \"external_contexts\": external_contexts,\n",
    "        \"external_rewards\": external_rewards, \"noise_model\": noise_model, \"fidelity_calculator\": fidelity_calc,\n",
    "    }\n",
    "\n",
    "\n",
    "def get_physics_params(\n",
    "    physics_model: str = \"default\",\n",
    "    current_frames: int = 4000,\n",
    "    base_seed: int = 42,\n",
    "    qubit_cap=None,\n",
    "    *,\n",
    "    topology: \"nx.Graph | None\" = None,\n",
    "    topology_model: str | None = None,\n",
    "    topology_path: str | Path | None = None,\n",
    "    topology_max_nodes: int | None = None,\n",
    "    topology_largest_cc_only: bool = True,\n",
    "    topology_relabel_to_int: bool = True,\n",
    "    synthetic_kind: str = \"barabasi_albert\",\n",
    "    synthetic_params: dict | None = None,\n",
    "):\n",
    "    \"\"\"Returns: {noise_model, fidelity_calculator, external_topology, external_contexts, external_rewards}\"\"\"\n",
    "\n",
    "    if physics_model == \"paper7\":\n",
    "        paper7_cfg = FRAMEWORK_CONFIG['paper7']\n",
    "        node_num = paper7_cfg.get('max_nodes')\n",
    "\n",
    "        if topology is not None:    final_topology = topology\n",
    "        else:\n",
    "            if paper7_cfg.get('use_synthetic', False) or not paper7_cfg.get('topology_path'):\n",
    "                topo_gen = Paper7ASTopologyGenerator(\n",
    "                    edge_list_path=\"dummy_nonexistent.txt\",\n",
    "                    max_nodes=topology_max_nodes or node_num,\n",
    "                    seed=base_seed,\n",
    "                    synthetic_fallback=True,\n",
    "                    synthetic_kind=\"barabasi_albert\",\n",
    "                    synthetic_params={\"n\": node_num or 100, \"m\": 3}\n",
    "                )\n",
    "                print(f\"üìä Paper7 Topology: Synthetic (Barab√°si-Albert, n={node_num or 100})\")\n",
    "            else:\n",
    "                topo_gen = Paper7ASTopologyGenerator(\n",
    "                    edge_list_path=paper7_cfg['topology_path'],\n",
    "                    max_nodes=node_num,\n",
    "                    seed=base_seed,\n",
    "                    relabel_to_integers=topology_relabel_to_int,\n",
    "                    largest_cc_only=topology_largest_cc_only,\n",
    "                    synthetic_fallback=True\n",
    "                )\n",
    "                print(f\"üìä Paper7 Topology: Real AS ({paper7_cfg['topology_path']})\")\n",
    "            final_topology = topo_gen.generate()\n",
    "\n",
    "        k = paper7_cfg[\"k\"]\n",
    "        n_qisps = paper7_cfg[\"n_qisps\"]\n",
    "        paths = generate_paper7_paths(final_topology, k, n_qisps, base_seed)\n",
    "        contexts = generate_paper7_contexts(paths, final_topology)\n",
    "        print(f\"üìä Paper7 Paths: {len(paths)} paths from {k}-shortest between {n_qisps} ISPs\")\n",
    "\n",
    "        external_rewards = None\n",
    "        if paper7_cfg.get('use_context_rewards', False):\n",
    "            reward_mode = paper7_cfg.get('reward_mode', 'neg_hop')\n",
    "            reward_func = Paper7RewardFunction(mode=reward_mode)\n",
    "            external_rewards = []\n",
    "            for ctx_list in contexts:\n",
    "                path_rewards = [reward_func.compute(ctx) for ctx in ctx_list]\n",
    "                external_rewards.append(path_rewards)\n",
    "            print(f\"üìä Paper7 Rewards: Context-aware (mode={reward_mode})\")\n",
    "        else:   print(f\"üìä Paper7 Rewards: Using default framework rewards\")\n",
    "\n",
    "        return {\n",
    "            \"noise_model\": None,\n",
    "            \"fidelity_calculator\": None,\n",
    "            \"external_topology\": final_topology,\n",
    "            \"external_contexts\": contexts,\n",
    "            \"external_rewards\": external_rewards\n",
    "        }\n",
    "    \n",
    "    elif physics_model == \"paper2\":\n",
    "        p2_config = FRAMEWORK_CONFIG[\"paper2\"]\n",
    "        topo_gen = Paper2TopologyGenerator(num_nodes=p2_config[\"num_nodes\"], seed=base_seed)\n",
    "        topo = topo_gen.generate()\n",
    "        \n",
    "        try:\n",
    "            path_generator = nx.shortest_simple_paths(topo, p2_config[\"source_node\"], p2_config[\"dest_node\"], weight=\"distance\")\n",
    "            paths = list(itertools.islice(path_generator, p2_config[\"num_paths\"]))\n",
    "        except nx.NetworkXNoPath:\n",
    "            paths = [[p2_config[\"source_node\"], p2_config[\"dest_node\"]]] * p2_config[\"num_paths\"]\n",
    "        \n",
    "        # ‚úÖ Stochastic noise model\n",
    "        noise_model = StochasticPaper2NoiseModel(\n",
    "            topology=topo,\n",
    "            paths=paths,\n",
    "            p_init=p2_config.get(\"p_init\", 0.00001),\n",
    "            f_attenuation=p2_config.get(\"f_attenuation\", 0.05),\n",
    "            p_BSM=p2_config.get(\"p_BSM\", 0.2),\n",
    "            p_GateErrors=p2_config.get(\"p_GateErrors\", 0.2),\n",
    "            p_depol=p2_config.get(\"p_depol\", 0.1)\n",
    "        )\n",
    "        \n",
    "        # ‚úÖ Use ADAPTER instead of Full calculator directly\n",
    "        if p2_config.get('use_memory_decay', False):\n",
    "            memory_model = MemoryNoiseModel(\n",
    "                T2=p2_config.get(\"memory_T2\", 5000),\n",
    "                swap_delay_per_link=p2_config.get(\"swap_delay_per_link\", 100)\n",
    "            )\n",
    "            if p2_config.get(\"swap_mode\", \"sync\") == \"sync\":\n",
    "                memory_model = None  # Sync doesn't need memory tracking\n",
    "        else:\n",
    "            memory_model = None\n",
    "        \n",
    "        fidelity_calc = AdaptedPaper2FidelityCalculator(\n",
    "            noise_model=noise_model,\n",
    "            gate_error_rate=p2_config.get(\"gate_error_rate\", 0.02) if p2_config.get('use_gate_error', False) else 0.0,\n",
    "            memory_model=memory_model\n",
    "        )\n",
    "        \n",
    "        print(f\"üìä Paper2 Physics: Stochastic + {'Memory' if memory_model else 'No Memory'} mode\")\n",
    "        \n",
    "        return {\n",
    "            \"noise_model\": noise_model,\n",
    "            \"fidelity_calculator\": fidelity_calc,  # ‚úÖ Now uses adapter\n",
    "            \"external_topology\": topo,\n",
    "            \"external_contexts\": None,\n",
    "            \"external_rewards\": None\n",
    "        }\n",
    "\n",
    "\n",
    "    elif physics_model == 'paper12':\n",
    "        p12config = FRAMEWORK_CONFIG['paper12']\n",
    "\n",
    "        decaycfg = p12config['time_decay_physics']\n",
    "        memlifetime = decaycfg['memory_lifetime']\n",
    "        # Get Paper12 physics\n",
    "        physics_params = get_physics_params_paper12(FRAMEWORK_CONFIG['paper12'], seed=base_seed, qubit_cap=qubit_cap)\n",
    "        base_fidelity_calc = physics_params['fidelity_calculator']\n",
    "        topology = physics_params['external_topology']\n",
    "        contexts = physics_params['external_contexts']\n",
    "        rewards = physics_params['external_rewards']\n",
    "        noise_model = physics_params['noise_model']\n",
    "        num_paths = len(contexts)\n",
    "        print(f\"Paper12 (QuARC) physics: {num_paths} paths, fusion_prob={FRAMEWORK_CONFIG['paper12']['fusion_prob']}\")\n",
    "\n",
    "        # # NEW: Wrap with retry logic\n",
    "        # fidelitycalc = Paper12RetryFidelityCalculator(\n",
    "        #     base_calculator=base_fidelity_calc,\n",
    "        #     threshold=p12config['retry_threshold'],\n",
    "        #     max_attempts=p12config['max_retry_attempts'],\n",
    "        #     decay_rate=p12config['retry_decay_rate']\n",
    "        # )\n",
    "\n",
    "        # Wrap with retry logic\n",
    "        fidelitycalc = Paper12RetryFidelityCalculator(\n",
    "            base_calculator=base_fidelity_calc,\n",
    "            threshold=p12config['retry_threshold'],\n",
    "            max_attempts=p12config['max_retry_attempts'],\n",
    "            decay_rate=p12config['retry_decay_rate']\n",
    "        )\n",
    "        \n",
    "        # üÜï NEW: Create metadata dict\n",
    "        metadata = {\n",
    "            'paper': 'Zhang2023Paper12',\n",
    "            'retry_enabled': True,\n",
    "            'retry_threshold': p12config['retry_threshold'],\n",
    "            'max_attempts': p12config['max_retry_attempts'],\n",
    "            'decay_rate': p12config['retry_decay_rate'],\n",
    "        }\n",
    "\n",
    "        physics_params['metadata'] = metadata,  # üÜï NEW: Safe - handled by __init__\n",
    "\n",
    "        return physics_params\n",
    "    # === DEFAULT ===\n",
    "    else: return {\"noise_model\": None, \"fidelity_calculator\": None, \"external_topology\": topology, \"external_contexts\": None, \"external_rewards\": None}\n",
    "\n",
    "\n",
    "\n",
    "def force_release_resources(evaluator=None, verbose=True):\n",
    "    \"\"\"Force release of ALL resources that could block. Call AFTER each allocator completes.\"\"\"\n",
    "    cleanup_log = []\n",
    "\n",
    "    # 1. Stop logging and close file handles\n",
    "    if evaluator is not None:\n",
    "        try:\n",
    "            if hasattr(evaluator, 'configs') and hasattr(evaluator.configs, 'backup_mgr'):\n",
    "                backup_mgr = evaluator.configs.backup_mgr\n",
    "                if hasattr(backup_mgr, 'stop_logging_redirect'): backup_mgr.stop_logging_redirect()\n",
    "                if hasattr(backup_mgr, '_log_file'):\n",
    "                    try:    backup_mgr._log_file.close()\n",
    "                    except: pass\n",
    "                if hasattr(backup_mgr, 'backup_registry'):  backup_mgr.backup_registry.clear()\n",
    "            cleanup_log.append(\"‚úÖ Backup manager cleaned\")\n",
    "        except Exception as e:  cleanup_log.append(f\"‚ö†Ô∏è Backup cleanup: {e}\")\n",
    "\n",
    "    # 2. Clear environment graphs\n",
    "    if evaluator is not None:\n",
    "        try:\n",
    "            if hasattr(evaluator, 'configs') and hasattr(evaluator.configs, 'environment'):\n",
    "                env = evaluator.configs.environment\n",
    "                if hasattr(env, 'topology') and hasattr(env.topology, 'clear'):\n",
    "                    env.topology.clear()\n",
    "                    del env.topology\n",
    "                if hasattr(env, 'paths'): env.paths = []\n",
    "            cleanup_log.append(\"‚úÖ Environment graphs cleared\")\n",
    "        except Exception as e: cleanup_log.append(f\"‚ö†Ô∏è Environment cleanup: {e}\")\n",
    "\n",
    "    # 3. Break circular references\n",
    "    if evaluator is not None:\n",
    "        try:\n",
    "            if hasattr(evaluator, 'configs'):\n",
    "                if hasattr(evaluator.configs, 'backup_mgr'): evaluator.configs.backup_mgr = None\n",
    "                if hasattr(evaluator.configs, 'environment'): evaluator.configs.environment = None\n",
    "                evaluator.configs = None\n",
    "            cleanup_log.append(\"‚úÖ Circular references broken\")\n",
    "        except Exception as e:  cleanup_log.append(f\"‚ö†Ô∏è Reference cleanup: {e}\")\n",
    "\n",
    "    # 4. Clear model registries\n",
    "    try:\n",
    "        import sys\n",
    "        for mod_name in list(sys.modules.keys()):\n",
    "            if 'bandit' in mod_name.lower() or 'neural' in mod_name.lower():\n",
    "                mod = sys.modules[mod_name]\n",
    "                if hasattr(mod, '_model_registry'): mod._model_registry.clear()\n",
    "                if hasattr(mod, '_global_models'):  mod._global_models.clear()\n",
    "        cleanup_log.append(\"‚úÖ Model registries cleared\")\n",
    "    except Exception as e:  cleanup_log.append(f\"‚ö†Ô∏è Registry cleanup: {e}\")\n",
    "\n",
    "    # 5. Torch cleanup\n",
    "    try:\n",
    "        import torch\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "            torch.cuda.synchronize()\n",
    "        cleanup_log.append(\"‚úÖ Torch CUDA cleared\")\n",
    "    except Exception as e:  cleanup_log.append(f\"‚ö†Ô∏è Torch cleanup: {e}\")\n",
    "\n",
    "    # 6. Garbage collection\n",
    "    collected = [gc.collect() for _ in range(3)]\n",
    "    cleanup_log.append(f\"‚úÖ GC collected: {sum(collected)} objects\")\n",
    "\n",
    "    # 7. Close file descriptors\n",
    "    try:\n",
    "        import os\n",
    "        import psutil\n",
    "        process = psutil.Process()\n",
    "        for f in process.open_files():\n",
    "            if any(ext in f.path for ext in ['.pkl', '.log', '.csv']):\n",
    "                try:    os.close(f.fd)\n",
    "                except: pass\n",
    "        cleanup_log.append(\"‚úÖ File descriptors closed\")\n",
    "    except Exception as e:  cleanup_log.append(f\"‚ö†Ô∏è FD cleanup: {e}\")\n",
    "\n",
    "    # 8. Delete evaluator and final collection\n",
    "    if evaluator is not None:   del evaluator\n",
    "    gc.collect(2)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"üßπ FORCED RESOURCE RELEASE\")\n",
    "        print(\"=\"*70)\n",
    "        for log in cleanup_log: print(log)\n",
    "        print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================== \n",
      "PAPER #2 QUANTUM MAB MODELS EVALUATION FRAMEWORK - STOCHASTIC FOCUS\n",
      " ======================================================================\n",
      "\n",
      "====================================================================== \n",
      "üéØ QUANTUM ROUTING ALLOCATOR EVALUATION\n",
      " ======================================================================\n",
      "Total Allocators to Test:   4\n",
      "Physics Models:             ['paper2']\n",
      "Allocators:                 ['Default', 'Dynamic', 'ThompsonSampling', 'Random']\n",
      "Scales:                     [1]\n",
      "Runs:                       [5]\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "üöÄ ALLOCATOR 4: Random\n",
      "======================================================================\n",
      "\n",
      "===================== GET LOCAL REGISTRY =====================\n",
      "‚Üí Skipping local cache (force=True or file missing)\n",
      "\n",
      "===================== BUILD LOCAL REGISTRY =====================\n",
      "\n",
      "================================================================================\n",
      "üîç SCANNING LOCAL FILES\n",
      "================================================================================\n",
      "Parameters: load_to_drive=False, force=False\n",
      "\n",
      "üìÇ Checking DRIVE mode: /content/drive/Shareddrives/ai_quantum_computing/quantum_data_lake\n",
      "   ‚ö†Ô∏è  Path does not exist, skipping\n",
      "\n",
      "üìÇ Checking LOCAL mode: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config\n",
      "   ‚úÖ Path exists, starting walk...\n",
      "   üö∂ Walking directory tree: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config\n",
      "\n",
      "   üìÅ Directory: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260128\n",
      "      Relative: framework_state/day_20260128\n",
      "      Component: framework_state\n",
      "      Date: day_20260128\n",
      "      üìÑ Processing 1900 files in framework_state/day_20260128\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "      üìä framework_state/day_20260128: 1772/1900 files processed\n",
      "      üìä framework_state/day_20260128: 0/1900 files skipped\n",
      "      üìä framework_state/day_20260128: 128/1900 files conflicted\n",
      "\n",
      "   üìÅ Directory: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/model_state/day_20260128\n",
      "      Relative: model_state/day_20260128\n",
      "      Component: model_state\n",
      "      Date: day_20260128\n",
      "      üìÑ Processing 5688 files in model_state/day_20260128\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "      üìä model_state/day_20260128: 5677/5688 files processed\n",
      "      üìä model_state/day_20260128: 0/5688 files skipped\n",
      "      üìä model_state/day_20260128: 11/5688 files conflicted\n",
      "\n",
      "   üìä Processed 2 directories\n",
      "\n",
      "================================================================================\n",
      "üì¶ BUILDING FINAL REGISTRY\n",
      "================================================================================\n",
      "Components found: ['framework_state', 'model_state']\n",
      "  ‚Ä¢ framework_state: 1772 files\n",
      "  ‚Ä¢ model_state: 5677 files\n",
      "\n",
      "‚úÖ SCAN COMPLETE\n",
      "Modes scanned: 1\n",
      "Total files in registry: 7449\n",
      "================================================================================\n",
      "\n",
      "\t‚Üí Filesystem scan found 7449 files\n",
      "\n",
      "===================== GET DRIVE REGISTRY =====================\n",
      "===================== REGISTRY BUILD COMPLETE =====================\n",
      "\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "\tüì¶ LocalBackupManager Registry Saved Locally in LOCAL\n",
      "BUILDING REGISTRY WITH 0 EXPECTED COMPONENTS KEYS\n",
      "\n",
      "===================== GET LOCAL REGISTRY =====================\n",
      "‚Üí Skipping local cache (force=True or file missing)\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "\tüì¶ LocalBackupManager Registry Saved Locally in LOCAL\n",
      "\n",
      "======================================================================\n",
      "üéØ AllocatorRunner initialized: Random\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "üöÄ STARTING ALLOCATOR: Random\n",
      "======================================================================\n",
      "\n",
      "üìä Physics Model: paper2\n",
      "\n",
      "üìã Allocator Config:\n",
      "   Type: Random\n",
      "   Testbed: paper2\n",
      "   Paths: 4\n",
      "   Total Qubits: 43\n",
      "   Min per route: 2\n",
      "   Seed: 42\n",
      "   Epsilon: 1.0, Decay: 1.0\n",
      "‚úÖ Allocator created: (22, 11, 7, 3)\n",
      "‚úì Allocator: RandomQubitAllocator (4 paths)\n",
      "   Initial allocation: (11, 5, 24, 3)\n",
      "Generated paper2 topology: 15 nodes, 51 edges\n",
      "üìä Paper2 Physics: Stochastic + Memory mode\n",
      "\n",
      "======================================================================\n",
      "RUN 1 | Scale: 1 | Exp: 5\n",
      "======================================================================\n",
      "üîÑ Random Dynamic Allocation (Initial): (6, 9, 12, 16)\n",
      "Multi-Run Evaluator Initialized\n",
      "Environment Type: None\n",
      "Frame Range: 4000 -> 12000 (step: 2000)\n",
      "quantum_exps-Random(paper2)_alloc-all_envs-5_attacks-4000_2000-5_runs-S1T\n",
      "[Logging Redirect Initialized]\n",
      "Log File: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/quantum_logs/quantum_exps-Random(paper2)_alloc-all_envs-5_attacks-4000_2000-5_runs-S1T_20260128_log.txt\n",
      "‚öô Running evaluation...\n",
      "======================================================================\n",
      "SCENARIOS MODEL EVALUATION\n",
      "======================================================================\n",
      "Testing algorithm performance against:\n",
      "\t‚Ä¢ Stochastic:  \tNatural quantum decoherence and network failures\n",
      "\t‚Ä¢ Baseline:    \tOptimal conditions for validation\n",
      "======================================================================\n",
      "Models to Test:             \tOracle, GNeuralUCB, EXPNeuralUCB, CPursuitNeuralUCB, iCPursuitNeuralUCB\n",
      "Experiments per Scenario:   \t5\n",
      "======================================================================\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: STOCHASTIC RANDOM FAILURES\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: STOCHASTIC\n",
      "Category: Stochastic (Natural Random Failures)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 4000 frames  <>  SCALED-CAPACITY: 4000 frames (CAPACITY:4000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[RandomAllocator Œµ=1.000] timestep=0 mode=random ‚Üí allocation=(6, 9, 12, 16)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 1: (6, 9, 12, 16)\n",
      "üîÑ Random Dynamic Allocation (Initial): (24, 13, 4, 2)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 1: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:4000, QubitAlloc=Random, SC:4000 (Scale=1 x Cap=4000), Seed: 18243\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 1: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=11297.21, Efficiency=098.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.712]\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 5: Env:Baseline (None), Attack:No, Rate:0.0, Frames:12000, QubitAlloc=Random, SC:12000 (Scale=1 x Cap=12000), Seed: 22607\n",
      "\t-->üèÜ EXP5 Winner:iCPursuitNeuralUCB  (Gap:002.0%) [Env:Baseline (None), Attack:No X Rate:0.0, Frames:12000, SCapacity=12000, Alloc=Random]\n",
      "‚úì Experiment 5 completed successfully.\n",
      "\n",
      "======================================================================\n",
      "COMPREHENSIVE SCENARIO PERFORMANCE ANALYSIS\n",
      "======================================================================\n",
      "SCENARIO: STOCHASTIC\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 7515.58\n",
      "\t‚Ä¢ Winner Avg Gap: 0008.19%\n",
      "\t‚Ä¢ Winner Avg Reward: 6900.81\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0091.81%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 1 wins\n",
      "\t\t- EXPNeuralUCB: 1 wins\n",
      "\t\t- CPursuitNeuralUCB: 2 wins\n",
      "\t\t- iCPursuitNeuralUCB: 1 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: STOCHASTIC\n",
      "======================================================================\n",
      "SCENARIO: \tSTOCHASTIC RANDOM FAILURES\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 1/5 experiments)\n",
      "\tWinner Avg Gap: \t008.2%\n",
      "\tWinner Avg Efficiency: \t091.8%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t091.8% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t091.7% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t091.7% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t091.4% Efficiency \t(Won 1/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: MARKOV\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 6914.98\n",
      "\t‚Ä¢ Winner Avg Gap: 0041.85%\n",
      "\t‚Ä¢ Winner Avg Reward: 4026.74\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0058.15%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 1 wins\n",
      "\t\t- iCPursuitNeuralUCB: 4 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: MARKOV\n",
      "======================================================================\n",
      "SCENARIO: \tMARKOV ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 4/5 experiments)\n",
      "\tWinner Avg Gap: \t041.9%\n",
      "\tWinner Avg Efficiency: \t058.1%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t058.1% Efficiency \t(Won 4/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t057.4% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t057.4% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t052.0% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: GNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 7445.10\n",
      "\t‚Ä¢ Winner Avg Gap: 0025.80%\n",
      "\t‚Ä¢ Winner Avg Reward: 5525.77\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0074.20%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 3 wins\n",
      "\t\t- EXPNeuralUCB: 1 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 1 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tADAPTIVE ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tGNeuralUCB (Won 3/5 experiments)\n",
      "\tWinner Avg Gap: \t025.8%\n",
      "\tWinner Avg Efficiency: \t074.2%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ GNeuralUCB     : \t074.2% Efficiency \t(Won 3/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t073.9% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t073.7% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t072.8% Efficiency \t(Won 1/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ONLINEADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: EXPNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 7475.58\n",
      "\t‚Ä¢ Winner Avg Gap: 0025.86%\n",
      "\t‚Ä¢ Winner Avg Reward: 5557.23\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0074.14%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 1 wins\n",
      "\t\t- EXPNeuralUCB: 4 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 0 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ONLINEADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tONLINE ADAPTIVE ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tEXPNeuralUCB (Won 4/5 experiments)\n",
      "\tWinner Avg Gap: \t025.9%\n",
      "\tWinner Avg Efficiency: \t074.1%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t074.1% Efficiency \t(Won 4/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t073.8% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t073.4% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t073.3% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: NONE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: EXPNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 7538.55\n",
      "\t‚Ä¢ Winner Avg Gap: 0001.36%\n",
      "\t‚Ä¢ Winner Avg Reward: 7406.16\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0098.64%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 3 wins\n",
      "\t\t- CPursuitNeuralUCB: 1 wins\n",
      "\t\t- iCPursuitNeuralUCB: 1 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: NONE\n",
      "======================================================================\n",
      "SCENARIO: \tBASELINE (OPTIMAL CONDITIONS)\n",
      "----------------------------------------\n",
      "Recommended Model: \tEXPNeuralUCB (Won 3/5 experiments)\n",
      "\tWinner Avg Gap: \t001.4%\n",
      "\tWinner Avg Efficiency: \t098.6%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t098.6% Efficiency \t(Won 3/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t098.4% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t098.4% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t098.3% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "‚úÖ Evaluation completed!\n",
      "[Logging Redirect Stopped]\n",
      "\n",
      "üßπ Final cleanup for Random\n",
      "\n",
      "======================================================================\n",
      "‚úÖ COMPLETED: Random\n",
      "======================================================================\n",
      "\n",
      "‚úÖ Random COMPLETED SUCCESSFULLY\n",
      "\n",
      "======================================================================\n",
      "‚úÖ ALL ALLOCATORS COMPLETE!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Cell 2: Allocator + ExperimentConfiguration for Paper #2\n",
    "# ============================================================\n",
    "importlib.reload(qubit_allocator)\n",
    "importlib.reload(experiment_config)\n",
    "importlib.reload(multi_run_evaluator)\n",
    "\n",
    "from daqr.core.quantum_physics              import *\n",
    "from daqr.core.qubit_allocator              import (\n",
    "                                                QubitAllocator,\n",
    "                                                RandomQubitAllocator,\n",
    "                                                DynamicQubitAllocator,\n",
    "                                                ThompsonSamplingAllocator\n",
    "                                            )\n",
    "\n",
    "from daqr.evaluation.allocator_runner       import AllocatorRunner\n",
    "from daqr.evaluation.multi_run_evaluator    import MultiRunEvaluator\n",
    "from daqr.config.experiment_config          import ExperimentConfiguration\n",
    "\n",
    "\n",
    "\n",
    "print(\"=\" * 70, \"\\nPAPER #2 QUANTUM MAB MODELS EVALUATION FRAMEWORK - STOCHASTIC FOCUS\\n\", \"=\" * 70)\n",
    "# ------------------------------------------------------------\n",
    "# 1) Allocator selection (Paper #2: start with fixed baseline)\n",
    "# ------------------------------------------------------------\n",
    "# You can swap these as needed:\n",
    "# allocator = RandomQubitAllocator(epsilon=0.5, seed=42)        # 50-50 mix\n",
    "# allocator = RandomQubitAllocator(epsilon=0.1, seed=42)        # mostly baseline\n",
    "# allocator = RandomQubitAllocator(epsilon=0.0, seed=42)        # deterministic\n",
    "# allocator = DynamicQubitAllocator(seed=42)                    # dynamic UCB\n",
    "# allocator = ThompsonSamplingAllocator(seed=42)                # Thompson\n",
    "\n",
    "allocator_type =    \"Random\" # Fixed allocator via environment (Paper #2 baseline)\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2) Derive run parameters from FRAMEWORK_CONFIG (Cell 1)\n",
    "# ------------------------------------------------------------\n",
    "# current_frames      = FRAMEWORK_CONFIG['base_frames'] \n",
    "# frame_step          = FRAMEWORK_CONFIG['frame_step']\n",
    "# attack_intensity    = FRAMEWORK_CONFIG['intensity']\n",
    "# current_experiments = FRAMEWORK_CONFIG['exp_num']\n",
    "\n",
    "attack_intensity    = FRAMEWORK_CONFIG['intensity']\n",
    "current_frames      = 50\n",
    "frame_step          = 50\n",
    "current_experiments = 1\n",
    "last_backup         = True\n",
    "base_cap            = False\n",
    "overwrite           = True\n",
    "\n",
    "# PHYSICS_MODELS = ['paper2', 'default']  # Set to ['default', 'paper2'] to test both\n",
    "ATTACK_SCENARIOS = ['stochastic']  # Start simple, expand later\n",
    "PHYSICS_MODELS = ['paper2']\n",
    "# PHYSICS_MODELS = ['default']\n",
    "ALLOCATORS = ['Default', 'Dynamic', 'ThompsonSampling', 'Random']\n",
    "SCALES = [1]\n",
    "RUNS = [5]\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70, \"\\nüéØ QUANTUM ROUTING ALLOCATOR EVALUATION\\n\", \"=\" * 70)\n",
    "print(f\"Total Allocators to Test:   {len(ALLOCATORS)}\")\n",
    "print(f\"Physics Models:             {PHYSICS_MODELS}\")\n",
    "print(f\"Allocators:                 {ALLOCATORS}\")\n",
    "print(f\"Scales:                     {SCALES}\")\n",
    "print(f\"Runs:                       {RUNS}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Run each allocator in isolation\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"üöÄ ALLOCATOR {len(ALLOCATORS)}: {allocator_type}\")\n",
    "print('='*70)\n",
    "\n",
    "try:\n",
    "    # Create isolated runner instance for this allocator\n",
    "    custom_config = ExperimentConfiguration(\n",
    "        env_type=FRAMEWORK_CONFIG['main_env'], scenarios=test_scenarios, use_last_backup=last_backup,\n",
    "        models=models, attack_intensity=attack_intensity, scale=1, base_capacity=base_cap, overwrite=overwrite)\n",
    "\n",
    "    alloc_runner = AllocatorRunner(\n",
    "        allocator_type=allocator_type, physics_models=PHYSICS_MODELS, framework_config=FRAMEWORK_CONFIG, \n",
    "        scales=SCALES, runs=RUNS, models=models, test_scenarios=test_scenarios, config=custom_config)\n",
    "\n",
    "    # Run this allocator with your existing get_physics_params function\n",
    "    alloc_runner.run(get_physics_params_func=get_physics_params)\n",
    "    print(f\"\\n‚úÖ {allocator_type} COMPLETED SUCCESSFULLY\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå {allocator_type} FAILED: {e}\")\n",
    "    traceback.print_exc()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"‚úÖ ALL ALLOCATORS COMPLETE!\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "robustness-analysis",
    "outputId": "d5bf77ec-ed26-474f-b68b-650ab683fece"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================== \n",
      "PAPER #2 QUANTUM MAB MODELS EVALUATION FRAMEWORK - STOCHASTIC FOCUS\n",
      " ======================================================================\n",
      "\n",
      "====================================================================== \n",
      "üéØ QUANTUM ROUTING ALLOCATOR EVALUATION\n",
      " ======================================================================\n",
      "Total Allocators to Test:   4\n",
      "Physics Models:             ['paper2']\n",
      "Allocators:                 ['Default', 'Dynamic', 'ThompsonSampling', 'Random']\n",
      "Scales:                     [1.5]\n",
      "Runs:                       [5]\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "üöÄ ALLOCATOR 4: Random\n",
      "======================================================================\n",
      "\n",
      "===================== GET LOCAL REGISTRY =====================\n",
      "‚Üí Skipping local cache (force=True or file missing)\n",
      "\n",
      "===================== BUILD LOCAL REGISTRY =====================\n",
      "\n",
      "================================================================================\n",
      "üîç SCANNING LOCAL FILES\n",
      "================================================================================\n",
      "Parameters: load_to_drive=False, force=False\n",
      "\n",
      "üìÇ Checking DRIVE mode: /content/drive/Shareddrives/ai_quantum_computing/quantum_data_lake\n",
      "   ‚ö†Ô∏è  Path does not exist, skipping\n",
      "\n",
      "üìÇ Checking LOCAL mode: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config\n",
      "   ‚úÖ Path exists, starting walk...\n",
      "   üö∂ Walking directory tree: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config\n",
      "\n",
      "   üìÅ Directory: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260128\n",
      "      Relative: framework_state/day_20260128\n",
      "      Component: framework_state\n",
      "      Date: day_20260128\n",
      "      üìÑ Processing 1799 files in framework_state/day_20260128\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "      üìä framework_state/day_20260128: 1798/1799 files processed\n",
      "      üìä framework_state/day_20260128: 0/1799 files skipped\n",
      "      üìä framework_state/day_20260128: 1/1799 files conflicted\n",
      "\n",
      "   üìÅ Directory: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/model_state/day_20260128\n",
      "      Relative: model_state/day_20260128\n",
      "      Component: model_state\n",
      "      Date: day_20260128\n",
      "      üìÑ Processing 5803 files in model_state/day_20260128\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "      üìä model_state/day_20260128: 5802/5803 files processed\n",
      "      üìä model_state/day_20260128: 0/5803 files skipped\n",
      "      üìä model_state/day_20260128: 1/5803 files conflicted\n",
      "\n",
      "   üìä Processed 2 directories\n",
      "\n",
      "================================================================================\n",
      "üì¶ BUILDING FINAL REGISTRY\n",
      "================================================================================\n",
      "Components found: ['framework_state', 'model_state']\n",
      "  ‚Ä¢ framework_state: 1798 files\n",
      "  ‚Ä¢ model_state: 5802 files\n",
      "\n",
      "‚úÖ SCAN COMPLETE\n",
      "Modes scanned: 1\n",
      "Total files in registry: 7600\n",
      "================================================================================\n",
      "\n",
      "\t‚Üí Filesystem scan found 7600 files\n",
      "\n",
      "===================== GET DRIVE REGISTRY =====================\n",
      "===================== REGISTRY BUILD COMPLETE =====================\n",
      "\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "\tüì¶ LocalBackupManager Registry Saved Locally in LOCAL\n",
      "BUILDING REGISTRY WITH 0 EXPECTED COMPONENTS KEYS\n",
      "\n",
      "===================== GET LOCAL REGISTRY =====================\n",
      "‚Üí Skipping local cache (force=True or file missing)\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "\tüì¶ LocalBackupManager Registry Saved Locally in LOCAL\n",
      "\n",
      "======================================================================\n",
      "üéØ AllocatorRunner initialized: Random\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "üöÄ STARTING ALLOCATOR: Random\n",
      "======================================================================\n",
      "\n",
      "üìä Physics Model: paper2\n",
      "\n",
      "üìã Allocator Config:\n",
      "   Type: Random\n",
      "   Testbed: paper2\n",
      "   Paths: 4\n",
      "   Total Qubits: 43\n",
      "   Min per route: 2\n",
      "   Seed: 42\n",
      "   Epsilon: 1.0, Decay: 1.0\n",
      "‚úÖ Allocator created: (22, 11, 7, 3)\n",
      "‚úì Allocator: RandomQubitAllocator (4 paths)\n",
      "   Initial allocation: (11, 5, 24, 3)\n",
      "Generated paper2 topology: 15 nodes, 51 edges\n",
      "üìä Paper2 Physics: Stochastic + Memory mode\n",
      "\n",
      "======================================================================\n",
      "RUN 1 | Scale: 1.5 | Exp: 5\n",
      "======================================================================\n",
      "üîÑ Random Dynamic Allocation (Initial): (6, 9, 12, 16)\n",
      "Multi-Run Evaluator Initialized\n",
      "Environment Type: None\n",
      "Frame Range: 4000 -> 12000 (step: 2000)\n",
      "quantum_exps-Random(paper2)_alloc-all_envs-5_attacks-4000_2000-5_runs-S1.5T\n",
      "[Logging Redirect Initialized]\n",
      "Log File: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/quantum_logs/quantum_exps-Random(paper2)_alloc-all_envs-5_attacks-4000_2000-5_runs-S1.5T_20260128_log.txt\n",
      "‚öô Running evaluation...\n",
      "======================================================================\n",
      "SCENARIOS MODEL EVALUATION\n",
      "======================================================================\n",
      "Testing algorithm performance against:\n",
      "\t‚Ä¢ Stochastic:  \tNatural quantum decoherence and network failures\n",
      "\t‚Ä¢ Baseline:    \tOptimal conditions for validation\n",
      "======================================================================\n",
      "Models to Test:             \tOracle, GNeuralUCB, EXPNeuralUCB, CPursuitNeuralUCB, iCPursuitNeuralUCB\n",
      "Experiments per Scenario:   \t5\n",
      "======================================================================\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: STOCHASTIC RANDOM FAILURES\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: STOCHASTIC\n",
      "Category: Stochastic (Natural Random Failures)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 4000 frames  <>  SCALED-CAPACITY: 6000.0 frames (CAPACITY:4000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[RandomAllocator Œµ=1.000] timestep=0 mode=random ‚Üí allocation=(6, 9, 12, 16)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 1: (6, 9, 12, 16)\n",
      "üîÑ Random Dynamic Allocation (Initial): (24, 13, 4, 2)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 1: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:4000, QubitAlloc=Random, SC:6000 (Scale=1.5 x Cap=4000), Seed: 18243\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 1: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 GNEURALUCB          : Reward=3225.68, Efficiency=092.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 1: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=3155.06, Efficiency=090.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 1: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=3208.31, Efficiency=091.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 1: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=3225.01, Efficiency=092.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.712]\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 1: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:4000, QubitAlloc=Random, SC:6000 (Scale=1.5 x Cap=4000), Seed: 18243\n",
      "\t-->üèÜ EXP1 Winner:GNeuralUCB          (Gap:007.9%) [Env:Stochastic, Attack:Random X Rate:0.0625, Frames:4000, SCapacity=6000, Alloc=Random]\n",
      "‚úì Experiment 1 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 6000 frames  <>  SCALED-CAPACITY: 9000.0 frames (CAPACITY:6000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[RandomAllocator Œµ=1.000] timestep=1 mode=random ‚Üí allocation=(24, 13, 4, 2)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 2: (24, 13, 4, 2)\n",
      "üîÑ Random Dynamic Allocation (Initial): (7, 3, 23, 10)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 2: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:6000, QubitAlloc=Random, SC:9000 (Scale=1.5 x Cap=6000), Seed: 20638\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 2: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 GNEURALUCB          : Reward=5133.26, Efficiency=091.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=9000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 2: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=4920.50, Efficiency=087.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=9000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 2: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=5124.21, Efficiency=090.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=9000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 2: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=5123.66, Efficiency=090.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=9000, Threshold=0.712]\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 2: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:6000, QubitAlloc=Random, SC:9000 (Scale=1.5 x Cap=6000), Seed: 20638\n",
      "\t-->üèÜ EXP2 Winner:GNeuralUCB          (Gap:008.9%) [Env:Stochastic, Attack:Random X Rate:0.0625, Frames:6000, SCapacity=9000, Alloc=Random]\n",
      "‚úì Experiment 2 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 8000 frames  <>  SCALED-CAPACITY: 12000.0 frames (CAPACITY:8000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[RandomAllocator Œµ=1.000] timestep=2 mode=random ‚Üí allocation=(7, 3, 23, 10)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 3: (7, 3, 23, 10)\n",
      "üîÑ Random Dynamic Allocation (Initial): (6, 8, 22, 7)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 3: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:8000, QubitAlloc=Random, SC:12000 (Scale=1.5 x Cap=8000), Seed: 18719\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 3: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 GNEURALUCB          : Reward=6878.76, Efficiency=092.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 3: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=6770.88, Efficiency=090.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 3: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=6851.80, Efficiency=092.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 3: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=6877.71, Efficiency=092.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.712]\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 3: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:8000, QubitAlloc=Random, SC:12000 (Scale=1.5 x Cap=8000), Seed: 18719\n",
      "\t-->üèÜ EXP3 Winner:GNeuralUCB          (Gap:007.7%) [Env:Stochastic, Attack:Random X Rate:0.0625, Frames:8000, SCapacity=12000, Alloc=Random]\n",
      "‚úì Experiment 3 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 10000 frames  <>  SCALED-CAPACITY: 15000.0 frames (CAPACITY:10000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[RandomAllocator Œµ=1.000] timestep=3 mode=random ‚Üí allocation=(6, 8, 22, 7)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 4: (6, 8, 22, 7)\n",
      "üîÑ Random Dynamic Allocation (Initial): (8, 10, 8, 17)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 4: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:10000, QubitAlloc=Random, SC:15000 (Scale=1.5 x Cap=10000), Seed: 13452\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 4: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 GNEURALUCB          : Reward=8658.23, Efficiency=092.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=15000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 4: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=8550.82, Efficiency=090.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=15000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 4: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=8696.33, Efficiency=092.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=15000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 4: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=8636.25, Efficiency=091.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=15000, Threshold=0.712]\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 4: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:10000, QubitAlloc=Random, SC:15000 (Scale=1.5 x Cap=10000), Seed: 13452\n",
      "\t-->üèÜ EXP4 Winner:CPursuitNeuralUCB   (Gap:007.6%) [Env:Stochastic, Attack:Random X Rate:0.0625, Frames:10000, SCapacity=15000, Alloc=Random]\n",
      "‚úì Experiment 4 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 12000 frames  <>  SCALED-CAPACITY: 18000.0 frames (CAPACITY:12000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[RandomAllocator Œµ=1.000] timestep=4 mode=random ‚Üí allocation=(8, 10, 8, 17)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 5: (8, 10, 8, 17)\n",
      "üîÑ Random Dynamic Allocation (Initial): (4, 8, 5, 26)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 5: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:12000, QubitAlloc=Random, SC:18000 (Scale=1.5 x Cap=12000), Seed: 15134\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 5: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 GNEURALUCB          : Reward=10107.25, Efficiency=092.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=18000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 5: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=9822.33, Efficiency=089.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=18000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 5: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=10131.65, Efficiency=092.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=18000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 5: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=10111.01, Efficiency=092.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=18000, Threshold=0.712]\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 5: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:12000, QubitAlloc=Random, SC:18000 (Scale=1.5 x Cap=12000), Seed: 15134\n",
      "\t-->üèÜ EXP5 Winner:CPursuitNeuralUCB   (Gap:007.5%) [Env:Stochastic, Attack:Random X Rate:0.0625, Frames:12000, SCapacity=18000, Alloc=Random]\n",
      "‚úì Experiment 5 completed successfully.\n",
      "Total experiment time: 2625.8s\n",
      "Experiments completed for stochastic\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: MARKOV ADVERSARIAL ATTACK\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: MARKOV\n",
      "Category: Structured (Markov Chain Based)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 4000 frames  <>  SCALED-CAPACITY: 6000.0 frames (CAPACITY:4000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[RandomAllocator Œµ=1.000] timestep=0 mode=random ‚Üí allocation=(4, 8, 5, 26)\n",
      "üîß Allocated qubits for MARKOV Exp 1: (4, 8, 5, 26)\n",
      "üîÑ Random Dynamic Allocation (Initial): (10, 5, 7, 21)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 1: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:4000, QubitAlloc=Random, SC:6000 (Scale=1.5 x Cap=4000), Seed: 19209\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 1: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 GNEURALUCB          : Reward=1886.99, Efficiency=054.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=6000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 1: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=1813.27, Efficiency=052.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=6000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 1: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=1994.56, Efficiency=058.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=6000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 1: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=1943.70, Efficiency=056.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=6000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 1: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:4000, QubitAlloc=Random, SC:6000 (Scale=1.5 x Cap=4000), Seed: 19209\n",
      "\t-->üèÜ EXP1 Winner:CPursuitNeuralUCB   (Gap:042.0%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:4000, SCapacity=6000, Alloc=Random]\n",
      "‚úì Experiment 1 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 6000 frames  <>  SCALED-CAPACITY: 9000.0 frames (CAPACITY:6000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[RandomAllocator Œµ=1.000] timestep=1 mode=random ‚Üí allocation=(10, 5, 7, 21)\n",
      "üîß Allocated qubits for MARKOV Exp 2: (10, 5, 7, 21)\n",
      "üîÑ Random Dynamic Allocation (Initial): (10, 16, 14, 3)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 2: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:6000, QubitAlloc=Random, SC:9000 (Scale=1.5 x Cap=6000), Seed: 14826\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 2: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 GNEURALUCB          : Reward=3074.22, Efficiency=058.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=9000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 2: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=2697.43, Efficiency=051.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=9000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 2: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=3075.10, Efficiency=058.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=9000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 2: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=3031.04, Efficiency=058.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=9000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 2: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:6000, QubitAlloc=Random, SC:9000 (Scale=1.5 x Cap=6000), Seed: 14826\n",
      "\t-->üèÜ EXP2 Winner:CPursuitNeuralUCB   (Gap:041.2%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:6000, SCapacity=9000, Alloc=Random]\n",
      "‚úì Experiment 2 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 8000 frames  <>  SCALED-CAPACITY: 12000.0 frames (CAPACITY:8000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[RandomAllocator Œµ=1.000] timestep=2 mode=random ‚Üí allocation=(10, 16, 14, 3)\n",
      "üîß Allocated qubits for MARKOV Exp 3: (10, 16, 14, 3)\n",
      "üîÑ Random Dynamic Allocation (Initial): (23, 3, 10, 7)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 3: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:8000, QubitAlloc=Random, SC:12000 (Scale=1.5 x Cap=8000), Seed: 17110\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 3: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 GNEURALUCB          : Reward=3882.19, Efficiency=056.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=12000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 3: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=3578.11, Efficiency=052.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=12000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 3: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=3846.51, Efficiency=056.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=12000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 3: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=3943.42, Efficiency=057.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=12000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 3: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:8000, QubitAlloc=Random, SC:12000 (Scale=1.5 x Cap=8000), Seed: 17110\n",
      "\t-->üèÜ EXP3 Winner:iCPursuitNeuralUCB  (Gap:042.6%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:8000, SCapacity=12000, Alloc=Random]\n",
      "‚úì Experiment 3 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 10000 frames  <>  SCALED-CAPACITY: 15000.0 frames (CAPACITY:10000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[RandomAllocator Œµ=1.000] timestep=3 mode=random ‚Üí allocation=(23, 3, 10, 7)\n",
      "üîß Allocated qubits for MARKOV Exp 4: (23, 3, 10, 7)\n",
      "üîÑ Random Dynamic Allocation (Initial): (26, 5, 8, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 4: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:10000, QubitAlloc=Random, SC:15000 (Scale=1.5 x Cap=10000), Seed: 16366\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 4: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 GNEURALUCB          : Reward=4890.36, Efficiency=057.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=15000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 4: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=4267.47, Efficiency=049.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=15000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 4: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=4904.66, Efficiency=057.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=15000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 4: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=5002.73, Efficiency=058.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=15000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 4: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:10000, QubitAlloc=Random, SC:15000 (Scale=1.5 x Cap=10000), Seed: 16366\n",
      "\t-->üèÜ EXP4 Winner:iCPursuitNeuralUCB  (Gap:041.5%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:10000, SCapacity=15000, Alloc=Random]\n",
      "‚úì Experiment 4 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 12000 frames  <>  SCALED-CAPACITY: 18000.0 frames (CAPACITY:12000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[RandomAllocator Œµ=1.000] timestep=4 mode=random ‚Üí allocation=(26, 5, 8, 4)\n",
      "üîß Allocated qubits for MARKOV Exp 5: (26, 5, 8, 4)\n",
      "üîÑ Random Dynamic Allocation (Initial): (11, 14, 15, 3)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 5: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:12000, QubitAlloc=Random, SC:18000 (Scale=1.5 x Cap=12000), Seed: 18969\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 5: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 GNEURALUCB          : Reward=5964.91, Efficiency=056.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=18000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 5: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=5597.21, Efficiency=053.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=18000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 5: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=5980.58, Efficiency=057.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=18000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 5: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=6166.92, Efficiency=058.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=18000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 5: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:12000, QubitAlloc=Random, SC:18000 (Scale=1.5 x Cap=12000), Seed: 18969\n",
      "\t-->üèÜ EXP5 Winner:iCPursuitNeuralUCB  (Gap:041.2%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:12000, SCapacity=18000, Alloc=Random]\n",
      "‚úì Experiment 5 completed successfully.\n",
      "Total experiment time: 4185.5s\n",
      "Experiments completed for markov\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: ADAPTIVE ADVERSARIAL ATTACK\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: ADAPTIVE\n",
      "Category: Adaptive (Reactive Strategic)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 4000 frames  <>  SCALED-CAPACITY: 6000.0 frames (CAPACITY:4000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[RandomAllocator Œµ=1.000] timestep=0 mode=random ‚Üí allocation=(11, 14, 15, 3)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 1: (11, 14, 15, 3)\n",
      "üîÑ Random Dynamic Allocation (Initial): (6, 2, 15, 20)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 1: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:4000, QubitAlloc=Random, SC:6000 (Scale=1.5 x Cap=4000), Seed: 20787\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 1: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 GNEURALUCB          : Reward=2814.60, Efficiency=074.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 1: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=2804.08, Efficiency=073.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 1: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=2773.70, Efficiency=073.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 1: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=2818.11, Efficiency=074.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 1: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:4000, QubitAlloc=Random, SC:6000 (Scale=1.5 x Cap=4000), Seed: 20787\n",
      "\t-->üèÜ EXP1 Winner:iCPursuitNeuralUCB  (Gap:025.7%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:4000, SCapacity=6000, Alloc=Random]\n",
      "‚úì Experiment 1 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 6000 frames  <>  SCALED-CAPACITY: 9000.0 frames (CAPACITY:6000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[RandomAllocator Œµ=1.000] timestep=1 mode=random ‚Üí allocation=(6, 2, 15, 20)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 2: (6, 2, 15, 20)\n",
      "üîÑ Random Dynamic Allocation (Initial): (5, 3, 19, 16)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 2: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:6000, QubitAlloc=Random, SC:9000 (Scale=1.5 x Cap=6000), Seed: 16496\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 2: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 GNEURALUCB          : Reward=4086.46, Efficiency=073.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=9000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 2: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=3967.81, Efficiency=071.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=9000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 2: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=4070.43, Efficiency=073.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=9000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 2: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=4070.25, Efficiency=073.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=9000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 2: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:6000, QubitAlloc=Random, SC:9000 (Scale=1.5 x Cap=6000), Seed: 16496\n",
      "\t-->üèÜ EXP2 Winner:GNeuralUCB          (Gap:026.2%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:6000, SCapacity=9000, Alloc=Random]\n",
      "‚úì Experiment 2 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 8000 frames  <>  SCALED-CAPACITY: 12000.0 frames (CAPACITY:8000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[RandomAllocator Œµ=1.000] timestep=2 mode=random ‚Üí allocation=(5, 3, 19, 16)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 3: (5, 3, 19, 16)\n",
      "üîÑ Random Dynamic Allocation (Initial): (5, 5, 13, 20)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 3: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:8000, QubitAlloc=Random, SC:12000 (Scale=1.5 x Cap=8000), Seed: 21414\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 3: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 GNEURALUCB          : Reward=5421.38, Efficiency=074.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 3: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=5524.15, Efficiency=075.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 3: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=5401.57, Efficiency=074.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 3: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=5426.28, Efficiency=074.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 3: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:8000, QubitAlloc=Random, SC:12000 (Scale=1.5 x Cap=8000), Seed: 21414\n",
      "\t-->üèÜ EXP3 Winner:EXPNeuralUCB        (Gap:024.1%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:8000, SCapacity=12000, Alloc=Random]\n",
      "‚úì Experiment 3 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 10000 frames  <>  SCALED-CAPACITY: 15000.0 frames (CAPACITY:10000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[RandomAllocator Œµ=1.000] timestep=3 mode=random ‚Üí allocation=(5, 5, 13, 20)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 4: (5, 5, 13, 20)\n",
      "üîÑ Random Dynamic Allocation (Initial): (21, 2, 4, 16)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 4: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:10000, QubitAlloc=Random, SC:15000 (Scale=1.5 x Cap=10000), Seed: 20112\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 4: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 GNEURALUCB          : Reward=6999.14, Efficiency=074.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=15000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 4: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=6700.10, Efficiency=071.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=15000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 4: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=6905.83, Efficiency=073.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=15000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 4: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=6924.05, Efficiency=073.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=15000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 4: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:10000, QubitAlloc=Random, SC:15000 (Scale=1.5 x Cap=10000), Seed: 20112\n",
      "\t-->üèÜ EXP4 Winner:GNeuralUCB          (Gap:025.9%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:10000, SCapacity=15000, Alloc=Random]\n",
      "‚úì Experiment 4 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 12000 frames  <>  SCALED-CAPACITY: 18000.0 frames (CAPACITY:12000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[RandomAllocator Œµ=1.000] timestep=4 mode=random ‚Üí allocation=(21, 2, 4, 16)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 5: (21, 2, 4, 16)\n",
      "üîÑ Random Dynamic Allocation (Initial): (20, 4, 11, 8)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 5: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:12000, QubitAlloc=Random, SC:18000 (Scale=1.5 x Cap=12000), Seed: 22168\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 5: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 GNEURALUCB          : Reward=8307.27, Efficiency=074.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=18000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 5: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=7984.19, Efficiency=071.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=18000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 5: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=8298.90, Efficiency=074.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=18000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 5: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=8264.95, Efficiency=073.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=18000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 5: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:12000, QubitAlloc=Random, SC:18000 (Scale=1.5 x Cap=12000), Seed: 22168\n",
      "\t-->üèÜ EXP5 Winner:GNeuralUCB          (Gap:025.7%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:12000, SCapacity=18000, Alloc=Random]\n",
      "‚úì Experiment 5 completed successfully.\n",
      "Total experiment time: 3852.7s\n",
      "Experiments completed for adaptive\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: ONLINE ADAPTIVE ATTACK\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: ONLINEADAPTIVE\n",
      "Category: Online Adaptive (Real-time Strategic)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 4000 frames  <>  SCALED-CAPACITY: 6000.0 frames (CAPACITY:4000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[RandomAllocator Œµ=1.000] timestep=0 mode=random ‚Üí allocation=(20, 4, 11, 8)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 1: (20, 4, 11, 8)\n",
      "üîÑ Random Dynamic Allocation (Initial): (4, 10, 12, 17)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:4000, QubitAlloc=Random, SC:6000 (Scale=1.5 x Cap=4000), Seed: 13976\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 GNEURALUCB          : Reward=2759.73, Efficiency=072.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=2781.23, Efficiency=073.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=2726.51, Efficiency=071.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=2764.71, Efficiency=072.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:4000, QubitAlloc=Random, SC:6000 (Scale=1.5 x Cap=4000), Seed: 13976\n",
      "\t-->üèÜ EXP1 Winner:EXPNeuralUCB        (Gap:026.6%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:4000, SCapacity=6000, Alloc=Random]\n",
      "‚úì Experiment 1 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 6000 frames  <>  SCALED-CAPACITY: 9000.0 frames (CAPACITY:6000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[RandomAllocator Œµ=1.000] timestep=1 mode=random ‚Üí allocation=(4, 10, 12, 17)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 2: (4, 10, 12, 17)\n",
      "üîÑ Random Dynamic Allocation (Initial): (8, 29, 2, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:6000, QubitAlloc=Random, SC:9000 (Scale=1.5 x Cap=6000), Seed: 18299\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 GNEURALUCB          : Reward=4111.21, Efficiency=073.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=9000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=4152.24, Efficiency=074.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=9000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=4069.97, Efficiency=073.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=9000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=4077.82, Efficiency=073.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=9000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:6000, QubitAlloc=Random, SC:9000 (Scale=1.5 x Cap=6000), Seed: 18299\n",
      "\t-->üèÜ EXP2 Winner:EXPNeuralUCB        (Gap:025.4%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:6000, SCapacity=9000, Alloc=Random]\n",
      "‚úì Experiment 2 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 8000 frames  <>  SCALED-CAPACITY: 12000.0 frames (CAPACITY:8000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[RandomAllocator Œµ=1.000] timestep=2 mode=random ‚Üí allocation=(8, 29, 2, 4)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 3: (8, 29, 2, 4)\n",
      "üîÑ Random Dynamic Allocation (Initial): (19, 9, 7, 8)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:8000, QubitAlloc=Random, SC:12000 (Scale=1.5 x Cap=8000), Seed: 19608\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 GNEURALUCB          : Reward=5528.81, Efficiency=073.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=5425.17, Efficiency=072.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=5517.50, Efficiency=073.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=5484.07, Efficiency=073.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:8000, QubitAlloc=Random, SC:12000 (Scale=1.5 x Cap=8000), Seed: 19608\n",
      "\t-->üèÜ EXP3 Winner:GNeuralUCB          (Gap:026.4%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:8000, SCapacity=12000, Alloc=Random]\n",
      "‚úì Experiment 3 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 10000 frames  <>  SCALED-CAPACITY: 15000.0 frames (CAPACITY:10000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[RandomAllocator Œµ=1.000] timestep=3 mode=random ‚Üí allocation=(19, 9, 7, 8)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 4: (19, 9, 7, 8)\n",
      "üîÑ Random Dynamic Allocation (Initial): (5, 2, 29, 7)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:10000, QubitAlloc=Random, SC:15000 (Scale=1.5 x Cap=10000), Seed: 18171\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 GNEURALUCB          : Reward=6821.10, Efficiency=074.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=15000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=6918.93, Efficiency=075.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=15000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=6803.78, Efficiency=074.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=15000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=6809.43, Efficiency=074.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=15000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:10000, QubitAlloc=Random, SC:15000 (Scale=1.5 x Cap=10000), Seed: 18171\n",
      "\t-->üèÜ EXP4 Winner:EXPNeuralUCB        (Gap:024.6%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:10000, SCapacity=15000, Alloc=Random]\n",
      "‚úì Experiment 4 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 12000 frames  <>  SCALED-CAPACITY: 18000.0 frames (CAPACITY:12000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[RandomAllocator Œµ=1.000] timestep=4 mode=random ‚Üí allocation=(5, 2, 29, 7)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 5: (5, 2, 29, 7)\n",
      "üîÑ Random Dynamic Allocation (Initial): (16, 7, 18, 2)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:12000, QubitAlloc=Random, SC:18000 (Scale=1.5 x Cap=12000), Seed: 14096\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 GNEURALUCB          : Reward=8407.94, Efficiency=074.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=18000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=8508.57, Efficiency=075.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=18000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=8402.57, Efficiency=074.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=18000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=8295.33, Efficiency=073.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=18000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:12000, QubitAlloc=Random, SC:18000 (Scale=1.5 x Cap=12000), Seed: 14096\n",
      "\t-->üèÜ EXP5 Winner:EXPNeuralUCB        (Gap:025.0%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:12000, SCapacity=18000, Alloc=Random]\n",
      "‚úì Experiment 5 completed successfully.\n",
      "Total experiment time: 2103.7s\n",
      "Experiments completed for onlineadaptive\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: BASELINE (OPTIMAL CONDITIONS)\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: NONE\n",
      "Category: Baseline (No Attacks)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 4000 frames  <>  SCALED-CAPACITY: 6000.0 frames (CAPACITY:4000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[RandomAllocator Œµ=1.000] timestep=0 mode=random ‚Üí allocation=(16, 7, 18, 2)\n",
      "üîß Allocated qubits for NONE Exp 1: (16, 7, 18, 2)\n",
      "üîÑ Random Dynamic Allocation (Initial): (2, 13, 13, 15)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 1: Env:Baseline (None), Attack:No, Rate:0.0, Frames:4000, QubitAlloc=Random, SC:6000 (Scale=1.5 x Cap=4000), Seed: 15576\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 1: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 GNEURALUCB          : Reward=3617.81, Efficiency=099.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 1: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=3643.50, Efficiency=099.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 1: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=3622.01, Efficiency=099.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 1: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=3620.82, Efficiency=099.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.712]\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 1: Env:Baseline (None), Attack:No, Rate:0.0, Frames:4000, QubitAlloc=Random, SC:6000 (Scale=1.5 x Cap=4000), Seed: 15576\n",
      "\t-->üèÜ EXP1 Winner:EXPNeuralUCB        (Gap:000.3%) [Env:Baseline (None), Attack:No X Rate:0.0, Frames:4000, SCapacity=6000, Alloc=Random]\n",
      "‚úì Experiment 1 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 6000 frames  <>  SCALED-CAPACITY: 9000.0 frames (CAPACITY:6000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[RandomAllocator Œµ=1.000] timestep=1 mode=random ‚Üí allocation=(2, 13, 13, 15)\n",
      "üîß Allocated qubits for NONE Exp 2: (2, 13, 13, 15)\n",
      "üîÑ Random Dynamic Allocation (Initial): (3, 12, 24, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 2: Env:Baseline (None), Attack:No, Rate:0.0, Frames:6000, QubitAlloc=Random, SC:9000 (Scale=1.5 x Cap=6000), Seed: 14771\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 2: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 GNEURALUCB          : Reward=5325.78, Efficiency=099.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=9000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 2: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=5314.97, Efficiency=099.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=9000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 2: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=5326.67, Efficiency=099.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=9000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 2: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=5323.64, Efficiency=099.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=9000, Threshold=0.712]\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 2: Env:Baseline (None), Attack:No, Rate:0.0, Frames:6000, QubitAlloc=Random, SC:9000 (Scale=1.5 x Cap=6000), Seed: 14771\n",
      "\t-->üèÜ EXP2 Winner:CPursuitNeuralUCB   (Gap:000.8%) [Env:Baseline (None), Attack:No X Rate:0.0, Frames:6000, SCapacity=9000, Alloc=Random]\n",
      "‚úì Experiment 2 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 8000 frames  <>  SCALED-CAPACITY: 12000.0 frames (CAPACITY:8000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[RandomAllocator Œµ=1.000] timestep=2 mode=random ‚Üí allocation=(3, 12, 24, 4)\n",
      "üîß Allocated qubits for NONE Exp 3: (3, 12, 24, 4)\n",
      "üîÑ Random Dynamic Allocation (Initial): (9, 19, 2, 13)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 3: Env:Baseline (None), Attack:No, Rate:0.0, Frames:8000, QubitAlloc=Random, SC:12000 (Scale=1.5 x Cap=8000), Seed: 16172\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 3: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 GNEURALUCB          : Reward=7395.05, Efficiency=098.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 3: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=7517.56, Efficiency=099.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 3: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=7425.90, Efficiency=098.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 3: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=7415.80, Efficiency=098.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.712]\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 3: Env:Baseline (None), Attack:No, Rate:0.0, Frames:8000, QubitAlloc=Random, SC:12000 (Scale=1.5 x Cap=8000), Seed: 16172\n",
      "\t-->üèÜ EXP3 Winner:EXPNeuralUCB        (Gap:000.2%) [Env:Baseline (None), Attack:No X Rate:0.0, Frames:8000, SCapacity=12000, Alloc=Random]\n",
      "‚úì Experiment 3 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 10000 frames  <>  SCALED-CAPACITY: 15000.0 frames (CAPACITY:10000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[RandomAllocator Œµ=1.000] timestep=3 mode=random ‚Üí allocation=(9, 19, 2, 13)\n",
      "üîß Allocated qubits for NONE Exp 4: (9, 19, 2, 13)\n",
      "üîÑ Random Dynamic Allocation (Initial): (14, 16, 5, 8)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 4: Env:Baseline (None), Attack:No, Rate:0.0, Frames:10000, QubitAlloc=Random, SC:15000 (Scale=1.5 x Cap=10000), Seed: 16282\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 4: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 GNEURALUCB          : Reward=9358.39, Efficiency=097.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=15000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 4: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=9456.94, Efficiency=098.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=15000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 4: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=9358.25, Efficiency=097.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=15000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 4: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=9365.39, Efficiency=097.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=15000, Threshold=0.712]\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 4: Env:Baseline (None), Attack:No, Rate:0.0, Frames:10000, QubitAlloc=Random, SC:15000 (Scale=1.5 x Cap=10000), Seed: 16282\n",
      "\t-->üèÜ EXP4 Winner:EXPNeuralUCB        (Gap:001.6%) [Env:Baseline (None), Attack:No X Rate:0.0, Frames:10000, SCapacity=15000, Alloc=Random]\n",
      "‚úì Experiment 4 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 12000 frames  <>  SCALED-CAPACITY: 18000.0 frames (CAPACITY:12000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[RandomAllocator Œµ=1.000] timestep=4 mode=random ‚Üí allocation=(14, 16, 5, 8)\n",
      "üîß Allocated qubits for NONE Exp 5: (14, 16, 5, 8)\n",
      "üîÑ Random Dynamic Allocation (Initial): (7, 4, 30, 2)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 5: Env:Baseline (None), Attack:No, Rate:0.0, Frames:12000, QubitAlloc=Random, SC:18000 (Scale=1.5 x Cap=12000), Seed: 22607\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 5: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 GNEURALUCB          : Reward=11282.57, Efficiency=097.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=18000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 5: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=11097.83, Efficiency=096.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=18000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 5: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=11271.47, Efficiency=097.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=18000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 5: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=11297.21, Efficiency=098.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=18000, Threshold=0.712]\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 5: Env:Baseline (None), Attack:No, Rate:0.0, Frames:12000, QubitAlloc=Random, SC:18000 (Scale=1.5 x Cap=12000), Seed: 22607\n",
      "\t-->üèÜ EXP5 Winner:iCPursuitNeuralUCB  (Gap:002.0%) [Env:Baseline (None), Attack:No X Rate:0.0, Frames:12000, SCapacity=18000, Alloc=Random]\n",
      "‚úì Experiment 5 completed successfully.\n",
      "Total experiment time: 3465.9s\n",
      "Experiments completed for none\n",
      "‚úì Scenario 'stochastic' evaluation completed.\n",
      "‚úì Scenario 'markov' evaluation completed.\n",
      "‚úì Scenario 'adaptive' evaluation completed.\n",
      "‚úì Scenario 'onlineadaptive' evaluation completed.\n",
      "‚úì Scenario 'none' evaluation completed.\n",
      "\n",
      "======================================================================\n",
      "COMPREHENSIVE SCENARIO PERFORMANCE ANALYSIS\n",
      "======================================================================\n",
      "SCENARIO: STOCHASTIC\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: GNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 7391.93\n",
      "\t‚Ä¢ Winner Avg Gap: 0008.06%\n",
      "\t‚Ä¢ Winner Avg Reward: 6800.64\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0091.94%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 3 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 2 wins\n",
      "\t\t- iCPursuitNeuralUCB: 0 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: STOCHASTIC\n",
      "======================================================================\n",
      "SCENARIO: \tSTOCHASTIC RANDOM FAILURES\n",
      "----------------------------------------\n",
      "Recommended Model: \tGNeuralUCB (Won 3/5 experiments)\n",
      "\tWinner Avg Gap: \t008.1%\n",
      "\tWinner Avg Efficiency: \t091.9%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ GNeuralUCB     : \t091.9% Efficiency \t(Won 3/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t091.9% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t091.9% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t089.7% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: MARKOV\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 6918.24\n",
      "\t‚Ä¢ Winner Avg Gap: 0042.18%\n",
      "\t‚Ä¢ Winner Avg Reward: 4017.56\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0057.82%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 2 wins\n",
      "\t\t- iCPursuitNeuralUCB: 3 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: MARKOV\n",
      "======================================================================\n",
      "SCENARIO: \tMARKOV ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 3/5 experiments)\n",
      "\tWinner Avg Gap: \t042.2%\n",
      "\tWinner Avg Efficiency: \t057.8%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t057.8% Efficiency \t(Won 3/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t057.4% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t056.8% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t051.9% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: GNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 7445.10\n",
      "\t‚Ä¢ Winner Avg Gap: 0025.80%\n",
      "\t‚Ä¢ Winner Avg Reward: 5525.77\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0074.20%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 3 wins\n",
      "\t\t- EXPNeuralUCB: 1 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 1 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tADAPTIVE ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tGNeuralUCB (Won 3/5 experiments)\n",
      "\tWinner Avg Gap: \t025.8%\n",
      "\tWinner Avg Efficiency: \t074.2%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ GNeuralUCB     : \t074.2% Efficiency \t(Won 3/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t073.9% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t073.7% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t072.8% Efficiency \t(Won 1/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ONLINEADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: EXPNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 7475.58\n",
      "\t‚Ä¢ Winner Avg Gap: 0025.86%\n",
      "\t‚Ä¢ Winner Avg Reward: 5557.23\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0074.14%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 1 wins\n",
      "\t\t- EXPNeuralUCB: 4 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 0 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ONLINEADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tONLINE ADAPTIVE ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tEXPNeuralUCB (Won 4/5 experiments)\n",
      "\tWinner Avg Gap: \t025.9%\n",
      "\tWinner Avg Efficiency: \t074.1%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t074.1% Efficiency \t(Won 4/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t073.8% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t073.4% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t073.3% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: NONE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: EXPNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 7538.55\n",
      "\t‚Ä¢ Winner Avg Gap: 0001.36%\n",
      "\t‚Ä¢ Winner Avg Reward: 7406.16\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0098.64%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 3 wins\n",
      "\t\t- CPursuitNeuralUCB: 1 wins\n",
      "\t\t- iCPursuitNeuralUCB: 1 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: NONE\n",
      "======================================================================\n",
      "SCENARIO: \tBASELINE (OPTIMAL CONDITIONS)\n",
      "----------------------------------------\n",
      "Recommended Model: \tEXPNeuralUCB (Won 3/5 experiments)\n",
      "\tWinner Avg Gap: \t001.4%\n",
      "\tWinner Avg Efficiency: \t098.6%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t098.6% Efficiency \t(Won 3/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t098.4% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t098.4% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t098.3% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "KEY INSIGHTS:\n",
      "Best Performing Model Analysis (GNeuralUCB):\n",
      "\t‚Ä¢ Stochastic Performance:    \t6800.636\n",
      "\t‚Ä¢ Baseline Performance:      \t7406.158\n",
      "\t‚Ä¢ Performance Retention:     \t091.8%\n",
      "\tGOOD:               \tAcceptable performance under stochastic conditions\n",
      "Statistical Analysis:\n",
      "\t‚Ä¢ Total models evaluated:     \t5\n",
      "\t‚Ä¢ Experiments per environment:\t5\n",
      "\t‚Ä¢ Quantum network simulation: \tComprehensive stochastic modeling\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "COMPREHENSIVE SCENARIO PERFORMANCE ANALYSIS\n",
      "======================================================================\n",
      "SCENARIO: STOCHASTIC\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: GNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 7391.93\n",
      "\t‚Ä¢ Winner Avg Gap: 0008.06%\n",
      "\t‚Ä¢ Winner Avg Reward: 6800.64\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0091.94%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 3 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 2 wins\n",
      "\t\t- iCPursuitNeuralUCB: 0 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: STOCHASTIC\n",
      "======================================================================\n",
      "SCENARIO: \tSTOCHASTIC RANDOM FAILURES\n",
      "----------------------------------------\n",
      "Recommended Model: \tGNeuralUCB (Won 3/5 experiments)\n",
      "\tWinner Avg Gap: \t008.1%\n",
      "\tWinner Avg Efficiency: \t091.9%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ GNeuralUCB     : \t091.9% Efficiency \t(Won 3/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t091.9% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t091.9% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t089.7% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: MARKOV\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 6918.24\n",
      "\t‚Ä¢ Winner Avg Gap: 0042.18%\n",
      "\t‚Ä¢ Winner Avg Reward: 4017.56\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0057.82%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 2 wins\n",
      "\t\t- iCPursuitNeuralUCB: 3 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: MARKOV\n",
      "======================================================================\n",
      "SCENARIO: \tMARKOV ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 3/5 experiments)\n",
      "\tWinner Avg Gap: \t042.2%\n",
      "\tWinner Avg Efficiency: \t057.8%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t057.8% Efficiency \t(Won 3/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t057.4% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t056.8% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t051.9% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: GNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 7445.10\n",
      "\t‚Ä¢ Winner Avg Gap: 0025.80%\n",
      "\t‚Ä¢ Winner Avg Reward: 5525.77\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0074.20%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 3 wins\n",
      "\t\t- EXPNeuralUCB: 1 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 1 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tADAPTIVE ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tGNeuralUCB (Won 3/5 experiments)\n",
      "\tWinner Avg Gap: \t025.8%\n",
      "\tWinner Avg Efficiency: \t074.2%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ GNeuralUCB     : \t074.2% Efficiency \t(Won 3/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t073.9% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t073.7% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t072.8% Efficiency \t(Won 1/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ONLINEADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: EXPNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 7475.58\n",
      "\t‚Ä¢ Winner Avg Gap: 0025.86%\n",
      "\t‚Ä¢ Winner Avg Reward: 5557.23\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0074.14%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 1 wins\n",
      "\t\t- EXPNeuralUCB: 4 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 0 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ONLINEADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tONLINE ADAPTIVE ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tEXPNeuralUCB (Won 4/5 experiments)\n",
      "\tWinner Avg Gap: \t025.9%\n",
      "\tWinner Avg Efficiency: \t074.1%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t074.1% Efficiency \t(Won 4/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t073.8% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t073.4% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t073.3% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: NONE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: EXPNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 7538.55\n",
      "\t‚Ä¢ Winner Avg Gap: 0001.36%\n",
      "\t‚Ä¢ Winner Avg Reward: 7406.16\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0098.64%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 3 wins\n",
      "\t\t- CPursuitNeuralUCB: 1 wins\n",
      "\t\t- iCPursuitNeuralUCB: 1 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: NONE\n",
      "======================================================================\n",
      "SCENARIO: \tBASELINE (OPTIMAL CONDITIONS)\n",
      "----------------------------------------\n",
      "Recommended Model: \tEXPNeuralUCB (Won 3/5 experiments)\n",
      "\tWinner Avg Gap: \t001.4%\n",
      "\tWinner Avg Efficiency: \t098.6%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t098.6% Efficiency \t(Won 3/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t098.4% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t098.4% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t098.3% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "‚úÖ Evaluation completed!\n",
      "[Logging Redirect Stopped]\n",
      "\n",
      "üßπ Final cleanup for Random\n",
      "\n",
      "======================================================================\n",
      "‚úÖ COMPLETED: Random\n",
      "======================================================================\n",
      "\n",
      "‚úÖ Random COMPLETED SUCCESSFULLY\n",
      "\n",
      "======================================================================\n",
      "‚úÖ ALL ALLOCATORS COMPLETE!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Cell 2: Allocator + ExperimentConfiguration for Paper #2\n",
    "# ============================================================\n",
    "importlib.reload(qubit_allocator)\n",
    "importlib.reload(experiment_config)\n",
    "importlib.reload(multi_run_evaluator)\n",
    "\n",
    "from daqr.core.quantum_physics              import *\n",
    "from daqr.core.qubit_allocator              import (\n",
    "                                                QubitAllocator,\n",
    "                                                RandomQubitAllocator,\n",
    "                                                DynamicQubitAllocator,\n",
    "                                                ThompsonSamplingAllocator\n",
    "                                            )\n",
    "\n",
    "from daqr.evaluation.allocator_runner       import AllocatorRunner\n",
    "from daqr.evaluation.multi_run_evaluator    import MultiRunEvaluator\n",
    "from daqr.config.experiment_config          import ExperimentConfiguration\n",
    "\n",
    "\n",
    "\n",
    "print(\"=\" * 70, \"\\nPAPER #2 QUANTUM MAB MODELS EVALUATION FRAMEWORK - STOCHASTIC FOCUS\\n\", \"=\" * 70)\n",
    "# ------------------------------------------------------------\n",
    "# 1) Allocator selection (Paper #2: start with fixed baseline)\n",
    "# ------------------------------------------------------------\n",
    "# You can swap these as needed:\n",
    "# allocator = RandomQubitAllocator(epsilon=0.5, seed=42)        # 50-50 mix\n",
    "# allocator = RandomQubitAllocator(epsilon=0.1, seed=42)        # mostly baseline\n",
    "# allocator = RandomQubitAllocator(epsilon=0.0, seed=42)        # deterministic\n",
    "# allocator = DynamicQubitAllocator(seed=42)                    # dynamic UCB\n",
    "# allocator = ThompsonSamplingAllocator(seed=42)                # Thompson\n",
    "\n",
    "allocator_type =    \"Random\" # Fixed allocator via environment (Paper #2 baseline)\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2) Derive run parameters from FRAMEWORK_CONFIG (Cell 1)\n",
    "# ------------------------------------------------------------\n",
    "# current_frames      = FRAMEWORK_CONFIG['base_frames'] \n",
    "# frame_step          = FRAMEWORK_CONFIG['frame_step']\n",
    "# attack_intensity    = FRAMEWORK_CONFIG['intensity']\n",
    "# current_experiments = FRAMEWORK_CONFIG['exp_num']\n",
    "\n",
    "attack_intensity    = FRAMEWORK_CONFIG['intensity']\n",
    "current_frames      = 50\n",
    "frame_step          = 50\n",
    "current_experiments = 1\n",
    "last_backup         = True\n",
    "base_cap            = False\n",
    "overwrite           = True\n",
    "\n",
    "# PHYSICS_MODELS = ['paper2', 'default']  # Set to ['default', 'paper2'] to test both\n",
    "ATTACK_SCENARIOS = ['stochastic']  # Start simple, expand later\n",
    "PHYSICS_MODELS = ['paper2']\n",
    "# PHYSICS_MODELS = ['default']\n",
    "ALLOCATORS = ['Default', 'Dynamic', 'ThompsonSampling', 'Random']\n",
    "SCALES = [1.5]\n",
    "RUNS = [5]\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70, \"\\nüéØ QUANTUM ROUTING ALLOCATOR EVALUATION\\n\", \"=\" * 70)\n",
    "print(f\"Total Allocators to Test:   {len(ALLOCATORS)}\")\n",
    "print(f\"Physics Models:             {PHYSICS_MODELS}\")\n",
    "print(f\"Allocators:                 {ALLOCATORS}\")\n",
    "print(f\"Scales:                     {SCALES}\")\n",
    "print(f\"Runs:                       {RUNS}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Run each allocator in isolation\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"üöÄ ALLOCATOR {len(ALLOCATORS)}: {allocator_type}\")\n",
    "print('='*70)\n",
    "\n",
    "try:\n",
    "    # Create isolated runner instance for this allocator\n",
    "    custom_config = ExperimentConfiguration(\n",
    "        env_type=FRAMEWORK_CONFIG['main_env'], scenarios=test_scenarios, use_last_backup=last_backup,\n",
    "        models=models, attack_intensity=attack_intensity, scale=1.5, base_capacity=base_cap, overwrite=overwrite)\n",
    "\n",
    "    alloc_runner = AllocatorRunner(\n",
    "        allocator_type=allocator_type, physics_models=PHYSICS_MODELS, framework_config=FRAMEWORK_CONFIG, \n",
    "        scales=SCALES, runs=RUNS, models=models, test_scenarios=test_scenarios, config=custom_config)\n",
    "\n",
    "    # Run this allocator with your existing get_physics_params function\n",
    "    alloc_runner.run(get_physics_params_func=get_physics_params)\n",
    "    print(f\"\\n‚úÖ {allocator_type} COMPLETED SUCCESSFULLY\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå {allocator_type} FAILED: {e}\")\n",
    "    traceback.print_exc()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"‚úÖ ALL ALLOCATORS COMPLETE!\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================== \n",
      "PAPER #2 QUANTUM MAB MODELS EVALUATION FRAMEWORK - STOCHASTIC FOCUS\n",
      " ======================================================================\n",
      "\n",
      "====================================================================== \n",
      "üéØ QUANTUM ROUTING ALLOCATOR EVALUATION\n",
      " ======================================================================\n",
      "Total Allocators to Test:   4\n",
      "Physics Models:             ['paper2']\n",
      "Allocators:                 ['Default', 'Dynamic', 'ThompsonSampling', 'Random']\n",
      "Scales:                     [2]\n",
      "Runs:                       [5]\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "üöÄ ALLOCATOR 4: Random\n",
      "======================================================================\n",
      "\n",
      "===================== GET LOCAL REGISTRY =====================\n",
      "‚Üí Skipping local cache (force=True or file missing)\n",
      "\n",
      "===================== BUILD LOCAL REGISTRY =====================\n",
      "\n",
      "================================================================================\n",
      "üîç SCANNING LOCAL FILES\n",
      "================================================================================\n",
      "Parameters: load_to_drive=False, force=False\n",
      "\n",
      "üìÇ Checking DRIVE mode: /content/drive/Shareddrives/ai_quantum_computing/quantum_data_lake\n",
      "   ‚ö†Ô∏è  Path does not exist, skipping\n",
      "\n",
      "üìÇ Checking LOCAL mode: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config\n",
      "   ‚úÖ Path exists, starting walk...\n",
      "   üö∂ Walking directory tree: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config\n",
      "\n",
      "   üìÅ Directory: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260128\n",
      "      Relative: framework_state/day_20260128\n",
      "      Component: framework_state\n",
      "      Date: day_20260128\n",
      "      üìÑ Processing 1825 files in framework_state/day_20260128\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "      üìä framework_state/day_20260128: 1824/1825 files processed\n",
      "      üìä framework_state/day_20260128: 0/1825 files skipped\n",
      "      üìä framework_state/day_20260128: 1/1825 files conflicted\n",
      "\n",
      "   üìÅ Directory: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260129\n",
      "      Relative: framework_state/day_20260129\n",
      "      Component: framework_state\n",
      "      Date: day_20260129\n",
      "      üìÑ Processing 2 files in framework_state/day_20260129\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "      üìä framework_state/day_20260129: 2/2 files processed\n",
      "      üìä framework_state/day_20260129: 0/2 files skipped\n",
      "      üìä framework_state/day_20260129: 0/2 files conflicted\n",
      "\n",
      "   üìÅ Directory: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/model_state/day_20260128\n",
      "      Relative: model_state/day_20260128\n",
      "      Component: model_state\n",
      "      Date: day_20260128\n",
      "      üìÑ Processing 5929 files in model_state/day_20260128\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "      üìä model_state/day_20260128: 5928/5929 files processed\n",
      "      üìä model_state/day_20260128: 0/5929 files skipped\n",
      "      üìä model_state/day_20260128: 1/5929 files conflicted\n",
      "\n",
      "   üìÅ Directory: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/model_state/day_20260129\n",
      "      Relative: model_state/day_20260129\n",
      "      Component: model_state\n",
      "      Date: day_20260129\n",
      "      üìÑ Processing 10 files in model_state/day_20260129\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "      üìä model_state/day_20260129: 10/10 files processed\n",
      "      üìä model_state/day_20260129: 0/10 files skipped\n",
      "      üìä model_state/day_20260129: 0/10 files conflicted\n",
      "\n",
      "   üìä Processed 4 directories\n",
      "\n",
      "================================================================================\n",
      "üì¶ BUILDING FINAL REGISTRY\n",
      "================================================================================\n",
      "Components found: ['framework_state', 'model_state']\n",
      "  ‚Ä¢ framework_state: 1826 files\n",
      "  ‚Ä¢ model_state: 5938 files\n",
      "\n",
      "‚úÖ SCAN COMPLETE\n",
      "Modes scanned: 1\n",
      "Total files in registry: 7764\n",
      "================================================================================\n",
      "\n",
      "\t‚Üí Filesystem scan found 7764 files\n",
      "\n",
      "===================== GET DRIVE REGISTRY =====================\n",
      "===================== REGISTRY BUILD COMPLETE =====================\n",
      "\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "\tüì¶ LocalBackupManager Registry Saved Locally in LOCAL\n",
      "BUILDING REGISTRY WITH 0 EXPECTED COMPONENTS KEYS\n",
      "\n",
      "===================== GET LOCAL REGISTRY =====================\n",
      "‚Üí Skipping local cache (force=True or file missing)\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "\tüì¶ LocalBackupManager Registry Saved Locally in LOCAL\n",
      "\n",
      "======================================================================\n",
      "üéØ AllocatorRunner initialized: Random\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "üöÄ STARTING ALLOCATOR: Random\n",
      "======================================================================\n",
      "\n",
      "üìä Physics Model: paper2\n",
      "\n",
      "üìã Allocator Config:\n",
      "   Type: Random\n",
      "   Testbed: paper2\n",
      "   Paths: 4\n",
      "   Total Qubits: 43\n",
      "   Min per route: 2\n",
      "   Seed: 42\n",
      "   Epsilon: 1.0, Decay: 1.0\n",
      "‚úÖ Allocator created: (22, 11, 7, 3)\n",
      "‚úì Allocator: RandomQubitAllocator (4 paths)\n",
      "   Initial allocation: (11, 5, 24, 3)\n",
      "Generated paper2 topology: 15 nodes, 51 edges\n",
      "üìä Paper2 Physics: Stochastic + Memory mode\n",
      "\n",
      "======================================================================\n",
      "RUN 1 | Scale: 2 | Exp: 5\n",
      "======================================================================\n",
      "üîÑ Random Dynamic Allocation (Initial): (6, 9, 12, 16)\n",
      "Multi-Run Evaluator Initialized\n",
      "Environment Type: None\n",
      "Frame Range: 4000 -> 12000 (step: 2000)\n",
      "quantum_exps-Random(paper2)_alloc-all_envs-5_attacks-4000_2000-5_runs-S2T\n",
      "[Logging Redirect Initialized]\n",
      "Log File: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/quantum_logs/quantum_exps-Random(paper2)_alloc-all_envs-5_attacks-4000_2000-5_runs-S2T_20260129_log.txt\n",
      "‚öô Running evaluation...\n",
      "======================================================================\n",
      "SCENARIOS MODEL EVALUATION\n",
      "======================================================================\n",
      "Testing algorithm performance against:\n",
      "\t‚Ä¢ Stochastic:  \tNatural quantum decoherence and network failures\n",
      "\t‚Ä¢ Baseline:    \tOptimal conditions for validation\n",
      "======================================================================\n",
      "Models to Test:             \tOracle, GNeuralUCB, EXPNeuralUCB, CPursuitNeuralUCB, iCPursuitNeuralUCB\n",
      "Experiments per Scenario:   \t5\n",
      "======================================================================\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: STOCHASTIC RANDOM FAILURES\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: STOCHASTIC\n",
      "Category: Stochastic (Natural Random Failures)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 4000 frames  <>  SCALED-CAPACITY: 8000 frames (CAPACITY:4000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[RandomAllocator Œµ=1.000] timestep=0 mode=random ‚Üí allocation=(6, 9, 12, 16)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 1: (6, 9, 12, 16)\n",
      "üîÑ Random Dynamic Allocation (Initial): (24, 13, 4, 2)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 1: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:4000, QubitAlloc=Random, SC:8000 (Scale=2 x Cap=4000), Seed: 18243\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 1: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 GNEURALUCB          : Reward=3335.16, Efficiency=091.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 1: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=3325.55, Efficiency=091.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 1: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=3358.05, Efficiency=092.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 1: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=3353.06, Efficiency=091.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.712]\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 1: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:4000, QubitAlloc=Random, SC:8000 (Scale=2 x Cap=4000), Seed: 18243\n",
      "\t-->üèÜ EXP1 Winner:CPursuitNeuralUCB   (Gap:008.0%) [Env:Stochastic, Attack:Random X Rate:0.0625, Frames:4000, SCapacity=8000, Alloc=Random]\n",
      "‚úì Experiment 1 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 6000 frames  <>  SCALED-CAPACITY: 12000 frames (CAPACITY:6000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[RandomAllocator Œµ=1.000] timestep=1 mode=random ‚Üí allocation=(24, 13, 4, 2)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 2: (24, 13, 4, 2)\n",
      "üîÑ Random Dynamic Allocation (Initial): (7, 3, 23, 10)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 2: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:6000, QubitAlloc=Random, SC:12000 (Scale=2 x Cap=6000), Seed: 20638\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 2: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 GNEURALUCB          : Reward=5229.65, Efficiency=090.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 2: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=5112.17, Efficiency=088.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 2: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=5265.92, Efficiency=091.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 2: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=5265.32, Efficiency=091.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.712]\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 2: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:6000, QubitAlloc=Random, SC:12000 (Scale=2 x Cap=6000), Seed: 20638\n",
      "\t-->üèÜ EXP2 Winner:CPursuitNeuralUCB   (Gap:008.5%) [Env:Stochastic, Attack:Random X Rate:0.0625, Frames:6000, SCapacity=12000, Alloc=Random]\n",
      "‚úì Experiment 2 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 8000 frames  <>  SCALED-CAPACITY: 16000 frames (CAPACITY:8000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[RandomAllocator Œµ=1.000] timestep=2 mode=random ‚Üí allocation=(7, 3, 23, 10)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 3: (7, 3, 23, 10)\n",
      "üîÑ Random Dynamic Allocation (Initial): (6, 8, 22, 7)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 3: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:8000, QubitAlloc=Random, SC:16000 (Scale=2 x Cap=8000), Seed: 18719\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 3: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 GNEURALUCB          : Reward=6958.88, Efficiency=092.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=16000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 3: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=6694.64, Efficiency=088.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=16000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 3: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=6951.13, Efficiency=092.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=16000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 3: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=6948.98, Efficiency=092.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=16000, Threshold=0.712]\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 3: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:8000, QubitAlloc=Random, SC:16000 (Scale=2 x Cap=8000), Seed: 18719\n",
      "\t-->üèÜ EXP3 Winner:GNeuralUCB          (Gap:007.6%) [Env:Stochastic, Attack:Random X Rate:0.0625, Frames:8000, SCapacity=16000, Alloc=Random]\n",
      "‚úì Experiment 3 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 10000 frames  <>  SCALED-CAPACITY: 20000 frames (CAPACITY:10000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[RandomAllocator Œµ=1.000] timestep=3 mode=random ‚Üí allocation=(6, 8, 22, 7)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 4: (6, 8, 22, 7)\n",
      "üîÑ Random Dynamic Allocation (Initial): (8, 10, 8, 17)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 4: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:10000, QubitAlloc=Random, SC:20000 (Scale=2 x Cap=10000), Seed: 13452\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 4: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 GNEURALUCB          : Reward=8529.88, Efficiency=091.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=20000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 4: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=8420.61, Efficiency=090.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=20000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 4: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=8514.49, Efficiency=091.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=20000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 4: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=8521.25, Efficiency=091.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=20000, Threshold=0.712]\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 4: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:10000, QubitAlloc=Random, SC:20000 (Scale=2 x Cap=10000), Seed: 13452\n",
      "\t-->üèÜ EXP4 Winner:GNeuralUCB          (Gap:008.3%) [Env:Stochastic, Attack:Random X Rate:0.0625, Frames:10000, SCapacity=20000, Alloc=Random]\n",
      "‚úì Experiment 4 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 12000 frames  <>  SCALED-CAPACITY: 24000 frames (CAPACITY:12000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[RandomAllocator Œµ=1.000] timestep=4 mode=random ‚Üí allocation=(8, 10, 8, 17)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 5: (8, 10, 8, 17)\n",
      "üîÑ Random Dynamic Allocation (Initial): (4, 8, 5, 26)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 5: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:12000, QubitAlloc=Random, SC:24000 (Scale=2 x Cap=12000), Seed: 15134\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 5: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 GNEURALUCB          : Reward=10114.76, Efficiency=092.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=24000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 5: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=9993.96, Efficiency=091.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=24000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 5: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=10085.88, Efficiency=092.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=24000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 5: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=10103.92, Efficiency=092.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=24000, Threshold=0.712]\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 5: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:12000, QubitAlloc=Random, SC:24000 (Scale=2 x Cap=12000), Seed: 15134\n",
      "\t-->üèÜ EXP5 Winner:GNeuralUCB          (Gap:007.7%) [Env:Stochastic, Attack:Random X Rate:0.0625, Frames:12000, SCapacity=24000, Alloc=Random]\n",
      "‚úì Experiment 5 completed successfully.\n",
      "Total experiment time: 2447.2s\n",
      "Experiments completed for stochastic\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: MARKOV ADVERSARIAL ATTACK\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: MARKOV\n",
      "Category: Structured (Markov Chain Based)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 4000 frames  <>  SCALED-CAPACITY: 8000 frames (CAPACITY:4000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[RandomAllocator Œµ=1.000] timestep=0 mode=random ‚Üí allocation=(4, 8, 5, 26)\n",
      "üîß Allocated qubits for MARKOV Exp 1: (4, 8, 5, 26)\n",
      "üîÑ Random Dynamic Allocation (Initial): (10, 5, 7, 21)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 1: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:4000, QubitAlloc=Random, SC:8000 (Scale=2 x Cap=4000), Seed: 19209\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 1: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 GNEURALUCB          : Reward=1984.02, Efficiency=056.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=8000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 1: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=1817.75, Efficiency=052.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=8000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 1: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=1961.20, Efficiency=056.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=8000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 1: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=2045.22, Efficiency=058.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=8000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 1: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:4000, QubitAlloc=Random, SC:8000 (Scale=2 x Cap=4000), Seed: 19209\n",
      "\t-->üèÜ EXP1 Winner:iCPursuitNeuralUCB  (Gap:041.5%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:4000, SCapacity=8000, Alloc=Random]\n",
      "‚úì Experiment 1 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 6000 frames  <>  SCALED-CAPACITY: 12000 frames (CAPACITY:6000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[RandomAllocator Œµ=1.000] timestep=1 mode=random ‚Üí allocation=(10, 5, 7, 21)\n",
      "üîß Allocated qubits for MARKOV Exp 2: (10, 5, 7, 21)\n",
      "üîÑ Random Dynamic Allocation (Initial): (10, 16, 14, 3)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 2: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:6000, QubitAlloc=Random, SC:12000 (Scale=2 x Cap=6000), Seed: 14826\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 2: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 GNEURALUCB          : Reward=3074.22, Efficiency=058.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 2: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=2697.43, Efficiency=051.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=12000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 2: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=3075.10, Efficiency=058.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=12000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 2: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=3031.04, Efficiency=058.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=12000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 2: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:6000, QubitAlloc=Random, SC:12000 (Scale=2 x Cap=6000), Seed: 14826\n",
      "\t-->üèÜ EXP2 Winner:CPursuitNeuralUCB   (Gap:041.2%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:6000, SCapacity=12000, Alloc=Random]\n",
      "‚úì Experiment 2 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 8000 frames  <>  SCALED-CAPACITY: 16000 frames (CAPACITY:8000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[RandomAllocator Œµ=1.000] timestep=2 mode=random ‚Üí allocation=(10, 16, 14, 3)\n",
      "üîß Allocated qubits for MARKOV Exp 3: (10, 16, 14, 3)\n",
      "üîÑ Random Dynamic Allocation (Initial): (23, 3, 10, 7)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 3: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:8000, QubitAlloc=Random, SC:16000 (Scale=2 x Cap=8000), Seed: 17110\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 3: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 GNEURALUCB          : Reward=3882.19, Efficiency=056.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=16000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 3: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=3578.11, Efficiency=052.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=16000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 3: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=3846.51, Efficiency=056.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=16000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 3: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=3943.42, Efficiency=057.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=16000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 3: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:8000, QubitAlloc=Random, SC:16000 (Scale=2 x Cap=8000), Seed: 17110\n",
      "\t-->üèÜ EXP3 Winner:iCPursuitNeuralUCB  (Gap:042.6%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:8000, SCapacity=16000, Alloc=Random]\n",
      "‚úì Experiment 3 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 10000 frames  <>  SCALED-CAPACITY: 20000 frames (CAPACITY:10000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[RandomAllocator Œµ=1.000] timestep=3 mode=random ‚Üí allocation=(23, 3, 10, 7)\n",
      "üîß Allocated qubits for MARKOV Exp 4: (23, 3, 10, 7)\n",
      "üîÑ Random Dynamic Allocation (Initial): (26, 5, 8, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 4: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:10000, QubitAlloc=Random, SC:20000 (Scale=2 x Cap=10000), Seed: 16366\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 4: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 GNEURALUCB          : Reward=4890.36, Efficiency=057.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=20000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 4: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=4267.47, Efficiency=049.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=20000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 4: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=4904.66, Efficiency=057.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=20000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 4: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=5002.73, Efficiency=058.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=20000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 4: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:10000, QubitAlloc=Random, SC:20000 (Scale=2 x Cap=10000), Seed: 16366\n",
      "\t-->üèÜ EXP4 Winner:iCPursuitNeuralUCB  (Gap:041.5%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:10000, SCapacity=20000, Alloc=Random]\n",
      "‚úì Experiment 4 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 12000 frames  <>  SCALED-CAPACITY: 24000 frames (CAPACITY:12000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[RandomAllocator Œµ=1.000] timestep=4 mode=random ‚Üí allocation=(26, 5, 8, 4)\n",
      "üîß Allocated qubits for MARKOV Exp 5: (26, 5, 8, 4)\n",
      "üîÑ Random Dynamic Allocation (Initial): (11, 14, 15, 3)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 5: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:12000, QubitAlloc=Random, SC:24000 (Scale=2 x Cap=12000), Seed: 18969\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 5: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 GNEURALUCB          : Reward=5964.91, Efficiency=056.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=24000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 5: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=5597.21, Efficiency=053.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=24000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 5: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=5980.58, Efficiency=057.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=24000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 5: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=6166.92, Efficiency=058.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=24000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 5: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:12000, QubitAlloc=Random, SC:24000 (Scale=2 x Cap=12000), Seed: 18969\n",
      "\t-->üèÜ EXP5 Winner:iCPursuitNeuralUCB  (Gap:041.2%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:12000, SCapacity=24000, Alloc=Random]\n",
      "‚úì Experiment 5 completed successfully.\n",
      "Total experiment time: 3126.1s\n",
      "Experiments completed for markov\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: ADAPTIVE ADVERSARIAL ATTACK\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: ADAPTIVE\n",
      "Category: Adaptive (Reactive Strategic)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 4000 frames  <>  SCALED-CAPACITY: 8000 frames (CAPACITY:4000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[RandomAllocator Œµ=1.000] timestep=0 mode=random ‚Üí allocation=(11, 14, 15, 3)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 1: (11, 14, 15, 3)\n",
      "üîÑ Random Dynamic Allocation (Initial): (6, 2, 15, 20)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 1: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:4000, QubitAlloc=Random, SC:8000 (Scale=2 x Cap=4000), Seed: 20787\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 1: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 GNEURALUCB          : Reward=2814.60, Efficiency=074.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 1: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=2804.08, Efficiency=073.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 1: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=2773.70, Efficiency=073.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 1: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=2818.11, Efficiency=074.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 1: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:4000, QubitAlloc=Random, SC:8000 (Scale=2 x Cap=4000), Seed: 20787\n",
      "\t-->üèÜ EXP1 Winner:iCPursuitNeuralUCB  (Gap:025.7%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:4000, SCapacity=8000, Alloc=Random]\n",
      "‚úì Experiment 1 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 6000 frames  <>  SCALED-CAPACITY: 12000 frames (CAPACITY:6000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[RandomAllocator Œµ=1.000] timestep=1 mode=random ‚Üí allocation=(6, 2, 15, 20)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 2: (6, 2, 15, 20)\n",
      "üîÑ Random Dynamic Allocation (Initial): (5, 3, 19, 16)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 2: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:6000, QubitAlloc=Random, SC:12000 (Scale=2 x Cap=6000), Seed: 16496\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 2: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 GNEURALUCB          : Reward=4086.46, Efficiency=073.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 2: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=3967.81, Efficiency=071.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 2: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=4070.43, Efficiency=073.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 2: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=4070.25, Efficiency=073.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 2: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:6000, QubitAlloc=Random, SC:12000 (Scale=2 x Cap=6000), Seed: 16496\n",
      "\t-->üèÜ EXP2 Winner:GNeuralUCB          (Gap:026.2%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:6000, SCapacity=12000, Alloc=Random]\n",
      "‚úì Experiment 2 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 8000 frames  <>  SCALED-CAPACITY: 16000 frames (CAPACITY:8000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[RandomAllocator Œµ=1.000] timestep=2 mode=random ‚Üí allocation=(5, 3, 19, 16)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 3: (5, 3, 19, 16)\n",
      "üîÑ Random Dynamic Allocation (Initial): (5, 5, 13, 20)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 3: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:8000, QubitAlloc=Random, SC:16000 (Scale=2 x Cap=8000), Seed: 21414\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 3: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 GNEURALUCB          : Reward=5421.38, Efficiency=074.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=16000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 3: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=5524.15, Efficiency=075.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=16000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 3: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=5401.57, Efficiency=074.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=16000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 3: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=5426.28, Efficiency=074.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=16000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 3: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:8000, QubitAlloc=Random, SC:16000 (Scale=2 x Cap=8000), Seed: 21414\n",
      "\t-->üèÜ EXP3 Winner:EXPNeuralUCB        (Gap:024.1%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:8000, SCapacity=16000, Alloc=Random]\n",
      "‚úì Experiment 3 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 10000 frames  <>  SCALED-CAPACITY: 20000 frames (CAPACITY:10000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[RandomAllocator Œµ=1.000] timestep=3 mode=random ‚Üí allocation=(5, 5, 13, 20)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 4: (5, 5, 13, 20)\n",
      "üîÑ Random Dynamic Allocation (Initial): (21, 2, 4, 16)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 4: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:10000, QubitAlloc=Random, SC:20000 (Scale=2 x Cap=10000), Seed: 20112\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 4: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 GNEURALUCB          : Reward=6999.14, Efficiency=074.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=20000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 4: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=6700.10, Efficiency=071.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=20000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 4: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=6905.83, Efficiency=073.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=20000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 4: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=6924.05, Efficiency=073.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=20000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 4: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:10000, QubitAlloc=Random, SC:20000 (Scale=2 x Cap=10000), Seed: 20112\n",
      "\t-->üèÜ EXP4 Winner:GNeuralUCB          (Gap:025.9%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:10000, SCapacity=20000, Alloc=Random]\n",
      "‚úì Experiment 4 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 12000 frames  <>  SCALED-CAPACITY: 24000 frames (CAPACITY:12000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[RandomAllocator Œµ=1.000] timestep=4 mode=random ‚Üí allocation=(21, 2, 4, 16)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 5: (21, 2, 4, 16)\n",
      "üîÑ Random Dynamic Allocation (Initial): (20, 4, 11, 8)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 5: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:12000, QubitAlloc=Random, SC:24000 (Scale=2 x Cap=12000), Seed: 22168\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 5: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 GNEURALUCB          : Reward=8307.27, Efficiency=074.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=24000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 5: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=7984.19, Efficiency=071.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=24000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 5: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=8298.90, Efficiency=074.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=24000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 5: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=8264.95, Efficiency=073.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=24000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 5: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:12000, QubitAlloc=Random, SC:24000 (Scale=2 x Cap=12000), Seed: 22168\n",
      "\t-->üèÜ EXP5 Winner:GNeuralUCB          (Gap:025.7%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:12000, SCapacity=24000, Alloc=Random]\n",
      "‚úì Experiment 5 completed successfully.\n",
      "Total experiment time: 2902.0s\n",
      "Experiments completed for adaptive\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: ONLINE ADAPTIVE ATTACK\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: ONLINEADAPTIVE\n",
      "Category: Online Adaptive (Real-time Strategic)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 4000 frames  <>  SCALED-CAPACITY: 8000 frames (CAPACITY:4000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[RandomAllocator Œµ=1.000] timestep=0 mode=random ‚Üí allocation=(20, 4, 11, 8)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 1: (20, 4, 11, 8)\n",
      "üîÑ Random Dynamic Allocation (Initial): (4, 10, 12, 17)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:4000, QubitAlloc=Random, SC:8000 (Scale=2 x Cap=4000), Seed: 13976\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 GNEURALUCB          : Reward=2759.73, Efficiency=072.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=2781.23, Efficiency=073.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=2726.51, Efficiency=071.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=2764.71, Efficiency=072.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:4000, QubitAlloc=Random, SC:8000 (Scale=2 x Cap=4000), Seed: 13976\n",
      "\t-->üèÜ EXP1 Winner:EXPNeuralUCB        (Gap:026.6%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:4000, SCapacity=8000, Alloc=Random]\n",
      "‚úì Experiment 1 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 6000 frames  <>  SCALED-CAPACITY: 12000 frames (CAPACITY:6000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[RandomAllocator Œµ=1.000] timestep=1 mode=random ‚Üí allocation=(4, 10, 12, 17)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 2: (4, 10, 12, 17)\n",
      "üîÑ Random Dynamic Allocation (Initial): (8, 29, 2, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:6000, QubitAlloc=Random, SC:12000 (Scale=2 x Cap=6000), Seed: 18299\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 GNEURALUCB          : Reward=4111.21, Efficiency=073.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=4152.24, Efficiency=074.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=4069.97, Efficiency=073.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=4077.82, Efficiency=073.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:6000, QubitAlloc=Random, SC:12000 (Scale=2 x Cap=6000), Seed: 18299\n",
      "\t-->üèÜ EXP2 Winner:EXPNeuralUCB        (Gap:025.4%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:6000, SCapacity=12000, Alloc=Random]\n",
      "‚úì Experiment 2 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 8000 frames  <>  SCALED-CAPACITY: 16000 frames (CAPACITY:8000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[RandomAllocator Œµ=1.000] timestep=2 mode=random ‚Üí allocation=(8, 29, 2, 4)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 3: (8, 29, 2, 4)\n",
      "üîÑ Random Dynamic Allocation (Initial): (19, 9, 7, 8)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:8000, QubitAlloc=Random, SC:16000 (Scale=2 x Cap=8000), Seed: 19608\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 GNEURALUCB          : Reward=5528.81, Efficiency=073.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=16000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=5425.17, Efficiency=072.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=16000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=5517.50, Efficiency=073.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=16000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=5484.07, Efficiency=073.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=16000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:8000, QubitAlloc=Random, SC:16000 (Scale=2 x Cap=8000), Seed: 19608\n",
      "\t-->üèÜ EXP3 Winner:GNeuralUCB          (Gap:026.4%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:8000, SCapacity=16000, Alloc=Random]\n",
      "‚úì Experiment 3 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 10000 frames  <>  SCALED-CAPACITY: 20000 frames (CAPACITY:10000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[RandomAllocator Œµ=1.000] timestep=3 mode=random ‚Üí allocation=(19, 9, 7, 8)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 4: (19, 9, 7, 8)\n",
      "üîÑ Random Dynamic Allocation (Initial): (5, 2, 29, 7)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:10000, QubitAlloc=Random, SC:20000 (Scale=2 x Cap=10000), Seed: 18171\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 GNEURALUCB          : Reward=6821.10, Efficiency=074.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=20000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=6918.93, Efficiency=075.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=20000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=6803.78, Efficiency=074.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=20000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=6809.43, Efficiency=074.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=20000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:10000, QubitAlloc=Random, SC:20000 (Scale=2 x Cap=10000), Seed: 18171\n",
      "\t-->üèÜ EXP4 Winner:EXPNeuralUCB        (Gap:024.6%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:10000, SCapacity=20000, Alloc=Random]\n",
      "‚úì Experiment 4 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 12000 frames  <>  SCALED-CAPACITY: 24000 frames (CAPACITY:12000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[RandomAllocator Œµ=1.000] timestep=4 mode=random ‚Üí allocation=(5, 2, 29, 7)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 5: (5, 2, 29, 7)\n",
      "üîÑ Random Dynamic Allocation (Initial): (16, 7, 18, 2)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:12000, QubitAlloc=Random, SC:24000 (Scale=2 x Cap=12000), Seed: 14096\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 GNEURALUCB          : Reward=8407.94, Efficiency=074.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=24000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=8508.57, Efficiency=075.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=24000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=8402.57, Efficiency=074.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=24000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=8295.33, Efficiency=073.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=24000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:12000, QubitAlloc=Random, SC:24000 (Scale=2 x Cap=12000), Seed: 14096\n",
      "\t-->üèÜ EXP5 Winner:EXPNeuralUCB        (Gap:025.0%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:12000, SCapacity=24000, Alloc=Random]\n",
      "‚úì Experiment 5 completed successfully.\n",
      "Total experiment time: 1944.9s\n",
      "Experiments completed for onlineadaptive\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: BASELINE (OPTIMAL CONDITIONS)\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: NONE\n",
      "Category: Baseline (No Attacks)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 4000 frames  <>  SCALED-CAPACITY: 8000 frames (CAPACITY:4000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[RandomAllocator Œµ=1.000] timestep=0 mode=random ‚Üí allocation=(16, 7, 18, 2)\n",
      "üîß Allocated qubits for NONE Exp 1: (16, 7, 18, 2)\n",
      "üîÑ Random Dynamic Allocation (Initial): (2, 13, 13, 15)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 1: Env:Baseline (None), Attack:No, Rate:0.0, Frames:4000, QubitAlloc=Random, SC:8000 (Scale=2 x Cap=4000), Seed: 15576\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 1: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 GNEURALUCB          : Reward=3617.81, Efficiency=099.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 1: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=3643.50, Efficiency=099.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 1: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=3622.01, Efficiency=099.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 1: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=3620.82, Efficiency=099.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.712]\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 1: Env:Baseline (None), Attack:No, Rate:0.0, Frames:4000, QubitAlloc=Random, SC:8000 (Scale=2 x Cap=4000), Seed: 15576\n",
      "\t-->üèÜ EXP1 Winner:EXPNeuralUCB        (Gap:000.3%) [Env:Baseline (None), Attack:No X Rate:0.0, Frames:4000, SCapacity=8000, Alloc=Random]\n",
      "‚úì Experiment 1 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 6000 frames  <>  SCALED-CAPACITY: 12000 frames (CAPACITY:6000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[RandomAllocator Œµ=1.000] timestep=1 mode=random ‚Üí allocation=(2, 13, 13, 15)\n",
      "üîß Allocated qubits for NONE Exp 2: (2, 13, 13, 15)\n",
      "üîÑ Random Dynamic Allocation (Initial): (3, 12, 24, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 2: Env:Baseline (None), Attack:No, Rate:0.0, Frames:6000, QubitAlloc=Random, SC:12000 (Scale=2 x Cap=6000), Seed: 14771\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 2: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 GNEURALUCB          : Reward=5325.78, Efficiency=099.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 2: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=5314.97, Efficiency=099.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 2: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=5326.67, Efficiency=099.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 2: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=5323.64, Efficiency=099.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.712]\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 2: Env:Baseline (None), Attack:No, Rate:0.0, Frames:6000, QubitAlloc=Random, SC:12000 (Scale=2 x Cap=6000), Seed: 14771\n",
      "\t-->üèÜ EXP2 Winner:CPursuitNeuralUCB   (Gap:000.8%) [Env:Baseline (None), Attack:No X Rate:0.0, Frames:6000, SCapacity=12000, Alloc=Random]\n",
      "‚úì Experiment 2 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 8000 frames  <>  SCALED-CAPACITY: 16000 frames (CAPACITY:8000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[RandomAllocator Œµ=1.000] timestep=2 mode=random ‚Üí allocation=(3, 12, 24, 4)\n",
      "üîß Allocated qubits for NONE Exp 3: (3, 12, 24, 4)\n",
      "üîÑ Random Dynamic Allocation (Initial): (9, 19, 2, 13)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 3: Env:Baseline (None), Attack:No, Rate:0.0, Frames:8000, QubitAlloc=Random, SC:16000 (Scale=2 x Cap=8000), Seed: 16172\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 3: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 GNEURALUCB          : Reward=7395.05, Efficiency=098.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=16000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 3: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=7517.56, Efficiency=099.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=16000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 3: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=7425.90, Efficiency=098.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=16000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 3: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=7415.80, Efficiency=098.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=16000, Threshold=0.712]\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 3: Env:Baseline (None), Attack:No, Rate:0.0, Frames:8000, QubitAlloc=Random, SC:16000 (Scale=2 x Cap=8000), Seed: 16172\n",
      "\t-->üèÜ EXP3 Winner:EXPNeuralUCB        (Gap:000.2%) [Env:Baseline (None), Attack:No X Rate:0.0, Frames:8000, SCapacity=16000, Alloc=Random]\n",
      "‚úì Experiment 3 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 10000 frames  <>  SCALED-CAPACITY: 20000 frames (CAPACITY:10000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[RandomAllocator Œµ=1.000] timestep=3 mode=random ‚Üí allocation=(9, 19, 2, 13)\n",
      "üîß Allocated qubits for NONE Exp 4: (9, 19, 2, 13)\n",
      "üîÑ Random Dynamic Allocation (Initial): (14, 16, 5, 8)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 4: Env:Baseline (None), Attack:No, Rate:0.0, Frames:10000, QubitAlloc=Random, SC:20000 (Scale=2 x Cap=10000), Seed: 16282\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 4: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 GNEURALUCB          : Reward=9358.39, Efficiency=097.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=20000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 4: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=9456.94, Efficiency=098.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=20000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 4: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=9358.25, Efficiency=097.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=20000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 4: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=9365.39, Efficiency=097.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=20000, Threshold=0.712]\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 4: Env:Baseline (None), Attack:No, Rate:0.0, Frames:10000, QubitAlloc=Random, SC:20000 (Scale=2 x Cap=10000), Seed: 16282\n",
      "\t-->üèÜ EXP4 Winner:EXPNeuralUCB        (Gap:001.6%) [Env:Baseline (None), Attack:No X Rate:0.0, Frames:10000, SCapacity=20000, Alloc=Random]\n",
      "‚úì Experiment 4 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 12000 frames  <>  SCALED-CAPACITY: 24000 frames (CAPACITY:12000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[RandomAllocator Œµ=1.000] timestep=4 mode=random ‚Üí allocation=(14, 16, 5, 8)\n",
      "üîß Allocated qubits for NONE Exp 5: (14, 16, 5, 8)\n",
      "üîÑ Random Dynamic Allocation (Initial): (7, 4, 30, 2)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 5: Env:Baseline (None), Attack:No, Rate:0.0, Frames:12000, QubitAlloc=Random, SC:24000 (Scale=2 x Cap=12000), Seed: 22607\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 5: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 GNEURALUCB          : Reward=11282.57, Efficiency=097.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=24000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 5: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=11097.83, Efficiency=096.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=24000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 5: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=11271.47, Efficiency=097.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=24000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 5: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=11297.21, Efficiency=098.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=24000, Threshold=0.712]\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 5: Env:Baseline (None), Attack:No, Rate:0.0, Frames:12000, QubitAlloc=Random, SC:24000 (Scale=2 x Cap=12000), Seed: 22607\n",
      "\t-->üèÜ EXP5 Winner:iCPursuitNeuralUCB  (Gap:002.0%) [Env:Baseline (None), Attack:No X Rate:0.0, Frames:12000, SCapacity=24000, Alloc=Random]\n",
      "‚úì Experiment 5 completed successfully.\n",
      "Total experiment time: 2616.1s\n",
      "Experiments completed for none\n",
      "‚úì Scenario 'stochastic' evaluation completed.\n",
      "‚úì Scenario 'markov' evaluation completed.\n",
      "‚úì Scenario 'adaptive' evaluation completed.\n",
      "‚úì Scenario 'onlineadaptive' evaluation completed.\n",
      "‚úì Scenario 'none' evaluation completed.\n",
      "\n",
      "======================================================================\n",
      "COMPREHENSIVE SCENARIO PERFORMANCE ANALYSIS\n",
      "======================================================================\n",
      "SCENARIO: STOCHASTIC\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 7440.43\n",
      "\t‚Ä¢ Winner Avg Gap: 0008.12%\n",
      "\t‚Ä¢ Winner Avg Reward: 6838.50\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0091.88%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 3 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 2 wins\n",
      "\t\t- iCPursuitNeuralUCB: 0 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: STOCHASTIC\n",
      "======================================================================\n",
      "SCENARIO: \tSTOCHASTIC RANDOM FAILURES\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 0/5 experiments)\n",
      "\tWinner Avg Gap: \t008.1%\n",
      "\tWinner Avg Efficiency: \t091.9%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t091.9% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t091.9% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t091.7% Efficiency \t(Won 3/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t090.1% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: MARKOV\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 6929.99\n",
      "\t‚Ä¢ Winner Avg Gap: 0041.79%\n",
      "\t‚Ä¢ Winner Avg Reward: 4037.86\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0058.21%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 1 wins\n",
      "\t\t- iCPursuitNeuralUCB: 4 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: MARKOV\n",
      "======================================================================\n",
      "SCENARIO: \tMARKOV ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 4/5 experiments)\n",
      "\tWinner Avg Gap: \t041.8%\n",
      "\tWinner Avg Efficiency: \t058.2%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t058.2% Efficiency \t(Won 4/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t057.2% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t057.0% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t051.8% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: GNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 7445.10\n",
      "\t‚Ä¢ Winner Avg Gap: 0025.80%\n",
      "\t‚Ä¢ Winner Avg Reward: 5525.77\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0074.20%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 3 wins\n",
      "\t\t- EXPNeuralUCB: 1 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 1 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tADAPTIVE ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tGNeuralUCB (Won 3/5 experiments)\n",
      "\tWinner Avg Gap: \t025.8%\n",
      "\tWinner Avg Efficiency: \t074.2%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ GNeuralUCB     : \t074.2% Efficiency \t(Won 3/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t073.9% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t073.7% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t072.8% Efficiency \t(Won 1/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ONLINEADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: EXPNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 7475.58\n",
      "\t‚Ä¢ Winner Avg Gap: 0025.86%\n",
      "\t‚Ä¢ Winner Avg Reward: 5557.23\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0074.14%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 1 wins\n",
      "\t\t- EXPNeuralUCB: 4 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 0 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ONLINEADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tONLINE ADAPTIVE ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tEXPNeuralUCB (Won 4/5 experiments)\n",
      "\tWinner Avg Gap: \t025.9%\n",
      "\tWinner Avg Efficiency: \t074.1%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t074.1% Efficiency \t(Won 4/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t073.8% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t073.4% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t073.3% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: NONE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: EXPNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 7538.55\n",
      "\t‚Ä¢ Winner Avg Gap: 0001.36%\n",
      "\t‚Ä¢ Winner Avg Reward: 7406.16\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0098.64%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 3 wins\n",
      "\t\t- CPursuitNeuralUCB: 1 wins\n",
      "\t\t- iCPursuitNeuralUCB: 1 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: NONE\n",
      "======================================================================\n",
      "SCENARIO: \tBASELINE (OPTIMAL CONDITIONS)\n",
      "----------------------------------------\n",
      "Recommended Model: \tEXPNeuralUCB (Won 3/5 experiments)\n",
      "\tWinner Avg Gap: \t001.4%\n",
      "\tWinner Avg Efficiency: \t098.6%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t098.6% Efficiency \t(Won 3/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t098.4% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t098.4% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t098.3% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "KEY INSIGHTS:\n",
      "Best Performing Model Analysis (iCPursuitNeuralUCB):\n",
      "\t‚Ä¢ Stochastic Performance:    \t6838.503\n",
      "\t‚Ä¢ Baseline Performance:      \t7406.158\n",
      "\t‚Ä¢ Performance Retention:     \t092.3%\n",
      "\tGOOD:               \tAcceptable performance under stochastic conditions\n",
      "Statistical Analysis:\n",
      "\t‚Ä¢ Total models evaluated:     \t5\n",
      "\t‚Ä¢ Experiments per environment:\t5\n",
      "\t‚Ä¢ Quantum network simulation: \tComprehensive stochastic modeling\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "COMPREHENSIVE SCENARIO PERFORMANCE ANALYSIS\n",
      "======================================================================\n",
      "SCENARIO: STOCHASTIC\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 7440.43\n",
      "\t‚Ä¢ Winner Avg Gap: 0008.12%\n",
      "\t‚Ä¢ Winner Avg Reward: 6838.50\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0091.88%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 3 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 2 wins\n",
      "\t\t- iCPursuitNeuralUCB: 0 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: STOCHASTIC\n",
      "======================================================================\n",
      "SCENARIO: \tSTOCHASTIC RANDOM FAILURES\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 0/5 experiments)\n",
      "\tWinner Avg Gap: \t008.1%\n",
      "\tWinner Avg Efficiency: \t091.9%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t091.9% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t091.9% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t091.7% Efficiency \t(Won 3/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t090.1% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: MARKOV\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 6929.99\n",
      "\t‚Ä¢ Winner Avg Gap: 0041.79%\n",
      "\t‚Ä¢ Winner Avg Reward: 4037.86\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0058.21%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 1 wins\n",
      "\t\t- iCPursuitNeuralUCB: 4 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: MARKOV\n",
      "======================================================================\n",
      "SCENARIO: \tMARKOV ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 4/5 experiments)\n",
      "\tWinner Avg Gap: \t041.8%\n",
      "\tWinner Avg Efficiency: \t058.2%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t058.2% Efficiency \t(Won 4/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t057.2% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t057.0% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t051.8% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: GNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 7445.10\n",
      "\t‚Ä¢ Winner Avg Gap: 0025.80%\n",
      "\t‚Ä¢ Winner Avg Reward: 5525.77\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0074.20%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 3 wins\n",
      "\t\t- EXPNeuralUCB: 1 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 1 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tADAPTIVE ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tGNeuralUCB (Won 3/5 experiments)\n",
      "\tWinner Avg Gap: \t025.8%\n",
      "\tWinner Avg Efficiency: \t074.2%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ GNeuralUCB     : \t074.2% Efficiency \t(Won 3/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t073.9% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t073.7% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t072.8% Efficiency \t(Won 1/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ONLINEADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: EXPNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 7475.58\n",
      "\t‚Ä¢ Winner Avg Gap: 0025.86%\n",
      "\t‚Ä¢ Winner Avg Reward: 5557.23\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0074.14%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 1 wins\n",
      "\t\t- EXPNeuralUCB: 4 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 0 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ONLINEADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tONLINE ADAPTIVE ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tEXPNeuralUCB (Won 4/5 experiments)\n",
      "\tWinner Avg Gap: \t025.9%\n",
      "\tWinner Avg Efficiency: \t074.1%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t074.1% Efficiency \t(Won 4/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t073.8% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t073.4% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t073.3% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: NONE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: EXPNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 7538.55\n",
      "\t‚Ä¢ Winner Avg Gap: 0001.36%\n",
      "\t‚Ä¢ Winner Avg Reward: 7406.16\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0098.64%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 3 wins\n",
      "\t\t- CPursuitNeuralUCB: 1 wins\n",
      "\t\t- iCPursuitNeuralUCB: 1 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: NONE\n",
      "======================================================================\n",
      "SCENARIO: \tBASELINE (OPTIMAL CONDITIONS)\n",
      "----------------------------------------\n",
      "Recommended Model: \tEXPNeuralUCB (Won 3/5 experiments)\n",
      "\tWinner Avg Gap: \t001.4%\n",
      "\tWinner Avg Efficiency: \t098.6%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t098.6% Efficiency \t(Won 3/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t098.4% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t098.4% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t098.3% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "‚úÖ Evaluation completed!\n",
      "[Logging Redirect Stopped]\n",
      "\n",
      "üßπ Final cleanup for Random\n",
      "\n",
      "======================================================================\n",
      "‚úÖ COMPLETED: Random\n",
      "======================================================================\n",
      "\n",
      "‚úÖ Random COMPLETED SUCCESSFULLY\n",
      "\n",
      "======================================================================\n",
      "‚úÖ ALL ALLOCATORS COMPLETE!\n",
      "======================================================================\n",
      "\tEXP 5 GNEURALUCB          : Reward=8308.11, Efficiency=074.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=24000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 5: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=8385.44, Efficiency=074.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=24000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 5: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=8402.92, Efficiency=074.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=24000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 5: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=8327.31, Efficiency=074.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=24000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 5: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:12000, QubitAlloc=Random, SC:24000 (Scale=2 x Cap=12000), Seed: 19901\n",
      "\t-->üèÜ EXP5 Winner:CPursuitNeuralUCB   (Gap:025.2%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:12000, SCapacity=24000, Alloc=Random]\n",
      "‚úì Experiment 5 completed successfully.\n",
      "Total experiment time: 4309.9s\n",
      "Experiments completed for adaptive\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: ONLINE ADAPTIVE ATTACK\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: ONLINEADAPTIVE\n",
      "Category: Online Adaptive (Real-time Strategic)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 4000 frames  <>  SCALED-CAPACITY: 8000 frames (CAPACITY:4000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[RandomAllocator Œµ=1.000] timestep=0 mode=random ‚Üí allocation=(20, 4, 11, 8)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 1: (20, 4, 11, 8)\n",
      "üîÑ Random Dynamic Allocation (Initial): (4, 10, 12, 17)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:4000, QubitAlloc=Random, SC:8000 (Scale=2 x Cap=4000), Seed: 19493\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 GNEURALUCB          : Reward=2799.67, Efficiency=075.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=2705.12, Efficiency=072.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=2808.99, Efficiency=075.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=2768.21, Efficiency=074.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:4000, QubitAlloc=Random, SC:8000 (Scale=2 x Cap=4000), Seed: 19493\n",
      "\t-->üèÜ EXP1 Winner:CPursuitNeuralUCB   (Gap:024.7%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:4000, SCapacity=8000, Alloc=Random]\n",
      "‚úì Experiment 1 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 6000 frames  <>  SCALED-CAPACITY: 12000 frames (CAPACITY:6000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[RandomAllocator Œµ=1.000] timestep=1 mode=random ‚Üí allocation=(4, 10, 12, 17)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 2: (4, 10, 12, 17)\n",
      "üîÑ Random Dynamic Allocation (Initial): (8, 29, 2, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:6000, QubitAlloc=Random, SC:12000 (Scale=2 x Cap=6000), Seed: 14806\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 GNEURALUCB          : Reward=4203.26, Efficiency=074.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=4201.46, Efficiency=073.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=4220.67, Efficiency=074.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=4147.31, Efficiency=073.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:6000, QubitAlloc=Random, SC:12000 (Scale=2 x Cap=6000), Seed: 14806\n",
      "\t-->üèÜ EXP2 Winner:CPursuitNeuralUCB   (Gap:025.7%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:6000, SCapacity=12000, Alloc=Random]\n",
      "‚úì Experiment 2 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 8000 frames  <>  SCALED-CAPACITY: 16000 frames (CAPACITY:8000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[RandomAllocator Œµ=1.000] timestep=2 mode=random ‚Üí allocation=(8, 29, 2, 4)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 3: (8, 29, 2, 4)\n",
      "üîÑ Random Dynamic Allocation (Initial): (19, 9, 7, 8)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:8000, QubitAlloc=Random, SC:16000 (Scale=2 x Cap=8000), Seed: 19655\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 GNEURALUCB          : Reward=5553.38, Efficiency=074.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=16000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=5319.34, Efficiency=071.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=16000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=5526.29, Efficiency=073.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=16000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=5530.64, Efficiency=074.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=16000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:8000, QubitAlloc=Random, SC:16000 (Scale=2 x Cap=8000), Seed: 19655\n",
      "\t-->üèÜ EXP3 Winner:GNeuralUCB          (Gap:025.7%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:8000, SCapacity=16000, Alloc=Random]\n",
      "‚úì Experiment 3 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 10000 frames  <>  SCALED-CAPACITY: 20000 frames (CAPACITY:10000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[RandomAllocator Œµ=1.000] timestep=3 mode=random ‚Üí allocation=(19, 9, 7, 8)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 4: (19, 9, 7, 8)\n",
      "üîÑ Random Dynamic Allocation (Initial): (5, 2, 29, 7)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:10000, QubitAlloc=Random, SC:20000 (Scale=2 x Cap=10000), Seed: 20502\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 GNEURALUCB          : Reward=6903.19, Efficiency=074.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=20000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=7057.73, Efficiency=076.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=20000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=6886.88, Efficiency=074.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=20000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=6927.94, Efficiency=074.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=20000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:10000, QubitAlloc=Random, SC:20000 (Scale=2 x Cap=10000), Seed: 20502\n",
      "\t-->üèÜ EXP4 Winner:EXPNeuralUCB        (Gap:023.8%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:10000, SCapacity=20000, Alloc=Random]\n",
      "‚úì Experiment 4 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 12000 frames  <>  SCALED-CAPACITY: 24000 frames (CAPACITY:12000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[RandomAllocator Œµ=1.000] timestep=4 mode=random ‚Üí allocation=(5, 2, 29, 7)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 5: (5, 2, 29, 7)\n",
      "üîÑ Random Dynamic Allocation (Initial): (16, 7, 18, 2)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:12000, QubitAlloc=Random, SC:24000 (Scale=2 x Cap=12000), Seed: 18262\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 GNEURALUCB          : Reward=8365.55, Efficiency=075.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=24000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=7686.16, Efficiency=069.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=24000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=8368.75, Efficiency=075.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=24000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=8393.69, Efficiency=075.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=24000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:12000, QubitAlloc=Random, SC:24000 (Scale=2 x Cap=12000), Seed: 18262\n",
      "\t-->üèÜ EXP5 Winner:iCPursuitNeuralUCB  (Gap:024.7%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:12000, SCapacity=24000, Alloc=Random]\n",
      "‚úì Experiment 5 completed successfully.\n",
      "Total experiment time: 4087.2s\n",
      "Experiments completed for onlineadaptive\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: BASELINE (OPTIMAL CONDITIONS)\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: NONE\n",
      "Category: Baseline (No Attacks)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 4000 frames  <>  SCALED-CAPACITY: 8000 frames (CAPACITY:4000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[RandomAllocator Œµ=1.000] timestep=0 mode=random ‚Üí allocation=(16, 7, 18, 2)\n",
      "üîß Allocated qubits for NONE Exp 1: (16, 7, 18, 2)\n",
      "üîÑ Random Dynamic Allocation (Initial): (2, 13, 13, 15)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 1: Env:Baseline (None), Attack:No, Rate:0.0, Frames:4000, QubitAlloc=Random, SC:8000 (Scale=2 x Cap=4000), Seed: 20264\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 1: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 GNEURALUCB          : Reward=3650.34, Efficiency=097.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 1: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=3632.67, Efficiency=097.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 1: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=3646.62, Efficiency=097.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 1: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=3650.80, Efficiency=097.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.712]\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 1: Env:Baseline (None), Attack:No, Rate:0.0, Frames:4000, QubitAlloc=Random, SC:8000 (Scale=2 x Cap=4000), Seed: 20264\n",
      "\t-->üèÜ EXP1 Winner:iCPursuitNeuralUCB  (Gap:002.1%) [Env:Baseline (None), Attack:No X Rate:0.0, Frames:4000, SCapacity=8000, Alloc=Random]\n",
      "‚úì Experiment 1 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 6000 frames  <>  SCALED-CAPACITY: 12000 frames (CAPACITY:6000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[RandomAllocator Œµ=1.000] timestep=1 mode=random ‚Üí allocation=(2, 13, 13, 15)\n",
      "üîß Allocated qubits for NONE Exp 2: (2, 13, 13, 15)\n",
      "üîÑ Random Dynamic Allocation (Initial): (3, 12, 24, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 2: Env:Baseline (None), Attack:No, Rate:0.0, Frames:6000, QubitAlloc=Random, SC:12000 (Scale=2 x Cap=6000), Seed: 15627\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 2: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 GNEURALUCB          : Reward=5611.86, Efficiency=097.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 2: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=5582.69, Efficiency=096.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 2: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=5620.92, Efficiency=097.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 2: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=5618.55, Efficiency=097.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.712]\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 2: Env:Baseline (None), Attack:No, Rate:0.0, Frames:6000, QubitAlloc=Random, SC:12000 (Scale=2 x Cap=6000), Seed: 15627\n",
      "\t-->üèÜ EXP2 Winner:CPursuitNeuralUCB   (Gap:002.5%) [Env:Baseline (None), Attack:No X Rate:0.0, Frames:6000, SCapacity=12000, Alloc=Random]\n",
      "‚úì Experiment 2 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 8000 frames  <>  SCALED-CAPACITY: 16000 frames (CAPACITY:8000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[RandomAllocator Œµ=1.000] timestep=2 mode=random ‚Üí allocation=(3, 12, 24, 4)\n",
      "üîß Allocated qubits for NONE Exp 3: (3, 12, 24, 4)\n",
      "üîÑ Random Dynamic Allocation (Initial): (9, 19, 2, 13)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 3: Env:Baseline (None), Attack:No, Rate:0.0, Frames:8000, QubitAlloc=Random, SC:16000 (Scale=2 x Cap=8000), Seed: 20434\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 3: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 GNEURALUCB          : Reward=7484.83, Efficiency=099.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=16000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 3: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=7521.98, Efficiency=099.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=16000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 3: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=7487.76, Efficiency=099.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=16000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 3: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=7487.20, Efficiency=099.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=16000, Threshold=0.712]\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 3: Env:Baseline (None), Attack:No, Rate:0.0, Frames:8000, QubitAlloc=Random, SC:16000 (Scale=2 x Cap=8000), Seed: 20434\n",
      "\t-->üèÜ EXP3 Winner:EXPNeuralUCB        (Gap:000.2%) [Env:Baseline (None), Attack:No X Rate:0.0, Frames:8000, SCapacity=16000, Alloc=Random]\n",
      "‚úì Experiment 3 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 10000 frames  <>  SCALED-CAPACITY: 20000 frames (CAPACITY:10000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[RandomAllocator Œµ=1.000] timestep=3 mode=random ‚Üí allocation=(9, 19, 2, 13)\n",
      "üîß Allocated qubits for NONE Exp 4: (9, 19, 2, 13)\n",
      "üîÑ Random Dynamic Allocation (Initial): (14, 16, 5, 8)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 4: Env:Baseline (None), Attack:No, Rate:0.0, Frames:10000, QubitAlloc=Random, SC:20000 (Scale=2 x Cap=10000), Seed: 15374\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 4: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 GNEURALUCB          : Reward=9280.35, Efficiency=098.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=20000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 4: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=9300.36, Efficiency=098.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=20000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 4: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=9257.22, Efficiency=098.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=20000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 4: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=9286.54, Efficiency=098.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=20000, Threshold=0.712]\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 4: Env:Baseline (None), Attack:No, Rate:0.0, Frames:10000, QubitAlloc=Random, SC:20000 (Scale=2 x Cap=10000), Seed: 15374\n",
      "\t-->üèÜ EXP4 Winner:EXPNeuralUCB        (Gap:001.2%) [Env:Baseline (None), Attack:No X Rate:0.0, Frames:10000, SCapacity=20000, Alloc=Random]\n",
      "‚úì Experiment 4 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 12000 frames  <>  SCALED-CAPACITY: 24000 frames (CAPACITY:12000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[RandomAllocator Œµ=1.000] timestep=4 mode=random ‚Üí allocation=(14, 16, 5, 8)\n",
      "üîß Allocated qubits for NONE Exp 5: (14, 16, 5, 8)\n",
      "üîÑ Random Dynamic Allocation (Initial): (7, 4, 30, 2)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 5: Env:Baseline (None), Attack:No, Rate:0.0, Frames:12000, QubitAlloc=Random, SC:24000 (Scale=2 x Cap=12000), Seed: 13685\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 5: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 GNEURALUCB          : Reward=11221.92, Efficiency=097.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=24000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 5: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=11189.85, Efficiency=097.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=24000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 5: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=11237.61, Efficiency=097.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=24000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 5: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=11268.79, Efficiency=097.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=24000, Threshold=0.712]\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 5: Env:Baseline (None), Attack:No, Rate:0.0, Frames:12000, QubitAlloc=Random, SC:24000 (Scale=2 x Cap=12000), Seed: 13685\n",
      "\t-->üèÜ EXP5 Winner:iCPursuitNeuralUCB  (Gap:002.3%) [Env:Baseline (None), Attack:No X Rate:0.0, Frames:12000, SCapacity=24000, Alloc=Random]\n",
      "‚úì Experiment 5 completed successfully.\n",
      "Total experiment time: 4985.2s\n",
      "Experiments completed for none\n",
      "‚úì Scenario 'stochastic' evaluation completed.\n",
      "‚úì Scenario 'markov' evaluation completed.\n",
      "‚úì Scenario 'adaptive' evaluation completed.\n",
      "‚úì Scenario 'onlineadaptive' evaluation completed.\n",
      "‚úì Scenario 'none' evaluation completed.\n",
      "\n",
      "======================================================================\n",
      "COMPREHENSIVE SCENARIO PERFORMANCE ANALYSIS\n",
      "======================================================================\n",
      "SCENARIO: STOCHASTIC\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: EXPNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 7495.10\n",
      "\t‚Ä¢ Winner Avg Gap: 0007.79%\n",
      "\t‚Ä¢ Winner Avg Reward: 6943.27\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0092.21%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 1 wins\n",
      "\t\t- EXPNeuralUCB: 3 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 1 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: STOCHASTIC\n",
      "======================================================================\n",
      "SCENARIO: \tSTOCHASTIC RANDOM FAILURES\n",
      "----------------------------------------\n",
      "Recommended Model: \tEXPNeuralUCB (Won 3/5 experiments)\n",
      "\tWinner Avg Gap: \t007.8%\n",
      "\tWinner Avg Efficiency: \t092.2%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t092.2% Efficiency \t(Won 3/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t092.0% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t091.9% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t091.8% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: MARKOV\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 6917.22\n",
      "\t‚Ä¢ Winner Avg Gap: 0042.18%\n",
      "\t‚Ä¢ Winner Avg Reward: 3993.03\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0057.82%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 1 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 1 wins\n",
      "\t\t- iCPursuitNeuralUCB: 3 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: MARKOV\n",
      "======================================================================\n",
      "SCENARIO: \tMARKOV ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 3/5 experiments)\n",
      "\tWinner Avg Gap: \t042.2%\n",
      "\tWinner Avg Efficiency: \t057.8%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t057.8% Efficiency \t(Won 3/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t057.2% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t057.1% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t051.3% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: CPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 7394.65\n",
      "\t‚Ä¢ Winner Avg Gap: 0025.60%\n",
      "\t‚Ä¢ Winner Avg Reward: 5509.75\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0074.40%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 1 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 3 wins\n",
      "\t\t- iCPursuitNeuralUCB: 1 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tADAPTIVE ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tCPursuitNeuralUCB (Won 3/5 experiments)\n",
      "\tWinner Avg Gap: \t025.6%\n",
      "\tWinner Avg Efficiency: \t074.4%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t074.4% Efficiency \t(Won 3/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t074.2% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t074.1% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t073.8% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ONLINEADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: CPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 7460.93\n",
      "\t‚Ä¢ Winner Avg Gap: 0025.43%\n",
      "\t‚Ä¢ Winner Avg Reward: 5562.32\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0074.57%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 1 wins\n",
      "\t\t- EXPNeuralUCB: 1 wins\n",
      "\t\t- CPursuitNeuralUCB: 2 wins\n",
      "\t\t- iCPursuitNeuralUCB: 1 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ONLINEADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tONLINE ADAPTIVE ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tCPursuitNeuralUCB (Won 2/5 experiments)\n",
      "\tWinner Avg Gap: \t025.4%\n",
      "\tWinner Avg Efficiency: \t074.6%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t074.6% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t074.6% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t074.2% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t072.5% Efficiency \t(Won 1/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: NONE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 7594.60\n",
      "\t‚Ä¢ Winner Avg Gap: 0001.77%\n",
      "\t‚Ä¢ Winner Avg Reward: 7462.37\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0098.23%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 2 wins\n",
      "\t\t- CPursuitNeuralUCB: 1 wins\n",
      "\t\t- iCPursuitNeuralUCB: 2 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: NONE\n",
      "======================================================================\n",
      "SCENARIO: \tBASELINE (OPTIMAL CONDITIONS)\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 2/5 experiments)\n",
      "\tWinner Avg Gap: \t001.8%\n",
      "\tWinner Avg Efficiency: \t098.2%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t098.2% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t098.1% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t098.1% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t098.0% Efficiency \t(Won 2/5 experiments)\n",
      "======================================================================\n",
      "KEY INSIGHTS:\n",
      "Best Performing Model Analysis (EXPNeuralUCB):\n",
      "\t‚Ä¢ Stochastic Performance:    \t6943.269\n",
      "\t‚Ä¢ Baseline Performance:      \t7462.374\n",
      "\t‚Ä¢ Performance Retention:     \t093.0%\n",
      "\tGOOD:               \tAcceptable performance under stochastic conditions\n",
      "Statistical Analysis:\n",
      "\t‚Ä¢ Total models evaluated:     \t5\n",
      "\t‚Ä¢ Experiments per environment:\t5\n",
      "\t‚Ä¢ Quantum network simulation: \tComprehensive stochastic modeling\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "COMPREHENSIVE SCENARIO PERFORMANCE ANALYSIS\n",
      "======================================================================\n",
      "SCENARIO: STOCHASTIC\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: EXPNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 7495.10\n",
      "\t‚Ä¢ Winner Avg Gap: 0007.79%\n",
      "\t‚Ä¢ Winner Avg Reward: 6943.27\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0092.21%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 1 wins\n",
      "\t\t- EXPNeuralUCB: 3 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 1 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: STOCHASTIC\n",
      "======================================================================\n",
      "SCENARIO: \tSTOCHASTIC RANDOM FAILURES\n",
      "----------------------------------------\n",
      "Recommended Model: \tEXPNeuralUCB (Won 3/5 experiments)\n",
      "\tWinner Avg Gap: \t007.8%\n",
      "\tWinner Avg Efficiency: \t092.2%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t092.2% Efficiency \t(Won 3/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t092.0% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t091.9% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t091.8% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: MARKOV\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 6917.22\n",
      "\t‚Ä¢ Winner Avg Gap: 0042.18%\n",
      "\t‚Ä¢ Winner Avg Reward: 3993.03\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0057.82%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 1 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 1 wins\n",
      "\t\t- iCPursuitNeuralUCB: 3 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: MARKOV\n",
      "======================================================================\n",
      "SCENARIO: \tMARKOV ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 3/5 experiments)\n",
      "\tWinner Avg Gap: \t042.2%\n",
      "\tWinner Avg Efficiency: \t057.8%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t057.8% Efficiency \t(Won 3/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t057.2% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t057.1% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t051.3% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: CPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 7394.65\n",
      "\t‚Ä¢ Winner Avg Gap: 0025.60%\n",
      "\t‚Ä¢ Winner Avg Reward: 5509.75\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0074.40%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 1 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 3 wins\n",
      "\t\t- iCPursuitNeuralUCB: 1 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tADAPTIVE ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tCPursuitNeuralUCB (Won 3/5 experiments)\n",
      "\tWinner Avg Gap: \t025.6%\n",
      "\tWinner Avg Efficiency: \t074.4%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t074.4% Efficiency \t(Won 3/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t074.2% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t074.1% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t073.8% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ONLINEADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: CPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 7460.93\n",
      "\t‚Ä¢ Winner Avg Gap: 0025.43%\n",
      "\t‚Ä¢ Winner Avg Reward: 5562.32\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0074.57%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 1 wins\n",
      "\t\t- EXPNeuralUCB: 1 wins\n",
      "\t\t- CPursuitNeuralUCB: 2 wins\n",
      "\t\t- iCPursuitNeuralUCB: 1 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ONLINEADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tONLINE ADAPTIVE ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tCPursuitNeuralUCB (Won 2/5 experiments)\n",
      "\tWinner Avg Gap: \t025.4%\n",
      "\tWinner Avg Efficiency: \t074.6%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t074.6% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t074.6% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t074.2% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t072.5% Efficiency \t(Won 1/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: NONE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 7594.60\n",
      "\t‚Ä¢ Winner Avg Gap: 0001.77%\n",
      "\t‚Ä¢ Winner Avg Reward: 7462.37\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0098.23%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 2 wins\n",
      "\t\t- CPursuitNeuralUCB: 1 wins\n",
      "\t\t- iCPursuitNeuralUCB: 2 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: NONE\n",
      "======================================================================\n",
      "SCENARIO: \tBASELINE (OPTIMAL CONDITIONS)\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 2/5 experiments)\n",
      "\tWinner Avg Gap: \t001.8%\n",
      "\tWinner Avg Efficiency: \t098.2%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t098.2% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t098.1% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t098.1% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t098.0% Efficiency \t(Won 2/5 experiments)\n",
      "======================================================================\n",
      "‚úÖ Evaluation completed!\n",
      "[Logging Redirect Stopped]\n",
      "\n",
      "üßπ Final cleanup for Random\n",
      "\n",
      "======================================================================\n",
      "‚úÖ COMPLETED: Random\n",
      "======================================================================\n",
      "\n",
      "‚úÖ Random COMPLETED SUCCESSFULLY\n",
      "\n",
      "======================================================================\n",
      "‚úÖ ALL ALLOCATORS COMPLETE!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Cell 2: Allocator + ExperimentConfiguration for Paper #2\n",
    "# ============================================================\n",
    "importlib.reload(qubit_allocator)\n",
    "importlib.reload(experiment_config)\n",
    "importlib.reload(multi_run_evaluator)\n",
    "\n",
    "from daqr.core.quantum_physics              import *\n",
    "from daqr.core.qubit_allocator              import (\n",
    "                                                QubitAllocator,\n",
    "                                                RandomQubitAllocator,\n",
    "                                                DynamicQubitAllocator,\n",
    "                                                ThompsonSamplingAllocator\n",
    "                                            )\n",
    "\n",
    "from daqr.evaluation.allocator_runner       import AllocatorRunner\n",
    "from daqr.evaluation.multi_run_evaluator    import MultiRunEvaluator\n",
    "from daqr.config.experiment_config          import ExperimentConfiguration\n",
    "\n",
    "\n",
    "\n",
    "print(\"=\" * 70, \"\\nPAPER #2 QUANTUM MAB MODELS EVALUATION FRAMEWORK - STOCHASTIC FOCUS\\n\", \"=\" * 70)\n",
    "# ------------------------------------------------------------\n",
    "# 1) Allocator selection (Paper #2: start with fixed baseline)\n",
    "# ------------------------------------------------------------\n",
    "# You can swap these as needed:\n",
    "# allocator = RandomQubitAllocator(epsilon=0.5, seed=42)        # 50-50 mix\n",
    "# allocator = RandomQubitAllocator(epsilon=0.1, seed=42)        # mostly baseline\n",
    "# allocator = RandomQubitAllocator(epsilon=0.0, seed=42)        # deterministic\n",
    "# allocator = DynamicQubitAllocator(seed=42)                    # dynamic UCB\n",
    "# allocator = ThompsonSamplingAllocator(seed=42)                # Thompson\n",
    "\n",
    "allocator_type =    \"Random\" # Fixed allocator via environment (Paper #2 baseline)\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2) Derive run parameters from FRAMEWORK_CONFIG (Cell 1)\n",
    "# ------------------------------------------------------------\n",
    "# current_frames      = FRAMEWORK_CONFIG['base_frames'] \n",
    "# frame_step          = FRAMEWORK_CONFIG['frame_step']\n",
    "# attack_intensity    = FRAMEWORK_CONFIG['intensity']\n",
    "# current_experiments = FRAMEWORK_CONFIG['exp_num']\n",
    "\n",
    "attack_intensity    = FRAMEWORK_CONFIG['intensity']\n",
    "current_frames      = 50\n",
    "frame_step          = 50\n",
    "current_experiments = 1\n",
    "last_backup         = False\n",
    "base_cap            = False\n",
    "overwrite           = True\n",
    "\n",
    "# PHYSICS_MODELS = ['paper2', 'default']  # Set to ['default', 'paper2'] to test both\n",
    "ATTACK_SCENARIOS = ['stochastic']  # Start simple, expand later\n",
    "PHYSICS_MODELS = ['paper2']\n",
    "# PHYSICS_MODELS = ['default']\n",
    "ALLOCATORS = ['Default', 'Dynamic', 'ThompsonSampling', 'Random']\n",
    "SCALES = [2]\n",
    "RUNS = [5]\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70, \"\\nüéØ QUANTUM ROUTING ALLOCATOR EVALUATION\\n\", \"=\" * 70)\n",
    "print(f\"Total Allocators to Test:   {len(ALLOCATORS)}\")\n",
    "print(f\"Physics Models:             {PHYSICS_MODELS}\")\n",
    "print(f\"Allocators:                 {ALLOCATORS}\")\n",
    "print(f\"Scales:                     {SCALES}\")\n",
    "print(f\"Runs:                       {RUNS}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Run each allocator in isolation\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"üöÄ ALLOCATOR {len(ALLOCATORS)}: {allocator_type}\")\n",
    "print('='*70)\n",
    "\n",
    "try:\n",
    "    # Create isolated runner instance for this allocator\n",
    "    custom_config = ExperimentConfiguration(\n",
    "        env_type=FRAMEWORK_CONFIG['main_env'], scenarios=test_scenarios, use_last_backup=last_backup,\n",
    "        models=models, attack_intensity=attack_intensity, scale=2, base_capacity=base_cap, overwrite=overwrite)\n",
    "\n",
    "    alloc_runner = AllocatorRunner(\n",
    "        allocator_type=allocator_type, physics_models=PHYSICS_MODELS, framework_config=FRAMEWORK_CONFIG, \n",
    "        scales=SCALES, runs=RUNS, models=models, test_scenarios=test_scenarios, config=custom_config)\n",
    "\n",
    "    # Run this allocator with your existing get_physics_params function\n",
    "    alloc_runner.run(get_physics_params_func=get_physics_params)\n",
    "    print(f\"\\n‚úÖ {allocator_type} COMPLETED SUCCESSFULLY\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå {allocator_type} FAILED: {e}\")\n",
    "    traceback.print_exc()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"‚úÖ ALL ALLOCATORS COMPLETE!\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "comprehensive-evaluation"
   },
   "source": [
    "## Multi-Environment Performance Analysis\n",
    "\n",
    "### Complete Evaluation Matrix\n",
    "\n",
    "This research extends beyond the primary stochastic-adversarial comparison to provide comprehensive algorithm assessment across the complete spectrum of operational environments, establishing a thorough empirical foundation for robustness evaluation.\n",
    "\n",
    "### Environmental Test Framework\n",
    "\n",
    "| Environment | Classification | Threat Characteristics | Analytical Purpose |\n",
    "|-------------|---------------|----------------------|-------------------|\n",
    "| `none` | Baseline | Deterministic optimal conditions | Theoretical performance ceiling |\n",
    "| `stochastic` | Probabilistic | Uniform random failures | Standard operational baseline |\n",
    "| `markov` | Adversarial | Memory-dependent strategic attacks | Oblivious adversarial model |\n",
    "| `adaptive` | Adversarial | Feedback-driven strategic attacks | Responsive adversarial model |\n",
    "| `onlineadaptive` | Adversarial | Real-time adaptive strategic attacks | Sophisticated adversarial model |\n",
    "\n",
    "### Research Contributions\n",
    "\n",
    "**Comprehensive Threat Model Coverage**\n",
    "The evaluation framework addresses the complete spectrum of operational conditions, from optimal deterministic environments through increasingly sophisticated adversarial scenarios, providing unprecedented coverage of realistic deployment conditions.\n",
    "\n",
    "**Graduated Adversarial Complexity Analysis**  \n",
    "The systematic progression from oblivious to sophisticated adversarial models enables precise quantification of algorithm performance degradation as threat sophistication increases, revealing critical robustness thresholds.\n",
    "\n",
    "**Cross-Environment Validation Protocol**\n",
    "Consistent algorithm ranking across multiple environments validates robustness claims and identifies algorithms with stable performance characteristics independent of operational conditions.\n",
    "\n",
    "**Empirical Robustness Quantification**\n",
    "The multi-environment approach enables precise measurement of performance degradation rates, establishing quantitative robustness metrics that support theoretical predictions and practical deployment decisions.\n",
    "\n",
    "### Methodological Significance\n",
    "\n",
    "This comprehensive evaluation protocol addresses limitations in existing literature where algorithm assessment often focuses on narrow operational scenarios, providing the empirical foundation necessary for robust algorithm deployment in practical quantum network environments."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1rknAIThhNzWIoGwNHJR_N0F6hBb7T3e-",
     "timestamp": 1759053280580
    }
   ]
  },
  "kernelspec": {
   "display_name": ".quantum",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
