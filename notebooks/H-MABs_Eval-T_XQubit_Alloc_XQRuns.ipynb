{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "title-cell"
   },
   "source": [
    "# Neural Bandit Algorithm Evaluation Framework\n",
    "\n",
    "## Graduate Research Project\n",
    "**AI & Quantum Computing Laboratory**  \n",
    "**Rochester Institute of Technology**\n",
    "\n",
    "---\n",
    "\n",
    "## Research Framework Overview\n",
    "\n",
    "This comprehensive evaluation framework provides rigorous analysis of neural bandit algorithms with clear categorical distinction between different operational environments:\n",
    "\n",
    "- **Baseline Environment**: Optimal performance benchmark (Oracle)\n",
    "- **Stochastic Environment**: Natural random failures and network noise\n",
    "- **Adversarial Environment**: Strategic intelligent attacks and malicious targeting\n",
    "\n",
    "## Primary Research Questions\n",
    "\n",
    "1. **Algorithm Robustness**: How do neural bandit algorithms perform across different threat models?\n",
    "2. **Comparative Analysis**: Which algorithms demonstrate superior performance in specific scenarios?\n",
    "3. **Quantified Performance**: What are the exact degradation metrics under adversarial conditions?\n",
    "4. **Theoretical Validation**: Do experimental results align with established regret bounds?\n",
    "\n",
    "## Key Research Contributions\n",
    "\n",
    "- **Systematic Environment Categorization**: Clear baseline/stochastic/adversarial taxonomy\n",
    "- **Multi-Algorithm Comparative Testing**: Comprehensive evaluation across 6+ algorithms\n",
    "- **Quantified Robustness Metrics**: Precise performance degradation measurements\n",
    "- **Publication-Ready Analysis**: Academic-quality visualizations and statistical validation\n",
    "\n",
    "## Evaluation Methodology\n",
    "\n",
    "The framework implements standardized testing protocols across three distinct categories:\n",
    "- **Baseline**: Oracle performance establishing theoretical upper bounds\n",
    "- **Stochastic**: Random environmental perturbations modeling realistic conditions  \n",
    "- **Adversarial**: Strategic attack scenarios simulating malicious interference\n",
    "\n",
    "Each algorithm undergoes identical testing conditions enabling direct performance comparison and robustness quantification across all operational environments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "framework-overview"
   },
   "source": [
    "## Threat Model Classification Framework\n",
    "\n",
    "### Systematic Environment Taxonomy\n",
    "\n",
    "This research framework establishes precise categorical distinctions for quantum network evaluation environments, addressing previous ambiguity in threat model classification:\n",
    "\n",
    "### Environmental Categories\n",
    "\n",
    "| Environment | Implementation | Threat Characteristic | Research Application |\n",
    "|-------------|----------------|----------------------|---------------------|\n",
    "| **Baseline** | `none` | Deterministic optimal performance | Theoretical upper bound |\n",
    "| **Stochastic** | `stochastic`/`random` | Natural random failures | Realistic network conditions |\n",
    "| **Adversarial** | `markov` | Oblivious strategic attacks | Pattern-based targeting |\n",
    "| **Adversarial** | `adaptive` | Responsive strategic attacks | Feedback-driven targeting |\n",
    "| **Adversarial** | `onlineadaptive` | Real-time strategic attacks | Dynamic threat adaptation |\n",
    "\n",
    "### Research Contribution\n",
    "\n",
    "This framework addresses a critical gap in existing literature where random network failures were often conflated with intentional adversarial attacks. The systematic categorization enables:\n",
    "\n",
    "- **Precise Robustness Quantification**: Exact performance degradation measurements across threat categories\n",
    "- **Comparative Algorithm Analysis**: Direct performance comparison under identical threat conditions\n",
    "- **Theoretical Validation**: Empirical verification of regret bounds across different adversarial models\n",
    "- **Reproducible Research Standards**: Standardized evaluation protocols for quantum network algorithms\n",
    "\n",
    "### Methodological Significance\n",
    "\n",
    "Previous research often lacked clear distinction between stochastic and adversarial environments, limiting the ability to assess true algorithm robustness under intentional attacks versus natural network degradation. This framework provides the necessary precision for rigorous academic evaluation of quantum routing algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup-cell"
   },
   "source": [
    "## Environment Setup & Library Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 58,
     "status": "ok",
     "timestamp": 1758879388611,
     "user": {
      "displayName": "Piter Garcia",
      "userId": "06279433864365870614"
     },
     "user_tz": 240
    },
    "id": "theoretical-setup",
    "outputId": "a6c0fc57-a152-45e1-9da6-5113e519b8fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: GA-Work\n",
      "Running locally (not in Colab)\n",
      "Changed to project directory: Dynamic_Routing_Eval_Framework\n",
      "Now working from: Dynamic_Routing_Eval_Framework\n",
      "Framework dependencies installed successfully\n",
      "Python version: 3.12.11\n",
      "PyTorch version: 2.8.0\n",
      "NumPy version: 1.26.4\n",
      "NetworkX version: 3.5\n",
      "Matplotlib version: 3.10.6\n",
      "Quantum MAB Models Evaluation Framework - Ready for Paper 7 (QBGP) testing\n",
      "‚ö†Ô∏è Cleanup script not found, skipping...\n",
      "‚úì Deep cleanup complete (memory cleared)\n",
      "‚úì daqr package found successfully\n",
      "PyTorch version: 2.8.0\n",
      "NumPy version: 1.26.4\n",
      "Using device: cpu\n",
      "PyTorch version: 2.8.0\n",
      "NumPy version: 1.26.4\n",
      "Using device: cpu\n",
      "‚úì All modules reloaded successfully (Paper 7 environment ready)\n",
      "PyTorch version: 2.8.0\n",
      "NumPy version: 1.26.4\n",
      "Using device: cpu\n",
      "PyTorch version: 2.8.0\n",
      "NumPy version: 1.26.4\n",
      "Using device: cpu\n",
      "\n",
      "===================== GET LOCAL REGISTRY =====================\n",
      "‚Üí Skipping local cache (force=True or file missing)\n",
      "\n",
      "===================== BUILD LOCAL REGISTRY =====================\n",
      "\n",
      "================================================================================\n",
      "üîç SCANNING LOCAL FILES\n",
      "================================================================================\n",
      "Parameters: load_to_drive=False, force=False\n",
      "\n",
      "üìÇ Checking DRIVE mode: /content/drive/Shareddrives/ai_quantum_computing/quantum_data_lake\n",
      "   ‚ö†Ô∏è  Path does not exist, skipping\n",
      "\n",
      "üìÇ Checking LOCAL mode: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config\n",
      "   ‚úÖ Path exists, starting walk...\n",
      "   üö∂ Walking directory tree: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config\n",
      "\n",
      "   üìÅ Directory: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201\n",
      "      Relative: framework_state/day_20260201\n",
      "      Component: framework_state\n",
      "      Date: day_20260201\n",
      "      üìÑ Processing 2517 files in framework_state/day_20260201\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "      üìä framework_state/day_20260201: 2491/2517 files processed\n",
      "      üìä framework_state/day_20260201: 0/2517 files skipped\n",
      "      üìä framework_state/day_20260201: 26/2517 files conflicted\n",
      "\n",
      "   üìÅ Directory: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/model_state/day_20260201\n",
      "      Relative: model_state/day_20260201\n",
      "      Component: model_state\n",
      "      Date: day_20260201\n",
      "      üìÑ Processing 8859 files in model_state/day_20260201\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "      üìä model_state/day_20260201: 8859/8859 files processed\n",
      "      üìä model_state/day_20260201: 0/8859 files skipped\n",
      "      üìä model_state/day_20260201: 0/8859 files conflicted\n",
      "\n",
      "   üìä Processed 2 directories\n",
      "\n",
      "================================================================================\n",
      "üì¶ BUILDING FINAL REGISTRY\n",
      "================================================================================\n",
      "Components found: ['framework_state', 'model_state']\n",
      "  ‚Ä¢ framework_state: 2491 files\n",
      "  ‚Ä¢ model_state: 8859 files\n",
      "\n",
      "‚úÖ SCAN COMPLETE\n",
      "Modes scanned: 1\n",
      "Total files in registry: 11350\n",
      "================================================================================\n",
      "\n",
      "\t‚Üí Filesystem scan found 11350 files\n",
      "\n",
      "===================== GET DRIVE REGISTRY =====================\n",
      "===================== REGISTRY BUILD COMPLETE =====================\n",
      "\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "\tüì¶ LocalBackupManager Registry Saved Locally in LOCAL\n",
      "BUILDING REGISTRY WITH 0 EXPECTED COMPONENTS KEYS\n",
      "\n",
      "===================== GET LOCAL REGISTRY =====================\n",
      "‚Üí Skipping local cache (force=True or file missing)\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "\tüì¶ LocalBackupManager Registry Saved Locally in LOCAL\n",
      "======================================================================\n",
      "DYNAMIC ROUTING EVALUATION FRAMEWORK - MULTI-TESTBED CONFIGURATION\n",
      "======================================================================\n",
      "Available Testbeds:\n",
      "  ‚Ä¢ Paper 2 (Chaudhary 2023) - Exact replication + Extended version\n",
      "  ‚Ä¢ Paper 7 (Liu 2024) - QBGP Multi-ISP Routing\n",
      "  ‚Ä¢ Paper 12 (Wang 2024) - QuARC Fusion-based Allocation\n",
      "\n",
      "Paper 2 Configurations:\n",
      "  ‚Ä¢ 'paper2': Exact MATLAB replication (8 paths, all original params)\n",
      "  ‚Ä¢ 'paper2_extended': Enhanced version (memory decay, async swapping)\n",
      "\n",
      "Models to evaluate: 5 total\n",
      "\n",
      "‚úì Configuration loaded successfully - Ready for evaluation\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Setup: Quantum MAB Framework (Paper 7 QBGP Testbed)\n",
    "# ============================================================\n",
    "\n",
    "# --- Install Dependencies ---\n",
    "!pip install -q torch torchvision numpy matplotlib seaborn pandas tqdm scipy scikit-learn pmdarima networkx\n",
    "\n",
    "# --- Core Imports ---\n",
    "import os, sys, gc, warnings, importlib, subprocess\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import networkx as nx\n",
    "from pathlib import Path\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- Path Setup ---\n",
    "print(f\"Current working directory: {os.getcwd().split('/')[-1]}\")\n",
    "try:\n",
    "    import google.colab\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    project_dir = '/content/drive/MyDrive/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework'\n",
    "    os.chdir(project_dir)\n",
    "    print(\"Running in Google Colab\")\n",
    "except ImportError:\n",
    "    print(\"Running locally (not in Colab)\")\n",
    "    # Navigate to the correct directory for local execution\n",
    "    current_dir = os.getcwd()\n",
    "    if 'GA-Work' in current_dir and 'Dynamic_Routing_Eval_Framework' not in current_dir:\n",
    "        project_dir = os.path.join(current_dir, 'hybrid_variable_framework', 'Dynamic_Routing_Eval_Framework')\n",
    "        if os.path.exists(project_dir):\n",
    "            os.chdir(project_dir)\n",
    "            print(f\"Changed to project directory: {os.getcwd().split('/')[-1]}\")\n",
    "\n",
    "# Add necessary paths for daqr package discovery\n",
    "sys.path.append(os.path.join(os.getcwd(), 'src'))\n",
    "sys.path.append(os.getcwd())  # Add current directory to find daqr package\n",
    "\n",
    "print(f\"Now working from: {os.getcwd().split('/')[-1]}\")\n",
    "\n",
    "# --- Framework Verification ---\n",
    "print(\"Framework dependencies installed successfully\")\n",
    "print(f\"Python version: {sys.version.split()[0]}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"NetworkX version: {nx.__version__}\")\n",
    "print(f\"Matplotlib version: {plt.matplotlib.__version__}\")\n",
    "print(\"Quantum MAB Models Evaluation Framework - Ready for Paper 7 (QBGP) testing\")\n",
    "\n",
    "# --- Cleanup Script Execution ---\n",
    "root = os.path.abspath(\"../..\")\n",
    "cleanup_script = os.path.join(root, \"cleanup_state_duplicates.py\")\n",
    "if os.path.exists(cleanup_script):\n",
    "    print(f\"\\nüöø Running cleanup script at: {cleanup_script}\\n\")\n",
    "    result = subprocess.run([\"python3\", cleanup_script], text=True, capture_output=True)\n",
    "    print(\"===== CLEANUP STDOUT =====\\n\", result.stdout)\n",
    "    print(\"===== CLEANUP STDERR =====\\n\", result.stderr)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Cleanup script not found, skipping...\")\n",
    "\n",
    "# --- Deep Cleanup ---\n",
    "def deep_cleanup():\n",
    "    to_clear = [\"oracle\", \"gneuralucb\", \"expneuralucb\", \"cpursuitneuralucb\",\n",
    "                \"icpursuitneuralucb\", \"evaluator\", \"results\"]\n",
    "    for name in to_clear:\n",
    "        if name in globals():\n",
    "            obj = globals().get(name)\n",
    "            if hasattr(obj, \"cleanup\"): obj.cleanup(verbose=False)\n",
    "            globals().pop(name, None)\n",
    "    gc.collect()\n",
    "    torch.set_default_dtype(torch.float32)\n",
    "    if torch.cuda.is_available(): torch.cuda.empty_cache()\n",
    "    print(\"‚úì Deep cleanup complete (memory cleared)\")\n",
    "\n",
    "deep_cleanup()\n",
    "\n",
    "# Ensure daqr package is discoverable\n",
    "PARENT_DIR = os.path.abspath(\"..\")\n",
    "if PARENT_DIR not in sys.path:\n",
    "    sys.path.insert(0, PARENT_DIR)\n",
    "    \n",
    "# Verify daqr package can be found\n",
    "try:\n",
    "    import daqr\n",
    "    print(\"‚úì daqr package found successfully\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå daqr package not found: {e}\")\n",
    "    print(f\"Current directory: {os.getcwd()}\")\n",
    "    print(f\"Python path includes: {[p for p in sys.path if 'GA-Work' in p or 'daqr' in p]}\")\n",
    "    print(\"Please ensure you're running from the Dynamic_Routing_Eval_Framework directory\")\n",
    "\n",
    "# --- Final Module Setup ---\n",
    "from daqr.core.quantum_physics              import (MemoryNoiseModel, FullPaper2FidelityCalculator)\n",
    "from daqr.evaluation                        import experiment_runner, multi_run_evaluator, visualizer\n",
    "from daqr.config                            import experiment_config\n",
    "from daqr.algorithms                        import base_bandit, neural_bandits, predictive_bandits\n",
    "from daqr.core                              import network_environment, qubit_allocator\n",
    "from daqr.config.experiment_config          import ExperimentConfiguration\n",
    "from experiments                            import stochastic_evaluation\n",
    "from daqr.core.network_environment          import *\n",
    "from daqr.core.qubit_allocator              import *\n",
    "from daqr.algorithms.base_bandit            import *\n",
    "from daqr.algorithms.neural_bandits         import *\n",
    "from daqr.algorithms.predictive_bandits     import *\n",
    "from daqr.evaluation.multi_run_evaluator    import *\n",
    "from daqr.evaluation.experiment_runner      import *\n",
    "\n",
    "# ============================================================================\n",
    "# PAPER-SPECIFIC IMPORTS\n",
    "# ============================================================================\n",
    "from daqr.core.topology_generator           import Paper2TopologyGenerator\n",
    "from daqr.core.topology_generator           import Paper7ASTopologyGenerator  # üÜï Paper 7\n",
    "from daqr.core.topology_generator           import Paper12WaxmanTopologyGenerator\n",
    "from daqr.core.quantum_physics              import FiberLossNoiseModel\n",
    "from daqr.core.quantum_physics              import FusionNoiseModel, FusionFidelityCalculator\n",
    "from daqr.core.quantum_physics              import Paper12RetryFidelityCalculator\n",
    "from daqr.core.quantum_physics              import Paper7RewardFunction  # üÜï Paper 7\n",
    "from daqr.core                              import attack_strategy\n",
    "\n",
    "print(\"‚úì All modules reloaded successfully (Paper 7 environment ready)\")\n",
    "\n",
    "# --- Config & Model Setup ---\n",
    "for module in [experiment_config, network_environment, qubit_allocator, attack_strategy, base_bandit, \n",
    "               neural_bandits, predictive_bandits, experiment_runner, multi_run_evaluator, visualizer, \n",
    "               stochastic_evaluation]:\n",
    "    importlib.reload(module)\n",
    "\n",
    "config = ExperimentConfiguration()\n",
    "models = config.NEURAL_MODELS\n",
    "\n",
    "# ============================================================================\n",
    "# FRAMEWORK CONFIGURATION\n",
    "# ============================================================================\n",
    "FRAMEWORK_CONFIG = {\n",
    "    'exp_num': 5,\n",
    "    'test_mode': True,\n",
    "    'base_frames': 4000,\n",
    "    'frame_step': 2000,\n",
    "    'models': models,\n",
    "    'intensity': 0.25,\n",
    "    'routing_strategy': 'fixed',\n",
    "    'capacity': 10000,\n",
    "    'main_env': 'stochastic',\n",
    "\n",
    "    # Environment parameters\n",
    "    'env_attrs': {\n",
    "        'intensity': 0.25,  # Natural failure rate for stochastic\n",
    "        'base_seed': 12345,\n",
    "        'reproducible': True\n",
    "    },\n",
    "\n",
    "    'default': {\n",
    "        'num_paths': 4,\n",
    "        'total_qubits': 35,\n",
    "        'min_qubits_per_route': 2,\n",
    "        'exploration_bonus': 2.0,\n",
    "        'epsilon': 1.0,\n",
    "        'seed': 42\n",
    "    },\n",
    "    \n",
    "    # ========================================================================\n",
    "    # Paper #2 (Chaudhary et al. 2023) - EXACT REPLICATION\n",
    "    # ========================================================================\n",
    "    # This configuration matches the original MATLAB code exactly\n",
    "    'paper2': {\n",
    "        # Topology & Paths (from QNetworkGraph_LearningAlgo.m)\n",
    "        'num_paths': 8,              # ‚úÖ CRITICAL: Original uses No_of_arms = 8\n",
    "        'num_nodes': 15,             # No_of_nodes = 15\n",
    "        'source_node': 1,            # ‚úÖ Python 0-indexed: node 1 = MATLAB node 2\n",
    "        'dest_node': 14,             # ‚úÖ Python 0-indexed: node 14 = MATLAB node 15\n",
    "        'total_qubits': 35,\n",
    "        \n",
    "        # Core Physics Parameters (from QNetworkGraph_LearningAlgo.m lines 80-88)\n",
    "        'p_init': 0.00001,           # ‚úÖ Probability of loss after generation\n",
    "        'f_attenuation': 0.05,       # ‚úÖ Fiber loss attenuation (dB/km)\n",
    "        'p_BSM': 0.2,                # ‚úÖ BSM operation error probability\n",
    "        'p_GateErrors': 0.2,         # ‚úÖ Gate error probability\n",
    "        \n",
    "        # Physical Constants (from QNetworkGraph_LearningAlgo.m)\n",
    "        'r_dephase': 10000,          # ‚úÖ Memory dephasing rate\n",
    "        'c_light': 3.0e8,            # ‚úÖ Speed of light (m/s)\n",
    "        't_BSM': 10e-9,              # ‚úÖ BSM operation time (10 ns)\n",
    "        't_d': 10e-9,                # ‚úÖ Gate operation time (10 ns)\n",
    "        'refractive_index': 1.5,     # ‚úÖ Fiber refractive index\n",
    "        \n",
    "        # Framework Parameters\n",
    "        'exploration_bonus': 2.0,\n",
    "        'min_qubits_per_route': 2,\n",
    "        'use_paper2_rewards': True,\n",
    "        \n",
    "        # Experiment Parameters (from QNetworkGraph_LearningAlgo.m lines 110-111)\n",
    "        'rounds': 1200,              # ‚úÖ Original experiment length\n",
    "        'experiments': 100,          # ‚úÖ Original number of experiments\n",
    "        \n",
    "        # State Management\n",
    "        'testbed': 'paper2',\n",
    "    },\n",
    "    \n",
    "    # ========================================================================\n",
    "    # Paper #2 Extended (Your Enhanced Version)\n",
    "    # ========================================================================\n",
    "    # This version includes your extensions: memory decay, async swapping, etc.\n",
    "    'paper2_extended': {\n",
    "        # Topology & Paths\n",
    "        'num_paths': 8,\n",
    "        'num_nodes': 15,\n",
    "        'source_node': 1,            # ‚úÖ Python 0-indexed: node 1 = MATLAB node 2\n",
    "        'dest_node': 14,             # ‚úÖ Python 0-indexed: node 14 = MATLAB node 15\n",
    "        'total_qubits': 35,          # Extended capacity\n",
    "        \n",
    "        # Core Physics (from original Paper 2)\n",
    "        'p_init': 0.00001,\n",
    "        'f_attenuation': 0.05,\n",
    "        'p_BSM': 0.2,\n",
    "        'p_GateErrors': 0.2,\n",
    "        \n",
    "        # Physical Constants (from original Paper 2)\n",
    "        'r_dephase': 10000,\n",
    "        'c_light': 3.0e8,\n",
    "        't_BSM': 10e-9,\n",
    "        't_d': 10e-9,\n",
    "        'refractive_index': 1.5,\n",
    "        \n",
    "        # ‚ö†Ô∏è YOUR EXTENSIONS (not in original Paper 2)\n",
    "        'p_depol': 0.1,              # ‚ö†Ô∏è Added: Depolarization noise\n",
    "        'memory_T2': 5000,           # ‚ö†Ô∏è Added: T2 coherence time\n",
    "        'swap_mode': 'async',        # ‚ö†Ô∏è Added: Asynchronous swapping\n",
    "        'swap_delay_per_link': 100,  # ‚ö†Ô∏è Added: Per-link swap delay\n",
    "        'gate_error_rate': 0.02,     # ‚ö†Ô∏è Added: Additional gate errors\n",
    "        'use_gate_error': True,      # ‚ö†Ô∏è Added: Enable gate error model\n",
    "        'use_memory_decay': True,    # ‚ö†Ô∏è Added: Enable memory decay\n",
    "        \n",
    "        # State Configuration\n",
    "        'testbed': 'paper2_extended',\n",
    "        'initial_state': 'idle',\n",
    "        'state_total_qubits': {'busy': 35, 'idle': 43},\n",
    "        \n",
    "        # Bandit Algorithm\n",
    "        'exploration_bonus': 2.0,\n",
    "        'min_qubits_per_route': 2,\n",
    "        'transition_trigger': True,\n",
    "        'paper2_transition_interval': 50,\n",
    "        'entanglement_success_factor': 4000,\n",
    "        'use_paper2_rewards': True,\n",
    "    },\n",
    "\n",
    "    # Paper #7 (Liu et al. 2024 - QBGP)\n",
    "    'paper7': {\n",
    "        'k': 5,                      # k-shortest paths per ISP pair\n",
    "        'n_qisps': 3,                # Number of ISP nodes\n",
    "        'num_paths': 4,              # Total paths (NOT 8)\n",
    "        'max_nodes': None,           # Use all 342 nodes from file\n",
    "        'total_qubits': 35,          # Your framework default\n",
    "        'network_scale': 'small',\n",
    "        'min_qubits_per_route': 2,\n",
    "        'reward_mode': 'neg_hop',    # or 'neg_length', etc.\n",
    "        'topology_path': '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/core/topology_data/as20000101.txt',\n",
    "\n",
    "\n",
    "        # üÜï NEW: Feature toggles\n",
    "        'use_context_rewards': True,      # Enable context-aware reward function\n",
    "        # 'reward_mode': 'neg_hop',         # 'neg_hop', 'neg_degree', 'neg_length', 'custom'\n",
    "        'use_synthetic': False,           # Force synthetic topology (ignore \n",
    "    },\n",
    "    \n",
    "    # Paper #12 (Wang et al. 2024 - QuARC)\n",
    "    'paper12': {\n",
    "        # Topology\n",
    "        'n_nodes': 100,              # Vary: 100-800\n",
    "        'avg_degree': 6,             # Ed (average degree)\n",
    "        'waxman_beta': 0.2,\n",
    "        'waxman_alpha': 0.4,\n",
    "        'topology_type': 'waxman',\n",
    "        \n",
    "        # Physical parameters\n",
    "        'channel_width': 3,          # Links per edge\n",
    "        'fusion_prob': 0.9,          # q (fusion success)\n",
    "        'qubits_per_node': 12,       # Memory capacity\n",
    "        'entanglement_prob': 0.6,    # Ep (average p)\n",
    "        \n",
    "        # Simulation parameters\n",
    "        'num_sd_pairs': 10,          # nsd (concurrent requests)\n",
    "        'epoch_length': 500,         # Reconfiguration interval\n",
    "        'total_timeslots': 7000,     # T\n",
    "        \n",
    "        # QuARC-specific\n",
    "        'split_constant': 4,         # k (Girvan-Newman)\n",
    "        'enable_clustering': True,\n",
    "        'enable_secondary_fusions': True,\n",
    "        \n",
    "        # Framework mapping\n",
    "        'num_paths': 4,              # For bandit comparison\n",
    "        'total_qubits': 120,         # 12 qubits/node √ó 10 nodes (estimated)\n",
    "        'exploration_bonus': 1.5,    # Lower for clustering\n",
    "        'min_qubits_per_route': 3,   # Higher for fusion-based\n",
    "        'use_fusion_rewards': True,\n",
    "\n",
    "        'time_decay_physics': {\n",
    "            'memory_lifetime': 0.5\n",
    "        },\n",
    "\n",
    "\n",
    "        # NEW: Paper12 retry parameters\n",
    "        'retry_threshold': 0.7,\n",
    "        'max_retry_attempts': 3,\n",
    "        'retry_decay_rate': 0.95,\n",
    "        'enable_retry_logging': True,\n",
    "        'retry_cost_per_attempt': 0.1,\n",
    "    }\n",
    "}\n",
    "\n",
    "# --- Test Scenarios ---\n",
    "if FRAMEWORK_CONFIG['main_env'] == 'stochastic':\n",
    "    test_scenarios = {\n",
    "        'stochastic': 'Stochastic Random Failures',\n",
    "        'markov': 'Markov Adversarial Attack',\n",
    "        'adaptive': 'Adaptive Adversarial Attack',\n",
    "        'onlineadaptive': 'Online Adaptive Attack',\n",
    "        'none': 'Baseline (Optimal Conditions)'\n",
    "    }\n",
    "    evaluation_type = \"STOCHASTIC-FOCUSED\"\n",
    "else:\n",
    "    test_scenarios = {'stochastic': 'Stochastic (Natural Network Failures)', 'adaptive': 'Adversarial (Strategic Attacks)'}\n",
    "    evaluation_type = \"COMPARATIVE\"\n",
    "\n",
    "# --- Display Configuration ---\n",
    "print(\"=\" * 70)\n",
    "print(\"DYNAMIC ROUTING EVALUATION FRAMEWORK - MULTI-TESTBED CONFIGURATION\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Available Testbeds:\")\n",
    "print(f\"  ‚Ä¢ Paper 2 (Chaudhary 2023) - Exact replication + Extended version\")\n",
    "print(f\"  ‚Ä¢ Paper 7 (Liu 2024) - QBGP Multi-ISP Routing\")\n",
    "print(f\"  ‚Ä¢ Paper 12 (Wang 2024) - QuARC Fusion-based Allocation\")\n",
    "print(f\"\\nPaper 2 Configurations:\")\n",
    "print(f\"  ‚Ä¢ 'paper2': Exact MATLAB replication (nodes 0-14, source=1‚Üídest=14)\")\n",
    "print(f\"    [Python 0-indexed translation of MATLAB nodes 1-15, source=2‚Üídest=15]\")\n",
    "print(f\"  ‚Ä¢ 'paper2_extended': Enhanced version (memory decay, async swapping)\")\n",
    "print(f\"\\nModels to evaluate: {len(models)} total\")\n",
    "print(\"\\n‚úì Configuration loaded successfully - Ready for evaluation\")\n",
    "print(\"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "stochastic-vs-adversarial"
   },
   "source": [
    "## Comparative Analysis Framework: Stochastic versus Adversarial Environments\n",
    "\n",
    "### Research Focus\n",
    "\n",
    "This evaluation constitutes the primary empirical contribution of the research: systematic quantification of algorithm performance across fundamentally different operational conditions that distinguish between natural system failures and intentional strategic attacks.\n",
    "\n",
    "### Environmental Characterization\n",
    "\n",
    "**Stochastic Environment**\n",
    "- **Operational Model**: Natural random failures representing realistic network degradation patterns\n",
    "- **Attack Distribution**: Probabilistic failures following uniform random distribution\n",
    "- **Research Significance**: Establishes baseline performance metrics under standard operational conditions\n",
    "\n",
    "**Adversarial Environment**  \n",
    "- **Operational Model**: Strategic intelligent attacks systematically targeting algorithmic decision-making processes\n",
    "- **Attack Distribution**: Adaptive targeting mechanisms that dynamically respond to observed algorithm behavior\n",
    "- **Research Significance**: Evaluates robustness under worst-case strategic threat scenarios\n",
    "\n",
    "### Experimental Predictions\n",
    "\n",
    "Based on the theoretical analysis and algorithm architecture, the following empirical outcomes are anticipated:\n",
    "\n",
    "**Performance Superiority Hypothesis**\n",
    "EXPNeuralUCB will demonstrate measurably superior performance retention in adversarial environments relative to baseline neural bandit algorithms lacking specialized adversarial robustness mechanisms.\n",
    "\n",
    "**Bounded Degradation Hypothesis**\n",
    "Performance degradation under adversarial conditions will remain within acceptable operational limits, specifically maintaining performance within 85% of stochastic environment baselines.\n",
    "\n",
    "**Stability Hypothesis**\n",
    "Algorithm performance rankings will exhibit stability across varying adversarial attack intensities, indicating consistent robustness characteristics rather than scenario-dependent performance fluctuations.\n",
    "\n",
    "### Research Methodology\n",
    "\n",
    "The comparative analysis employs identical experimental conditions across both environments, enabling precise quantification of performance degradation attributable to adversarial targeting while controlling for environmental variables and maintaining statistical rigor in the evaluation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PAPER 7 HELPER FUNCTIONS\n",
    "# ============================================================================\n",
    "from daqr.core.quantum_physics import AdaptedPaper2FidelityCalculator, StochasticPaper2NoiseModel\n",
    "\n",
    "\n",
    "def generate_paper7_paths(topology, k: int, n_qisps: int, seed: int):\n",
    "    \"\"\"Generate k-shortest paths between n_qisps ISP nodes.\"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    nodes = list(topology.nodes())\n",
    "\n",
    "    if len(nodes) < n_qisps: raise ValueError(f\"Topology has {len(nodes)} nodes, need {n_qisps} for ISPs\")\n",
    "    isp_nodes = rng.choice(nodes, size=n_qisps, replace=False)\n",
    "    all_paths = []\n",
    "\n",
    "    for src, dst in itertools.combinations(isp_nodes, 2):\n",
    "        try:\n",
    "            path_generator = nx.shortest_simple_paths(topology, src, dst, weight='distance')\n",
    "            paths = list(itertools.islice(path_generator, k))\n",
    "            all_paths.extend(paths)\n",
    "        except nx.NetworkXNoPath:   continue\n",
    "    return all_paths\n",
    "\n",
    "\n",
    "def generate_paper7_contexts(paths, topology):\n",
    "    \"\"\"Generate context vectors for each path (hop_count, avg_degree, path_length).\"\"\"\n",
    "    contexts = []\n",
    "    \n",
    "    for path in paths:\n",
    "        hop_count = len(path) - 1\n",
    "        degrees = [topology.degree(node) for node in path]\n",
    "        avg_degree = sum(degrees) / len(degrees) if degrees else 0.0\n",
    "\n",
    "        path_length = 0.0\n",
    "        for i in range(len(path) - 1):\n",
    "            edge_data = topology.get_edge_data(path[i], path[i+1])\n",
    "            path_length += edge_data.get('distance', 1.0)\n",
    "\n",
    "        context_vector = np.array([hop_count, avg_degree, path_length])\n",
    "        contexts.append([context_vector])\n",
    "    return contexts\n",
    "\n",
    "\n",
    "def get_physics_params_paper12(config, seed, qubit_cap):\n",
    "    \"\"\"\n",
    "    Paper #12 (Waxman + QuARC) physics adapter.\n",
    "    Returns: {external_topology, external_contexts, external_rewards, noise_model, fidelity_calculator}\n",
    "    \"\"\"\n",
    "    topology = Paper12WaxmanTopologyGenerator().generate()\n",
    "    num_paths = 4\n",
    "    nodes = list(topology.nodes())\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    # Find 4 paths\n",
    "    paths = []\n",
    "    attempts = 0\n",
    "    max_attempts = 10 * num_paths\n",
    "    \n",
    "    while len(paths) < num_paths and attempts < max_attempts:\n",
    "        attempts += 1\n",
    "        src, dst = rng.choice(nodes, 2, replace=False)\n",
    "        try:\n",
    "            path = nx.shortest_path(topology, src, dst)\n",
    "            if path not in paths:   paths.append(path)\n",
    "        except nx.NetworkXNoPath:   continue\n",
    "    if len(paths) < num_paths:  raise RuntimeError(f\"Could not find {num_paths} valid paths in Waxman topology\")\n",
    "\n",
    "    # Physics models\n",
    "    fusion_prob = float(config.get(\"fusion_prob\", 0.9))\n",
    "    entanglement_prob = float(config.get(\"entanglement_prob\", 0.6))\n",
    "    noise_model = FusionNoiseModel(topology=topology, paths=paths, fusion_prob=fusion_prob, entanglement_prob=entanglement_prob)\n",
    "    fidelity_calc = FusionFidelityCalculator()\n",
    "    reward_func = QuARCRewardFunction()\n",
    "\n",
    "    # Contexts: 4 arrays with shapes (8,3), (10,3), (8,3), (9,3)\n",
    "    external_contexts = []\n",
    "    arms_per_path = [8, 10, 8, 9]\n",
    "    degrees = dict(topology.degree())\n",
    "    max_degree = max(degrees.values()) if degrees else 1.0\n",
    "\n",
    "    for p_idx, K in enumerate(arms_per_path):\n",
    "        path = paths[p_idx]\n",
    "        hop_count = len(path) - 1\n",
    "        path_degrees = [degrees[n] for n in path]\n",
    "        avg_degree = float(sum(path_degrees) / len(path_degrees))\n",
    "        f2_deg_norm = avg_degree / max_degree if max_degree > 0 else 0.0\n",
    "        ctx = np.full((K, 3), [float(hop_count), f2_deg_norm, fusion_prob], dtype=float)\n",
    "        external_contexts.append(ctx)\n",
    "\n",
    "    # Rewards: 4 lists with lengths [8,10,8,9]\n",
    "    external_rewards = []\n",
    "    for p_idx, K in enumerate(arms_per_path):\n",
    "        path = paths[p_idx]\n",
    "        err_info = noise_model.get_error_rates(p_idx)\n",
    "        base_fidelity = fidelity_calc.compute_path_fidelity(err_info, context=None, fusion_prob=fusion_prob)\n",
    "        base_fidelity = float(np.clip(base_fidelity, 0.0, 1.0))\n",
    "\n",
    "        path_rewards = []\n",
    "        for _ in range(K):\n",
    "            success = rng.random() < base_fidelity\n",
    "            r = reward_func.compute_reward(success=success, aggregate_throughput=1)\n",
    "            path_rewards.append(float(r))\n",
    "        \n",
    "        external_rewards.append(path_rewards)\n",
    "    return {\n",
    "        \"external_topology\": topology, \"external_contexts\": external_contexts,\n",
    "        \"external_rewards\": external_rewards, \"noise_model\": noise_model, \"fidelity_calculator\": fidelity_calc,\n",
    "    }\n",
    "\n",
    "\n",
    "def get_physics_params(\n",
    "    physics_model: str = \"default\",\n",
    "    current_frames: int = 4000,\n",
    "    base_seed: int = 42,\n",
    "    qubit_cap=None,\n",
    "    *,\n",
    "    topology: \"nx.Graph | None\" = None,\n",
    "    topology_model: str | None = None,\n",
    "    topology_path: str | Path | None = None,\n",
    "    topology_max_nodes: int | None = None,\n",
    "    topology_largest_cc_only: bool = True,\n",
    "    topology_relabel_to_int: bool = True,\n",
    "    synthetic_kind: str = \"barabasi_albert\",\n",
    "    synthetic_params: dict | None = None,\n",
    "):\n",
    "    \"\"\"Returns: {noise_model, fidelity_calculator, external_topology, external_contexts, external_rewards}\"\"\"\n",
    "\n",
    "    if physics_model == \"paper7\":\n",
    "        paper7_cfg = FRAMEWORK_CONFIG['paper7']\n",
    "        node_num = paper7_cfg.get('max_nodes')\n",
    "\n",
    "        if topology is not None:    final_topology = topology\n",
    "        else:\n",
    "            if paper7_cfg.get('use_synthetic', False) or not paper7_cfg.get('topology_path'):\n",
    "                topo_gen = Paper7ASTopologyGenerator(\n",
    "                    edge_list_path=\"dummy_nonexistent.txt\",\n",
    "                    max_nodes=topology_max_nodes or node_num,\n",
    "                    seed=base_seed,\n",
    "                    synthetic_fallback=True,\n",
    "                    synthetic_kind=\"barabasi_albert\",\n",
    "                    synthetic_params={\"n\": node_num or 100, \"m\": 3}\n",
    "                )\n",
    "                print(f\"üìä Paper7 Topology: Synthetic (Barab√°si-Albert, n={node_num or 100})\")\n",
    "            else:\n",
    "                topo_gen = Paper7ASTopologyGenerator(\n",
    "                    edge_list_path=paper7_cfg['topology_path'],\n",
    "                    max_nodes=node_num,\n",
    "                    seed=base_seed,\n",
    "                    relabel_to_integers=topology_relabel_to_int,\n",
    "                    largest_cc_only=topology_largest_cc_only,\n",
    "                    synthetic_fallback=True\n",
    "                )\n",
    "                print(f\"üìä Paper7 Topology: Real AS ({paper7_cfg['topology_path']})\")\n",
    "            final_topology = topo_gen.generate()\n",
    "\n",
    "        k = paper7_cfg[\"k\"]\n",
    "        n_qisps = paper7_cfg[\"n_qisps\"]\n",
    "        paths = generate_paper7_paths(final_topology, k, n_qisps, base_seed)\n",
    "        contexts = generate_paper7_contexts(paths, final_topology)\n",
    "        print(f\"üìä Paper7 Paths: {len(paths)} paths from {k}-shortest between {n_qisps} ISPs\")\n",
    "\n",
    "        external_rewards = None\n",
    "        if paper7_cfg.get('use_context_rewards', False):\n",
    "            reward_mode = paper7_cfg.get('reward_mode', 'neg_hop')\n",
    "            reward_func = Paper7RewardFunction(mode=reward_mode)\n",
    "            external_rewards = []\n",
    "            for ctx_list in contexts:\n",
    "                path_rewards = [reward_func.compute(ctx) for ctx in ctx_list]\n",
    "                external_rewards.append(path_rewards)\n",
    "            print(f\"üìä Paper7 Rewards: Context-aware (mode={reward_mode})\")\n",
    "        else:   print(f\"üìä Paper7 Rewards: Using default framework rewards\")\n",
    "\n",
    "        return {\n",
    "            \"noise_model\": None,\n",
    "            \"fidelity_calculator\": None,\n",
    "            \"external_topology\": final_topology,\n",
    "            \"external_contexts\": contexts,\n",
    "            \"external_rewards\": external_rewards\n",
    "        }\n",
    "    \n",
    "    elif physics_model == \"paper2\":\n",
    "        p2_config = FRAMEWORK_CONFIG[\"paper2\"]\n",
    "        topo_gen = Paper2TopologyGenerator(num_nodes=p2_config[\"num_nodes\"], seed=base_seed)\n",
    "        topo = topo_gen.generate()\n",
    "        \n",
    "        try:\n",
    "            path_generator = nx.shortest_simple_paths(topo, p2_config[\"source_node\"], p2_config[\"dest_node\"], weight=\"distance\")\n",
    "            paths = list(itertools.islice(path_generator, p2_config[\"num_paths\"]))\n",
    "        except nx.NetworkXNoPath:\n",
    "            paths = [[p2_config[\"source_node\"], p2_config[\"dest_node\"]]] * p2_config[\"num_paths\"]\n",
    "        \n",
    "        # ‚úÖ NEW: Pass ALL Paper 2 physical constants to noise model\n",
    "        noise_model = StochasticPaper2NoiseModel(\n",
    "            topology=topo,\n",
    "            paths=paths,\n",
    "            p_init=p2_config.get(\"p_init\", 0.00001),\n",
    "            f_attenuation=p2_config.get(\"f_attenuation\", 0.05),\n",
    "            p_BSM=p2_config.get(\"p_BSM\", 0.2),\n",
    "            p_GateErrors=p2_config.get(\"p_GateErrors\", 0.2),\n",
    "            p_depol=p2_config.get(\"p_depol\", 0.1),\n",
    "            # ‚úÖ Paper 2 physical constants (enables time-based decay)\n",
    "            r_dephase=p2_config.get(\"r_dephase\"),\n",
    "            c_light=p2_config.get(\"c_light\"),\n",
    "            t_BSM=p2_config.get(\"t_BSM\"),\n",
    "            t_d=p2_config.get(\"t_d\"),\n",
    "            refractive_index=p2_config.get(\"refractive_index\")\n",
    "        )\n",
    "        \n",
    "        # ‚úÖ Use ADAPTER instead of Full calculator directly\n",
    "        if p2_config.get('use_memory_decay', False):\n",
    "            memory_model = MemoryNoiseModel(\n",
    "                T2=p2_config.get(\"memory_T2\", 5000),\n",
    "                swap_delay_per_link=p2_config.get(\"swap_delay_per_link\", 100)\n",
    "            )\n",
    "            if p2_config.get(\"swap_mode\", \"sync\") == \"sync\":\n",
    "                memory_model = None  # Sync doesn't need memory tracking\n",
    "        else:\n",
    "            memory_model = None\n",
    "        \n",
    "        fidelity_calc = AdaptedPaper2FidelityCalculator(\n",
    "            noise_model=noise_model,\n",
    "            gate_error_rate=p2_config.get(\"gate_error_rate\", 0.02) if p2_config.get('use_gate_error', False) else 0.0,\n",
    "            memory_model=memory_model\n",
    "        )\n",
    "        \n",
    "        # ‚úÖ Log which physics mode is active\n",
    "        physics_mode = []\n",
    "        if noise_model.use_time_based_decay:\n",
    "            physics_mode.append(\"Time-based decay\")\n",
    "        if memory_model:\n",
    "            physics_mode.append(\"T2 memory\")\n",
    "        physics_status = \" + \".join(physics_mode) if physics_mode else \"Basic stochastic\"\n",
    "        \n",
    "        print(f\"üìä Paper2 Physics: {physics_status}\")\n",
    "        if noise_model.use_time_based_decay:\n",
    "            print(f\"   ‚úì Using MATLAB constants: r_dephase={p2_config.get('r_dephase')}, c_light={p2_config.get('c_light')}\")\n",
    "        \n",
    "        return {\n",
    "            \"noise_model\": noise_model,\n",
    "            \"fidelity_calculator\": fidelity_calc,\n",
    "            \"external_topology\": topo,\n",
    "            \"external_contexts\": None,\n",
    "            \"external_rewards\": None\n",
    "        }\n",
    "\n",
    "\n",
    "    elif physics_model == 'paper12':\n",
    "        p12config = FRAMEWORK_CONFIG['paper12']\n",
    "\n",
    "        decaycfg = p12config['time_decay_physics']\n",
    "        memlifetime = decaycfg['memory_lifetime']\n",
    "        # Get Paper12 physics\n",
    "        physics_params = get_physics_params_paper12(FRAMEWORK_CONFIG['paper12'], seed=base_seed, qubit_cap=qubit_cap)\n",
    "        base_fidelity_calc = physics_params['fidelity_calculator']\n",
    "        topology = physics_params['external_topology']\n",
    "        contexts = physics_params['external_contexts']\n",
    "        rewards = physics_params['external_rewards']\n",
    "        noise_model = physics_params['noise_model']\n",
    "        num_paths = len(contexts)\n",
    "        print(f\"Paper12 (QuARC) physics: {num_paths} paths, fusion_prob={FRAMEWORK_CONFIG['paper12']['fusion_prob']}\")\n",
    "\n",
    "        # Wrap with retry logic\n",
    "        fidelitycalc = Paper12RetryFidelityCalculator(\n",
    "            base_calculator=base_fidelity_calc,\n",
    "            threshold=p12config['retry_threshold'],\n",
    "            max_attempts=p12config['max_retry_attempts'],\n",
    "            decay_rate=p12config['retry_decay_rate']\n",
    "        )\n",
    "        \n",
    "        # üÜï NEW: Create metadata dict\n",
    "        metadata = {\n",
    "            'paper': 'Zhang2023Paper12',\n",
    "            'retry_enabled': True,\n",
    "            'retry_threshold': p12config['retry_threshold'],\n",
    "            'max_attempts': p12config['max_retry_attempts'],\n",
    "            'decay_rate': p12config['retry_decay_rate'],\n",
    "        }\n",
    "\n",
    "        physics_params['metadata'] = metadata,  # üÜï NEW: Safe - handled by __init__\n",
    "\n",
    "        return physics_params\n",
    "    # === DEFAULT ===\n",
    "    else: return {\"noise_model\": None, \"fidelity_calculator\": None, \"external_topology\": topology, \"external_contexts\": None, \"external_rewards\": None}\n",
    "\n",
    "\n",
    "\n",
    "def force_release_resources(evaluator=None, verbose=True):\n",
    "    \"\"\"Force release of ALL resources that could block. Call AFTER each allocator completes.\"\"\"\n",
    "    cleanup_log = []\n",
    "\n",
    "    # 1. Stop logging and close file handles\n",
    "    if evaluator is not None:\n",
    "        try:\n",
    "            if hasattr(evaluator, 'configs') and hasattr(evaluator.configs, 'backup_mgr'):\n",
    "                backup_mgr = evaluator.configs.backup_mgr\n",
    "                if hasattr(backup_mgr, 'stop_logging_redirect'): backup_mgr.stop_logging_redirect()\n",
    "                if hasattr(backup_mgr, '_log_file'):\n",
    "                    try:    backup_mgr._log_file.close()\n",
    "                    except: pass\n",
    "                if hasattr(backup_mgr, 'backup_registry'):  backup_mgr.backup_registry.clear()\n",
    "            cleanup_log.append(\"‚úÖ Backup manager cleaned\")\n",
    "        except Exception as e:  cleanup_log.append(f\"‚ö†Ô∏è Backup cleanup: {e}\")\n",
    "\n",
    "    # 2. Clear environment graphs\n",
    "    if evaluator is not None:\n",
    "        try:\n",
    "            if hasattr(evaluator, 'configs') and hasattr(evaluator.configs, 'environment'):\n",
    "                env = evaluator.configs.environment\n",
    "                if hasattr(env, 'topology') and hasattr(env.topology, 'clear'):\n",
    "                    env.topology.clear()\n",
    "                    del env.topology\n",
    "                if hasattr(env, 'paths'): env.paths = []\n",
    "            cleanup_log.append(\"‚úÖ Environment graphs cleared\")\n",
    "        except Exception as e: cleanup_log.append(f\"‚ö†Ô∏è Environment cleanup: {e}\")\n",
    "\n",
    "    # 3. Break circular references\n",
    "    if evaluator is not None:\n",
    "        try:\n",
    "            if hasattr(evaluator, 'configs'):\n",
    "                if hasattr(evaluator.configs, 'backup_mgr'): evaluator.configs.backup_mgr = None\n",
    "                if hasattr(evaluator.configs, 'environment'): evaluator.configs.environment = None\n",
    "                evaluator.configs = None\n",
    "            cleanup_log.append(\"‚úÖ Circular references broken\")\n",
    "        except Exception as e:  cleanup_log.append(f\"‚ö†Ô∏è Reference cleanup: {e}\")\n",
    "\n",
    "    # 4. Clear model registries\n",
    "    try:\n",
    "        import sys\n",
    "        for mod_name in list(sys.modules.keys()):\n",
    "            if 'bandit' in mod_name.lower() or 'neural' in mod_name.lower():\n",
    "                mod = sys.modules[mod_name]\n",
    "                if hasattr(mod, '_model_registry'): mod._model_registry.clear()\n",
    "                if hasattr(mod, '_global_models'):  mod._global_models.clear()\n",
    "        cleanup_log.append(\"‚úÖ Model registries cleared\")\n",
    "    except Exception as e:  cleanup_log.append(f\"‚ö†Ô∏è Registry cleanup: {e}\")\n",
    "\n",
    "    # 5. Torch cleanup\n",
    "    try:\n",
    "        import torch\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "            torch.cuda.synchronize()\n",
    "        cleanup_log.append(\"‚úÖ Torch CUDA cleared\")\n",
    "    except Exception as e:  cleanup_log.append(f\"‚ö†Ô∏è Torch cleanup: {e}\")\n",
    "\n",
    "    # 6. Garbage collection\n",
    "    collected = [gc.collect() for _ in range(3)]\n",
    "    cleanup_log.append(f\"‚úÖ GC collected: {sum(collected)} objects\")\n",
    "\n",
    "    # 7. Close file descriptors\n",
    "    try:\n",
    "        import os\n",
    "        import psutil\n",
    "        process = psutil.Process()\n",
    "        for f in process.open_files():\n",
    "            if any(ext in f.path for ext in ['.pkl', '.log', '.csv']):\n",
    "                try:    os.close(f.fd)\n",
    "                except: pass\n",
    "        cleanup_log.append(\"‚úÖ File descriptors closed\")\n",
    "    except Exception as e:  cleanup_log.append(f\"‚ö†Ô∏è FD cleanup: {e}\")\n",
    "\n",
    "    # 8. Delete evaluator and final collection\n",
    "    if evaluator is not None:   del evaluator\n",
    "    gc.collect(2)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"üßπ FORCED RESOURCE RELEASE\")\n",
    "        print(\"=\"*70)\n",
    "        for log in cleanup_log: print(log)\n",
    "        print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ============================================================\n",
    "# # Cell 2: Allocator + ExperimentConfiguration for Paper #2\n",
    "# # ============================================================\n",
    "# importlib.reload(qubit_allocator)\n",
    "# importlib.reload(experiment_config)\n",
    "# importlib.reload(multi_run_evaluator)\n",
    "\n",
    "# from daqr.core.quantum_physics              import *\n",
    "# from daqr.core.qubit_allocator              import (\n",
    "#                                                 QubitAllocator,\n",
    "#                                                 RandomQubitAllocator,\n",
    "#                                                 DynamicQubitAllocator,\n",
    "#                                                 ThompsonSamplingAllocator\n",
    "#                                             )\n",
    "\n",
    "# from daqr.evaluation.allocator_runner       import AllocatorRunner\n",
    "# from daqr.evaluation.multi_run_evaluator    import MultiRunEvaluator\n",
    "# from daqr.config.experiment_config          import ExperimentConfiguration\n",
    "\n",
    "\n",
    "\n",
    "# print(\"=\" * 70, \"\\nPAPER #2 QUANTUM MAB MODELS EVALUATION FRAMEWORK - STOCHASTIC FOCUS\\n\", \"=\" * 70)\n",
    "# # ------------------------------------------------------------\n",
    "# # 1) Allocator selection (Paper #2: start with fixed baseline)\n",
    "# # ------------------------------------------------------------\n",
    "# # You can swap these as needed:\n",
    "# # allocator = RandomQubitAllocator(epsilon=0.5, seed=42)        # 50-50 mix\n",
    "# # allocator = RandomQubitAllocator(epsilon=0.1, seed=42)        # mostly baseline\n",
    "# # allocator = RandomQubitAllocator(epsilon=0.0, seed=42)        # deterministic\n",
    "# # allocator = DynamicQubitAllocator(seed=42)                    # dynamic UCB\n",
    "# # allocator = ThompsonSamplingAllocator(seed=42)                # Thompson\n",
    "\n",
    "# allocator_type =    \"Default\"\n",
    "# ALLOCATORS = [\"Default\"]\n",
    "\n",
    "\n",
    "# # ------------------------------------------------------------\n",
    "# # 2) Derive run parameters from FRAMEWORK_CONFIG (Cell 1)\n",
    "# # ------------------------------------------------------------\n",
    "# # current_frames      = FRAMEWORK_CONFIG['base_frames'] \n",
    "# # frame_step          = FRAMEWORK_CONFIG['frame_step']\n",
    "# # attack_intensity    = FRAMEWORK_CONFIG['intensity']\n",
    "# # current_experiments = FRAMEWORK_CONFIG['exp_num']\n",
    "\n",
    "# attack_intensity    = FRAMEWORK_CONFIG['intensity']\n",
    "# current_frames      = 50\n",
    "# frame_step          = 50\n",
    "# current_experiments = 1\n",
    "# last_backup         = False\n",
    "# base_cap            = False\n",
    "# overwrite           = False\n",
    "\n",
    "# # PHYSICS_MODELS = ['paper2', 'default']  # Set to ['default', 'paper2'] to test both\n",
    "# ATTACK_SCENARIOS = ['stochastic']  # Start simple, expand later\n",
    "# PHYSICS_MODELS = ['paper2']\n",
    "# # PHYSICS_MODELS = ['default']\n",
    "# ALLOCATORS = ['Default', 'Dynamic', 'ThompsonSampling', 'Random']\n",
    "# SCALES = [1]\n",
    "# RUNS = [1]\n",
    "\n",
    "\n",
    "# print(\"\\n\" + \"=\" * 70, \"\\nüéØ QUANTUM ROUTING ALLOCATOR EVALUATION\\n\", \"=\" * 70)\n",
    "# print(f\"Total Allocators to Test:   {len(ALLOCATORS)}\")\n",
    "# print(f\"Physics Models:             {PHYSICS_MODELS}\")\n",
    "# print(f\"Allocators:                 {ALLOCATORS}\")\n",
    "# print(f\"Scales:                     {SCALES}\")\n",
    "# print(f\"Runs:                       {RUNS}\")\n",
    "# print(\"=\" * 70)\n",
    "\n",
    "# # Run allocator\n",
    "# for allocator_type in ALLOCATORS:\n",
    "#     print(f\"\\n{'='*70}\")\n",
    "#     print(f\"RUNNING: {allocator_type} on Paper 2 (Chaudhary et al. 2023 - Quantum MAB)\")\n",
    "#     print('='*70)\n",
    "\n",
    "#     for scale in SCALES:\n",
    "#         print(f\"\\n{'-'*70}\")\n",
    "#         print(f\"Preparing: {allocator_type} at scale {scale}\")\n",
    "#         print(f\"{'-'*70}\")\n",
    "\n",
    "#         for physics_model in PHYSICS_MODELS:\n",
    "#             print(f\"\\nüîß Generating physics parameters for model: {physics_model}\") \n",
    "#             try:\n",
    "#                 # Create isolated runner instance\n",
    "#                 custom_config = ExperimentConfiguration(\n",
    "#                     env_type=FRAMEWORK_CONFIG['main_env'],\n",
    "#                     scenarios=test_scenarios,\n",
    "#                     use_last_backup=last_backup,\n",
    "#                     models=models,\n",
    "#                     attack_intensity=attack_intensity,\n",
    "#                     scale=scale,\n",
    "#                     base_capacity=base_cap,\n",
    "#                     overwrite=overwrite\n",
    "#                 )\n",
    "\n",
    "#                 alloc_runner = AllocatorRunner(\n",
    "#                     allocator_type=allocator_type,\n",
    "#                     physics_models=[physics_model],\n",
    "#                     framework_config=FRAMEWORK_CONFIG,\n",
    "#                     scales=[scale],\n",
    "#                     runs=RUNS,\n",
    "#                     models=models,\n",
    "#                     test_scenarios=test_scenarios,\n",
    "#                     config=custom_config\n",
    "#                 )\n",
    "\n",
    "#                 # Run with Paper 2 physics\n",
    "#                 alloc_runner.run(get_physics_params_func=get_physics_params)\n",
    "#                 print(f\"\\n{allocator_type} COMPLETED SUCCESSFULLY\")\n",
    "\n",
    "#             except Exception as e:\n",
    "#                 print(f\"\\n{allocator_type} FAILED: {e}\")\n",
    "#                 import traceback\n",
    "#                 traceback.print_exc()\n",
    "\n",
    "# print(\"\\n\" + \"=\" * 70)\n",
    "# print(\"ALL ALLOCATORS COMPLETE!\")\n",
    "# print(\"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================== \n",
      "PAPER #2 QUANTUM MAB MODELS EVALUATION FRAMEWORK - STOCHASTIC FOCUS\n",
      " ======================================================================\n",
      "\n",
      "====================================================================== \n",
      "üéØ QUANTUM ROUTING ALLOCATOR EVALUATION\n",
      " ======================================================================\n",
      "Total Allocators to Test:   4\n",
      "Physics Models:             ['paper2']\n",
      "Allocators:                 ['Default', 'Dynamic', 'ThompsonSampling', 'Random']\n",
      "Scales:                     [1, 1.5, 2]\n",
      "Runs:                       [5]\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "RUNNING: Default on Paper 2 (Chaudhary et al. 2023 - Quantum MAB)\n",
      "======================================================================\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Preparing: Default at scale 1\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üîß Generating physics parameters for model: paper2\n",
      "\n",
      "===================== GET LOCAL REGISTRY =====================\n",
      "‚Üí Skipping local cache (force=True or file missing)\n",
      "\n",
      "===================== BUILD LOCAL REGISTRY =====================\n",
      "\n",
      "================================================================================\n",
      "üîç SCANNING LOCAL FILES\n",
      "================================================================================\n",
      "Parameters: load_to_drive=False, force=False\n",
      "\n",
      "üìÇ Checking DRIVE mode: /content/drive/Shareddrives/ai_quantum_computing/quantum_data_lake\n",
      "   ‚ö†Ô∏è  Path does not exist, skipping\n",
      "\n",
      "üìÇ Checking LOCAL mode: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config\n",
      "   ‚úÖ Path exists, starting walk...\n",
      "   üö∂ Walking directory tree: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config\n",
      "\n",
      "   üìÅ Directory: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201\n",
      "      Relative: framework_state/day_20260201\n",
      "      Component: framework_state\n",
      "      Date: day_20260201\n",
      "      üìÑ Processing 2517 files in framework_state/day_20260201\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "      üìä framework_state/day_20260201: 2491/2517 files processed\n",
      "      üìä framework_state/day_20260201: 0/2517 files skipped\n",
      "      üìä framework_state/day_20260201: 26/2517 files conflicted\n",
      "\n",
      "   üìÅ Directory: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/model_state/day_20260201\n",
      "      Relative: model_state/day_20260201\n",
      "      Component: model_state\n",
      "      Date: day_20260201\n",
      "      üìÑ Processing 8859 files in model_state/day_20260201\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "      üìä model_state/day_20260201: 8859/8859 files processed\n",
      "      üìä model_state/day_20260201: 0/8859 files skipped\n",
      "      üìä model_state/day_20260201: 0/8859 files conflicted\n",
      "\n",
      "   üìä Processed 2 directories\n",
      "\n",
      "================================================================================\n",
      "üì¶ BUILDING FINAL REGISTRY\n",
      "================================================================================\n",
      "Components found: ['framework_state', 'model_state']\n",
      "  ‚Ä¢ framework_state: 2491 files\n",
      "  ‚Ä¢ model_state: 8859 files\n",
      "\n",
      "‚úÖ SCAN COMPLETE\n",
      "Modes scanned: 1\n",
      "Total files in registry: 11350\n",
      "================================================================================\n",
      "\n",
      "\t‚Üí Filesystem scan found 11350 files\n",
      "\n",
      "===================== GET DRIVE REGISTRY =====================\n",
      "===================== REGISTRY BUILD COMPLETE =====================\n",
      "\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "\tüì¶ LocalBackupManager Registry Saved Locally in LOCAL\n",
      "BUILDING REGISTRY WITH 0 EXPECTED COMPONENTS KEYS\n",
      "\n",
      "===================== GET LOCAL REGISTRY =====================\n",
      "‚Üí Skipping local cache (force=True or file missing)\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "\tüì¶ LocalBackupManager Registry Saved Locally in LOCAL\n",
      "\n",
      "======================================================================\n",
      "üéØ AllocatorRunner initialized: Default\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "üöÄ STARTING ALLOCATOR: Default\n",
      "======================================================================\n",
      "\n",
      "üìä Physics Model: paper2\n",
      "\n",
      "üìã Allocator Config:\n",
      "   Type: Default\n",
      "   Testbed: paper2\n",
      "   Paths: 8\n",
      "   Total Qubits: 35\n",
      "   Min per route: 2\n",
      "   Seed: 42\n",
      "‚úÖ Allocator created: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "‚úì Allocator: QubitAllocator (8 paths)\n",
      "   Initial allocation: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "Generated paper2 topology: 15 nodes, 51 edges\n",
      "üìä Paper2 Physics: Time-based decay\n",
      "   ‚úì Using MATLAB constants: r_dephase=10000, c_light=300000000.0\n",
      "\n",
      "======================================================================\n",
      "RUN 1 | Scale: 1 | Exp: 5\n",
      "======================================================================\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "No state found for MultiRunEvaluator, disabling resume for Experiment Runners\n",
      "Multi-Run Evaluator Initialized\n",
      "Environment Type: None\n",
      "Frame Range: 4000 -> 12000 (step: 2000)\n",
      "quantum_exps-Default(paper2)_alloc-all_envs-5_attacks-4000_2000-5_runs-S1T\n",
      "[Logging Redirect Initialized]\n",
      "Log File: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/quantum_logs/quantum_exps-Default(paper2)_alloc-all_envs-5_attacks-4000_2000-5_runs-S1T_20260201_log.txt\n",
      "‚öô Running evaluation...\n",
      "======================================================================\n",
      "SCENARIOS MODEL EVALUATION\n",
      "======================================================================\n",
      "Testing algorithm performance against:\n",
      "\t‚Ä¢ Stochastic:  \tNatural quantum decoherence and network failures\n",
      "\t‚Ä¢ Baseline:    \tOptimal conditions for validation\n",
      "======================================================================\n",
      "Models to Test:             \tOracle, GNeuralUCB, EXPNeuralUCB, CPursuitNeuralUCB, iCPursuitNeuralUCB\n",
      "Experiments per Scenario:   \t5\n",
      "======================================================================\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: STOCHASTIC RANDOM FAILURES\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: STOCHASTIC\n",
      "Category: Stochastic (Natural Random Failures)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 4000 frames  <>  SCALED-CAPACITY: 4000 frames (CAPACITY:4000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=0 ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 1: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 1: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:4000, QubitAlloc=Default, SC:4000 (Scale=1 x Cap=4000), Seed: 19730\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.38834376320949965], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 1: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 GNEURALUCB          : Reward=1345.58, Efficiency=084.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=4000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 1: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=1326.94, Efficiency=082.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=4000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 1: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=1325.46, Efficiency=082.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=4000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 1: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=1330.37, Efficiency=083.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=4000, Threshold=0.712]\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 1: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:4000, QubitAlloc=Default, SC:4000 (Scale=1 x Cap=4000), Seed: 19730\n",
      "\t-->üèÜ EXP1 Winner:GNeuralUCB          (Gap:016.0%) [Env:Stochastic, Attack:Random X Rate:0.0625, Frames:4000, SCapacity=4000, Alloc=Default]\n",
      "‚úì Experiment 1 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 6000 frames  <>  SCALED-CAPACITY: 6000 frames (CAPACITY:6000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=1 ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 2: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 2: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:6000, QubitAlloc=Default, SC:6000 (Scale=1 x Cap=6000), Seed: 17421\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.3758204606627883], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 2: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 GNEURALUCB          : Reward=1984.20, Efficiency=088.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 2: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=1996.02, Efficiency=088.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 2: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=1957.84, Efficiency=086.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 2: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=1958.95, Efficiency=086.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.712]\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 2: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:6000, QubitAlloc=Default, SC:6000 (Scale=1 x Cap=6000), Seed: 17421\n",
      "\t-->üèÜ EXP2 Winner:EXPNeuralUCB        (Gap:011.4%) [Env:Stochastic, Attack:Random X Rate:0.0625, Frames:6000, SCapacity=6000, Alloc=Default]\n",
      "‚úì Experiment 2 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 8000 frames  <>  SCALED-CAPACITY: 8000 frames (CAPACITY:8000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=2 ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 3: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 3: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:8000, QubitAlloc=Default, SC:8000 (Scale=1 x Cap=8000), Seed: 17649\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.4202961453677382], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 3: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 GNEURALUCB          : Reward=2849.14, Efficiency=085.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 3: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=2698.95, Efficiency=080.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 3: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=2839.56, Efficiency=084.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 3: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=2857.23, Efficiency=085.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.712]\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 3: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:8000, QubitAlloc=Default, SC:8000 (Scale=1 x Cap=8000), Seed: 17649\n",
      "\t-->üèÜ EXP3 Winner:iCPursuitNeuralUCB  (Gap:014.7%) [Env:Stochastic, Attack:Random X Rate:0.0625, Frames:8000, SCapacity=8000, Alloc=Default]\n",
      "‚úì Experiment 3 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 10000 frames  <>  SCALED-CAPACITY: 10000 frames (CAPACITY:10000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=3 ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 4: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 4: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:10000, QubitAlloc=Default, SC:10000 (Scale=1 x Cap=10000), Seed: 20670\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.40758880688060967], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 4: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 GNEURALUCB          : Reward=3514.27, Efficiency=086.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=10000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 4: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=3364.36, Efficiency=082.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=10000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 4: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=3463.75, Efficiency=085.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=10000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 4: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=3448.91, Efficiency=085.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=10000, Threshold=0.712]\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 4: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:10000, QubitAlloc=Default, SC:10000 (Scale=1 x Cap=10000), Seed: 20670\n",
      "\t-->üèÜ EXP4 Winner:GNeuralUCB          (Gap:013.4%) [Env:Stochastic, Attack:Random X Rate:0.0625, Frames:10000, SCapacity=10000, Alloc=Default]\n",
      "‚úì Experiment 4 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 12000 frames  <>  SCALED-CAPACITY: 12000 frames (CAPACITY:12000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=4 ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 5: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 5: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:12000, QubitAlloc=Default, SC:12000 (Scale=1 x Cap=12000), Seed: 19632\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.38229009396593533], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 5: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 GNEURALUCB          : Reward=4136.16, Efficiency=088.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 5: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=4136.04, Efficiency=088.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 5: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=4090.41, Efficiency=087.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 5: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=4120.43, Efficiency=088.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.712]\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 5: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:12000, QubitAlloc=Default, SC:12000 (Scale=1 x Cap=12000), Seed: 19632\n",
      "\t-->üèÜ EXP5 Winner:GNeuralUCB          (Gap:011.3%) [Env:Stochastic, Attack:Random X Rate:0.0625, Frames:12000, SCapacity=12000, Alloc=Default]\n",
      "‚úì Experiment 5 completed successfully.\n",
      "Total experiment time: 2778.2s\n",
      "Experiments completed for stochastic\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: MARKOV ADVERSARIAL ATTACK\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: MARKOV\n",
      "Category: Structured (Markov Chain Based)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 4000 frames  <>  SCALED-CAPACITY: 4000 frames (CAPACITY:4000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=0 ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for MARKOV Exp 1: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 1: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:4000, QubitAlloc=Default, SC:4000 (Scale=1 x Cap=4000), Seed: 15617\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.40758880688060967], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 1: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 GNEURALUCB          : Reward=0737.33, Efficiency=047.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=4000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 1: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=0712.16, Efficiency=045.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=4000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 1: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=0780.01, Efficiency=050.2% [Retries=3, Failed=0, < Threshold=3, SCapacity=4000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 1: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=0856.38, Efficiency=055.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=4000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 1: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:4000, QubitAlloc=Default, SC:4000 (Scale=1 x Cap=4000), Seed: 15617\n",
      "\t-->üèÜ EXP1 Winner:iCPursuitNeuralUCB  (Gap:044.9%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:4000, SCapacity=4000, Alloc=Default]\n",
      "‚úì Experiment 1 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 6000 frames  <>  SCALED-CAPACITY: 6000 frames (CAPACITY:6000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=1 ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for MARKOV Exp 2: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 2: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:6000, QubitAlloc=Default, SC:6000 (Scale=1 x Cap=6000), Seed: 15214\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.40706611625366484], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 2: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 GNEURALUCB          : Reward=1120.32, Efficiency=048.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=6000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 2: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=1053.67, Efficiency=046.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=6000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 2: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=1119.56, Efficiency=048.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=6000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 2: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=1258.38, Efficiency=055.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=6000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 2: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:6000, QubitAlloc=Default, SC:6000 (Scale=1 x Cap=6000), Seed: 15214\n",
      "\t-->üèÜ EXP2 Winner:iCPursuitNeuralUCB  (Gap:045.0%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:6000, SCapacity=6000, Alloc=Default]\n",
      "‚úì Experiment 2 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 8000 frames  <>  SCALED-CAPACITY: 8000 frames (CAPACITY:8000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=2 ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for MARKOV Exp 3: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 3: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:8000, QubitAlloc=Default, SC:8000 (Scale=1 x Cap=8000), Seed: 15164\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.4202961453677382], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 3: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 GNEURALUCB          : Reward=1471.96, Efficiency=046.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=8000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 3: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=1425.56, Efficiency=045.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=8000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 3: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=1538.67, Efficiency=048.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=8000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 3: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=1713.52, Efficiency=054.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=8000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 3: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:8000, QubitAlloc=Default, SC:8000 (Scale=1 x Cap=8000), Seed: 15164\n",
      "\t-->üèÜ EXP3 Winner:iCPursuitNeuralUCB  (Gap:045.6%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:8000, SCapacity=8000, Alloc=Default]\n",
      "‚úì Experiment 3 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 10000 frames  <>  SCALED-CAPACITY: 10000 frames (CAPACITY:10000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=3 ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for MARKOV Exp 4: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 4: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:10000, QubitAlloc=Default, SC:10000 (Scale=1 x Cap=10000), Seed: 14599\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.38852779914991686], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 4: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 GNEURALUCB          : Reward=1887.44, Efficiency=049.2% [Retries=3, Failed=0, < Threshold=3, SCapacity=10000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 4: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=1920.04, Efficiency=050.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=10000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 4: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=1879.95, Efficiency=049.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=10000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 4: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=2137.25, Efficiency=055.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=10000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 4: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:10000, QubitAlloc=Default, SC:10000 (Scale=1 x Cap=10000), Seed: 14599\n",
      "\t-->üèÜ EXP4 Winner:iCPursuitNeuralUCB  (Gap:044.2%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:10000, SCapacity=10000, Alloc=Default]\n",
      "‚úì Experiment 4 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 12000 frames  <>  SCALED-CAPACITY: 12000 frames (CAPACITY:12000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=4 ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for MARKOV Exp 5: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 5: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:12000, QubitAlloc=Default, SC:12000 (Scale=1 x Cap=12000), Seed: 14153\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.3579527263647335], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 5: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 GNEURALUCB          : Reward=2220.32, Efficiency=056.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=12000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 5: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=1958.34, Efficiency=050.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=12000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 5: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=2187.99, Efficiency=055.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=12000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 5: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=2474.06, Efficiency=063.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=12000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 5: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:12000, QubitAlloc=Default, SC:12000 (Scale=1 x Cap=12000), Seed: 14153\n",
      "\t-->üèÜ EXP5 Winner:iCPursuitNeuralUCB  (Gap:036.7%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:12000, SCapacity=12000, Alloc=Default]\n",
      "‚úì Experiment 5 completed successfully.\n",
      "Total experiment time: 951.2s\n",
      "Experiments completed for markov\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: ADAPTIVE ADVERSARIAL ATTACK\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: ADAPTIVE\n",
      "Category: Adaptive (Reactive Strategic)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 4000 frames  <>  SCALED-CAPACITY: 4000 frames (CAPACITY:4000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=0 ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 1: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 1: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:4000, QubitAlloc=Default, SC:4000 (Scale=1 x Cap=4000), Seed: 12509\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.38860510852297203], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 1: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 GNEURALUCB          : Reward=1058.16, Efficiency=069.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=4000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 1: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=1017.20, Efficiency=066.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=4000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 1: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=1068.45, Efficiency=070.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=4000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 1: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=1041.23, Efficiency=068.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=4000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 1: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:4000, QubitAlloc=Default, SC:4000 (Scale=1 x Cap=4000), Seed: 12509\n",
      "\t-->üèÜ EXP1 Winner:CPursuitNeuralUCB   (Gap:029.7%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:4000, SCapacity=4000, Alloc=Default]\n",
      "‚úì Experiment 1 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 6000 frames  <>  SCALED-CAPACITY: 6000 frames (CAPACITY:6000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=1 ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 2: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 2: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:6000, QubitAlloc=Default, SC:6000 (Scale=1 x Cap=6000), Seed: 21611\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.38722107258255484], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 2: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 GNEURALUCB          : Reward=1618.60, Efficiency=070.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 2: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=1546.63, Efficiency=067.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 2: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=1603.83, Efficiency=069.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 2: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=1604.04, Efficiency=069.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=6000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 2: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:6000, QubitAlloc=Default, SC:6000 (Scale=1 x Cap=6000), Seed: 21611\n",
      "\t-->üèÜ EXP2 Winner:GNeuralUCB          (Gap:029.6%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:6000, SCapacity=6000, Alloc=Default]\n",
      "‚úì Experiment 2 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 8000 frames  <>  SCALED-CAPACITY: 8000 frames (CAPACITY:8000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=2 ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 3: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 3: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:8000, QubitAlloc=Default, SC:8000 (Scale=1 x Cap=8000), Seed: 19675\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.38229009396593533], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 3: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 GNEURALUCB          : Reward=2124.58, Efficiency=070.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 3: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=2152.00, Efficiency=071.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 3: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=2137.37, Efficiency=070.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 3: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=2126.83, Efficiency=070.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=8000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 3: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:8000, QubitAlloc=Default, SC:8000 (Scale=1 x Cap=8000), Seed: 19675\n",
      "\t-->üèÜ EXP3 Winner:EXPNeuralUCB        (Gap:028.9%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:8000, SCapacity=8000, Alloc=Default]\n",
      "‚úì Experiment 3 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 10000 frames  <>  SCALED-CAPACITY: 10000 frames (CAPACITY:10000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=3 ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 4: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 4: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:10000, QubitAlloc=Default, SC:10000 (Scale=1 x Cap=10000), Seed: 20231\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.4202961453677382], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 4: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 GNEURALUCB          : Reward=2830.21, Efficiency=068.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=10000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 4: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=2916.66, Efficiency=070.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=10000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 4: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=2828.79, Efficiency=068.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=10000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 4: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=2807.28, Efficiency=068.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=10000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 4: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:10000, QubitAlloc=Default, SC:10000 (Scale=1 x Cap=10000), Seed: 20231\n",
      "\t-->üèÜ EXP4 Winner:EXPNeuralUCB        (Gap:029.2%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:10000, SCapacity=10000, Alloc=Default]\n",
      "‚úì Experiment 4 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 12000 frames  <>  SCALED-CAPACITY: 12000 frames (CAPACITY:12000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=4 ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 5: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 5: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:12000, QubitAlloc=Default, SC:12000 (Scale=1 x Cap=12000), Seed: 15657\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.4202961453677382], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 5: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 GNEURALUCB          : Reward=3329.19, Efficiency=070.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 5: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=3291.62, Efficiency=069.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 5: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=3429.29, Efficiency=072.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 5: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=3394.31, Efficiency=071.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 5: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:12000, QubitAlloc=Default, SC:12000 (Scale=1 x Cap=12000), Seed: 15657\n",
      "\t-->üèÜ EXP5 Winner:CPursuitNeuralUCB   (Gap:027.9%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:12000, SCapacity=12000, Alloc=Default]\n",
      "‚úì Experiment 5 completed successfully.\n",
      "Total experiment time: 1024.3s\n",
      "Experiments completed for adaptive\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: ONLINE ADAPTIVE ATTACK\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: ONLINEADAPTIVE\n",
      "Category: Online Adaptive (Real-time Strategic)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 4000 frames  <>  SCALED-CAPACITY: 4000 frames (CAPACITY:4000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=0 ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 1: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:4000, QubitAlloc=Default, SC:4000 (Scale=1 x Cap=4000), Seed: 16665\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.38722107258255484], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 GNEURALUCB          : Reward=1027.32, Efficiency=067.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=4000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=1023.88, Efficiency=067.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=4000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=1012.04, Efficiency=066.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=4000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=1023.05, Efficiency=067.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=4000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:4000, QubitAlloc=Default, SC:4000 (Scale=1 x Cap=4000), Seed: 16665\n",
      "\t-->üèÜ EXP1 Winner:GNeuralUCB          (Gap:032.1%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:4000, SCapacity=4000, Alloc=Default]\n",
      "‚úì Experiment 1 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 6000 frames  <>  SCALED-CAPACITY: 6000 frames (CAPACITY:6000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=1 ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 2: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:6000, QubitAlloc=Default, SC:6000 (Scale=1 x Cap=6000), Seed: 21573\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.4012351376370454], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 GNEURALUCB          : Reward=1616.29, Efficiency=068.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=1547.04, Efficiency=065.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=1618.93, Efficiency=068.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=1648.16, Efficiency=069.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=6000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:6000, QubitAlloc=Default, SC:6000 (Scale=1 x Cap=6000), Seed: 21573\n",
      "\t-->üèÜ EXP2 Winner:iCPursuitNeuralUCB  (Gap:030.6%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:6000, SCapacity=6000, Alloc=Default]\n",
      "‚úì Experiment 2 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 8000 frames  <>  SCALED-CAPACITY: 8000 frames (CAPACITY:8000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=2 ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 3: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:8000, QubitAlloc=Default, SC:8000 (Scale=1 x Cap=8000), Seed: 14973\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.4202961453677382], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 GNEURALUCB          : Reward=2294.40, Efficiency=069.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=2152.46, Efficiency=064.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=2279.63, Efficiency=068.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=2241.88, Efficiency=067.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=8000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:8000, QubitAlloc=Default, SC:8000 (Scale=1 x Cap=8000), Seed: 14973\n",
      "\t-->üèÜ EXP3 Winner:GNeuralUCB          (Gap:031.0%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:8000, SCapacity=8000, Alloc=Default]\n",
      "‚úì Experiment 3 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 10000 frames  <>  SCALED-CAPACITY: 10000 frames (CAPACITY:10000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=3 ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 4: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:10000, QubitAlloc=Default, SC:10000 (Scale=1 x Cap=10000), Seed: 18379\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.4202961453677382], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 GNEURALUCB          : Reward=2776.12, Efficiency=067.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=10000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=2526.34, Efficiency=061.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=10000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=2776.06, Efficiency=067.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=10000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=2760.54, Efficiency=067.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=10000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:10000, QubitAlloc=Default, SC:10000 (Scale=1 x Cap=10000), Seed: 18379\n",
      "\t-->üèÜ EXP4 Winner:GNeuralUCB          (Gap:032.1%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:10000, SCapacity=10000, Alloc=Default]\n",
      "‚úì Experiment 4 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 12000 frames  <>  SCALED-CAPACITY: 12000 frames (CAPACITY:12000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=4 ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 5: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:12000, QubitAlloc=Default, SC:12000 (Scale=1 x Cap=12000), Seed: 14049\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.3739910434684815], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 GNEURALUCB          : Reward=3250.30, Efficiency=072.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=3386.02, Efficiency=075.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=3243.36, Efficiency=072.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=3273.88, Efficiency=073.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:12000, QubitAlloc=Default, SC:12000 (Scale=1 x Cap=12000), Seed: 14049\n",
      "\t-->üèÜ EXP5 Winner:EXPNeuralUCB        (Gap:024.5%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:12000, SCapacity=12000, Alloc=Default]\n",
      "‚úì Experiment 5 completed successfully.\n",
      "Total experiment time: 894.0s\n",
      "Experiments completed for onlineadaptive\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: BASELINE (OPTIMAL CONDITIONS)\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: NONE\n",
      "Category: Baseline (No Attacks)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 4000 frames  <>  SCALED-CAPACITY: 4000 frames (CAPACITY:4000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=0 ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for NONE Exp 1: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 1: Env:Baseline (None), Attack:No, Rate:0.0, Frames:4000, QubitAlloc=Default, SC:4000 (Scale=1 x Cap=4000), Seed: 19677\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.4004511016966282], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 1: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 GNEURALUCB          : Reward=1430.43, Efficiency=089.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=4000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 1: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=1451.54, Efficiency=090.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=4000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 1: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=1439.35, Efficiency=089.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=4000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 1: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=1443.49, Efficiency=090.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=4000, Threshold=0.712]\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 1: Env:Baseline (None), Attack:No, Rate:0.0, Frames:4000, QubitAlloc=Default, SC:4000 (Scale=1 x Cap=4000), Seed: 19677\n",
      "\t-->üèÜ EXP1 Winner:EXPNeuralUCB        (Gap:009.4%) [Env:Baseline (None), Attack:No X Rate:0.0, Frames:4000, SCapacity=4000, Alloc=Default]\n",
      "‚úì Experiment 1 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 6000 frames  <>  SCALED-CAPACITY: 6000 frames (CAPACITY:6000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=1 ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for NONE Exp 2: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 2: Env:Baseline (None), Attack:No, Rate:0.0, Frames:6000, QubitAlloc=Default, SC:6000 (Scale=1 x Cap=6000), Seed: 16724\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.38860510852297203], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 2: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 GNEURALUCB          : Reward=2163.45, Efficiency=092.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 2: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=2002.09, Efficiency=085.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 2: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=2158.16, Efficiency=092.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 2: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=2151.21, Efficiency=092.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.712]\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 2: Env:Baseline (None), Attack:No, Rate:0.0, Frames:6000, QubitAlloc=Default, SC:6000 (Scale=1 x Cap=6000), Seed: 16724\n",
      "\t-->üèÜ EXP2 Winner:GNeuralUCB          (Gap:007.2%) [Env:Baseline (None), Attack:No X Rate:0.0, Frames:6000, SCapacity=6000, Alloc=Default]\n",
      "‚úì Experiment 2 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 8000 frames  <>  SCALED-CAPACITY: 8000 frames (CAPACITY:8000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=2 ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for NONE Exp 3: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 3: Env:Baseline (None), Attack:No, Rate:0.0, Frames:8000, QubitAlloc=Default, SC:8000 (Scale=1 x Cap=8000), Seed: 16587\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.40706611625366484], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 3: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 GNEURALUCB          : Reward=3015.55, Efficiency=091.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 3: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=2698.94, Efficiency=081.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 3: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=2978.50, Efficiency=089.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 3: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=3012.68, Efficiency=090.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.712]\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 3: Env:Baseline (None), Attack:No, Rate:0.0, Frames:8000, QubitAlloc=Default, SC:8000 (Scale=1 x Cap=8000), Seed: 16587\n",
      "\t-->üèÜ EXP3 Winner:GNeuralUCB          (Gap:009.0%) [Env:Baseline (None), Attack:No X Rate:0.0, Frames:8000, SCapacity=8000, Alloc=Default]\n",
      "‚úì Experiment 3 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 10000 frames  <>  SCALED-CAPACITY: 10000 frames (CAPACITY:10000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=3 ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for NONE Exp 4: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 4: Env:Baseline (None), Attack:No, Rate:0.0, Frames:10000, QubitAlloc=Default, SC:10000 (Scale=1 x Cap=10000), Seed: 13579\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.4202961453677382], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 4: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 GNEURALUCB          : Reward=3823.88, Efficiency=091.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=10000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 4: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=4103.22, Efficiency=097.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=10000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 4: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=3814.89, Efficiency=090.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=10000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 4: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=3799.27, Efficiency=090.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=10000, Threshold=0.712]\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 4: Env:Baseline (None), Attack:No, Rate:0.0, Frames:10000, QubitAlloc=Default, SC:10000 (Scale=1 x Cap=10000), Seed: 13579\n",
      "\t-->üèÜ EXP4 Winner:EXPNeuralUCB        (Gap:002.4%) [Env:Baseline (None), Attack:No X Rate:0.0, Frames:10000, SCapacity=10000, Alloc=Default]\n",
      "‚úì Experiment 4 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 12000 frames  <>  SCALED-CAPACITY: 12000 frames (CAPACITY:12000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=4 ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for NONE Exp 5: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 5: Env:Baseline (None), Attack:No, Rate:0.0, Frames:12000, QubitAlloc=Default, SC:12000 (Scale=1 x Cap=12000), Seed: 15608\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.3570300357377887], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 5: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 GNEURALUCB          : Reward=4459.93, Efficiency=089.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 5: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=4186.32, Efficiency=084.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 5: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=4458.33, Efficiency=089.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 5: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=4495.93, Efficiency=090.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.712]\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 5: Env:Baseline (None), Attack:No, Rate:0.0, Frames:12000, QubitAlloc=Default, SC:12000 (Scale=1 x Cap=12000), Seed: 15608\n",
      "\t-->üèÜ EXP5 Winner:iCPursuitNeuralUCB  (Gap:009.5%) [Env:Baseline (None), Attack:No X Rate:0.0, Frames:12000, SCapacity=12000, Alloc=Default]\n",
      "‚úì Experiment 5 completed successfully.\n",
      "Total experiment time: 1003.3s\n",
      "Experiments completed for none\n",
      "‚úì Scenario 'stochastic' evaluation completed.\n",
      "‚úì Scenario 'markov' evaluation completed.\n",
      "‚úì Scenario 'adaptive' evaluation completed.\n",
      "‚úì Scenario 'onlineadaptive' evaluation completed.\n",
      "‚úì Scenario 'none' evaluation completed.\n",
      "\n",
      "======================================================================\n",
      "COMPREHENSIVE SCENARIO PERFORMANCE ANALYSIS\n",
      "======================================================================\n",
      "SCENARIO: STOCHASTIC\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: GNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 3185.14\n",
      "\t‚Ä¢ Winner Avg Gap: 0013.52%\n",
      "\t‚Ä¢ Winner Avg Reward: 2765.87\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0086.48%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 3 wins\n",
      "\t\t- EXPNeuralUCB: 1 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 1 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: STOCHASTIC\n",
      "======================================================================\n",
      "SCENARIO: \tSTOCHASTIC RANDOM FAILURES\n",
      "----------------------------------------\n",
      "Recommended Model: \tGNeuralUCB (Won 3/5 experiments)\n",
      "\tWinner Avg Gap: \t013.5%\n",
      "\tWinner Avg Efficiency: \t086.5%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ GNeuralUCB     : \t086.5% Efficiency \t(Won 3/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t085.7% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t085.5% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t084.7% Efficiency \t(Won 1/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: MARKOV\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 2947.27\n",
      "\t‚Ä¢ Winner Avg Gap: 0043.30%\n",
      "\t‚Ä¢ Winner Avg Reward: 1687.92\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0056.70%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 5 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: MARKOV\n",
      "======================================================================\n",
      "SCENARIO: \tMARKOV ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 5/5 experiments)\n",
      "\tWinner Avg Gap: \t043.3%\n",
      "\tWinner Avg Efficiency: \t056.7%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t056.7% Efficiency \t(Won 5/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t050.6% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t049.8% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t047.5% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: CPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 3143.66\n",
      "\t‚Ä¢ Winner Avg Gap: 0029.70%\n",
      "\t‚Ä¢ Winner Avg Reward: 2213.55\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0070.30%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 1 wins\n",
      "\t\t- EXPNeuralUCB: 2 wins\n",
      "\t\t- CPursuitNeuralUCB: 2 wins\n",
      "\t\t- iCPursuitNeuralUCB: 0 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tADAPTIVE ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tCPursuitNeuralUCB (Won 2/5 experiments)\n",
      "\tWinner Avg Gap: \t029.7%\n",
      "\tWinner Avg Efficiency: \t070.3%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t070.3% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t069.8% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t069.6% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t069.1% Efficiency \t(Won 2/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ONLINEADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: GNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 3156.63\n",
      "\t‚Ä¢ Winner Avg Gap: 0030.92%\n",
      "\t‚Ä¢ Winner Avg Reward: 2192.88\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0069.08%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 3 wins\n",
      "\t\t- EXPNeuralUCB: 1 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 1 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ONLINEADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tONLINE ADAPTIVE ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tGNeuralUCB (Won 3/5 experiments)\n",
      "\tWinner Avg Gap: \t030.9%\n",
      "\tWinner Avg Efficiency: \t069.1%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ GNeuralUCB     : \t069.1% Efficiency \t(Won 3/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t069.0% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t068.8% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t067.0% Efficiency \t(Won 1/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: NONE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 3283.79\n",
      "\t‚Ä¢ Winner Avg Gap: 0009.16%\n",
      "\t‚Ä¢ Winner Avg Reward: 2980.52\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0090.84%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 2 wins\n",
      "\t\t- EXPNeuralUCB: 2 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 1 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: NONE\n",
      "======================================================================\n",
      "SCENARIO: \tBASELINE (OPTIMAL CONDITIONS)\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 1/5 experiments)\n",
      "\tWinner Avg Gap: \t009.2%\n",
      "\tWinner Avg Efficiency: \t090.8%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t090.8% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t090.8% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t090.6% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t088.0% Efficiency \t(Won 2/5 experiments)\n",
      "======================================================================\n",
      "KEY INSIGHTS:\n",
      "Best Performing Model Analysis (GNeuralUCB):\n",
      "\t‚Ä¢ Stochastic Performance:    \t2765.870\n",
      "\t‚Ä¢ Baseline Performance:      \t2980.517\n",
      "\t‚Ä¢ Performance Retention:     \t092.8%\n",
      "\tGOOD:               \tAcceptable performance under stochastic conditions\n",
      "Statistical Analysis:\n",
      "\t‚Ä¢ Total models evaluated:     \t5\n",
      "\t‚Ä¢ Experiments per environment:\t5\n",
      "\t‚Ä¢ Quantum network simulation: \tComprehensive stochastic modeling\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "COMPREHENSIVE SCENARIO PERFORMANCE ANALYSIS\n",
      "======================================================================\n",
      "SCENARIO: STOCHASTIC\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: GNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 3185.14\n",
      "\t‚Ä¢ Winner Avg Gap: 0013.52%\n",
      "\t‚Ä¢ Winner Avg Reward: 2765.87\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0086.48%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 3 wins\n",
      "\t\t- EXPNeuralUCB: 1 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 1 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: STOCHASTIC\n",
      "======================================================================\n",
      "SCENARIO: \tSTOCHASTIC RANDOM FAILURES\n",
      "----------------------------------------\n",
      "Recommended Model: \tGNeuralUCB (Won 3/5 experiments)\n",
      "\tWinner Avg Gap: \t013.5%\n",
      "\tWinner Avg Efficiency: \t086.5%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ GNeuralUCB     : \t086.5% Efficiency \t(Won 3/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t085.7% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t085.5% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t084.7% Efficiency \t(Won 1/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: MARKOV\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 2947.27\n",
      "\t‚Ä¢ Winner Avg Gap: 0043.30%\n",
      "\t‚Ä¢ Winner Avg Reward: 1687.92\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0056.70%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 5 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: MARKOV\n",
      "======================================================================\n",
      "SCENARIO: \tMARKOV ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 5/5 experiments)\n",
      "\tWinner Avg Gap: \t043.3%\n",
      "\tWinner Avg Efficiency: \t056.7%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t056.7% Efficiency \t(Won 5/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t050.6% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t049.8% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t047.5% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: CPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 3143.66\n",
      "\t‚Ä¢ Winner Avg Gap: 0029.70%\n",
      "\t‚Ä¢ Winner Avg Reward: 2213.55\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0070.30%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 1 wins\n",
      "\t\t- EXPNeuralUCB: 2 wins\n",
      "\t\t- CPursuitNeuralUCB: 2 wins\n",
      "\t\t- iCPursuitNeuralUCB: 0 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tADAPTIVE ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tCPursuitNeuralUCB (Won 2/5 experiments)\n",
      "\tWinner Avg Gap: \t029.7%\n",
      "\tWinner Avg Efficiency: \t070.3%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t070.3% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t069.8% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t069.6% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t069.1% Efficiency \t(Won 2/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ONLINEADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: GNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 3156.63\n",
      "\t‚Ä¢ Winner Avg Gap: 0030.92%\n",
      "\t‚Ä¢ Winner Avg Reward: 2192.88\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0069.08%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 3 wins\n",
      "\t\t- EXPNeuralUCB: 1 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 1 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ONLINEADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tONLINE ADAPTIVE ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tGNeuralUCB (Won 3/5 experiments)\n",
      "\tWinner Avg Gap: \t030.9%\n",
      "\tWinner Avg Efficiency: \t069.1%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ GNeuralUCB     : \t069.1% Efficiency \t(Won 3/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t069.0% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t068.8% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t067.0% Efficiency \t(Won 1/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: NONE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 3283.79\n",
      "\t‚Ä¢ Winner Avg Gap: 0009.16%\n",
      "\t‚Ä¢ Winner Avg Reward: 2980.52\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0090.84%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 2 wins\n",
      "\t\t- EXPNeuralUCB: 2 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 1 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: NONE\n",
      "======================================================================\n",
      "SCENARIO: \tBASELINE (OPTIMAL CONDITIONS)\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 1/5 experiments)\n",
      "\tWinner Avg Gap: \t009.2%\n",
      "\tWinner Avg Efficiency: \t090.8%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t090.8% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t090.8% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t090.6% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t088.0% Efficiency \t(Won 2/5 experiments)\n",
      "======================================================================\n",
      "‚úÖ Evaluation completed!\n",
      "[Logging Redirect Stopped]\n",
      "\n",
      "üßπ Final cleanup for Default\n",
      "\n",
      "======================================================================\n",
      "‚úÖ COMPLETED: Default\n",
      "======================================================================\n",
      "\n",
      "Default COMPLETED SUCCESSFULLY\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Preparing: Default at scale 1.5\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üîß Generating physics parameters for model: paper2\n",
      "\n",
      "===================== GET LOCAL REGISTRY =====================\n",
      "‚Üí Skipping local cache (force=True or file missing)\n",
      "\n",
      "===================== BUILD LOCAL REGISTRY =====================\n",
      "\n",
      "================================================================================\n",
      "üîç SCANNING LOCAL FILES\n",
      "================================================================================\n",
      "Parameters: load_to_drive=False, force=False\n",
      "\n",
      "üìÇ Checking DRIVE mode: /content/drive/Shareddrives/ai_quantum_computing/quantum_data_lake\n",
      "   ‚ö†Ô∏è  Path does not exist, skipping\n",
      "\n",
      "üìÇ Checking LOCAL mode: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config\n",
      "   ‚úÖ Path exists, starting walk...\n",
      "   üö∂ Walking directory tree: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config\n",
      "\n",
      "   üìÅ Directory: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201\n",
      "      Relative: framework_state/day_20260201\n",
      "      Component: framework_state\n",
      "      Date: day_20260201\n",
      "      üìÑ Processing 2540 files in framework_state/day_20260201\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "      üìä framework_state/day_20260201: 2514/2540 files processed\n",
      "      üìä framework_state/day_20260201: 0/2540 files skipped\n",
      "      üìä framework_state/day_20260201: 26/2540 files conflicted\n",
      "\n",
      "   üìÅ Directory: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/model_state/day_20260201\n",
      "      Relative: model_state/day_20260201\n",
      "      Component: model_state\n",
      "      Date: day_20260201\n",
      "      üìÑ Processing 9000 files in model_state/day_20260201\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "      üìä model_state/day_20260201: 9000/9000 files processed\n",
      "      üìä model_state/day_20260201: 0/9000 files skipped\n",
      "      üìä model_state/day_20260201: 0/9000 files conflicted\n",
      "\n",
      "   üìä Processed 2 directories\n",
      "\n",
      "================================================================================\n",
      "üì¶ BUILDING FINAL REGISTRY\n",
      "================================================================================\n",
      "Components found: ['framework_state', 'model_state']\n",
      "  ‚Ä¢ framework_state: 2514 files\n",
      "  ‚Ä¢ model_state: 9000 files\n",
      "\n",
      "‚úÖ SCAN COMPLETE\n",
      "Modes scanned: 1\n",
      "Total files in registry: 11514\n",
      "================================================================================\n",
      "\n",
      "\t‚Üí Filesystem scan found 11514 files\n",
      "\n",
      "===================== GET DRIVE REGISTRY =====================\n",
      "===================== REGISTRY BUILD COMPLETE =====================\n",
      "\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "\tüì¶ LocalBackupManager Registry Saved Locally in LOCAL\n",
      "BUILDING REGISTRY WITH 0 EXPECTED COMPONENTS KEYS\n",
      "\n",
      "===================== GET LOCAL REGISTRY =====================\n",
      "‚Üí Skipping local cache (force=True or file missing)\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "\tüì¶ LocalBackupManager Registry Saved Locally in LOCAL\n",
      "\n",
      "======================================================================\n",
      "üéØ AllocatorRunner initialized: Default\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "üöÄ STARTING ALLOCATOR: Default\n",
      "======================================================================\n",
      "\n",
      "üìä Physics Model: paper2\n",
      "\n",
      "üìã Allocator Config:\n",
      "   Type: Default\n",
      "   Testbed: paper2\n",
      "   Paths: 8\n",
      "   Total Qubits: 35\n",
      "   Min per route: 2\n",
      "   Seed: 42\n",
      "‚úÖ Allocator created: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "‚úì Allocator: QubitAllocator (8 paths)\n",
      "   Initial allocation: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "Generated paper2 topology: 15 nodes, 51 edges\n",
      "üìä Paper2 Physics: Time-based decay\n",
      "   ‚úì Using MATLAB constants: r_dephase=10000, c_light=300000000.0\n",
      "\n",
      "======================================================================\n",
      "RUN 1 | Scale: 1.5 | Exp: 5\n",
      "======================================================================\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "No state found for MultiRunEvaluator, disabling resume for Experiment Runners\n",
      "Multi-Run Evaluator Initialized\n",
      "Environment Type: None\n",
      "Frame Range: 4000 -> 12000 (step: 2000)\n",
      "quantum_exps-Default(paper2)_alloc-all_envs-5_attacks-4000_2000-5_runs-S1.5T\n",
      "[Logging Redirect Initialized]\n",
      "Log File: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/quantum_logs/quantum_exps-Default(paper2)_alloc-all_envs-5_attacks-4000_2000-5_runs-S1.5T_20260201_log.txt\n",
      "‚öô Running evaluation...\n",
      "======================================================================\n",
      "SCENARIOS MODEL EVALUATION\n",
      "======================================================================\n",
      "Testing algorithm performance against:\n",
      "\t‚Ä¢ Stochastic:  \tNatural quantum decoherence and network failures\n",
      "\t‚Ä¢ Baseline:    \tOptimal conditions for validation\n",
      "======================================================================\n",
      "Models to Test:             \tOracle, GNeuralUCB, EXPNeuralUCB, CPursuitNeuralUCB, iCPursuitNeuralUCB\n",
      "Experiments per Scenario:   \t5\n",
      "======================================================================\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: STOCHASTIC RANDOM FAILURES\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: STOCHASTIC\n",
      "Category: Stochastic (Natural Random Failures)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 4000 frames  <>  SCALED-CAPACITY: 6000.0 frames (CAPACITY:4000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=0 ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 1: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 1: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:4000, QubitAlloc=Default, SC:6000 (Scale=1.5 x Cap=4000), Seed: 19730\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.38852779914991686], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 1: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 GNEURALUCB          : Reward=1385.61, Efficiency=084.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 1: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=1429.95, Efficiency=086.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 1: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=1396.64, Efficiency=084.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 1: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=1382.21, Efficiency=083.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.712]\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 1: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:4000, QubitAlloc=Default, SC:6000 (Scale=1.5 x Cap=4000), Seed: 19730\n",
      "\t-->üèÜ EXP1 Winner:EXPNeuralUCB        (Gap:013.3%) [Env:Stochastic, Attack:Random X Rate:0.0625, Frames:4000, SCapacity=6000, Alloc=Default]\n",
      "‚úì Experiment 1 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 6000 frames  <>  SCALED-CAPACITY: 9000.0 frames (CAPACITY:6000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=1 ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 2: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 2: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:6000, QubitAlloc=Default, SC:9000 (Scale=1.5 x Cap=6000), Seed: 17421\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.38852779914991686], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 2: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 GNEURALUCB          : Reward=2039.52, Efficiency=087.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=9000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 2: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=2146.60, Efficiency=092.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=9000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 2: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=2038.43, Efficiency=087.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=9000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 2: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=2032.94, Efficiency=087.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=9000, Threshold=0.712]\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 2: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:6000, QubitAlloc=Default, SC:9000 (Scale=1.5 x Cap=6000), Seed: 17421\n",
      "\t-->üèÜ EXP2 Winner:EXPNeuralUCB        (Gap:007.8%) [Env:Stochastic, Attack:Random X Rate:0.0625, Frames:6000, SCapacity=9000, Alloc=Default]\n",
      "‚úì Experiment 2 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 8000 frames  <>  SCALED-CAPACITY: 12000.0 frames (CAPACITY:8000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=2 ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 3: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 3: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:8000, QubitAlloc=Default, SC:12000 (Scale=1.5 x Cap=8000), Seed: 17649\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.369660064851862], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 3: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 GNEURALUCB          : Reward=2588.23, Efficiency=086.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 3: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=2421.80, Efficiency=081.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 3: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=2612.19, Efficiency=087.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 3: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=2598.71, Efficiency=087.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.712]\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 3: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:8000, QubitAlloc=Default, SC:12000 (Scale=1.5 x Cap=8000), Seed: 17649\n",
      "\t-->üèÜ EXP3 Winner:CPursuitNeuralUCB   (Gap:012.3%) [Env:Stochastic, Attack:Random X Rate:0.0625, Frames:8000, SCapacity=12000, Alloc=Default]\n",
      "‚úì Experiment 3 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 10000 frames  <>  SCALED-CAPACITY: 15000.0 frames (CAPACITY:10000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=3 ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 4: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 4: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:10000, QubitAlloc=Default, SC:15000 (Scale=1.5 x Cap=10000), Seed: 20670\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.4202961453677382], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 4: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 GNEURALUCB          : Reward=3605.00, Efficiency=085.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=15000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 4: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=3357.83, Efficiency=080.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=15000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 4: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=3568.78, Efficiency=085.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=15000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 4: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=3588.73, Efficiency=085.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=15000, Threshold=0.712]\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 4: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:10000, QubitAlloc=Default, SC:15000 (Scale=1.5 x Cap=10000), Seed: 20670\n",
      "\t-->üèÜ EXP4 Winner:GNeuralUCB          (Gap:014.1%) [Env:Stochastic, Attack:Random X Rate:0.0625, Frames:10000, SCapacity=15000, Alloc=Default]\n",
      "‚úì Experiment 4 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 12000 frames  <>  SCALED-CAPACITY: 18000.0 frames (CAPACITY:12000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=4 ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 5: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 5: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:12000, QubitAlloc=Default, SC:18000 (Scale=1.5 x Cap=12000), Seed: 19632\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.4012351376370454], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 5: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 GNEURALUCB          : Reward=4135.48, Efficiency=087.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=18000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 5: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=3993.42, Efficiency=084.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=18000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 5: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=4135.88, Efficiency=087.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=18000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 5: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=4141.72, Efficiency=087.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=18000, Threshold=0.712]\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 5: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:12000, QubitAlloc=Default, SC:18000 (Scale=1.5 x Cap=12000), Seed: 19632\n",
      "\t-->üèÜ EXP5 Winner:iCPursuitNeuralUCB  (Gap:012.8%) [Env:Stochastic, Attack:Random X Rate:0.0625, Frames:12000, SCapacity=18000, Alloc=Default]\n",
      "‚úì Experiment 5 completed successfully.\n",
      "Total experiment time: 869.1s\n",
      "Experiments completed for stochastic\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: MARKOV ADVERSARIAL ATTACK\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: MARKOV\n",
      "Category: Structured (Markov Chain Based)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 4000 frames  <>  SCALED-CAPACITY: 6000.0 frames (CAPACITY:4000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=0 ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for MARKOV Exp 1: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 1: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:4000, QubitAlloc=Default, SC:6000 (Scale=1.5 x Cap=4000), Seed: 15617\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.40706611625366484], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 1: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 GNEURALUCB          : Reward=0764.39, Efficiency=049.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=6000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 1: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=0727.57, Efficiency=046.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=6000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 1: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=0753.74, Efficiency=048.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=6000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 1: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=0850.50, Efficiency=054.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=6000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 1: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:4000, QubitAlloc=Default, SC:6000 (Scale=1.5 x Cap=4000), Seed: 15617\n",
      "\t-->üèÜ EXP1 Winner:iCPursuitNeuralUCB  (Gap:045.4%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:4000, SCapacity=6000, Alloc=Default]\n",
      "‚úì Experiment 1 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 6000 frames  <>  SCALED-CAPACITY: 9000.0 frames (CAPACITY:6000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=1 ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for MARKOV Exp 2: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 2: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:6000, QubitAlloc=Default, SC:9000 (Scale=1.5 x Cap=6000), Seed: 15214\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.40706611625366484], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 2: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 GNEURALUCB          : Reward=1120.32, Efficiency=048.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=9000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 2: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=1053.67, Efficiency=046.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=9000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 2: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=1119.56, Efficiency=048.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=9000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 2: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=1258.38, Efficiency=055.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=9000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 2: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:6000, QubitAlloc=Default, SC:9000 (Scale=1.5 x Cap=6000), Seed: 15214\n",
      "\t-->üèÜ EXP2 Winner:iCPursuitNeuralUCB  (Gap:045.0%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:6000, SCapacity=9000, Alloc=Default]\n",
      "‚úì Experiment 2 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 8000 frames  <>  SCALED-CAPACITY: 12000.0 frames (CAPACITY:8000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=2 ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for MARKOV Exp 3: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 3: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:8000, QubitAlloc=Default, SC:12000 (Scale=1.5 x Cap=8000), Seed: 15164\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.4202961453677382], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 3: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 GNEURALUCB          : Reward=1471.96, Efficiency=046.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=12000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 3: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=1425.56, Efficiency=045.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=12000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 3: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=1538.67, Efficiency=048.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=12000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 3: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=1713.52, Efficiency=054.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=12000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 3: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:8000, QubitAlloc=Default, SC:12000 (Scale=1.5 x Cap=8000), Seed: 15164\n",
      "\t-->üèÜ EXP3 Winner:iCPursuitNeuralUCB  (Gap:045.6%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:8000, SCapacity=12000, Alloc=Default]\n",
      "‚úì Experiment 3 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 10000 frames  <>  SCALED-CAPACITY: 15000.0 frames (CAPACITY:10000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=3 ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for MARKOV Exp 4: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 4: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:10000, QubitAlloc=Default, SC:15000 (Scale=1.5 x Cap=10000), Seed: 14599\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.38852779914991686], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 4: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 GNEURALUCB          : Reward=1887.44, Efficiency=049.2% [Retries=3, Failed=0, < Threshold=3, SCapacity=15000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 4: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=1920.04, Efficiency=050.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=15000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 4: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=1879.95, Efficiency=049.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=15000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 4: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=2137.25, Efficiency=055.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=15000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 4: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:10000, QubitAlloc=Default, SC:15000 (Scale=1.5 x Cap=10000), Seed: 14599\n",
      "\t-->üèÜ EXP4 Winner:iCPursuitNeuralUCB  (Gap:044.2%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:10000, SCapacity=15000, Alloc=Default]\n",
      "‚úì Experiment 4 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 12000 frames  <>  SCALED-CAPACITY: 18000.0 frames (CAPACITY:12000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=4 ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for MARKOV Exp 5: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 5: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:12000, QubitAlloc=Default, SC:18000 (Scale=1.5 x Cap=12000), Seed: 14153\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.3579527263647335], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 5: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 GNEURALUCB          : Reward=2220.32, Efficiency=056.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=18000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 5: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=1958.34, Efficiency=050.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=18000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 5: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=2187.99, Efficiency=055.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=18000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 5: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=2474.06, Efficiency=063.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=18000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 5: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:12000, QubitAlloc=Default, SC:18000 (Scale=1.5 x Cap=12000), Seed: 14153\n",
      "\t-->üèÜ EXP5 Winner:iCPursuitNeuralUCB  (Gap:036.7%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:12000, SCapacity=18000, Alloc=Default]\n",
      "‚úì Experiment 5 completed successfully.\n",
      "Total experiment time: 752.6s\n",
      "Experiments completed for markov\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: ADAPTIVE ADVERSARIAL ATTACK\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: ADAPTIVE\n",
      "Category: Adaptive (Reactive Strategic)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 4000 frames  <>  SCALED-CAPACITY: 6000.0 frames (CAPACITY:4000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=0 ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 1: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 1: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:4000, QubitAlloc=Default, SC:6000 (Scale=1.5 x Cap=4000), Seed: 12509\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.38860510852297203], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 1: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 GNEURALUCB          : Reward=1058.16, Efficiency=069.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 1: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=1017.20, Efficiency=066.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 1: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=1068.45, Efficiency=070.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 1: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=1041.23, Efficiency=068.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=6000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 1: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:4000, QubitAlloc=Default, SC:6000 (Scale=1.5 x Cap=4000), Seed: 12509\n",
      "\t-->üèÜ EXP1 Winner:CPursuitNeuralUCB   (Gap:029.7%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:4000, SCapacity=6000, Alloc=Default]\n",
      "‚úì Experiment 1 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 6000 frames  <>  SCALED-CAPACITY: 9000.0 frames (CAPACITY:6000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=1 ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 2: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 2: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:6000, QubitAlloc=Default, SC:9000 (Scale=1.5 x Cap=6000), Seed: 21611\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.38722107258255484], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 2: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 GNEURALUCB          : Reward=1618.60, Efficiency=070.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=9000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 2: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=1546.63, Efficiency=067.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=9000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 2: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=1603.83, Efficiency=069.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=9000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 2: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=1604.04, Efficiency=069.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=9000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 2: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:6000, QubitAlloc=Default, SC:9000 (Scale=1.5 x Cap=6000), Seed: 21611\n",
      "\t-->üèÜ EXP2 Winner:GNeuralUCB          (Gap:029.6%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:6000, SCapacity=9000, Alloc=Default]\n",
      "‚úì Experiment 2 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 8000 frames  <>  SCALED-CAPACITY: 12000.0 frames (CAPACITY:8000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=2 ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 3: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 3: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:8000, QubitAlloc=Default, SC:12000 (Scale=1.5 x Cap=8000), Seed: 19675\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.38229009396593533], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 3: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 GNEURALUCB          : Reward=2124.58, Efficiency=070.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 3: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=2152.00, Efficiency=071.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 3: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=2137.37, Efficiency=070.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 3: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=2126.83, Efficiency=070.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=12000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 3: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:8000, QubitAlloc=Default, SC:12000 (Scale=1.5 x Cap=8000), Seed: 19675\n",
      "\t-->üèÜ EXP3 Winner:EXPNeuralUCB        (Gap:028.9%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:8000, SCapacity=12000, Alloc=Default]\n",
      "‚úì Experiment 3 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 10000 frames  <>  SCALED-CAPACITY: 15000.0 frames (CAPACITY:10000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=3 ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 4: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 4: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:10000, QubitAlloc=Default, SC:15000 (Scale=1.5 x Cap=10000), Seed: 20231\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.4202961453677382], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 4: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 GNEURALUCB          : Reward=2830.21, Efficiency=068.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=15000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 4: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=2916.66, Efficiency=070.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=15000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 4: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=2828.79, Efficiency=068.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=15000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 4: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=2807.28, Efficiency=068.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=15000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 4: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:10000, QubitAlloc=Default, SC:15000 (Scale=1.5 x Cap=10000), Seed: 20231\n",
      "\t-->üèÜ EXP4 Winner:EXPNeuralUCB        (Gap:029.2%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:10000, SCapacity=15000, Alloc=Default]\n",
      "‚úì Experiment 4 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 12000 frames  <>  SCALED-CAPACITY: 18000.0 frames (CAPACITY:12000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=4 ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 5: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 5: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:12000, QubitAlloc=Default, SC:18000 (Scale=1.5 x Cap=12000), Seed: 15657\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.4202961453677382], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 5: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 GNEURALUCB          : Reward=3329.19, Efficiency=070.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=18000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 5: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=3291.62, Efficiency=069.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=18000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 5: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=3429.29, Efficiency=072.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=18000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 5: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=3394.31, Efficiency=071.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=18000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 5: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:12000, QubitAlloc=Default, SC:18000 (Scale=1.5 x Cap=12000), Seed: 15657\n",
      "\t-->üèÜ EXP5 Winner:CPursuitNeuralUCB   (Gap:027.9%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:12000, SCapacity=18000, Alloc=Default]\n",
      "‚úì Experiment 5 completed successfully.\n",
      "Total experiment time: 857.9s\n",
      "Experiments completed for adaptive\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: ONLINE ADAPTIVE ATTACK\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: ONLINEADAPTIVE\n",
      "Category: Online Adaptive (Real-time Strategic)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 4000 frames  <>  SCALED-CAPACITY: 6000.0 frames (CAPACITY:4000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=0 ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 1: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:4000, QubitAlloc=Default, SC:6000 (Scale=1.5 x Cap=4000), Seed: 16665\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.38722107258255484], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 GNEURALUCB          : Reward=1027.32, Efficiency=067.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=1023.88, Efficiency=067.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=1012.04, Efficiency=066.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=1023.05, Efficiency=067.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=6000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:4000, QubitAlloc=Default, SC:6000 (Scale=1.5 x Cap=4000), Seed: 16665\n",
      "\t-->üèÜ EXP1 Winner:GNeuralUCB          (Gap:032.1%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:4000, SCapacity=6000, Alloc=Default]\n",
      "‚úì Experiment 1 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 6000 frames  <>  SCALED-CAPACITY: 9000.0 frames (CAPACITY:6000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=1 ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 2: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:6000, QubitAlloc=Default, SC:9000 (Scale=1.5 x Cap=6000), Seed: 21573\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.4012351376370454], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 GNEURALUCB          : Reward=1616.29, Efficiency=068.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=9000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=1547.04, Efficiency=065.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=9000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=1618.93, Efficiency=068.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=9000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=1648.16, Efficiency=069.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=9000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:6000, QubitAlloc=Default, SC:9000 (Scale=1.5 x Cap=6000), Seed: 21573\n",
      "\t-->üèÜ EXP2 Winner:iCPursuitNeuralUCB  (Gap:030.6%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:6000, SCapacity=9000, Alloc=Default]\n",
      "‚úì Experiment 2 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 8000 frames  <>  SCALED-CAPACITY: 12000.0 frames (CAPACITY:8000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=2 ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 3: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:8000, QubitAlloc=Default, SC:12000 (Scale=1.5 x Cap=8000), Seed: 14973\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.4202961453677382], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 GNEURALUCB          : Reward=2294.40, Efficiency=069.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=2152.46, Efficiency=064.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=2279.63, Efficiency=068.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=2241.88, Efficiency=067.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=12000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:8000, QubitAlloc=Default, SC:12000 (Scale=1.5 x Cap=8000), Seed: 14973\n",
      "\t-->üèÜ EXP3 Winner:GNeuralUCB          (Gap:031.0%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:8000, SCapacity=12000, Alloc=Default]\n",
      "‚úì Experiment 3 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 10000 frames  <>  SCALED-CAPACITY: 15000.0 frames (CAPACITY:10000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=3 ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 4: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:10000, QubitAlloc=Default, SC:15000 (Scale=1.5 x Cap=10000), Seed: 18379\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.4202961453677382], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 GNEURALUCB          : Reward=2776.12, Efficiency=067.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=15000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=2526.34, Efficiency=061.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=15000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=2776.06, Efficiency=067.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=15000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=2760.54, Efficiency=067.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=15000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:10000, QubitAlloc=Default, SC:15000 (Scale=1.5 x Cap=10000), Seed: 18379\n",
      "\t-->üèÜ EXP4 Winner:GNeuralUCB          (Gap:032.1%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:10000, SCapacity=15000, Alloc=Default]\n",
      "‚úì Experiment 4 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 12000 frames  <>  SCALED-CAPACITY: 18000.0 frames (CAPACITY:12000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=4 ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 5: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:12000, QubitAlloc=Default, SC:18000 (Scale=1.5 x Cap=12000), Seed: 14049\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.3739910434684815], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 GNEURALUCB          : Reward=3250.30, Efficiency=072.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=18000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=3386.02, Efficiency=075.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=18000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=3243.36, Efficiency=072.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=18000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=3273.88, Efficiency=073.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=18000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:12000, QubitAlloc=Default, SC:18000 (Scale=1.5 x Cap=12000), Seed: 14049\n",
      "\t-->üèÜ EXP5 Winner:EXPNeuralUCB        (Gap:024.5%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:12000, SCapacity=18000, Alloc=Default]\n",
      "‚úì Experiment 5 completed successfully.\n",
      "Total experiment time: 903.6s\n",
      "Experiments completed for onlineadaptive\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: BASELINE (OPTIMAL CONDITIONS)\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: NONE\n",
      "Category: Baseline (No Attacks)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 4000 frames  <>  SCALED-CAPACITY: 6000.0 frames (CAPACITY:4000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=0 ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for NONE Exp 1: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 1: Env:Baseline (None), Attack:No, Rate:0.0, Frames:4000, QubitAlloc=Default, SC:6000 (Scale=1.5 x Cap=4000), Seed: 19677\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.4004511016966282], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 1: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 GNEURALUCB          : Reward=1430.43, Efficiency=089.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 1: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=1451.54, Efficiency=090.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 1: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=1439.35, Efficiency=089.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 1: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=1443.49, Efficiency=090.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.712]\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 1: Env:Baseline (None), Attack:No, Rate:0.0, Frames:4000, QubitAlloc=Default, SC:6000 (Scale=1.5 x Cap=4000), Seed: 19677\n",
      "\t-->üèÜ EXP1 Winner:EXPNeuralUCB        (Gap:009.4%) [Env:Baseline (None), Attack:No X Rate:0.0, Frames:4000, SCapacity=6000, Alloc=Default]\n",
      "‚úì Experiment 1 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 6000 frames  <>  SCALED-CAPACITY: 9000.0 frames (CAPACITY:6000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=1 ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for NONE Exp 2: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 2: Env:Baseline (None), Attack:No, Rate:0.0, Frames:6000, QubitAlloc=Default, SC:9000 (Scale=1.5 x Cap=6000), Seed: 16724\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.38860510852297203], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 2: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 GNEURALUCB          : Reward=2163.45, Efficiency=092.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=9000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 2: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=2002.09, Efficiency=085.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=9000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 2: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=2158.16, Efficiency=092.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=9000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 2: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=2151.21, Efficiency=092.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=9000, Threshold=0.712]\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 2: Env:Baseline (None), Attack:No, Rate:0.0, Frames:6000, QubitAlloc=Default, SC:9000 (Scale=1.5 x Cap=6000), Seed: 16724\n",
      "\t-->üèÜ EXP2 Winner:GNeuralUCB          (Gap:007.2%) [Env:Baseline (None), Attack:No X Rate:0.0, Frames:6000, SCapacity=9000, Alloc=Default]\n",
      "‚úì Experiment 2 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 8000 frames  <>  SCALED-CAPACITY: 12000.0 frames (CAPACITY:8000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=2 ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for NONE Exp 3: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 3: Env:Baseline (None), Attack:No, Rate:0.0, Frames:8000, QubitAlloc=Default, SC:12000 (Scale=1.5 x Cap=8000), Seed: 16587\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.40706611625366484], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 3: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 GNEURALUCB          : Reward=3015.55, Efficiency=091.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 3: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=2698.94, Efficiency=081.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 3: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=2978.50, Efficiency=089.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 3: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=3012.68, Efficiency=090.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.712]\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 3: Env:Baseline (None), Attack:No, Rate:0.0, Frames:8000, QubitAlloc=Default, SC:12000 (Scale=1.5 x Cap=8000), Seed: 16587\n",
      "\t-->üèÜ EXP3 Winner:GNeuralUCB          (Gap:009.0%) [Env:Baseline (None), Attack:No X Rate:0.0, Frames:8000, SCapacity=12000, Alloc=Default]\n",
      "‚úì Experiment 3 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 10000 frames  <>  SCALED-CAPACITY: 15000.0 frames (CAPACITY:10000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=3 ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for NONE Exp 4: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 4: Env:Baseline (None), Attack:No, Rate:0.0, Frames:10000, QubitAlloc=Default, SC:15000 (Scale=1.5 x Cap=10000), Seed: 13579\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.4202961453677382], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 4: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 GNEURALUCB          : Reward=3823.88, Efficiency=091.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=15000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 4: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=4103.22, Efficiency=097.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=15000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 4: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=3814.89, Efficiency=090.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=15000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 4: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=3799.27, Efficiency=090.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=15000, Threshold=0.712]\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 4: Env:Baseline (None), Attack:No, Rate:0.0, Frames:10000, QubitAlloc=Default, SC:15000 (Scale=1.5 x Cap=10000), Seed: 13579\n",
      "\t-->üèÜ EXP4 Winner:EXPNeuralUCB        (Gap:002.4%) [Env:Baseline (None), Attack:No X Rate:0.0, Frames:10000, SCapacity=15000, Alloc=Default]\n",
      "‚úì Experiment 4 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 12000 frames  <>  SCALED-CAPACITY: 18000.0 frames (CAPACITY:12000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=4 ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for NONE Exp 5: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 5: Env:Baseline (None), Attack:No, Rate:0.0, Frames:12000, QubitAlloc=Default, SC:18000 (Scale=1.5 x Cap=12000), Seed: 15608\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.3570300357377887], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 5: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 GNEURALUCB          : Reward=4459.93, Efficiency=089.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=18000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 5: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=4186.32, Efficiency=084.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=18000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 5: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=4458.33, Efficiency=089.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=18000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 5: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=4495.93, Efficiency=090.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=18000, Threshold=0.712]\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 5: Env:Baseline (None), Attack:No, Rate:0.0, Frames:12000, QubitAlloc=Default, SC:18000 (Scale=1.5 x Cap=12000), Seed: 15608\n",
      "\t-->üèÜ EXP5 Winner:iCPursuitNeuralUCB  (Gap:009.5%) [Env:Baseline (None), Attack:No X Rate:0.0, Frames:12000, SCapacity=18000, Alloc=Default]\n",
      "‚úì Experiment 5 completed successfully.\n",
      "Total experiment time: 1019.0s\n",
      "Experiments completed for none\n",
      "‚úì Scenario 'stochastic' evaluation completed.\n",
      "‚úì Scenario 'markov' evaluation completed.\n",
      "‚úì Scenario 'adaptive' evaluation completed.\n",
      "‚úì Scenario 'onlineadaptive' evaluation completed.\n",
      "‚úì Scenario 'none' evaluation completed.\n",
      "\n",
      "======================================================================\n",
      "COMPREHENSIVE SCENARIO PERFORMANCE ANALYSIS\n",
      "======================================================================\n",
      "SCENARIO: STOCHASTIC\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: CPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 3180.83\n",
      "\t‚Ä¢ Winner Avg Gap: 0013.60%\n",
      "\t‚Ä¢ Winner Avg Reward: 2750.38\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0086.40%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 1 wins\n",
      "\t\t- EXPNeuralUCB: 2 wins\n",
      "\t\t- CPursuitNeuralUCB: 1 wins\n",
      "\t\t- iCPursuitNeuralUCB: 1 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: STOCHASTIC\n",
      "======================================================================\n",
      "SCENARIO: \tSTOCHASTIC RANDOM FAILURES\n",
      "----------------------------------------\n",
      "Recommended Model: \tCPursuitNeuralUCB (Won 1/5 experiments)\n",
      "\tWinner Avg Gap: \t013.6%\n",
      "\tWinner Avg Efficiency: \t086.4%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t086.4% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t086.3% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t086.2% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t084.8% Efficiency \t(Won 2/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: MARKOV\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 2947.96\n",
      "\t‚Ä¢ Winner Avg Gap: 0043.40%\n",
      "\t‚Ä¢ Winner Avg Reward: 1686.74\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0056.60%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 5 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: MARKOV\n",
      "======================================================================\n",
      "SCENARIO: \tMARKOV ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 5/5 experiments)\n",
      "\tWinner Avg Gap: \t043.4%\n",
      "\tWinner Avg Efficiency: \t056.6%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t056.6% Efficiency \t(Won 5/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t050.2% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t050.2% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t047.6% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: CPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 3143.66\n",
      "\t‚Ä¢ Winner Avg Gap: 0029.70%\n",
      "\t‚Ä¢ Winner Avg Reward: 2213.55\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0070.30%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 1 wins\n",
      "\t\t- EXPNeuralUCB: 2 wins\n",
      "\t\t- CPursuitNeuralUCB: 2 wins\n",
      "\t\t- iCPursuitNeuralUCB: 0 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tADAPTIVE ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tCPursuitNeuralUCB (Won 2/5 experiments)\n",
      "\tWinner Avg Gap: \t029.7%\n",
      "\tWinner Avg Efficiency: \t070.3%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t070.3% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t069.8% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t069.6% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t069.1% Efficiency \t(Won 2/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ONLINEADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: GNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 3156.63\n",
      "\t‚Ä¢ Winner Avg Gap: 0030.92%\n",
      "\t‚Ä¢ Winner Avg Reward: 2192.88\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0069.08%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 3 wins\n",
      "\t\t- EXPNeuralUCB: 1 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 1 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ONLINEADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tONLINE ADAPTIVE ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tGNeuralUCB (Won 3/5 experiments)\n",
      "\tWinner Avg Gap: \t030.9%\n",
      "\tWinner Avg Efficiency: \t069.1%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ GNeuralUCB     : \t069.1% Efficiency \t(Won 3/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t069.0% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t068.8% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t067.0% Efficiency \t(Won 1/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: NONE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 3283.79\n",
      "\t‚Ä¢ Winner Avg Gap: 0009.16%\n",
      "\t‚Ä¢ Winner Avg Reward: 2980.52\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0090.84%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 2 wins\n",
      "\t\t- EXPNeuralUCB: 2 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 1 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: NONE\n",
      "======================================================================\n",
      "SCENARIO: \tBASELINE (OPTIMAL CONDITIONS)\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 1/5 experiments)\n",
      "\tWinner Avg Gap: \t009.2%\n",
      "\tWinner Avg Efficiency: \t090.8%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t090.8% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t090.8% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t090.6% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t088.0% Efficiency \t(Won 2/5 experiments)\n",
      "======================================================================\n",
      "KEY INSIGHTS:\n",
      "Best Performing Model Analysis (CPursuitNeuralUCB):\n",
      "\t‚Ä¢ Stochastic Performance:    \t2750.385\n",
      "\t‚Ä¢ Baseline Performance:      \t2980.517\n",
      "\t‚Ä¢ Performance Retention:     \t092.3%\n",
      "\tGOOD:               \tAcceptable performance under stochastic conditions\n",
      "Statistical Analysis:\n",
      "\t‚Ä¢ Total models evaluated:     \t5\n",
      "\t‚Ä¢ Experiments per environment:\t5\n",
      "\t‚Ä¢ Quantum network simulation: \tComprehensive stochastic modeling\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "COMPREHENSIVE SCENARIO PERFORMANCE ANALYSIS\n",
      "======================================================================\n",
      "SCENARIO: STOCHASTIC\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: CPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 3180.83\n",
      "\t‚Ä¢ Winner Avg Gap: 0013.60%\n",
      "\t‚Ä¢ Winner Avg Reward: 2750.38\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0086.40%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 1 wins\n",
      "\t\t- EXPNeuralUCB: 2 wins\n",
      "\t\t- CPursuitNeuralUCB: 1 wins\n",
      "\t\t- iCPursuitNeuralUCB: 1 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: STOCHASTIC\n",
      "======================================================================\n",
      "SCENARIO: \tSTOCHASTIC RANDOM FAILURES\n",
      "----------------------------------------\n",
      "Recommended Model: \tCPursuitNeuralUCB (Won 1/5 experiments)\n",
      "\tWinner Avg Gap: \t013.6%\n",
      "\tWinner Avg Efficiency: \t086.4%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t086.4% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t086.3% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t086.2% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t084.8% Efficiency \t(Won 2/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: MARKOV\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 2947.96\n",
      "\t‚Ä¢ Winner Avg Gap: 0043.40%\n",
      "\t‚Ä¢ Winner Avg Reward: 1686.74\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0056.60%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 5 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: MARKOV\n",
      "======================================================================\n",
      "SCENARIO: \tMARKOV ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 5/5 experiments)\n",
      "\tWinner Avg Gap: \t043.4%\n",
      "\tWinner Avg Efficiency: \t056.6%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t056.6% Efficiency \t(Won 5/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t050.2% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t050.2% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t047.6% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: CPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 3143.66\n",
      "\t‚Ä¢ Winner Avg Gap: 0029.70%\n",
      "\t‚Ä¢ Winner Avg Reward: 2213.55\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0070.30%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 1 wins\n",
      "\t\t- EXPNeuralUCB: 2 wins\n",
      "\t\t- CPursuitNeuralUCB: 2 wins\n",
      "\t\t- iCPursuitNeuralUCB: 0 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tADAPTIVE ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tCPursuitNeuralUCB (Won 2/5 experiments)\n",
      "\tWinner Avg Gap: \t029.7%\n",
      "\tWinner Avg Efficiency: \t070.3%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t070.3% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t069.8% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t069.6% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t069.1% Efficiency \t(Won 2/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ONLINEADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: GNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 3156.63\n",
      "\t‚Ä¢ Winner Avg Gap: 0030.92%\n",
      "\t‚Ä¢ Winner Avg Reward: 2192.88\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0069.08%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 3 wins\n",
      "\t\t- EXPNeuralUCB: 1 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 1 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ONLINEADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tONLINE ADAPTIVE ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tGNeuralUCB (Won 3/5 experiments)\n",
      "\tWinner Avg Gap: \t030.9%\n",
      "\tWinner Avg Efficiency: \t069.1%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ GNeuralUCB     : \t069.1% Efficiency \t(Won 3/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t069.0% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t068.8% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t067.0% Efficiency \t(Won 1/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: NONE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 3283.79\n",
      "\t‚Ä¢ Winner Avg Gap: 0009.16%\n",
      "\t‚Ä¢ Winner Avg Reward: 2980.52\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0090.84%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 2 wins\n",
      "\t\t- EXPNeuralUCB: 2 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 1 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: NONE\n",
      "======================================================================\n",
      "SCENARIO: \tBASELINE (OPTIMAL CONDITIONS)\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 1/5 experiments)\n",
      "\tWinner Avg Gap: \t009.2%\n",
      "\tWinner Avg Efficiency: \t090.8%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t090.8% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t090.8% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t090.6% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t088.0% Efficiency \t(Won 2/5 experiments)\n",
      "======================================================================\n",
      "‚úÖ Evaluation completed!\n",
      "[Logging Redirect Stopped]\n",
      "\n",
      "üßπ Final cleanup for Default\n",
      "\n",
      "======================================================================\n",
      "‚úÖ COMPLETED: Default\n",
      "======================================================================\n",
      "\n",
      "Default COMPLETED SUCCESSFULLY\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Preparing: Default at scale 2\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üîß Generating physics parameters for model: paper2\n",
      "\n",
      "===================== GET LOCAL REGISTRY =====================\n",
      "‚Üí Skipping local cache (force=True or file missing)\n",
      "\n",
      "===================== BUILD LOCAL REGISTRY =====================\n",
      "\n",
      "================================================================================\n",
      "üîç SCANNING LOCAL FILES\n",
      "================================================================================\n",
      "Parameters: load_to_drive=False, force=False\n",
      "\n",
      "üìÇ Checking DRIVE mode: /content/drive/Shareddrives/ai_quantum_computing/quantum_data_lake\n",
      "   ‚ö†Ô∏è  Path does not exist, skipping\n",
      "\n",
      "üìÇ Checking LOCAL mode: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config\n",
      "   ‚úÖ Path exists, starting walk...\n",
      "   üö∂ Walking directory tree: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config\n",
      "\n",
      "   üìÅ Directory: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201\n",
      "      Relative: framework_state/day_20260201\n",
      "      Component: framework_state\n",
      "      Date: day_20260201\n",
      "      üìÑ Processing 2540 files in framework_state/day_20260201\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "      üìä framework_state/day_20260201: 2514/2540 files processed\n",
      "      üìä framework_state/day_20260201: 0/2540 files skipped\n",
      "      üìä framework_state/day_20260201: 26/2540 files conflicted\n",
      "\n",
      "   üìÅ Directory: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/model_state/day_20260201\n",
      "      Relative: model_state/day_20260201\n",
      "      Component: model_state\n",
      "      Date: day_20260201\n",
      "      üìÑ Processing 9020 files in model_state/day_20260201\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "      üìä model_state/day_20260201: 9020/9020 files processed\n",
      "      üìä model_state/day_20260201: 0/9020 files skipped\n",
      "      üìä model_state/day_20260201: 0/9020 files conflicted\n",
      "\n",
      "   üìä Processed 2 directories\n",
      "\n",
      "================================================================================\n",
      "üì¶ BUILDING FINAL REGISTRY\n",
      "================================================================================\n",
      "Components found: ['framework_state', 'model_state']\n",
      "  ‚Ä¢ framework_state: 2514 files\n",
      "  ‚Ä¢ model_state: 9020 files\n",
      "\n",
      "‚úÖ SCAN COMPLETE\n",
      "Modes scanned: 1\n",
      "Total files in registry: 11534\n",
      "================================================================================\n",
      "\n",
      "\t‚Üí Filesystem scan found 11534 files\n",
      "\n",
      "===================== GET DRIVE REGISTRY =====================\n",
      "===================== REGISTRY BUILD COMPLETE =====================\n",
      "\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "\tüì¶ LocalBackupManager Registry Saved Locally in LOCAL\n",
      "BUILDING REGISTRY WITH 0 EXPECTED COMPONENTS KEYS\n",
      "\n",
      "===================== GET LOCAL REGISTRY =====================\n",
      "‚Üí Skipping local cache (force=True or file missing)\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "\tüì¶ LocalBackupManager Registry Saved Locally in LOCAL\n",
      "\n",
      "======================================================================\n",
      "üéØ AllocatorRunner initialized: Default\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "üöÄ STARTING ALLOCATOR: Default\n",
      "======================================================================\n",
      "\n",
      "üìä Physics Model: paper2\n",
      "\n",
      "üìã Allocator Config:\n",
      "   Type: Default\n",
      "   Testbed: paper2\n",
      "   Paths: 8\n",
      "   Total Qubits: 35\n",
      "   Min per route: 2\n",
      "   Seed: 42\n",
      "‚úÖ Allocator created: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "‚úì Allocator: QubitAllocator (8 paths)\n",
      "   Initial allocation: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "Generated paper2 topology: 15 nodes, 51 edges\n",
      "üìä Paper2 Physics: Time-based decay\n",
      "   ‚úì Using MATLAB constants: r_dephase=10000, c_light=300000000.0\n",
      "\n",
      "======================================================================\n",
      "RUN 1 | Scale: 2 | Exp: 5\n",
      "======================================================================\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "No state found for MultiRunEvaluator, disabling resume for Experiment Runners\n",
      "Multi-Run Evaluator Initialized\n",
      "Environment Type: None\n",
      "Frame Range: 4000 -> 12000 (step: 2000)\n",
      "quantum_exps-Default(paper2)_alloc-all_envs-5_attacks-4000_2000-5_runs-S2T\n",
      "[Logging Redirect Initialized]\n",
      "Log File: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/quantum_logs/quantum_exps-Default(paper2)_alloc-all_envs-5_attacks-4000_2000-5_runs-S2T_20260201_log.txt\n",
      "‚öô Running evaluation...\n",
      "======================================================================\n",
      "SCENARIOS MODEL EVALUATION\n",
      "======================================================================\n",
      "Testing algorithm performance against:\n",
      "\t‚Ä¢ Stochastic:  \tNatural quantum decoherence and network failures\n",
      "\t‚Ä¢ Baseline:    \tOptimal conditions for validation\n",
      "======================================================================\n",
      "Models to Test:             \tOracle, GNeuralUCB, EXPNeuralUCB, CPursuitNeuralUCB, iCPursuitNeuralUCB\n",
      "Experiments per Scenario:   \t5\n",
      "======================================================================\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: STOCHASTIC RANDOM FAILURES\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: STOCHASTIC\n",
      "Category: Stochastic (Natural Random Failures)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 4000 frames  <>  SCALED-CAPACITY: 8000 frames (CAPACITY:4000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=0 ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 1: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 1: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:4000, QubitAlloc=Default, SC:8000 (Scale=2 x Cap=4000), Seed: 19730\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.38852779914991686], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 1: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 GNEURALUCB          : Reward=1385.61, Efficiency=084.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 1: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=1429.95, Efficiency=086.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 1: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=1396.64, Efficiency=084.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 1: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=1382.21, Efficiency=083.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.712]\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 1: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:4000, QubitAlloc=Default, SC:8000 (Scale=2 x Cap=4000), Seed: 19730\n",
      "\t-->üèÜ EXP1 Winner:EXPNeuralUCB        (Gap:013.3%) [Env:Stochastic, Attack:Random X Rate:0.0625, Frames:4000, SCapacity=8000, Alloc=Default]\n",
      "‚úì Experiment 1 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 6000 frames  <>  SCALED-CAPACITY: 12000 frames (CAPACITY:6000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=1 ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 2: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 2: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:6000, QubitAlloc=Default, SC:12000 (Scale=2 x Cap=6000), Seed: 17421\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.38852779914991686], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 2: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 GNEURALUCB          : Reward=2039.52, Efficiency=087.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 2: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=2146.60, Efficiency=092.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 2: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=2038.43, Efficiency=087.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 2: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=2032.94, Efficiency=087.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.712]\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 2: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:6000, QubitAlloc=Default, SC:12000 (Scale=2 x Cap=6000), Seed: 17421\n",
      "\t-->üèÜ EXP2 Winner:EXPNeuralUCB        (Gap:007.8%) [Env:Stochastic, Attack:Random X Rate:0.0625, Frames:6000, SCapacity=12000, Alloc=Default]\n",
      "‚úì Experiment 2 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 8000 frames  <>  SCALED-CAPACITY: 16000 frames (CAPACITY:8000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=2 ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 3: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 3: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:8000, QubitAlloc=Default, SC:16000 (Scale=2 x Cap=8000), Seed: 17649\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.369660064851862], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 3: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 GNEURALUCB          : Reward=2588.23, Efficiency=086.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=16000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 3: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=2421.80, Efficiency=081.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=16000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 3: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=2612.19, Efficiency=087.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=16000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 3: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=2598.71, Efficiency=087.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=16000, Threshold=0.712]\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 3: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:8000, QubitAlloc=Default, SC:16000 (Scale=2 x Cap=8000), Seed: 17649\n",
      "\t-->üèÜ EXP3 Winner:CPursuitNeuralUCB   (Gap:012.3%) [Env:Stochastic, Attack:Random X Rate:0.0625, Frames:8000, SCapacity=16000, Alloc=Default]\n",
      "‚úì Experiment 3 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 10000 frames  <>  SCALED-CAPACITY: 20000 frames (CAPACITY:10000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=3 ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 4: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 4: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:10000, QubitAlloc=Default, SC:20000 (Scale=2 x Cap=10000), Seed: 20670\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.4202961453677382], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 4: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 GNEURALUCB          : Reward=3605.00, Efficiency=085.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=20000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 4: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=3357.83, Efficiency=080.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=20000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 4: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=3568.78, Efficiency=085.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=20000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 4: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=3588.73, Efficiency=085.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=20000, Threshold=0.712]\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 4: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:10000, QubitAlloc=Default, SC:20000 (Scale=2 x Cap=10000), Seed: 20670\n",
      "\t-->üèÜ EXP4 Winner:GNeuralUCB          (Gap:014.1%) [Env:Stochastic, Attack:Random X Rate:0.0625, Frames:10000, SCapacity=20000, Alloc=Default]\n",
      "‚úì Experiment 4 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 12000 frames  <>  SCALED-CAPACITY: 24000 frames (CAPACITY:12000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=4 ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 5: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 5: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:12000, QubitAlloc=Default, SC:24000 (Scale=2 x Cap=12000), Seed: 19632\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.4012351376370454], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 5: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 GNEURALUCB          : Reward=4135.48, Efficiency=087.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=24000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 5: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=3993.42, Efficiency=084.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=24000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 5: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=4135.88, Efficiency=087.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=24000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 5: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=4141.72, Efficiency=087.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=24000, Threshold=0.712]\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 5: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:12000, QubitAlloc=Default, SC:24000 (Scale=2 x Cap=12000), Seed: 19632\n",
      "\t-->üèÜ EXP5 Winner:iCPursuitNeuralUCB  (Gap:012.8%) [Env:Stochastic, Attack:Random X Rate:0.0625, Frames:12000, SCapacity=24000, Alloc=Default]\n",
      "‚úì Experiment 5 completed successfully.\n",
      "Total experiment time: 867.4s\n",
      "Experiments completed for stochastic\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: MARKOV ADVERSARIAL ATTACK\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: MARKOV\n",
      "Category: Structured (Markov Chain Based)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 4000 frames  <>  SCALED-CAPACITY: 8000 frames (CAPACITY:4000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=0 ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for MARKOV Exp 1: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 1: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:4000, QubitAlloc=Default, SC:8000 (Scale=2 x Cap=4000), Seed: 15617\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.40706611625366484], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 1: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 GNEURALUCB          : Reward=0764.39, Efficiency=049.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=8000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 1: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=0727.57, Efficiency=046.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=8000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 1: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=0753.74, Efficiency=048.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=8000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 1: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=0850.50, Efficiency=054.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=8000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 1: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:4000, QubitAlloc=Default, SC:8000 (Scale=2 x Cap=4000), Seed: 15617\n",
      "\t-->üèÜ EXP1 Winner:iCPursuitNeuralUCB  (Gap:045.4%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:4000, SCapacity=8000, Alloc=Default]\n",
      "‚úì Experiment 1 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 6000 frames  <>  SCALED-CAPACITY: 12000 frames (CAPACITY:6000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=1 ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for MARKOV Exp 2: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 2: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:6000, QubitAlloc=Default, SC:12000 (Scale=2 x Cap=6000), Seed: 15214\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.40706611625366484], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 2: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 GNEURALUCB          : Reward=1120.32, Efficiency=048.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=12000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 2: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=1053.67, Efficiency=046.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=12000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 2: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=1119.56, Efficiency=048.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=12000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 2: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=1258.38, Efficiency=055.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=12000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 2: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:6000, QubitAlloc=Default, SC:12000 (Scale=2 x Cap=6000), Seed: 15214\n",
      "\t-->üèÜ EXP2 Winner:iCPursuitNeuralUCB  (Gap:045.0%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:6000, SCapacity=12000, Alloc=Default]\n",
      "‚úì Experiment 2 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 8000 frames  <>  SCALED-CAPACITY: 16000 frames (CAPACITY:8000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=2 ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for MARKOV Exp 3: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 3: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:8000, QubitAlloc=Default, SC:16000 (Scale=2 x Cap=8000), Seed: 15164\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.4202961453677382], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 3: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 GNEURALUCB          : Reward=1471.96, Efficiency=046.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=16000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 3: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=1425.56, Efficiency=045.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=16000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 3: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=1538.67, Efficiency=048.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=16000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 3: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=1713.52, Efficiency=054.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=16000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 3: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:8000, QubitAlloc=Default, SC:16000 (Scale=2 x Cap=8000), Seed: 15164\n",
      "\t-->üèÜ EXP3 Winner:iCPursuitNeuralUCB  (Gap:045.6%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:8000, SCapacity=16000, Alloc=Default]\n",
      "‚úì Experiment 3 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 10000 frames  <>  SCALED-CAPACITY: 20000 frames (CAPACITY:10000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=3 ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for MARKOV Exp 4: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 4: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:10000, QubitAlloc=Default, SC:20000 (Scale=2 x Cap=10000), Seed: 14599\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.38852779914991686], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 4: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 GNEURALUCB          : Reward=1887.44, Efficiency=049.2% [Retries=3, Failed=0, < Threshold=3, SCapacity=20000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 4: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=1920.04, Efficiency=050.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=20000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 4: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=1879.95, Efficiency=049.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=20000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 4: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=2137.25, Efficiency=055.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=20000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 4: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:10000, QubitAlloc=Default, SC:20000 (Scale=2 x Cap=10000), Seed: 14599\n",
      "\t-->üèÜ EXP4 Winner:iCPursuitNeuralUCB  (Gap:044.2%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:10000, SCapacity=20000, Alloc=Default]\n",
      "‚úì Experiment 4 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 12000 frames  <>  SCALED-CAPACITY: 24000 frames (CAPACITY:12000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=4 ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for MARKOV Exp 5: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 5: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:12000, QubitAlloc=Default, SC:24000 (Scale=2 x Cap=12000), Seed: 14153\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.3579527263647335], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 5: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 GNEURALUCB          : Reward=2220.32, Efficiency=056.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=24000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 5: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=1958.34, Efficiency=050.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=24000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 5: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=2187.99, Efficiency=055.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=24000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 5: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=2474.06, Efficiency=063.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=24000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 5: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:12000, QubitAlloc=Default, SC:24000 (Scale=2 x Cap=12000), Seed: 14153\n",
      "\t-->üèÜ EXP5 Winner:iCPursuitNeuralUCB  (Gap:036.7%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:12000, SCapacity=24000, Alloc=Default]\n",
      "‚úì Experiment 5 completed successfully.\n",
      "Total experiment time: 764.7s\n",
      "Experiments completed for markov\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: ADAPTIVE ADVERSARIAL ATTACK\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: ADAPTIVE\n",
      "Category: Adaptive (Reactive Strategic)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 4000 frames  <>  SCALED-CAPACITY: 8000 frames (CAPACITY:4000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=0 ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 1: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 1: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:4000, QubitAlloc=Default, SC:8000 (Scale=2 x Cap=4000), Seed: 12509\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.38860510852297203], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 1: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 GNEURALUCB          : Reward=1058.16, Efficiency=069.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 1: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=1017.20, Efficiency=066.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 1: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=1068.45, Efficiency=070.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 1: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=1041.23, Efficiency=068.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=8000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 1: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:4000, QubitAlloc=Default, SC:8000 (Scale=2 x Cap=4000), Seed: 12509\n",
      "\t-->üèÜ EXP1 Winner:CPursuitNeuralUCB   (Gap:029.7%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:4000, SCapacity=8000, Alloc=Default]\n",
      "‚úì Experiment 1 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 6000 frames  <>  SCALED-CAPACITY: 12000 frames (CAPACITY:6000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=1 ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 2: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 2: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:6000, QubitAlloc=Default, SC:12000 (Scale=2 x Cap=6000), Seed: 21611\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.38722107258255484], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 2: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 GNEURALUCB          : Reward=1618.60, Efficiency=070.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 2: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=1546.63, Efficiency=067.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 2: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=1603.83, Efficiency=069.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 2: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=1604.04, Efficiency=069.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=12000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 2: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:6000, QubitAlloc=Default, SC:12000 (Scale=2 x Cap=6000), Seed: 21611\n",
      "\t-->üèÜ EXP2 Winner:GNeuralUCB          (Gap:029.6%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:6000, SCapacity=12000, Alloc=Default]\n",
      "‚úì Experiment 2 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 8000 frames  <>  SCALED-CAPACITY: 16000 frames (CAPACITY:8000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=2 ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 3: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 3: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:8000, QubitAlloc=Default, SC:16000 (Scale=2 x Cap=8000), Seed: 19675\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.38229009396593533], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 3: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 GNEURALUCB          : Reward=2124.58, Efficiency=070.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=16000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 3: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=2152.00, Efficiency=071.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=16000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 3: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=2137.37, Efficiency=070.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=16000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 3: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=2126.83, Efficiency=070.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=16000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 3: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:8000, QubitAlloc=Default, SC:16000 (Scale=2 x Cap=8000), Seed: 19675\n",
      "\t-->üèÜ EXP3 Winner:EXPNeuralUCB        (Gap:028.9%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:8000, SCapacity=16000, Alloc=Default]\n",
      "‚úì Experiment 3 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 10000 frames  <>  SCALED-CAPACITY: 20000 frames (CAPACITY:10000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=3 ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 4: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 4: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:10000, QubitAlloc=Default, SC:20000 (Scale=2 x Cap=10000), Seed: 20231\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.4202961453677382], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 4: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 GNEURALUCB          : Reward=2830.21, Efficiency=068.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=20000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 4: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=2916.66, Efficiency=070.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=20000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 4: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=2828.79, Efficiency=068.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=20000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 4: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=2807.28, Efficiency=068.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=20000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 4: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:10000, QubitAlloc=Default, SC:20000 (Scale=2 x Cap=10000), Seed: 20231\n",
      "\t-->üèÜ EXP4 Winner:EXPNeuralUCB        (Gap:029.2%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:10000, SCapacity=20000, Alloc=Default]\n",
      "‚úì Experiment 4 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 12000 frames  <>  SCALED-CAPACITY: 24000 frames (CAPACITY:12000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=4 ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 5: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 5: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:12000, QubitAlloc=Default, SC:24000 (Scale=2 x Cap=12000), Seed: 15657\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.4202961453677382], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 5: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 GNEURALUCB          : Reward=3329.19, Efficiency=070.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=24000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 5: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=3291.62, Efficiency=069.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=24000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 5: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=3429.29, Efficiency=072.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=24000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 5: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=3394.31, Efficiency=071.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=24000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 5: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:12000, QubitAlloc=Default, SC:24000 (Scale=2 x Cap=12000), Seed: 15657\n",
      "\t-->üèÜ EXP5 Winner:CPursuitNeuralUCB   (Gap:027.9%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:12000, SCapacity=24000, Alloc=Default]\n",
      "‚úì Experiment 5 completed successfully.\n",
      "Total experiment time: 881.5s\n",
      "Experiments completed for adaptive\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: ONLINE ADAPTIVE ATTACK\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: ONLINEADAPTIVE\n",
      "Category: Online Adaptive (Real-time Strategic)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 4000 frames  <>  SCALED-CAPACITY: 8000 frames (CAPACITY:4000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=0 ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 1: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:4000, QubitAlloc=Default, SC:8000 (Scale=2 x Cap=4000), Seed: 16665\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.38722107258255484], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 GNEURALUCB          : Reward=1027.32, Efficiency=067.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=1023.88, Efficiency=067.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=1012.04, Efficiency=066.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=1023.05, Efficiency=067.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=8000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:4000, QubitAlloc=Default, SC:8000 (Scale=2 x Cap=4000), Seed: 16665\n",
      "\t-->üèÜ EXP1 Winner:GNeuralUCB          (Gap:032.1%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:4000, SCapacity=8000, Alloc=Default]\n",
      "‚úì Experiment 1 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 6000 frames  <>  SCALED-CAPACITY: 12000 frames (CAPACITY:6000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=1 ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 2: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:6000, QubitAlloc=Default, SC:12000 (Scale=2 x Cap=6000), Seed: 21573\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.4012351376370454], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 GNEURALUCB          : Reward=1616.29, Efficiency=068.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=1547.04, Efficiency=065.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=1618.93, Efficiency=068.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=1648.16, Efficiency=069.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=12000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:6000, QubitAlloc=Default, SC:12000 (Scale=2 x Cap=6000), Seed: 21573\n",
      "\t-->üèÜ EXP2 Winner:iCPursuitNeuralUCB  (Gap:030.6%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:6000, SCapacity=12000, Alloc=Default]\n",
      "‚úì Experiment 2 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 8000 frames  <>  SCALED-CAPACITY: 16000 frames (CAPACITY:8000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=2 ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 3: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:8000, QubitAlloc=Default, SC:16000 (Scale=2 x Cap=8000), Seed: 14973\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.4202961453677382], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 GNEURALUCB          : Reward=2294.40, Efficiency=069.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=16000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=2152.46, Efficiency=064.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=16000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=2279.63, Efficiency=068.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=16000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=2241.88, Efficiency=067.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=16000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:8000, QubitAlloc=Default, SC:16000 (Scale=2 x Cap=8000), Seed: 14973\n",
      "\t-->üèÜ EXP3 Winner:GNeuralUCB          (Gap:031.0%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:8000, SCapacity=16000, Alloc=Default]\n",
      "‚úì Experiment 3 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 10000 frames  <>  SCALED-CAPACITY: 20000 frames (CAPACITY:10000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=3 ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 4: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:10000, QubitAlloc=Default, SC:20000 (Scale=2 x Cap=10000), Seed: 18379\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.4202961453677382], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 GNEURALUCB          : Reward=2776.12, Efficiency=067.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=20000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=2526.34, Efficiency=061.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=20000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=2776.06, Efficiency=067.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=20000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=2760.54, Efficiency=067.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=20000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:10000, QubitAlloc=Default, SC:20000 (Scale=2 x Cap=10000), Seed: 18379\n",
      "\t-->üèÜ EXP4 Winner:GNeuralUCB          (Gap:032.1%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:10000, SCapacity=20000, Alloc=Default]\n",
      "‚úì Experiment 4 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 12000 frames  <>  SCALED-CAPACITY: 24000 frames (CAPACITY:12000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=4 ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 5: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:12000, QubitAlloc=Default, SC:24000 (Scale=2 x Cap=12000), Seed: 14049\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.3739910434684815], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 GNEURALUCB          : Reward=3250.30, Efficiency=072.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=24000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=3386.02, Efficiency=075.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=24000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=3243.36, Efficiency=072.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=24000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=3273.88, Efficiency=073.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=24000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:12000, QubitAlloc=Default, SC:24000 (Scale=2 x Cap=12000), Seed: 14049\n",
      "\t-->üèÜ EXP5 Winner:EXPNeuralUCB        (Gap:024.5%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:12000, SCapacity=24000, Alloc=Default]\n",
      "‚úì Experiment 5 completed successfully.\n",
      "Total experiment time: 912.8s\n",
      "Experiments completed for onlineadaptive\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: BASELINE (OPTIMAL CONDITIONS)\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: NONE\n",
      "Category: Baseline (No Attacks)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 4000 frames  <>  SCALED-CAPACITY: 8000 frames (CAPACITY:4000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=0 ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for NONE Exp 1: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 1: Env:Baseline (None), Attack:No, Rate:0.0, Frames:4000, QubitAlloc=Default, SC:8000 (Scale=2 x Cap=4000), Seed: 19677\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.4004511016966282], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 1: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 GNEURALUCB          : Reward=1430.43, Efficiency=089.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 1: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=1451.54, Efficiency=090.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 1: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=1439.35, Efficiency=089.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 1: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=1443.49, Efficiency=090.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.712]\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 1: Env:Baseline (None), Attack:No, Rate:0.0, Frames:4000, QubitAlloc=Default, SC:8000 (Scale=2 x Cap=4000), Seed: 19677\n",
      "\t-->üèÜ EXP1 Winner:EXPNeuralUCB        (Gap:009.4%) [Env:Baseline (None), Attack:No X Rate:0.0, Frames:4000, SCapacity=8000, Alloc=Default]\n",
      "‚úì Experiment 1 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 6000 frames  <>  SCALED-CAPACITY: 12000 frames (CAPACITY:6000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=1 ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for NONE Exp 2: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 2: Env:Baseline (None), Attack:No, Rate:0.0, Frames:6000, QubitAlloc=Default, SC:12000 (Scale=2 x Cap=6000), Seed: 16724\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.38860510852297203], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 2: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 GNEURALUCB          : Reward=2163.45, Efficiency=092.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 2: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=2002.09, Efficiency=085.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 2: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=2158.16, Efficiency=092.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 2: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=2151.21, Efficiency=092.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.712]\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 2: Env:Baseline (None), Attack:No, Rate:0.0, Frames:6000, QubitAlloc=Default, SC:12000 (Scale=2 x Cap=6000), Seed: 16724\n",
      "\t-->üèÜ EXP2 Winner:GNeuralUCB          (Gap:007.2%) [Env:Baseline (None), Attack:No X Rate:0.0, Frames:6000, SCapacity=12000, Alloc=Default]\n",
      "‚úì Experiment 2 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 8000 frames  <>  SCALED-CAPACITY: 16000 frames (CAPACITY:8000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=2 ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for NONE Exp 3: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 3: Env:Baseline (None), Attack:No, Rate:0.0, Frames:8000, QubitAlloc=Default, SC:16000 (Scale=2 x Cap=8000), Seed: 16587\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.40706611625366484], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 3: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 GNEURALUCB          : Reward=3015.55, Efficiency=091.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=16000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 3: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=2698.94, Efficiency=081.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=16000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 3: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=2978.50, Efficiency=089.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=16000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 3: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=3012.68, Efficiency=090.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=16000, Threshold=0.712]\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 3: Env:Baseline (None), Attack:No, Rate:0.0, Frames:8000, QubitAlloc=Default, SC:16000 (Scale=2 x Cap=8000), Seed: 16587\n",
      "\t-->üèÜ EXP3 Winner:GNeuralUCB          (Gap:009.0%) [Env:Baseline (None), Attack:No X Rate:0.0, Frames:8000, SCapacity=16000, Alloc=Default]\n",
      "‚úì Experiment 3 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 10000 frames  <>  SCALED-CAPACITY: 20000 frames (CAPACITY:10000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=3 ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for NONE Exp 4: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 4: Env:Baseline (None), Attack:No, Rate:0.0, Frames:10000, QubitAlloc=Default, SC:20000 (Scale=2 x Cap=10000), Seed: 13579\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.4202961453677382], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 4: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 GNEURALUCB          : Reward=3823.88, Efficiency=091.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=20000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 4: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=4103.22, Efficiency=097.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=20000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 4: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=3814.89, Efficiency=090.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=20000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 4: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=3799.27, Efficiency=090.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=20000, Threshold=0.712]\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 4: Env:Baseline (None), Attack:No, Rate:0.0, Frames:10000, QubitAlloc=Default, SC:20000 (Scale=2 x Cap=10000), Seed: 13579\n",
      "\t-->üèÜ EXP4 Winner:EXPNeuralUCB        (Gap:002.4%) [Env:Baseline (None), Attack:No X Rate:0.0, Frames:10000, SCapacity=20000, Alloc=Default]\n",
      "‚úì Experiment 4 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 12000 frames  <>  SCALED-CAPACITY: 24000 frames (CAPACITY:12000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=4 ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for NONE Exp 5: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 5: Env:Baseline (None), Attack:No, Rate:0.0, Frames:12000, QubitAlloc=Default, SC:24000 (Scale=2 x Cap=12000), Seed: 15608\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.3570300357377887], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 5: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 GNEURALUCB          : Reward=4459.93, Efficiency=089.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=24000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 5: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=4186.32, Efficiency=084.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=24000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 5: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=4458.33, Efficiency=089.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=24000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 5: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=4495.93, Efficiency=090.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=24000, Threshold=0.712]\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 5: Env:Baseline (None), Attack:No, Rate:0.0, Frames:12000, QubitAlloc=Default, SC:24000 (Scale=2 x Cap=12000), Seed: 15608\n",
      "\t-->üèÜ EXP5 Winner:iCPursuitNeuralUCB  (Gap:009.5%) [Env:Baseline (None), Attack:No X Rate:0.0, Frames:12000, SCapacity=24000, Alloc=Default]\n",
      "‚úì Experiment 5 completed successfully.\n",
      "Total experiment time: 1007.4s\n",
      "Experiments completed for none\n",
      "‚úì Scenario 'stochastic' evaluation completed.\n",
      "‚úì Scenario 'markov' evaluation completed.\n",
      "‚úì Scenario 'adaptive' evaluation completed.\n",
      "‚úì Scenario 'onlineadaptive' evaluation completed.\n",
      "‚úì Scenario 'none' evaluation completed.\n",
      "\n",
      "======================================================================\n",
      "COMPREHENSIVE SCENARIO PERFORMANCE ANALYSIS\n",
      "======================================================================\n",
      "SCENARIO: STOCHASTIC\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: CPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 3180.83\n",
      "\t‚Ä¢ Winner Avg Gap: 0013.60%\n",
      "\t‚Ä¢ Winner Avg Reward: 2750.38\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0086.40%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 1 wins\n",
      "\t\t- EXPNeuralUCB: 2 wins\n",
      "\t\t- CPursuitNeuralUCB: 1 wins\n",
      "\t\t- iCPursuitNeuralUCB: 1 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: STOCHASTIC\n",
      "======================================================================\n",
      "SCENARIO: \tSTOCHASTIC RANDOM FAILURES\n",
      "----------------------------------------\n",
      "Recommended Model: \tCPursuitNeuralUCB (Won 1/5 experiments)\n",
      "\tWinner Avg Gap: \t013.6%\n",
      "\tWinner Avg Efficiency: \t086.4%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t086.4% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t086.3% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t086.2% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t084.8% Efficiency \t(Won 2/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: MARKOV\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 2947.96\n",
      "\t‚Ä¢ Winner Avg Gap: 0043.40%\n",
      "\t‚Ä¢ Winner Avg Reward: 1686.74\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0056.60%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 5 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: MARKOV\n",
      "======================================================================\n",
      "SCENARIO: \tMARKOV ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 5/5 experiments)\n",
      "\tWinner Avg Gap: \t043.4%\n",
      "\tWinner Avg Efficiency: \t056.6%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t056.6% Efficiency \t(Won 5/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t050.2% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t050.2% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t047.6% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: CPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 3143.66\n",
      "\t‚Ä¢ Winner Avg Gap: 0029.70%\n",
      "\t‚Ä¢ Winner Avg Reward: 2213.55\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0070.30%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 1 wins\n",
      "\t\t- EXPNeuralUCB: 2 wins\n",
      "\t\t- CPursuitNeuralUCB: 2 wins\n",
      "\t\t- iCPursuitNeuralUCB: 0 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tADAPTIVE ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tCPursuitNeuralUCB (Won 2/5 experiments)\n",
      "\tWinner Avg Gap: \t029.7%\n",
      "\tWinner Avg Efficiency: \t070.3%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t070.3% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t069.8% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t069.6% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t069.1% Efficiency \t(Won 2/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ONLINEADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: GNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 3156.63\n",
      "\t‚Ä¢ Winner Avg Gap: 0030.92%\n",
      "\t‚Ä¢ Winner Avg Reward: 2192.88\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0069.08%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 3 wins\n",
      "\t\t- EXPNeuralUCB: 1 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 1 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ONLINEADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tONLINE ADAPTIVE ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tGNeuralUCB (Won 3/5 experiments)\n",
      "\tWinner Avg Gap: \t030.9%\n",
      "\tWinner Avg Efficiency: \t069.1%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ GNeuralUCB     : \t069.1% Efficiency \t(Won 3/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t069.0% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t068.8% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t067.0% Efficiency \t(Won 1/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: NONE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 3283.79\n",
      "\t‚Ä¢ Winner Avg Gap: 0009.16%\n",
      "\t‚Ä¢ Winner Avg Reward: 2980.52\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0090.84%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 2 wins\n",
      "\t\t- EXPNeuralUCB: 2 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 1 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: NONE\n",
      "======================================================================\n",
      "SCENARIO: \tBASELINE (OPTIMAL CONDITIONS)\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 1/5 experiments)\n",
      "\tWinner Avg Gap: \t009.2%\n",
      "\tWinner Avg Efficiency: \t090.8%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t090.8% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t090.8% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t090.6% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t088.0% Efficiency \t(Won 2/5 experiments)\n",
      "======================================================================\n",
      "KEY INSIGHTS:\n",
      "Best Performing Model Analysis (CPursuitNeuralUCB):\n",
      "\t‚Ä¢ Stochastic Performance:    \t2750.385\n",
      "\t‚Ä¢ Baseline Performance:      \t2980.517\n",
      "\t‚Ä¢ Performance Retention:     \t092.3%\n",
      "\tGOOD:               \tAcceptable performance under stochastic conditions\n",
      "Statistical Analysis:\n",
      "\t‚Ä¢ Total models evaluated:     \t5\n",
      "\t‚Ä¢ Experiments per environment:\t5\n",
      "\t‚Ä¢ Quantum network simulation: \tComprehensive stochastic modeling\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "COMPREHENSIVE SCENARIO PERFORMANCE ANALYSIS\n",
      "======================================================================\n",
      "SCENARIO: STOCHASTIC\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: CPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 3180.83\n",
      "\t‚Ä¢ Winner Avg Gap: 0013.60%\n",
      "\t‚Ä¢ Winner Avg Reward: 2750.38\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0086.40%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 1 wins\n",
      "\t\t- EXPNeuralUCB: 2 wins\n",
      "\t\t- CPursuitNeuralUCB: 1 wins\n",
      "\t\t- iCPursuitNeuralUCB: 1 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: STOCHASTIC\n",
      "======================================================================\n",
      "SCENARIO: \tSTOCHASTIC RANDOM FAILURES\n",
      "----------------------------------------\n",
      "Recommended Model: \tCPursuitNeuralUCB (Won 1/5 experiments)\n",
      "\tWinner Avg Gap: \t013.6%\n",
      "\tWinner Avg Efficiency: \t086.4%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t086.4% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t086.3% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t086.2% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t084.8% Efficiency \t(Won 2/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: MARKOV\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 2947.96\n",
      "\t‚Ä¢ Winner Avg Gap: 0043.40%\n",
      "\t‚Ä¢ Winner Avg Reward: 1686.74\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0056.60%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 5 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: MARKOV\n",
      "======================================================================\n",
      "SCENARIO: \tMARKOV ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 5/5 experiments)\n",
      "\tWinner Avg Gap: \t043.4%\n",
      "\tWinner Avg Efficiency: \t056.6%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t056.6% Efficiency \t(Won 5/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t050.2% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t050.2% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t047.6% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: CPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 3143.66\n",
      "\t‚Ä¢ Winner Avg Gap: 0029.70%\n",
      "\t‚Ä¢ Winner Avg Reward: 2213.55\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0070.30%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 1 wins\n",
      "\t\t- EXPNeuralUCB: 2 wins\n",
      "\t\t- CPursuitNeuralUCB: 2 wins\n",
      "\t\t- iCPursuitNeuralUCB: 0 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tADAPTIVE ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tCPursuitNeuralUCB (Won 2/5 experiments)\n",
      "\tWinner Avg Gap: \t029.7%\n",
      "\tWinner Avg Efficiency: \t070.3%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t070.3% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t069.8% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t069.6% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t069.1% Efficiency \t(Won 2/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ONLINEADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: GNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 3156.63\n",
      "\t‚Ä¢ Winner Avg Gap: 0030.92%\n",
      "\t‚Ä¢ Winner Avg Reward: 2192.88\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0069.08%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 3 wins\n",
      "\t\t- EXPNeuralUCB: 1 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 1 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ONLINEADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tONLINE ADAPTIVE ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tGNeuralUCB (Won 3/5 experiments)\n",
      "\tWinner Avg Gap: \t030.9%\n",
      "\tWinner Avg Efficiency: \t069.1%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ GNeuralUCB     : \t069.1% Efficiency \t(Won 3/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t069.0% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t068.8% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t067.0% Efficiency \t(Won 1/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: NONE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 3283.79\n",
      "\t‚Ä¢ Winner Avg Gap: 0009.16%\n",
      "\t‚Ä¢ Winner Avg Reward: 2980.52\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0090.84%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 2 wins\n",
      "\t\t- EXPNeuralUCB: 2 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 1 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: NONE\n",
      "======================================================================\n",
      "SCENARIO: \tBASELINE (OPTIMAL CONDITIONS)\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 1/5 experiments)\n",
      "\tWinner Avg Gap: \t009.2%\n",
      "\tWinner Avg Efficiency: \t090.8%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t090.8% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t090.8% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t090.6% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t088.0% Efficiency \t(Won 2/5 experiments)\n",
      "======================================================================\n",
      "‚úÖ Evaluation completed!\n",
      "[Logging Redirect Stopped]\n",
      "\n",
      "üßπ Final cleanup for Default\n",
      "\n",
      "======================================================================\n",
      "‚úÖ COMPLETED: Default\n",
      "======================================================================\n",
      "\n",
      "Default COMPLETED SUCCESSFULLY\n",
      "\n",
      "======================================================================\n",
      "RUNNING: Dynamic on Paper 2 (Chaudhary et al. 2023 - Quantum MAB)\n",
      "======================================================================\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Preparing: Dynamic at scale 1\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üîß Generating physics parameters for model: paper2\n",
      "\n",
      "===================== GET LOCAL REGISTRY =====================\n",
      "‚Üí Skipping local cache (force=True or file missing)\n",
      "\n",
      "===================== BUILD LOCAL REGISTRY =====================\n",
      "\n",
      "================================================================================\n",
      "üîç SCANNING LOCAL FILES\n",
      "================================================================================\n",
      "Parameters: load_to_drive=False, force=False\n",
      "\n",
      "üìÇ Checking DRIVE mode: /content/drive/Shareddrives/ai_quantum_computing/quantum_data_lake\n",
      "   ‚ö†Ô∏è  Path does not exist, skipping\n",
      "\n",
      "üìÇ Checking LOCAL mode: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config\n",
      "   ‚úÖ Path exists, starting walk...\n",
      "   üö∂ Walking directory tree: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config\n",
      "\n",
      "   üìÅ Directory: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201\n",
      "      Relative: framework_state/day_20260201\n",
      "      Component: framework_state\n",
      "      Date: day_20260201\n",
      "      üìÑ Processing 2540 files in framework_state/day_20260201\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "      üìä framework_state/day_20260201: 2514/2540 files processed\n",
      "      üìä framework_state/day_20260201: 0/2540 files skipped\n",
      "      üìä framework_state/day_20260201: 26/2540 files conflicted\n",
      "\n",
      "   üìÅ Directory: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/model_state/day_20260201\n",
      "      Relative: model_state/day_20260201\n",
      "      Component: model_state\n",
      "      Date: day_20260201\n",
      "      üìÑ Processing 9040 files in model_state/day_20260201\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "      üìä model_state/day_20260201: 9040/9040 files processed\n",
      "      üìä model_state/day_20260201: 0/9040 files skipped\n",
      "      üìä model_state/day_20260201: 0/9040 files conflicted\n",
      "\n",
      "   üìä Processed 2 directories\n",
      "\n",
      "================================================================================\n",
      "üì¶ BUILDING FINAL REGISTRY\n",
      "================================================================================\n",
      "Components found: ['framework_state', 'model_state']\n",
      "  ‚Ä¢ framework_state: 2514 files\n",
      "  ‚Ä¢ model_state: 9040 files\n",
      "\n",
      "‚úÖ SCAN COMPLETE\n",
      "Modes scanned: 1\n",
      "Total files in registry: 11554\n",
      "================================================================================\n",
      "\n",
      "\t‚Üí Filesystem scan found 11554 files\n",
      "\n",
      "===================== GET DRIVE REGISTRY =====================\n",
      "===================== REGISTRY BUILD COMPLETE =====================\n",
      "\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "\tüì¶ LocalBackupManager Registry Saved Locally in LOCAL\n",
      "BUILDING REGISTRY WITH 0 EXPECTED COMPONENTS KEYS\n",
      "\n",
      "===================== GET LOCAL REGISTRY =====================\n",
      "‚Üí Skipping local cache (force=True or file missing)\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "\tüì¶ LocalBackupManager Registry Saved Locally in LOCAL\n",
      "\n",
      "======================================================================\n",
      "üéØ AllocatorRunner initialized: Dynamic\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "üöÄ STARTING ALLOCATOR: Dynamic\n",
      "======================================================================\n",
      "\n",
      "üìä Physics Model: paper2\n",
      "\n",
      "üìã Allocator Config:\n",
      "   Type: Dynamic\n",
      "   Testbed: paper2\n",
      "   Paths: 8\n",
      "   Total Qubits: 35\n",
      "   Min per route: 2\n",
      "   Seed: 42\n",
      "   Exploration bonus: 2.0\n",
      "‚úÖ Allocator created: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "‚úì Allocator: DynamicQubitAllocator (8 paths)\n",
      "   Initial allocation: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "Generated paper2 topology: 15 nodes, 51 edges\n",
      "üìä Paper2 Physics: Time-based decay\n",
      "   ‚úì Using MATLAB constants: r_dephase=10000, c_light=300000000.0\n",
      "\n",
      "======================================================================\n",
      "RUN 1 | Scale: 1 | Exp: 5\n",
      "======================================================================\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "No state found for MultiRunEvaluator, disabling resume for Experiment Runners\n",
      "Multi-Run Evaluator Initialized\n",
      "Environment Type: None\n",
      "Frame Range: 4000 -> 12000 (step: 2000)\n",
      "quantum_exps-Dynamic(paper2)_alloc-all_envs-5_attacks-4000_2000-5_runs-S1T\n",
      "[Logging Redirect Initialized]\n",
      "Log File: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/quantum_logs/quantum_exps-Dynamic(paper2)_alloc-all_envs-5_attacks-4000_2000-5_runs-S1T_20260201_log.txt\n",
      "‚öô Running evaluation...\n",
      "======================================================================\n",
      "SCENARIOS MODEL EVALUATION\n",
      "======================================================================\n",
      "Testing algorithm performance against:\n",
      "\t‚Ä¢ Stochastic:  \tNatural quantum decoherence and network failures\n",
      "\t‚Ä¢ Baseline:    \tOptimal conditions for validation\n",
      "======================================================================\n",
      "Models to Test:             \tOracle, GNeuralUCB, EXPNeuralUCB, CPursuitNeuralUCB, iCPursuitNeuralUCB\n",
      "Experiments per Scenario:   \t5\n",
      "======================================================================\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: STOCHASTIC RANDOM FAILURES\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: STOCHASTIC\n",
      "Category: Stochastic (Natural Random Failures)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 4000 frames  <>  SCALED-CAPACITY: 4000 frames (CAPACITY:4000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=0 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 1: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 1: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:4000, QubitAlloc=Dynamic, SC:4000 (Scale=1 x Cap=4000), Seed: 19730\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.38852779914991686], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 1: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 GNEURALUCB          : Reward=1385.61, Efficiency=084.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=4000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 1: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=1429.95, Efficiency=086.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=4000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 1: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=1396.64, Efficiency=084.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=4000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 1: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=1382.21, Efficiency=083.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=4000, Threshold=0.712]\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 1: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:4000, QubitAlloc=Dynamic, SC:4000 (Scale=1 x Cap=4000), Seed: 19730\n",
      "\t-->üèÜ EXP1 Winner:EXPNeuralUCB        (Gap:013.3%) [Env:Stochastic, Attack:Random X Rate:0.0625, Frames:4000, SCapacity=4000, Alloc=Dynamic]\n",
      "‚úì Experiment 1 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 6000 frames  <>  SCALED-CAPACITY: 6000 frames (CAPACITY:6000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=1 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 2: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 2: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:6000, QubitAlloc=Dynamic, SC:6000 (Scale=1 x Cap=6000), Seed: 17421\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.38852779914991686], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 2: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 GNEURALUCB          : Reward=2039.52, Efficiency=087.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 2: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=2146.60, Efficiency=092.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 2: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=2038.43, Efficiency=087.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 2: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=2032.94, Efficiency=087.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.712]\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 2: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:6000, QubitAlloc=Dynamic, SC:6000 (Scale=1 x Cap=6000), Seed: 17421\n",
      "\t-->üèÜ EXP2 Winner:EXPNeuralUCB        (Gap:007.8%) [Env:Stochastic, Attack:Random X Rate:0.0625, Frames:6000, SCapacity=6000, Alloc=Dynamic]\n",
      "‚úì Experiment 2 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 8000 frames  <>  SCALED-CAPACITY: 8000 frames (CAPACITY:8000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=2 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 3: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 3: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:8000, QubitAlloc=Dynamic, SC:8000 (Scale=1 x Cap=8000), Seed: 17649\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.369660064851862], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 3: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 GNEURALUCB          : Reward=2588.23, Efficiency=086.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 3: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=2421.80, Efficiency=081.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 3: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=2612.19, Efficiency=087.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 3: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=2598.71, Efficiency=087.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.712]\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 3: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:8000, QubitAlloc=Dynamic, SC:8000 (Scale=1 x Cap=8000), Seed: 17649\n",
      "\t-->üèÜ EXP3 Winner:CPursuitNeuralUCB   (Gap:012.3%) [Env:Stochastic, Attack:Random X Rate:0.0625, Frames:8000, SCapacity=8000, Alloc=Dynamic]\n",
      "‚úì Experiment 3 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 10000 frames  <>  SCALED-CAPACITY: 10000 frames (CAPACITY:10000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=3 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 4: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 4: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:10000, QubitAlloc=Dynamic, SC:10000 (Scale=1 x Cap=10000), Seed: 20670\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.4202961453677382], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 4: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 GNEURALUCB          : Reward=3605.00, Efficiency=085.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=10000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 4: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=3357.83, Efficiency=080.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=10000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 4: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=3568.78, Efficiency=085.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=10000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 4: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=3588.73, Efficiency=085.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=10000, Threshold=0.712]\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 4: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:10000, QubitAlloc=Dynamic, SC:10000 (Scale=1 x Cap=10000), Seed: 20670\n",
      "\t-->üèÜ EXP4 Winner:GNeuralUCB          (Gap:014.1%) [Env:Stochastic, Attack:Random X Rate:0.0625, Frames:10000, SCapacity=10000, Alloc=Dynamic]\n",
      "‚úì Experiment 4 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 12000 frames  <>  SCALED-CAPACITY: 12000 frames (CAPACITY:12000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=4 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 5: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 5: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:12000, QubitAlloc=Dynamic, SC:12000 (Scale=1 x Cap=12000), Seed: 19632\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.4012351376370454], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 5: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 GNEURALUCB          : Reward=4135.48, Efficiency=087.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 5: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=3993.42, Efficiency=084.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 5: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=4135.88, Efficiency=087.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 5: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=4141.72, Efficiency=087.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.712]\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 5: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:12000, QubitAlloc=Dynamic, SC:12000 (Scale=1 x Cap=12000), Seed: 19632\n",
      "\t-->üèÜ EXP5 Winner:iCPursuitNeuralUCB  (Gap:012.8%) [Env:Stochastic, Attack:Random X Rate:0.0625, Frames:12000, SCapacity=12000, Alloc=Dynamic]\n",
      "‚úì Experiment 5 completed successfully.\n",
      "Total experiment time: 867.9s\n",
      "Experiments completed for stochastic\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: MARKOV ADVERSARIAL ATTACK\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: MARKOV\n",
      "Category: Structured (Markov Chain Based)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 4000 frames  <>  SCALED-CAPACITY: 4000 frames (CAPACITY:4000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=0 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for MARKOV Exp 1: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 1: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:4000, QubitAlloc=Dynamic, SC:4000 (Scale=1 x Cap=4000), Seed: 15617\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.40706611625366484], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 1: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 GNEURALUCB          : Reward=0764.39, Efficiency=049.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=4000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 1: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=0727.57, Efficiency=046.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=4000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 1: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=0753.74, Efficiency=048.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=4000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 1: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=0850.50, Efficiency=054.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=4000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 1: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:4000, QubitAlloc=Dynamic, SC:4000 (Scale=1 x Cap=4000), Seed: 15617\n",
      "\t-->üèÜ EXP1 Winner:iCPursuitNeuralUCB  (Gap:045.4%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:4000, SCapacity=4000, Alloc=Dynamic]\n",
      "‚úì Experiment 1 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 6000 frames  <>  SCALED-CAPACITY: 6000 frames (CAPACITY:6000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=1 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for MARKOV Exp 2: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 2: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:6000, QubitAlloc=Dynamic, SC:6000 (Scale=1 x Cap=6000), Seed: 15214\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.40706611625366484], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 2: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 GNEURALUCB          : Reward=1120.32, Efficiency=048.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=6000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 2: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=1053.67, Efficiency=046.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=6000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 2: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=1119.56, Efficiency=048.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=6000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 2: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=1258.38, Efficiency=055.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=6000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 2: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:6000, QubitAlloc=Dynamic, SC:6000 (Scale=1 x Cap=6000), Seed: 15214\n",
      "\t-->üèÜ EXP2 Winner:iCPursuitNeuralUCB  (Gap:045.0%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:6000, SCapacity=6000, Alloc=Dynamic]\n",
      "‚úì Experiment 2 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 8000 frames  <>  SCALED-CAPACITY: 8000 frames (CAPACITY:8000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=2 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for MARKOV Exp 3: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 3: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:8000, QubitAlloc=Dynamic, SC:8000 (Scale=1 x Cap=8000), Seed: 15164\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.4202961453677382], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 3: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 GNEURALUCB          : Reward=1471.96, Efficiency=046.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=8000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 3: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=1425.56, Efficiency=045.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=8000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 3: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=1538.67, Efficiency=048.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=8000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 3: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=1713.52, Efficiency=054.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=8000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 3: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:8000, QubitAlloc=Dynamic, SC:8000 (Scale=1 x Cap=8000), Seed: 15164\n",
      "\t-->üèÜ EXP3 Winner:iCPursuitNeuralUCB  (Gap:045.6%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:8000, SCapacity=8000, Alloc=Dynamic]\n",
      "‚úì Experiment 3 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 10000 frames  <>  SCALED-CAPACITY: 10000 frames (CAPACITY:10000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=3 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for MARKOV Exp 4: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 4: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:10000, QubitAlloc=Dynamic, SC:10000 (Scale=1 x Cap=10000), Seed: 14599\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.38852779914991686], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 4: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 GNEURALUCB          : Reward=1887.44, Efficiency=049.2% [Retries=3, Failed=0, < Threshold=3, SCapacity=10000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 4: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=1920.04, Efficiency=050.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=10000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 4: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=1879.95, Efficiency=049.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=10000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 4: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=2137.25, Efficiency=055.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=10000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 4: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:10000, QubitAlloc=Dynamic, SC:10000 (Scale=1 x Cap=10000), Seed: 14599\n",
      "\t-->üèÜ EXP4 Winner:iCPursuitNeuralUCB  (Gap:044.2%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:10000, SCapacity=10000, Alloc=Dynamic]\n",
      "‚úì Experiment 4 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 12000 frames  <>  SCALED-CAPACITY: 12000 frames (CAPACITY:12000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=4 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for MARKOV Exp 5: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 5: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:12000, QubitAlloc=Dynamic, SC:12000 (Scale=1 x Cap=12000), Seed: 14153\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.3579527263647335], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 5: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 GNEURALUCB          : Reward=2220.32, Efficiency=056.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=12000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 5: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=1958.34, Efficiency=050.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=12000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 5: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=2187.99, Efficiency=055.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=12000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 5: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=2474.06, Efficiency=063.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=12000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 5: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:12000, QubitAlloc=Dynamic, SC:12000 (Scale=1 x Cap=12000), Seed: 14153\n",
      "\t-->üèÜ EXP5 Winner:iCPursuitNeuralUCB  (Gap:036.7%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:12000, SCapacity=12000, Alloc=Dynamic]\n",
      "‚úì Experiment 5 completed successfully.\n",
      "Total experiment time: 754.2s\n",
      "Experiments completed for markov\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: ADAPTIVE ADVERSARIAL ATTACK\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: ADAPTIVE\n",
      "Category: Adaptive (Reactive Strategic)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 4000 frames  <>  SCALED-CAPACITY: 4000 frames (CAPACITY:4000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=0 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 1: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 1: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:4000, QubitAlloc=Dynamic, SC:4000 (Scale=1 x Cap=4000), Seed: 12509\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.38860510852297203], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 1: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 GNEURALUCB          : Reward=1058.16, Efficiency=069.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=4000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 1: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=1017.20, Efficiency=066.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=4000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 1: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=1068.45, Efficiency=070.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=4000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 1: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=1041.23, Efficiency=068.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=4000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 1: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:4000, QubitAlloc=Dynamic, SC:4000 (Scale=1 x Cap=4000), Seed: 12509\n",
      "\t-->üèÜ EXP1 Winner:CPursuitNeuralUCB   (Gap:029.7%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:4000, SCapacity=4000, Alloc=Dynamic]\n",
      "‚úì Experiment 1 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 6000 frames  <>  SCALED-CAPACITY: 6000 frames (CAPACITY:6000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=1 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 2: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 2: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:6000, QubitAlloc=Dynamic, SC:6000 (Scale=1 x Cap=6000), Seed: 21611\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.38722107258255484], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 2: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 GNEURALUCB          : Reward=1618.60, Efficiency=070.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 2: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=1546.63, Efficiency=067.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 2: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=1603.83, Efficiency=069.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 2: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=1604.04, Efficiency=069.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=6000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 2: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:6000, QubitAlloc=Dynamic, SC:6000 (Scale=1 x Cap=6000), Seed: 21611\n",
      "\t-->üèÜ EXP2 Winner:GNeuralUCB          (Gap:029.6%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:6000, SCapacity=6000, Alloc=Dynamic]\n",
      "‚úì Experiment 2 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 8000 frames  <>  SCALED-CAPACITY: 8000 frames (CAPACITY:8000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=2 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 3: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 3: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:8000, QubitAlloc=Dynamic, SC:8000 (Scale=1 x Cap=8000), Seed: 19675\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.38229009396593533], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 3: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 GNEURALUCB          : Reward=2124.58, Efficiency=070.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 3: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=2152.00, Efficiency=071.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 3: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=2137.37, Efficiency=070.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 3: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=2126.83, Efficiency=070.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=8000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 3: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:8000, QubitAlloc=Dynamic, SC:8000 (Scale=1 x Cap=8000), Seed: 19675\n",
      "\t-->üèÜ EXP3 Winner:EXPNeuralUCB        (Gap:028.9%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:8000, SCapacity=8000, Alloc=Dynamic]\n",
      "‚úì Experiment 3 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 10000 frames  <>  SCALED-CAPACITY: 10000 frames (CAPACITY:10000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=3 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 4: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 4: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:10000, QubitAlloc=Dynamic, SC:10000 (Scale=1 x Cap=10000), Seed: 20231\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.4202961453677382], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 4: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 GNEURALUCB          : Reward=2830.21, Efficiency=068.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=10000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 4: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=2916.66, Efficiency=070.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=10000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 4: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=2828.79, Efficiency=068.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=10000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 4: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=2807.28, Efficiency=068.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=10000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 4: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:10000, QubitAlloc=Dynamic, SC:10000 (Scale=1 x Cap=10000), Seed: 20231\n",
      "\t-->üèÜ EXP4 Winner:EXPNeuralUCB        (Gap:029.2%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:10000, SCapacity=10000, Alloc=Dynamic]\n",
      "‚úì Experiment 4 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 12000 frames  <>  SCALED-CAPACITY: 12000 frames (CAPACITY:12000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=4 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 5: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 5: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:12000, QubitAlloc=Dynamic, SC:12000 (Scale=1 x Cap=12000), Seed: 15657\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.4202961453677382], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 5: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 GNEURALUCB          : Reward=3329.19, Efficiency=070.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 5: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=3291.62, Efficiency=069.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 5: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=3429.29, Efficiency=072.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 5: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=3394.31, Efficiency=071.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 5: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:12000, QubitAlloc=Dynamic, SC:12000 (Scale=1 x Cap=12000), Seed: 15657\n",
      "\t-->üèÜ EXP5 Winner:CPursuitNeuralUCB   (Gap:027.9%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:12000, SCapacity=12000, Alloc=Dynamic]\n",
      "‚úì Experiment 5 completed successfully.\n",
      "Total experiment time: 895.1s\n",
      "Experiments completed for adaptive\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: ONLINE ADAPTIVE ATTACK\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: ONLINEADAPTIVE\n",
      "Category: Online Adaptive (Real-time Strategic)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 4000 frames  <>  SCALED-CAPACITY: 4000 frames (CAPACITY:4000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=0 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 1: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:4000, QubitAlloc=Dynamic, SC:4000 (Scale=1 x Cap=4000), Seed: 16665\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.38722107258255484], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 GNEURALUCB          : Reward=1027.32, Efficiency=067.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=4000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=1023.88, Efficiency=067.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=4000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=1012.04, Efficiency=066.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=4000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=1023.05, Efficiency=067.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=4000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:4000, QubitAlloc=Dynamic, SC:4000 (Scale=1 x Cap=4000), Seed: 16665\n",
      "\t-->üèÜ EXP1 Winner:GNeuralUCB          (Gap:032.1%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:4000, SCapacity=4000, Alloc=Dynamic]\n",
      "‚úì Experiment 1 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 6000 frames  <>  SCALED-CAPACITY: 6000 frames (CAPACITY:6000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=1 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 2: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:6000, QubitAlloc=Dynamic, SC:6000 (Scale=1 x Cap=6000), Seed: 21573\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.4012351376370454], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 GNEURALUCB          : Reward=1616.29, Efficiency=068.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=1547.04, Efficiency=065.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=1618.93, Efficiency=068.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=1648.16, Efficiency=069.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=6000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:6000, QubitAlloc=Dynamic, SC:6000 (Scale=1 x Cap=6000), Seed: 21573\n",
      "\t-->üèÜ EXP2 Winner:iCPursuitNeuralUCB  (Gap:030.6%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:6000, SCapacity=6000, Alloc=Dynamic]\n",
      "‚úì Experiment 2 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 8000 frames  <>  SCALED-CAPACITY: 8000 frames (CAPACITY:8000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=2 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 3: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:8000, QubitAlloc=Dynamic, SC:8000 (Scale=1 x Cap=8000), Seed: 14973\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.4202961453677382], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 GNEURALUCB          : Reward=2294.40, Efficiency=069.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=2152.46, Efficiency=064.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=2279.63, Efficiency=068.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=2241.88, Efficiency=067.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=8000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:8000, QubitAlloc=Dynamic, SC:8000 (Scale=1 x Cap=8000), Seed: 14973\n",
      "\t-->üèÜ EXP3 Winner:GNeuralUCB          (Gap:031.0%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:8000, SCapacity=8000, Alloc=Dynamic]\n",
      "‚úì Experiment 3 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 10000 frames  <>  SCALED-CAPACITY: 10000 frames (CAPACITY:10000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=3 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 4: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:10000, QubitAlloc=Dynamic, SC:10000 (Scale=1 x Cap=10000), Seed: 18379\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.4202961453677382], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 GNEURALUCB          : Reward=2776.12, Efficiency=067.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=10000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=2526.34, Efficiency=061.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=10000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=2776.06, Efficiency=067.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=10000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=2760.54, Efficiency=067.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=10000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:10000, QubitAlloc=Dynamic, SC:10000 (Scale=1 x Cap=10000), Seed: 18379\n",
      "\t-->üèÜ EXP4 Winner:GNeuralUCB          (Gap:032.1%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:10000, SCapacity=10000, Alloc=Dynamic]\n",
      "‚úì Experiment 4 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 12000 frames  <>  SCALED-CAPACITY: 12000 frames (CAPACITY:12000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=4 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 5: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:12000, QubitAlloc=Dynamic, SC:12000 (Scale=1 x Cap=12000), Seed: 14049\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.3739910434684815], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 GNEURALUCB          : Reward=3250.30, Efficiency=072.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=3386.02, Efficiency=075.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=3243.36, Efficiency=072.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=3273.88, Efficiency=073.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:12000, QubitAlloc=Dynamic, SC:12000 (Scale=1 x Cap=12000), Seed: 14049\n",
      "\t-->üèÜ EXP5 Winner:EXPNeuralUCB        (Gap:024.5%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:12000, SCapacity=12000, Alloc=Dynamic]\n",
      "‚úì Experiment 5 completed successfully.\n",
      "Total experiment time: 899.8s\n",
      "Experiments completed for onlineadaptive\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: BASELINE (OPTIMAL CONDITIONS)\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: NONE\n",
      "Category: Baseline (No Attacks)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 4000 frames  <>  SCALED-CAPACITY: 4000 frames (CAPACITY:4000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=0 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for NONE Exp 1: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 1: Env:Baseline (None), Attack:No, Rate:0.0, Frames:4000, QubitAlloc=Dynamic, SC:4000 (Scale=1 x Cap=4000), Seed: 19677\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.4004511016966282], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 1: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 GNEURALUCB          : Reward=1430.43, Efficiency=089.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=4000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 1: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=1451.54, Efficiency=090.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=4000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 1: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=1439.35, Efficiency=089.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=4000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 1: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=1443.49, Efficiency=090.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=4000, Threshold=0.712]\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 1: Env:Baseline (None), Attack:No, Rate:0.0, Frames:4000, QubitAlloc=Dynamic, SC:4000 (Scale=1 x Cap=4000), Seed: 19677\n",
      "\t-->üèÜ EXP1 Winner:EXPNeuralUCB        (Gap:009.4%) [Env:Baseline (None), Attack:No X Rate:0.0, Frames:4000, SCapacity=4000, Alloc=Dynamic]\n",
      "‚úì Experiment 1 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 6000 frames  <>  SCALED-CAPACITY: 6000 frames (CAPACITY:6000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=1 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for NONE Exp 2: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 2: Env:Baseline (None), Attack:No, Rate:0.0, Frames:6000, QubitAlloc=Dynamic, SC:6000 (Scale=1 x Cap=6000), Seed: 16724\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.38860510852297203], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 2: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 GNEURALUCB          : Reward=2163.45, Efficiency=092.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 2: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=2002.09, Efficiency=085.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 2: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=2158.16, Efficiency=092.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 2: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=2151.21, Efficiency=092.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.712]\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 2: Env:Baseline (None), Attack:No, Rate:0.0, Frames:6000, QubitAlloc=Dynamic, SC:6000 (Scale=1 x Cap=6000), Seed: 16724\n",
      "\t-->üèÜ EXP2 Winner:GNeuralUCB          (Gap:007.2%) [Env:Baseline (None), Attack:No X Rate:0.0, Frames:6000, SCapacity=6000, Alloc=Dynamic]\n",
      "‚úì Experiment 2 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 8000 frames  <>  SCALED-CAPACITY: 8000 frames (CAPACITY:8000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=2 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for NONE Exp 3: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 3: Env:Baseline (None), Attack:No, Rate:0.0, Frames:8000, QubitAlloc=Dynamic, SC:8000 (Scale=1 x Cap=8000), Seed: 16587\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.40706611625366484], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 3: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 GNEURALUCB          : Reward=3015.55, Efficiency=091.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 3: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=2698.94, Efficiency=081.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 3: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=2978.50, Efficiency=089.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 3: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=3012.68, Efficiency=090.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.712]\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 3: Env:Baseline (None), Attack:No, Rate:0.0, Frames:8000, QubitAlloc=Dynamic, SC:8000 (Scale=1 x Cap=8000), Seed: 16587\n",
      "\t-->üèÜ EXP3 Winner:GNeuralUCB          (Gap:009.0%) [Env:Baseline (None), Attack:No X Rate:0.0, Frames:8000, SCapacity=8000, Alloc=Dynamic]\n",
      "‚úì Experiment 3 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 10000 frames  <>  SCALED-CAPACITY: 10000 frames (CAPACITY:10000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=3 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for NONE Exp 4: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 4: Env:Baseline (None), Attack:No, Rate:0.0, Frames:10000, QubitAlloc=Dynamic, SC:10000 (Scale=1 x Cap=10000), Seed: 13579\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.4202961453677382], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 4: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 GNEURALUCB          : Reward=3823.88, Efficiency=091.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=10000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 4: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=4103.22, Efficiency=097.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=10000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 4: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=3814.89, Efficiency=090.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=10000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 4: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=3799.27, Efficiency=090.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=10000, Threshold=0.712]\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 4: Env:Baseline (None), Attack:No, Rate:0.0, Frames:10000, QubitAlloc=Dynamic, SC:10000 (Scale=1 x Cap=10000), Seed: 13579\n",
      "\t-->üèÜ EXP4 Winner:EXPNeuralUCB        (Gap:002.4%) [Env:Baseline (None), Attack:No X Rate:0.0, Frames:10000, SCapacity=10000, Alloc=Dynamic]\n",
      "‚úì Experiment 4 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 12000 frames  <>  SCALED-CAPACITY: 12000 frames (CAPACITY:12000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=4 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for NONE Exp 5: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 5: Env:Baseline (None), Attack:No, Rate:0.0, Frames:12000, QubitAlloc=Dynamic, SC:12000 (Scale=1 x Cap=12000), Seed: 15608\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.3570300357377887], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 5: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 GNEURALUCB          : Reward=4459.93, Efficiency=089.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 5: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=4186.32, Efficiency=084.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 5: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=4458.33, Efficiency=089.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 5: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=4495.93, Efficiency=090.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.712]\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 5: Env:Baseline (None), Attack:No, Rate:0.0, Frames:12000, QubitAlloc=Dynamic, SC:12000 (Scale=1 x Cap=12000), Seed: 15608\n",
      "\t-->üèÜ EXP5 Winner:iCPursuitNeuralUCB  (Gap:009.5%) [Env:Baseline (None), Attack:No X Rate:0.0, Frames:12000, SCapacity=12000, Alloc=Dynamic]\n",
      "‚úì Experiment 5 completed successfully.\n",
      "Total experiment time: 1010.6s\n",
      "Experiments completed for none\n",
      "‚úì Scenario 'stochastic' evaluation completed.\n",
      "‚úì Scenario 'markov' evaluation completed.\n",
      "‚úì Scenario 'adaptive' evaluation completed.\n",
      "‚úì Scenario 'onlineadaptive' evaluation completed.\n",
      "‚úì Scenario 'none' evaluation completed.\n",
      "\n",
      "======================================================================\n",
      "COMPREHENSIVE SCENARIO PERFORMANCE ANALYSIS\n",
      "======================================================================\n",
      "SCENARIO: STOCHASTIC\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: CPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 3180.83\n",
      "\t‚Ä¢ Winner Avg Gap: 0013.60%\n",
      "\t‚Ä¢ Winner Avg Reward: 2750.38\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0086.40%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 1 wins\n",
      "\t\t- EXPNeuralUCB: 2 wins\n",
      "\t\t- CPursuitNeuralUCB: 1 wins\n",
      "\t\t- iCPursuitNeuralUCB: 1 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: STOCHASTIC\n",
      "======================================================================\n",
      "SCENARIO: \tSTOCHASTIC RANDOM FAILURES\n",
      "----------------------------------------\n",
      "Recommended Model: \tCPursuitNeuralUCB (Won 1/5 experiments)\n",
      "\tWinner Avg Gap: \t013.6%\n",
      "\tWinner Avg Efficiency: \t086.4%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t086.4% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t086.3% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t086.2% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t084.8% Efficiency \t(Won 2/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: MARKOV\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 2947.96\n",
      "\t‚Ä¢ Winner Avg Gap: 0043.40%\n",
      "\t‚Ä¢ Winner Avg Reward: 1686.74\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0056.60%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 5 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: MARKOV\n",
      "======================================================================\n",
      "SCENARIO: \tMARKOV ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 5/5 experiments)\n",
      "\tWinner Avg Gap: \t043.4%\n",
      "\tWinner Avg Efficiency: \t056.6%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t056.6% Efficiency \t(Won 5/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t050.2% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t050.2% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t047.6% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: CPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 3143.66\n",
      "\t‚Ä¢ Winner Avg Gap: 0029.70%\n",
      "\t‚Ä¢ Winner Avg Reward: 2213.55\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0070.30%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 1 wins\n",
      "\t\t- EXPNeuralUCB: 2 wins\n",
      "\t\t- CPursuitNeuralUCB: 2 wins\n",
      "\t\t- iCPursuitNeuralUCB: 0 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tADAPTIVE ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tCPursuitNeuralUCB (Won 2/5 experiments)\n",
      "\tWinner Avg Gap: \t029.7%\n",
      "\tWinner Avg Efficiency: \t070.3%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t070.3% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t069.8% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t069.6% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t069.1% Efficiency \t(Won 2/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ONLINEADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: GNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 3156.63\n",
      "\t‚Ä¢ Winner Avg Gap: 0030.92%\n",
      "\t‚Ä¢ Winner Avg Reward: 2192.88\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0069.08%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 3 wins\n",
      "\t\t- EXPNeuralUCB: 1 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 1 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ONLINEADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tONLINE ADAPTIVE ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tGNeuralUCB (Won 3/5 experiments)\n",
      "\tWinner Avg Gap: \t030.9%\n",
      "\tWinner Avg Efficiency: \t069.1%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ GNeuralUCB     : \t069.1% Efficiency \t(Won 3/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t069.0% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t068.8% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t067.0% Efficiency \t(Won 1/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: NONE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 3283.79\n",
      "\t‚Ä¢ Winner Avg Gap: 0009.16%\n",
      "\t‚Ä¢ Winner Avg Reward: 2980.52\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0090.84%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 2 wins\n",
      "\t\t- EXPNeuralUCB: 2 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 1 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: NONE\n",
      "======================================================================\n",
      "SCENARIO: \tBASELINE (OPTIMAL CONDITIONS)\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 1/5 experiments)\n",
      "\tWinner Avg Gap: \t009.2%\n",
      "\tWinner Avg Efficiency: \t090.8%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t090.8% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t090.8% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t090.6% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t088.0% Efficiency \t(Won 2/5 experiments)\n",
      "======================================================================\n",
      "KEY INSIGHTS:\n",
      "Best Performing Model Analysis (CPursuitNeuralUCB):\n",
      "\t‚Ä¢ Stochastic Performance:    \t2750.385\n",
      "\t‚Ä¢ Baseline Performance:      \t2980.517\n",
      "\t‚Ä¢ Performance Retention:     \t092.3%\n",
      "\tGOOD:               \tAcceptable performance under stochastic conditions\n",
      "Statistical Analysis:\n",
      "\t‚Ä¢ Total models evaluated:     \t5\n",
      "\t‚Ä¢ Experiments per environment:\t5\n",
      "\t‚Ä¢ Quantum network simulation: \tComprehensive stochastic modeling\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "COMPREHENSIVE SCENARIO PERFORMANCE ANALYSIS\n",
      "======================================================================\n",
      "SCENARIO: STOCHASTIC\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: CPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 3180.83\n",
      "\t‚Ä¢ Winner Avg Gap: 0013.60%\n",
      "\t‚Ä¢ Winner Avg Reward: 2750.38\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0086.40%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 1 wins\n",
      "\t\t- EXPNeuralUCB: 2 wins\n",
      "\t\t- CPursuitNeuralUCB: 1 wins\n",
      "\t\t- iCPursuitNeuralUCB: 1 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: STOCHASTIC\n",
      "======================================================================\n",
      "SCENARIO: \tSTOCHASTIC RANDOM FAILURES\n",
      "----------------------------------------\n",
      "Recommended Model: \tCPursuitNeuralUCB (Won 1/5 experiments)\n",
      "\tWinner Avg Gap: \t013.6%\n",
      "\tWinner Avg Efficiency: \t086.4%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t086.4% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t086.3% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t086.2% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t084.8% Efficiency \t(Won 2/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: MARKOV\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 2947.96\n",
      "\t‚Ä¢ Winner Avg Gap: 0043.40%\n",
      "\t‚Ä¢ Winner Avg Reward: 1686.74\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0056.60%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 5 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: MARKOV\n",
      "======================================================================\n",
      "SCENARIO: \tMARKOV ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 5/5 experiments)\n",
      "\tWinner Avg Gap: \t043.4%\n",
      "\tWinner Avg Efficiency: \t056.6%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t056.6% Efficiency \t(Won 5/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t050.2% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t050.2% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t047.6% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: CPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 3143.66\n",
      "\t‚Ä¢ Winner Avg Gap: 0029.70%\n",
      "\t‚Ä¢ Winner Avg Reward: 2213.55\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0070.30%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 1 wins\n",
      "\t\t- EXPNeuralUCB: 2 wins\n",
      "\t\t- CPursuitNeuralUCB: 2 wins\n",
      "\t\t- iCPursuitNeuralUCB: 0 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tADAPTIVE ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tCPursuitNeuralUCB (Won 2/5 experiments)\n",
      "\tWinner Avg Gap: \t029.7%\n",
      "\tWinner Avg Efficiency: \t070.3%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t070.3% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t069.8% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t069.6% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t069.1% Efficiency \t(Won 2/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ONLINEADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: GNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 3156.63\n",
      "\t‚Ä¢ Winner Avg Gap: 0030.92%\n",
      "\t‚Ä¢ Winner Avg Reward: 2192.88\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0069.08%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 3 wins\n",
      "\t\t- EXPNeuralUCB: 1 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 1 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ONLINEADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tONLINE ADAPTIVE ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tGNeuralUCB (Won 3/5 experiments)\n",
      "\tWinner Avg Gap: \t030.9%\n",
      "\tWinner Avg Efficiency: \t069.1%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ GNeuralUCB     : \t069.1% Efficiency \t(Won 3/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t069.0% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t068.8% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t067.0% Efficiency \t(Won 1/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: NONE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 3283.79\n",
      "\t‚Ä¢ Winner Avg Gap: 0009.16%\n",
      "\t‚Ä¢ Winner Avg Reward: 2980.52\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0090.84%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 2 wins\n",
      "\t\t- EXPNeuralUCB: 2 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 1 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: NONE\n",
      "======================================================================\n",
      "SCENARIO: \tBASELINE (OPTIMAL CONDITIONS)\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 1/5 experiments)\n",
      "\tWinner Avg Gap: \t009.2%\n",
      "\tWinner Avg Efficiency: \t090.8%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t090.8% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t090.8% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t090.6% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t088.0% Efficiency \t(Won 2/5 experiments)\n",
      "======================================================================\n",
      "‚úÖ Evaluation completed!\n",
      "[Logging Redirect Stopped]\n",
      "\n",
      "üßπ Final cleanup for Dynamic\n",
      "\n",
      "======================================================================\n",
      "‚úÖ COMPLETED: Dynamic\n",
      "======================================================================\n",
      "\n",
      "Dynamic COMPLETED SUCCESSFULLY\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Preparing: Dynamic at scale 1.5\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üîß Generating physics parameters for model: paper2\n",
      "\n",
      "===================== GET LOCAL REGISTRY =====================\n",
      "‚Üí Skipping local cache (force=True or file missing)\n",
      "\n",
      "===================== BUILD LOCAL REGISTRY =====================\n",
      "\n",
      "================================================================================\n",
      "üîç SCANNING LOCAL FILES\n",
      "================================================================================\n",
      "Parameters: load_to_drive=False, force=False\n",
      "\n",
      "üìÇ Checking DRIVE mode: /content/drive/Shareddrives/ai_quantum_computing/quantum_data_lake\n",
      "   ‚ö†Ô∏è  Path does not exist, skipping\n",
      "\n",
      "üìÇ Checking LOCAL mode: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config\n",
      "   ‚úÖ Path exists, starting walk...\n",
      "   üö∂ Walking directory tree: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config\n",
      "\n",
      "   üìÅ Directory: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201\n",
      "      Relative: framework_state/day_20260201\n",
      "      Component: framework_state\n",
      "      Date: day_20260201\n",
      "      üìÑ Processing 2540 files in framework_state/day_20260201\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "      üìä framework_state/day_20260201: 2514/2540 files processed\n",
      "      üìä framework_state/day_20260201: 0/2540 files skipped\n",
      "      üìä framework_state/day_20260201: 26/2540 files conflicted\n",
      "\n",
      "   üìÅ Directory: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/model_state/day_20260201\n",
      "      Relative: model_state/day_20260201\n",
      "      Component: model_state\n",
      "      Date: day_20260201\n",
      "      üìÑ Processing 9060 files in model_state/day_20260201\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "      üìä model_state/day_20260201: 9060/9060 files processed\n",
      "      üìä model_state/day_20260201: 0/9060 files skipped\n",
      "      üìä model_state/day_20260201: 0/9060 files conflicted\n",
      "\n",
      "   üìä Processed 2 directories\n",
      "\n",
      "================================================================================\n",
      "üì¶ BUILDING FINAL REGISTRY\n",
      "================================================================================\n",
      "Components found: ['framework_state', 'model_state']\n",
      "  ‚Ä¢ framework_state: 2514 files\n",
      "  ‚Ä¢ model_state: 9060 files\n",
      "\n",
      "‚úÖ SCAN COMPLETE\n",
      "Modes scanned: 1\n",
      "Total files in registry: 11574\n",
      "================================================================================\n",
      "\n",
      "\t‚Üí Filesystem scan found 11574 files\n",
      "\n",
      "===================== GET DRIVE REGISTRY =====================\n",
      "===================== REGISTRY BUILD COMPLETE =====================\n",
      "\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "\tüì¶ LocalBackupManager Registry Saved Locally in LOCAL\n",
      "BUILDING REGISTRY WITH 0 EXPECTED COMPONENTS KEYS\n",
      "\n",
      "===================== GET LOCAL REGISTRY =====================\n",
      "‚Üí Skipping local cache (force=True or file missing)\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "\tüì¶ LocalBackupManager Registry Saved Locally in LOCAL\n",
      "\n",
      "======================================================================\n",
      "üéØ AllocatorRunner initialized: Dynamic\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "üöÄ STARTING ALLOCATOR: Dynamic\n",
      "======================================================================\n",
      "\n",
      "üìä Physics Model: paper2\n",
      "\n",
      "üìã Allocator Config:\n",
      "   Type: Dynamic\n",
      "   Testbed: paper2\n",
      "   Paths: 8\n",
      "   Total Qubits: 35\n",
      "   Min per route: 2\n",
      "   Seed: 42\n",
      "   Exploration bonus: 2.0\n",
      "‚úÖ Allocator created: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "‚úì Allocator: DynamicQubitAllocator (8 paths)\n",
      "   Initial allocation: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "Generated paper2 topology: 15 nodes, 51 edges\n",
      "üìä Paper2 Physics: Time-based decay\n",
      "   ‚úì Using MATLAB constants: r_dephase=10000, c_light=300000000.0\n",
      "\n",
      "======================================================================\n",
      "RUN 1 | Scale: 1.5 | Exp: 5\n",
      "======================================================================\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "No state found for MultiRunEvaluator, disabling resume for Experiment Runners\n",
      "Multi-Run Evaluator Initialized\n",
      "Environment Type: None\n",
      "Frame Range: 4000 -> 12000 (step: 2000)\n",
      "quantum_exps-Dynamic(paper2)_alloc-all_envs-5_attacks-4000_2000-5_runs-S1.5T\n",
      "[Logging Redirect Initialized]\n",
      "Log File: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/quantum_logs/quantum_exps-Dynamic(paper2)_alloc-all_envs-5_attacks-4000_2000-5_runs-S1.5T_20260201_log.txt\n",
      "‚öô Running evaluation...\n",
      "======================================================================\n",
      "SCENARIOS MODEL EVALUATION\n",
      "======================================================================\n",
      "Testing algorithm performance against:\n",
      "\t‚Ä¢ Stochastic:  \tNatural quantum decoherence and network failures\n",
      "\t‚Ä¢ Baseline:    \tOptimal conditions for validation\n",
      "======================================================================\n",
      "Models to Test:             \tOracle, GNeuralUCB, EXPNeuralUCB, CPursuitNeuralUCB, iCPursuitNeuralUCB\n",
      "Experiments per Scenario:   \t5\n",
      "======================================================================\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: STOCHASTIC RANDOM FAILURES\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: STOCHASTIC\n",
      "Category: Stochastic (Natural Random Failures)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 4000 frames  <>  SCALED-CAPACITY: 6000.0 frames (CAPACITY:4000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=0 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 1: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 1: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:4000, QubitAlloc=Dynamic, SC:6000 (Scale=1.5 x Cap=4000), Seed: 19730\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.38852779914991686], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 1: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 GNEURALUCB          : Reward=1385.61, Efficiency=084.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 1: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=1429.95, Efficiency=086.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 1: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=1396.64, Efficiency=084.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 1: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=1382.21, Efficiency=083.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.712]\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 1: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:4000, QubitAlloc=Dynamic, SC:6000 (Scale=1.5 x Cap=4000), Seed: 19730\n",
      "\t-->üèÜ EXP1 Winner:EXPNeuralUCB        (Gap:013.3%) [Env:Stochastic, Attack:Random X Rate:0.0625, Frames:4000, SCapacity=6000, Alloc=Dynamic]\n",
      "‚úì Experiment 1 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 6000 frames  <>  SCALED-CAPACITY: 9000.0 frames (CAPACITY:6000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=1 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 2: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 2: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:6000, QubitAlloc=Dynamic, SC:9000 (Scale=1.5 x Cap=6000), Seed: 17421\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.38852779914991686], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 2: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 GNEURALUCB          : Reward=2039.52, Efficiency=087.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=9000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 2: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=2146.60, Efficiency=092.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=9000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 2: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=2038.43, Efficiency=087.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=9000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 2: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=2032.94, Efficiency=087.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=9000, Threshold=0.712]\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 2: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:6000, QubitAlloc=Dynamic, SC:9000 (Scale=1.5 x Cap=6000), Seed: 17421\n",
      "\t-->üèÜ EXP2 Winner:EXPNeuralUCB        (Gap:007.8%) [Env:Stochastic, Attack:Random X Rate:0.0625, Frames:6000, SCapacity=9000, Alloc=Dynamic]\n",
      "‚úì Experiment 2 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 8000 frames  <>  SCALED-CAPACITY: 12000.0 frames (CAPACITY:8000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=2 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 3: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 3: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:8000, QubitAlloc=Dynamic, SC:12000 (Scale=1.5 x Cap=8000), Seed: 17649\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.369660064851862], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 3: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 GNEURALUCB          : Reward=2588.23, Efficiency=086.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 3: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=2421.80, Efficiency=081.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 3: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=2612.19, Efficiency=087.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 3: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=2598.71, Efficiency=087.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.712]\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 3: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:8000, QubitAlloc=Dynamic, SC:12000 (Scale=1.5 x Cap=8000), Seed: 17649\n",
      "\t-->üèÜ EXP3 Winner:CPursuitNeuralUCB   (Gap:012.3%) [Env:Stochastic, Attack:Random X Rate:0.0625, Frames:8000, SCapacity=12000, Alloc=Dynamic]\n",
      "‚úì Experiment 3 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 10000 frames  <>  SCALED-CAPACITY: 15000.0 frames (CAPACITY:10000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=3 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 4: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 4: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:10000, QubitAlloc=Dynamic, SC:15000 (Scale=1.5 x Cap=10000), Seed: 20670\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.4202961453677382], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 4: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 GNEURALUCB          : Reward=3605.00, Efficiency=085.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=15000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 4: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=3357.83, Efficiency=080.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=15000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 4: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=3568.78, Efficiency=085.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=15000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 4: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=3588.73, Efficiency=085.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=15000, Threshold=0.712]\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 4: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:10000, QubitAlloc=Dynamic, SC:15000 (Scale=1.5 x Cap=10000), Seed: 20670\n",
      "\t-->üèÜ EXP4 Winner:GNeuralUCB          (Gap:014.1%) [Env:Stochastic, Attack:Random X Rate:0.0625, Frames:10000, SCapacity=15000, Alloc=Dynamic]\n",
      "‚úì Experiment 4 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 12000 frames  <>  SCALED-CAPACITY: 18000.0 frames (CAPACITY:12000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=4 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 5: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 5: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:12000, QubitAlloc=Dynamic, SC:18000 (Scale=1.5 x Cap=12000), Seed: 19632\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.4012351376370454], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 5: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 GNEURALUCB          : Reward=4135.48, Efficiency=087.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=18000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 5: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=3993.42, Efficiency=084.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=18000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 5: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=4135.88, Efficiency=087.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=18000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 5: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=4141.72, Efficiency=087.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=18000, Threshold=0.712]\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 5: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:12000, QubitAlloc=Dynamic, SC:18000 (Scale=1.5 x Cap=12000), Seed: 19632\n",
      "\t-->üèÜ EXP5 Winner:iCPursuitNeuralUCB  (Gap:012.8%) [Env:Stochastic, Attack:Random X Rate:0.0625, Frames:12000, SCapacity=18000, Alloc=Dynamic]\n",
      "‚úì Experiment 5 completed successfully.\n",
      "Total experiment time: 926.1s\n",
      "Experiments completed for stochastic\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: MARKOV ADVERSARIAL ATTACK\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: MARKOV\n",
      "Category: Structured (Markov Chain Based)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 4000 frames  <>  SCALED-CAPACITY: 6000.0 frames (CAPACITY:4000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=0 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for MARKOV Exp 1: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 1: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:4000, QubitAlloc=Dynamic, SC:6000 (Scale=1.5 x Cap=4000), Seed: 15617\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.40706611625366484], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 1: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 GNEURALUCB          : Reward=0764.39, Efficiency=049.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=6000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 1: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=0727.57, Efficiency=046.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=6000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 1: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=0753.74, Efficiency=048.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=6000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 1: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=0850.50, Efficiency=054.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=6000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 1: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:4000, QubitAlloc=Dynamic, SC:6000 (Scale=1.5 x Cap=4000), Seed: 15617\n",
      "\t-->üèÜ EXP1 Winner:iCPursuitNeuralUCB  (Gap:045.4%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:4000, SCapacity=6000, Alloc=Dynamic]\n",
      "‚úì Experiment 1 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 6000 frames  <>  SCALED-CAPACITY: 9000.0 frames (CAPACITY:6000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=1 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for MARKOV Exp 2: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 2: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:6000, QubitAlloc=Dynamic, SC:9000 (Scale=1.5 x Cap=6000), Seed: 15214\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.40706611625366484], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 2: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 GNEURALUCB          : Reward=1120.32, Efficiency=048.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=9000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 2: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=1053.67, Efficiency=046.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=9000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 2: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=1119.56, Efficiency=048.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=9000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 2: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=1258.38, Efficiency=055.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=9000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 2: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:6000, QubitAlloc=Dynamic, SC:9000 (Scale=1.5 x Cap=6000), Seed: 15214\n",
      "\t-->üèÜ EXP2 Winner:iCPursuitNeuralUCB  (Gap:045.0%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:6000, SCapacity=9000, Alloc=Dynamic]\n",
      "‚úì Experiment 2 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 8000 frames  <>  SCALED-CAPACITY: 12000.0 frames (CAPACITY:8000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=2 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for MARKOV Exp 3: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 3: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:8000, QubitAlloc=Dynamic, SC:12000 (Scale=1.5 x Cap=8000), Seed: 15164\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.4202961453677382], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 3: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 GNEURALUCB          : Reward=1471.96, Efficiency=046.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=12000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 3: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=1425.56, Efficiency=045.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=12000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 3: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=1538.67, Efficiency=048.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=12000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 3: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=1713.52, Efficiency=054.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=12000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 3: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:8000, QubitAlloc=Dynamic, SC:12000 (Scale=1.5 x Cap=8000), Seed: 15164\n",
      "\t-->üèÜ EXP3 Winner:iCPursuitNeuralUCB  (Gap:045.6%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:8000, SCapacity=12000, Alloc=Dynamic]\n",
      "‚úì Experiment 3 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 10000 frames  <>  SCALED-CAPACITY: 15000.0 frames (CAPACITY:10000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=3 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for MARKOV Exp 4: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 4: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:10000, QubitAlloc=Dynamic, SC:15000 (Scale=1.5 x Cap=10000), Seed: 14599\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.38852779914991686], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 4: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 GNEURALUCB          : Reward=1887.44, Efficiency=049.2% [Retries=3, Failed=0, < Threshold=3, SCapacity=15000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 4: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=1920.04, Efficiency=050.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=15000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 4: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=1879.95, Efficiency=049.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=15000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 4: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=2137.25, Efficiency=055.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=15000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 4: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:10000, QubitAlloc=Dynamic, SC:15000 (Scale=1.5 x Cap=10000), Seed: 14599\n",
      "\t-->üèÜ EXP4 Winner:iCPursuitNeuralUCB  (Gap:044.2%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:10000, SCapacity=15000, Alloc=Dynamic]\n",
      "‚úì Experiment 4 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 12000 frames  <>  SCALED-CAPACITY: 18000.0 frames (CAPACITY:12000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=4 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for MARKOV Exp 5: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 5: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:12000, QubitAlloc=Dynamic, SC:18000 (Scale=1.5 x Cap=12000), Seed: 14153\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.3579527263647335], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 5: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 GNEURALUCB          : Reward=2220.32, Efficiency=056.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=18000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 5: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=1958.34, Efficiency=050.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=18000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 5: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=2187.99, Efficiency=055.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=18000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 5: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=2474.06, Efficiency=063.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=18000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 5: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:12000, QubitAlloc=Dynamic, SC:18000 (Scale=1.5 x Cap=12000), Seed: 14153\n",
      "\t-->üèÜ EXP5 Winner:iCPursuitNeuralUCB  (Gap:036.7%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:12000, SCapacity=18000, Alloc=Dynamic]\n",
      "‚úì Experiment 5 completed successfully.\n",
      "Total experiment time: 755.0s\n",
      "Experiments completed for markov\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: ADAPTIVE ADVERSARIAL ATTACK\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: ADAPTIVE\n",
      "Category: Adaptive (Reactive Strategic)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 4000 frames  <>  SCALED-CAPACITY: 6000.0 frames (CAPACITY:4000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=0 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 1: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 1: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:4000, QubitAlloc=Dynamic, SC:6000 (Scale=1.5 x Cap=4000), Seed: 12509\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.38860510852297203], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 1: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 GNEURALUCB          : Reward=1058.16, Efficiency=069.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 1: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=1017.20, Efficiency=066.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 1: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=1068.45, Efficiency=070.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 1: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=1041.23, Efficiency=068.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=6000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 1: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:4000, QubitAlloc=Dynamic, SC:6000 (Scale=1.5 x Cap=4000), Seed: 12509\n",
      "\t-->üèÜ EXP1 Winner:CPursuitNeuralUCB   (Gap:029.7%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:4000, SCapacity=6000, Alloc=Dynamic]\n",
      "‚úì Experiment 1 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 6000 frames  <>  SCALED-CAPACITY: 9000.0 frames (CAPACITY:6000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=1 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 2: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 2: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:6000, QubitAlloc=Dynamic, SC:9000 (Scale=1.5 x Cap=6000), Seed: 21611\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.38722107258255484], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 2: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 GNEURALUCB          : Reward=1618.60, Efficiency=070.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=9000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 2: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=1546.63, Efficiency=067.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=9000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 2: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=1603.83, Efficiency=069.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=9000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 2: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=1604.04, Efficiency=069.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=9000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 2: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:6000, QubitAlloc=Dynamic, SC:9000 (Scale=1.5 x Cap=6000), Seed: 21611\n",
      "\t-->üèÜ EXP2 Winner:GNeuralUCB          (Gap:029.6%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:6000, SCapacity=9000, Alloc=Dynamic]\n",
      "‚úì Experiment 2 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 8000 frames  <>  SCALED-CAPACITY: 12000.0 frames (CAPACITY:8000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=2 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 3: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 3: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:8000, QubitAlloc=Dynamic, SC:12000 (Scale=1.5 x Cap=8000), Seed: 19675\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.38229009396593533], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 3: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 GNEURALUCB          : Reward=2124.58, Efficiency=070.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 3: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=2152.00, Efficiency=071.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 3: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=2137.37, Efficiency=070.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 3: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=2126.83, Efficiency=070.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=12000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 3: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:8000, QubitAlloc=Dynamic, SC:12000 (Scale=1.5 x Cap=8000), Seed: 19675\n",
      "\t-->üèÜ EXP3 Winner:EXPNeuralUCB        (Gap:028.9%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:8000, SCapacity=12000, Alloc=Dynamic]\n",
      "‚úì Experiment 3 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 10000 frames  <>  SCALED-CAPACITY: 15000.0 frames (CAPACITY:10000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=3 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 4: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 4: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:10000, QubitAlloc=Dynamic, SC:15000 (Scale=1.5 x Cap=10000), Seed: 20231\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.4202961453677382], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 4: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 GNEURALUCB          : Reward=2830.21, Efficiency=068.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=15000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 4: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=2916.66, Efficiency=070.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=15000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 4: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=2828.79, Efficiency=068.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=15000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 4: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=2807.28, Efficiency=068.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=15000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 4: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:10000, QubitAlloc=Dynamic, SC:15000 (Scale=1.5 x Cap=10000), Seed: 20231\n",
      "\t-->üèÜ EXP4 Winner:EXPNeuralUCB        (Gap:029.2%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:10000, SCapacity=15000, Alloc=Dynamic]\n",
      "‚úì Experiment 4 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 12000 frames  <>  SCALED-CAPACITY: 18000.0 frames (CAPACITY:12000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=4 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 5: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 5: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:12000, QubitAlloc=Dynamic, SC:18000 (Scale=1.5 x Cap=12000), Seed: 15657\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.4202961453677382], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 5: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 GNEURALUCB          : Reward=3329.19, Efficiency=070.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=18000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 5: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=3291.62, Efficiency=069.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=18000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 5: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=3429.29, Efficiency=072.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=18000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 5: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=3394.31, Efficiency=071.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=18000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 5: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:12000, QubitAlloc=Dynamic, SC:18000 (Scale=1.5 x Cap=12000), Seed: 15657\n",
      "\t-->üèÜ EXP5 Winner:CPursuitNeuralUCB   (Gap:027.9%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:12000, SCapacity=18000, Alloc=Dynamic]\n",
      "‚úì Experiment 5 completed successfully.\n",
      "Total experiment time: 852.1s\n",
      "Experiments completed for adaptive\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: ONLINE ADAPTIVE ATTACK\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: ONLINEADAPTIVE\n",
      "Category: Online Adaptive (Real-time Strategic)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 4000 frames  <>  SCALED-CAPACITY: 6000.0 frames (CAPACITY:4000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=0 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 1: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:4000, QubitAlloc=Dynamic, SC:6000 (Scale=1.5 x Cap=4000), Seed: 16665\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.38722107258255484], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 GNEURALUCB          : Reward=1027.32, Efficiency=067.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=1023.88, Efficiency=067.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=1012.04, Efficiency=066.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=1023.05, Efficiency=067.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=6000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:4000, QubitAlloc=Dynamic, SC:6000 (Scale=1.5 x Cap=4000), Seed: 16665\n",
      "\t-->üèÜ EXP1 Winner:GNeuralUCB          (Gap:032.1%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:4000, SCapacity=6000, Alloc=Dynamic]\n",
      "‚úì Experiment 1 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 6000 frames  <>  SCALED-CAPACITY: 9000.0 frames (CAPACITY:6000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=1 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 2: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:6000, QubitAlloc=Dynamic, SC:9000 (Scale=1.5 x Cap=6000), Seed: 21573\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.4012351376370454], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 GNEURALUCB          : Reward=1616.29, Efficiency=068.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=9000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=1547.04, Efficiency=065.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=9000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=1618.93, Efficiency=068.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=9000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=1648.16, Efficiency=069.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=9000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:6000, QubitAlloc=Dynamic, SC:9000 (Scale=1.5 x Cap=6000), Seed: 21573\n",
      "\t-->üèÜ EXP2 Winner:iCPursuitNeuralUCB  (Gap:030.6%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:6000, SCapacity=9000, Alloc=Dynamic]\n",
      "‚úì Experiment 2 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 8000 frames  <>  SCALED-CAPACITY: 12000.0 frames (CAPACITY:8000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=2 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 3: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:8000, QubitAlloc=Dynamic, SC:12000 (Scale=1.5 x Cap=8000), Seed: 14973\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.4202961453677382], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 GNEURALUCB          : Reward=2294.40, Efficiency=069.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=2152.46, Efficiency=064.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=2279.63, Efficiency=068.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=2241.88, Efficiency=067.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=12000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:8000, QubitAlloc=Dynamic, SC:12000 (Scale=1.5 x Cap=8000), Seed: 14973\n",
      "\t-->üèÜ EXP3 Winner:GNeuralUCB          (Gap:031.0%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:8000, SCapacity=12000, Alloc=Dynamic]\n",
      "‚úì Experiment 3 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 10000 frames  <>  SCALED-CAPACITY: 15000.0 frames (CAPACITY:10000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=3 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 4: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:10000, QubitAlloc=Dynamic, SC:15000 (Scale=1.5 x Cap=10000), Seed: 18379\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.4202961453677382], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 GNEURALUCB          : Reward=2776.12, Efficiency=067.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=15000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=2526.34, Efficiency=061.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=15000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=2776.06, Efficiency=067.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=15000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=2760.54, Efficiency=067.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=15000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:10000, QubitAlloc=Dynamic, SC:15000 (Scale=1.5 x Cap=10000), Seed: 18379\n",
      "\t-->üèÜ EXP4 Winner:GNeuralUCB          (Gap:032.1%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:10000, SCapacity=15000, Alloc=Dynamic]\n",
      "‚úì Experiment 4 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 12000 frames  <>  SCALED-CAPACITY: 18000.0 frames (CAPACITY:12000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=4 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 5: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:12000, QubitAlloc=Dynamic, SC:18000 (Scale=1.5 x Cap=12000), Seed: 14049\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.3739910434684815], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 GNEURALUCB          : Reward=3250.30, Efficiency=072.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=18000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=3386.02, Efficiency=075.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=18000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=3243.36, Efficiency=072.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=18000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=3273.88, Efficiency=073.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=18000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:12000, QubitAlloc=Dynamic, SC:18000 (Scale=1.5 x Cap=12000), Seed: 14049\n",
      "\t-->üèÜ EXP5 Winner:EXPNeuralUCB        (Gap:024.5%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:12000, SCapacity=18000, Alloc=Dynamic]\n",
      "‚úì Experiment 5 completed successfully.\n",
      "Total experiment time: 889.8s\n",
      "Experiments completed for onlineadaptive\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: BASELINE (OPTIMAL CONDITIONS)\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: NONE\n",
      "Category: Baseline (No Attacks)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 4000 frames  <>  SCALED-CAPACITY: 6000.0 frames (CAPACITY:4000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=0 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for NONE Exp 1: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 1: Env:Baseline (None), Attack:No, Rate:0.0, Frames:4000, QubitAlloc=Dynamic, SC:6000 (Scale=1.5 x Cap=4000), Seed: 19677\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.4004511016966282], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 1: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 GNEURALUCB          : Reward=1430.43, Efficiency=089.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 1: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=1451.54, Efficiency=090.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 1: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=1439.35, Efficiency=089.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 1: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=1443.49, Efficiency=090.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.712]\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 1: Env:Baseline (None), Attack:No, Rate:0.0, Frames:4000, QubitAlloc=Dynamic, SC:6000 (Scale=1.5 x Cap=4000), Seed: 19677\n",
      "\t-->üèÜ EXP1 Winner:EXPNeuralUCB        (Gap:009.4%) [Env:Baseline (None), Attack:No X Rate:0.0, Frames:4000, SCapacity=6000, Alloc=Dynamic]\n",
      "‚úì Experiment 1 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 6000 frames  <>  SCALED-CAPACITY: 9000.0 frames (CAPACITY:6000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=1 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for NONE Exp 2: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 2: Env:Baseline (None), Attack:No, Rate:0.0, Frames:6000, QubitAlloc=Dynamic, SC:9000 (Scale=1.5 x Cap=6000), Seed: 16724\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.38860510852297203], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 2: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 GNEURALUCB          : Reward=2163.45, Efficiency=092.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=9000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 2: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=2002.09, Efficiency=085.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=9000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 2: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=2158.16, Efficiency=092.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=9000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 2: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=2151.21, Efficiency=092.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=9000, Threshold=0.712]\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 2: Env:Baseline (None), Attack:No, Rate:0.0, Frames:6000, QubitAlloc=Dynamic, SC:9000 (Scale=1.5 x Cap=6000), Seed: 16724\n",
      "\t-->üèÜ EXP2 Winner:GNeuralUCB          (Gap:007.2%) [Env:Baseline (None), Attack:No X Rate:0.0, Frames:6000, SCapacity=9000, Alloc=Dynamic]\n",
      "‚úì Experiment 2 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 8000 frames  <>  SCALED-CAPACITY: 12000.0 frames (CAPACITY:8000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=2 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for NONE Exp 3: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 3: Env:Baseline (None), Attack:No, Rate:0.0, Frames:8000, QubitAlloc=Dynamic, SC:12000 (Scale=1.5 x Cap=8000), Seed: 16587\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.40706611625366484], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 3: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 GNEURALUCB          : Reward=3015.55, Efficiency=091.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 3: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=2698.94, Efficiency=081.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 3: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=2978.50, Efficiency=089.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 3: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=3012.68, Efficiency=090.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.712]\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 3: Env:Baseline (None), Attack:No, Rate:0.0, Frames:8000, QubitAlloc=Dynamic, SC:12000 (Scale=1.5 x Cap=8000), Seed: 16587\n",
      "\t-->üèÜ EXP3 Winner:GNeuralUCB          (Gap:009.0%) [Env:Baseline (None), Attack:No X Rate:0.0, Frames:8000, SCapacity=12000, Alloc=Dynamic]\n",
      "‚úì Experiment 3 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 10000 frames  <>  SCALED-CAPACITY: 15000.0 frames (CAPACITY:10000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=3 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for NONE Exp 4: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 4: Env:Baseline (None), Attack:No, Rate:0.0, Frames:10000, QubitAlloc=Dynamic, SC:15000 (Scale=1.5 x Cap=10000), Seed: 13579\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.4202961453677382], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 4: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 GNEURALUCB          : Reward=3823.88, Efficiency=091.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=15000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 4: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=4103.22, Efficiency=097.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=15000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 4: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=3814.89, Efficiency=090.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=15000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 4: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=3799.27, Efficiency=090.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=15000, Threshold=0.712]\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 4: Env:Baseline (None), Attack:No, Rate:0.0, Frames:10000, QubitAlloc=Dynamic, SC:15000 (Scale=1.5 x Cap=10000), Seed: 13579\n",
      "\t-->üèÜ EXP4 Winner:EXPNeuralUCB        (Gap:002.4%) [Env:Baseline (None), Attack:No X Rate:0.0, Frames:10000, SCapacity=15000, Alloc=Dynamic]\n",
      "‚úì Experiment 4 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 12000 frames  <>  SCALED-CAPACITY: 18000.0 frames (CAPACITY:12000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=4 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for NONE Exp 5: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 5: Env:Baseline (None), Attack:No, Rate:0.0, Frames:12000, QubitAlloc=Dynamic, SC:18000 (Scale=1.5 x Cap=12000), Seed: 15608\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.3570300357377887], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 5: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 GNEURALUCB          : Reward=4459.93, Efficiency=089.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=18000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 5: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=4186.32, Efficiency=084.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=18000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 5: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=4458.33, Efficiency=089.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=18000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 5: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=4495.93, Efficiency=090.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=18000, Threshold=0.712]\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 5: Env:Baseline (None), Attack:No, Rate:0.0, Frames:12000, QubitAlloc=Dynamic, SC:18000 (Scale=1.5 x Cap=12000), Seed: 15608\n",
      "\t-->üèÜ EXP5 Winner:iCPursuitNeuralUCB  (Gap:009.5%) [Env:Baseline (None), Attack:No X Rate:0.0, Frames:12000, SCapacity=18000, Alloc=Dynamic]\n",
      "‚úì Experiment 5 completed successfully.\n",
      "Total experiment time: 994.9s\n",
      "Experiments completed for none\n",
      "‚úì Scenario 'stochastic' evaluation completed.\n",
      "‚úì Scenario 'markov' evaluation completed.\n",
      "‚úì Scenario 'adaptive' evaluation completed.\n",
      "‚úì Scenario 'onlineadaptive' evaluation completed.\n",
      "‚úì Scenario 'none' evaluation completed.\n",
      "\n",
      "======================================================================\n",
      "COMPREHENSIVE SCENARIO PERFORMANCE ANALYSIS\n",
      "======================================================================\n",
      "SCENARIO: STOCHASTIC\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: CPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 3180.83\n",
      "\t‚Ä¢ Winner Avg Gap: 0013.60%\n",
      "\t‚Ä¢ Winner Avg Reward: 2750.38\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0086.40%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 1 wins\n",
      "\t\t- EXPNeuralUCB: 2 wins\n",
      "\t\t- CPursuitNeuralUCB: 1 wins\n",
      "\t\t- iCPursuitNeuralUCB: 1 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: STOCHASTIC\n",
      "======================================================================\n",
      "SCENARIO: \tSTOCHASTIC RANDOM FAILURES\n",
      "----------------------------------------\n",
      "Recommended Model: \tCPursuitNeuralUCB (Won 1/5 experiments)\n",
      "\tWinner Avg Gap: \t013.6%\n",
      "\tWinner Avg Efficiency: \t086.4%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t086.4% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t086.3% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t086.2% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t084.8% Efficiency \t(Won 2/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: MARKOV\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 2947.96\n",
      "\t‚Ä¢ Winner Avg Gap: 0043.40%\n",
      "\t‚Ä¢ Winner Avg Reward: 1686.74\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0056.60%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 5 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: MARKOV\n",
      "======================================================================\n",
      "SCENARIO: \tMARKOV ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 5/5 experiments)\n",
      "\tWinner Avg Gap: \t043.4%\n",
      "\tWinner Avg Efficiency: \t056.6%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t056.6% Efficiency \t(Won 5/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t050.2% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t050.2% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t047.6% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: CPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 3143.66\n",
      "\t‚Ä¢ Winner Avg Gap: 0029.70%\n",
      "\t‚Ä¢ Winner Avg Reward: 2213.55\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0070.30%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 1 wins\n",
      "\t\t- EXPNeuralUCB: 2 wins\n",
      "\t\t- CPursuitNeuralUCB: 2 wins\n",
      "\t\t- iCPursuitNeuralUCB: 0 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tADAPTIVE ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tCPursuitNeuralUCB (Won 2/5 experiments)\n",
      "\tWinner Avg Gap: \t029.7%\n",
      "\tWinner Avg Efficiency: \t070.3%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t070.3% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t069.8% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t069.6% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t069.1% Efficiency \t(Won 2/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ONLINEADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: GNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 3156.63\n",
      "\t‚Ä¢ Winner Avg Gap: 0030.92%\n",
      "\t‚Ä¢ Winner Avg Reward: 2192.88\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0069.08%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 3 wins\n",
      "\t\t- EXPNeuralUCB: 1 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 1 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ONLINEADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tONLINE ADAPTIVE ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tGNeuralUCB (Won 3/5 experiments)\n",
      "\tWinner Avg Gap: \t030.9%\n",
      "\tWinner Avg Efficiency: \t069.1%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ GNeuralUCB     : \t069.1% Efficiency \t(Won 3/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t069.0% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t068.8% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t067.0% Efficiency \t(Won 1/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: NONE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 3283.79\n",
      "\t‚Ä¢ Winner Avg Gap: 0009.16%\n",
      "\t‚Ä¢ Winner Avg Reward: 2980.52\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0090.84%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 2 wins\n",
      "\t\t- EXPNeuralUCB: 2 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 1 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: NONE\n",
      "======================================================================\n",
      "SCENARIO: \tBASELINE (OPTIMAL CONDITIONS)\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 1/5 experiments)\n",
      "\tWinner Avg Gap: \t009.2%\n",
      "\tWinner Avg Efficiency: \t090.8%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t090.8% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t090.8% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t090.6% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t088.0% Efficiency \t(Won 2/5 experiments)\n",
      "======================================================================\n",
      "KEY INSIGHTS:\n",
      "Best Performing Model Analysis (CPursuitNeuralUCB):\n",
      "\t‚Ä¢ Stochastic Performance:    \t2750.385\n",
      "\t‚Ä¢ Baseline Performance:      \t2980.517\n",
      "\t‚Ä¢ Performance Retention:     \t092.3%\n",
      "\tGOOD:               \tAcceptable performance under stochastic conditions\n",
      "Statistical Analysis:\n",
      "\t‚Ä¢ Total models evaluated:     \t5\n",
      "\t‚Ä¢ Experiments per environment:\t5\n",
      "\t‚Ä¢ Quantum network simulation: \tComprehensive stochastic modeling\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "COMPREHENSIVE SCENARIO PERFORMANCE ANALYSIS\n",
      "======================================================================\n",
      "SCENARIO: STOCHASTIC\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: CPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 3180.83\n",
      "\t‚Ä¢ Winner Avg Gap: 0013.60%\n",
      "\t‚Ä¢ Winner Avg Reward: 2750.38\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0086.40%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 1 wins\n",
      "\t\t- EXPNeuralUCB: 2 wins\n",
      "\t\t- CPursuitNeuralUCB: 1 wins\n",
      "\t\t- iCPursuitNeuralUCB: 1 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: STOCHASTIC\n",
      "======================================================================\n",
      "SCENARIO: \tSTOCHASTIC RANDOM FAILURES\n",
      "----------------------------------------\n",
      "Recommended Model: \tCPursuitNeuralUCB (Won 1/5 experiments)\n",
      "\tWinner Avg Gap: \t013.6%\n",
      "\tWinner Avg Efficiency: \t086.4%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t086.4% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t086.3% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t086.2% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t084.8% Efficiency \t(Won 2/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: MARKOV\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 2947.96\n",
      "\t‚Ä¢ Winner Avg Gap: 0043.40%\n",
      "\t‚Ä¢ Winner Avg Reward: 1686.74\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0056.60%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 5 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: MARKOV\n",
      "======================================================================\n",
      "SCENARIO: \tMARKOV ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 5/5 experiments)\n",
      "\tWinner Avg Gap: \t043.4%\n",
      "\tWinner Avg Efficiency: \t056.6%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t056.6% Efficiency \t(Won 5/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t050.2% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t050.2% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t047.6% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: CPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 3143.66\n",
      "\t‚Ä¢ Winner Avg Gap: 0029.70%\n",
      "\t‚Ä¢ Winner Avg Reward: 2213.55\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0070.30%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 1 wins\n",
      "\t\t- EXPNeuralUCB: 2 wins\n",
      "\t\t- CPursuitNeuralUCB: 2 wins\n",
      "\t\t- iCPursuitNeuralUCB: 0 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tADAPTIVE ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tCPursuitNeuralUCB (Won 2/5 experiments)\n",
      "\tWinner Avg Gap: \t029.7%\n",
      "\tWinner Avg Efficiency: \t070.3%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t070.3% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t069.8% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t069.6% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t069.1% Efficiency \t(Won 2/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ONLINEADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: GNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 3156.63\n",
      "\t‚Ä¢ Winner Avg Gap: 0030.92%\n",
      "\t‚Ä¢ Winner Avg Reward: 2192.88\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0069.08%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 3 wins\n",
      "\t\t- EXPNeuralUCB: 1 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 1 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ONLINEADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tONLINE ADAPTIVE ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tGNeuralUCB (Won 3/5 experiments)\n",
      "\tWinner Avg Gap: \t030.9%\n",
      "\tWinner Avg Efficiency: \t069.1%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ GNeuralUCB     : \t069.1% Efficiency \t(Won 3/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t069.0% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t068.8% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t067.0% Efficiency \t(Won 1/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: NONE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 3283.79\n",
      "\t‚Ä¢ Winner Avg Gap: 0009.16%\n",
      "\t‚Ä¢ Winner Avg Reward: 2980.52\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0090.84%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 2 wins\n",
      "\t\t- EXPNeuralUCB: 2 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 1 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: NONE\n",
      "======================================================================\n",
      "SCENARIO: \tBASELINE (OPTIMAL CONDITIONS)\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 1/5 experiments)\n",
      "\tWinner Avg Gap: \t009.2%\n",
      "\tWinner Avg Efficiency: \t090.8%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t090.8% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t090.8% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t090.6% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t088.0% Efficiency \t(Won 2/5 experiments)\n",
      "======================================================================\n",
      "‚úÖ Evaluation completed!\n",
      "[Logging Redirect Stopped]\n",
      "\n",
      "üßπ Final cleanup for Dynamic\n",
      "\n",
      "======================================================================\n",
      "‚úÖ COMPLETED: Dynamic\n",
      "======================================================================\n",
      "\n",
      "Dynamic COMPLETED SUCCESSFULLY\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Preparing: Dynamic at scale 2\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üîß Generating physics parameters for model: paper2\n",
      "\n",
      "===================== GET LOCAL REGISTRY =====================\n",
      "‚Üí Skipping local cache (force=True or file missing)\n",
      "\n",
      "===================== BUILD LOCAL REGISTRY =====================\n",
      "\n",
      "================================================================================\n",
      "üîç SCANNING LOCAL FILES\n",
      "================================================================================\n",
      "Parameters: load_to_drive=False, force=False\n",
      "\n",
      "üìÇ Checking DRIVE mode: /content/drive/Shareddrives/ai_quantum_computing/quantum_data_lake\n",
      "   ‚ö†Ô∏è  Path does not exist, skipping\n",
      "\n",
      "üìÇ Checking LOCAL mode: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config\n",
      "   ‚úÖ Path exists, starting walk...\n",
      "   üö∂ Walking directory tree: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config\n",
      "\n",
      "   üìÅ Directory: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201\n",
      "      Relative: framework_state/day_20260201\n",
      "      Component: framework_state\n",
      "      Date: day_20260201\n",
      "      üìÑ Processing 2540 files in framework_state/day_20260201\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "      üìä framework_state/day_20260201: 2514/2540 files processed\n",
      "      üìä framework_state/day_20260201: 0/2540 files skipped\n",
      "      üìä framework_state/day_20260201: 26/2540 files conflicted\n",
      "\n",
      "   üìÅ Directory: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/model_state/day_20260201\n",
      "      Relative: model_state/day_20260201\n",
      "      Component: model_state\n",
      "      Date: day_20260201\n",
      "      üìÑ Processing 9080 files in model_state/day_20260201\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "      üìä model_state/day_20260201: 9080/9080 files processed\n",
      "      üìä model_state/day_20260201: 0/9080 files skipped\n",
      "      üìä model_state/day_20260201: 0/9080 files conflicted\n",
      "\n",
      "   üìä Processed 2 directories\n",
      "\n",
      "================================================================================\n",
      "üì¶ BUILDING FINAL REGISTRY\n",
      "================================================================================\n",
      "Components found: ['framework_state', 'model_state']\n",
      "  ‚Ä¢ framework_state: 2514 files\n",
      "  ‚Ä¢ model_state: 9080 files\n",
      "\n",
      "‚úÖ SCAN COMPLETE\n",
      "Modes scanned: 1\n",
      "Total files in registry: 11594\n",
      "================================================================================\n",
      "\n",
      "\t‚Üí Filesystem scan found 11594 files\n",
      "\n",
      "===================== GET DRIVE REGISTRY =====================\n",
      "===================== REGISTRY BUILD COMPLETE =====================\n",
      "\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "\tüì¶ LocalBackupManager Registry Saved Locally in LOCAL\n",
      "BUILDING REGISTRY WITH 0 EXPECTED COMPONENTS KEYS\n",
      "\n",
      "===================== GET LOCAL REGISTRY =====================\n",
      "‚Üí Skipping local cache (force=True or file missing)\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "\tüì¶ LocalBackupManager Registry Saved Locally in LOCAL\n",
      "\n",
      "======================================================================\n",
      "üéØ AllocatorRunner initialized: Dynamic\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "üöÄ STARTING ALLOCATOR: Dynamic\n",
      "======================================================================\n",
      "\n",
      "üìä Physics Model: paper2\n",
      "\n",
      "üìã Allocator Config:\n",
      "   Type: Dynamic\n",
      "   Testbed: paper2\n",
      "   Paths: 8\n",
      "   Total Qubits: 35\n",
      "   Min per route: 2\n",
      "   Seed: 42\n",
      "   Exploration bonus: 2.0\n",
      "‚úÖ Allocator created: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "‚úì Allocator: DynamicQubitAllocator (8 paths)\n",
      "   Initial allocation: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "Generated paper2 topology: 15 nodes, 51 edges\n",
      "üìä Paper2 Physics: Time-based decay\n",
      "   ‚úì Using MATLAB constants: r_dephase=10000, c_light=300000000.0\n",
      "\n",
      "======================================================================\n",
      "RUN 1 | Scale: 2 | Exp: 5\n",
      "======================================================================\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "No state found for MultiRunEvaluator, disabling resume for Experiment Runners\n",
      "Multi-Run Evaluator Initialized\n",
      "Environment Type: None\n",
      "Frame Range: 4000 -> 12000 (step: 2000)\n",
      "quantum_exps-Dynamic(paper2)_alloc-all_envs-5_attacks-4000_2000-5_runs-S2T\n",
      "[Logging Redirect Initialized]\n",
      "Log File: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/quantum_logs/quantum_exps-Dynamic(paper2)_alloc-all_envs-5_attacks-4000_2000-5_runs-S2T_20260201_log.txt\n",
      "‚öô Running evaluation...\n",
      "======================================================================\n",
      "SCENARIOS MODEL EVALUATION\n",
      "======================================================================\n",
      "Testing algorithm performance against:\n",
      "\t‚Ä¢ Stochastic:  \tNatural quantum decoherence and network failures\n",
      "\t‚Ä¢ Baseline:    \tOptimal conditions for validation\n",
      "======================================================================\n",
      "Models to Test:             \tOracle, GNeuralUCB, EXPNeuralUCB, CPursuitNeuralUCB, iCPursuitNeuralUCB\n",
      "Experiments per Scenario:   \t5\n",
      "======================================================================\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: STOCHASTIC RANDOM FAILURES\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: STOCHASTIC\n",
      "Category: Stochastic (Natural Random Failures)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 4000 frames  <>  SCALED-CAPACITY: 8000 frames (CAPACITY:4000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=0 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 1: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 1: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:4000, QubitAlloc=Dynamic, SC:8000 (Scale=2 x Cap=4000), Seed: 19730\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.38852779914991686], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 1: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 GNEURALUCB          : Reward=1385.61, Efficiency=084.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 1: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=1429.95, Efficiency=086.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 1: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=1396.64, Efficiency=084.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 1: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=1382.21, Efficiency=083.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.712]\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 1: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:4000, QubitAlloc=Dynamic, SC:8000 (Scale=2 x Cap=4000), Seed: 19730\n",
      "\t-->üèÜ EXP1 Winner:EXPNeuralUCB        (Gap:013.3%) [Env:Stochastic, Attack:Random X Rate:0.0625, Frames:4000, SCapacity=8000, Alloc=Dynamic]\n",
      "‚úì Experiment 1 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 6000 frames  <>  SCALED-CAPACITY: 12000 frames (CAPACITY:6000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=1 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 2: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 2: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:6000, QubitAlloc=Dynamic, SC:12000 (Scale=2 x Cap=6000), Seed: 17421\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.38852779914991686], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 2: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 GNEURALUCB          : Reward=2039.52, Efficiency=087.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 2: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=2146.60, Efficiency=092.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 2: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=2038.43, Efficiency=087.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 2: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=2032.94, Efficiency=087.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.712]\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 2: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:6000, QubitAlloc=Dynamic, SC:12000 (Scale=2 x Cap=6000), Seed: 17421\n",
      "\t-->üèÜ EXP2 Winner:EXPNeuralUCB        (Gap:007.8%) [Env:Stochastic, Attack:Random X Rate:0.0625, Frames:6000, SCapacity=12000, Alloc=Dynamic]\n",
      "‚úì Experiment 2 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 8000 frames  <>  SCALED-CAPACITY: 16000 frames (CAPACITY:8000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=2 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 3: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 3: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:8000, QubitAlloc=Dynamic, SC:16000 (Scale=2 x Cap=8000), Seed: 17649\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.369660064851862], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 3: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 GNEURALUCB          : Reward=2588.23, Efficiency=086.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=16000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 3: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=2421.80, Efficiency=081.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=16000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 3: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=2612.19, Efficiency=087.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=16000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 3: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=2598.71, Efficiency=087.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=16000, Threshold=0.712]\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 3: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:8000, QubitAlloc=Dynamic, SC:16000 (Scale=2 x Cap=8000), Seed: 17649\n",
      "\t-->üèÜ EXP3 Winner:CPursuitNeuralUCB   (Gap:012.3%) [Env:Stochastic, Attack:Random X Rate:0.0625, Frames:8000, SCapacity=16000, Alloc=Dynamic]\n",
      "‚úì Experiment 3 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 10000 frames  <>  SCALED-CAPACITY: 20000 frames (CAPACITY:10000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=3 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 4: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 4: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:10000, QubitAlloc=Dynamic, SC:20000 (Scale=2 x Cap=10000), Seed: 20670\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.4202961453677382], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 4: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 GNEURALUCB          : Reward=3605.00, Efficiency=085.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=20000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 4: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=3357.83, Efficiency=080.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=20000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 4: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=3568.78, Efficiency=085.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=20000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 4: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=3588.73, Efficiency=085.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=20000, Threshold=0.712]\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 4: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:10000, QubitAlloc=Dynamic, SC:20000 (Scale=2 x Cap=10000), Seed: 20670\n",
      "\t-->üèÜ EXP4 Winner:GNeuralUCB          (Gap:014.1%) [Env:Stochastic, Attack:Random X Rate:0.0625, Frames:10000, SCapacity=20000, Alloc=Dynamic]\n",
      "‚úì Experiment 4 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 12000 frames  <>  SCALED-CAPACITY: 24000 frames (CAPACITY:12000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=4 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 5: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 5: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:12000, QubitAlloc=Dynamic, SC:24000 (Scale=2 x Cap=12000), Seed: 19632\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.4012351376370454], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 5: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 GNEURALUCB          : Reward=4135.48, Efficiency=087.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=24000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 5: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=3993.42, Efficiency=084.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=24000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 5: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=4135.88, Efficiency=087.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=24000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 5: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=4141.72, Efficiency=087.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=24000, Threshold=0.712]\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 5: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:12000, QubitAlloc=Dynamic, SC:24000 (Scale=2 x Cap=12000), Seed: 19632\n",
      "\t-->üèÜ EXP5 Winner:iCPursuitNeuralUCB  (Gap:012.8%) [Env:Stochastic, Attack:Random X Rate:0.0625, Frames:12000, SCapacity=24000, Alloc=Dynamic]\n",
      "‚úì Experiment 5 completed successfully.\n",
      "Total experiment time: 871.7s\n",
      "Experiments completed for stochastic\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: MARKOV ADVERSARIAL ATTACK\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: MARKOV\n",
      "Category: Structured (Markov Chain Based)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 4000 frames  <>  SCALED-CAPACITY: 8000 frames (CAPACITY:4000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=0 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for MARKOV Exp 1: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 1: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:4000, QubitAlloc=Dynamic, SC:8000 (Scale=2 x Cap=4000), Seed: 15617\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.40706611625366484], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 1: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 GNEURALUCB          : Reward=0764.39, Efficiency=049.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=8000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 1: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=0727.57, Efficiency=046.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=8000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 1: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=0753.74, Efficiency=048.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=8000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 1: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=0850.50, Efficiency=054.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=8000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 1: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:4000, QubitAlloc=Dynamic, SC:8000 (Scale=2 x Cap=4000), Seed: 15617\n",
      "\t-->üèÜ EXP1 Winner:iCPursuitNeuralUCB  (Gap:045.4%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:4000, SCapacity=8000, Alloc=Dynamic]\n",
      "‚úì Experiment 1 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 6000 frames  <>  SCALED-CAPACITY: 12000 frames (CAPACITY:6000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=1 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for MARKOV Exp 2: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 2: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:6000, QubitAlloc=Dynamic, SC:12000 (Scale=2 x Cap=6000), Seed: 15214\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.40706611625366484], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 2: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 GNEURALUCB          : Reward=1120.32, Efficiency=048.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=12000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 2: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=1053.67, Efficiency=046.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=12000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 2: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=1119.56, Efficiency=048.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=12000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 2: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=1258.38, Efficiency=055.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=12000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 2: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:6000, QubitAlloc=Dynamic, SC:12000 (Scale=2 x Cap=6000), Seed: 15214\n",
      "\t-->üèÜ EXP2 Winner:iCPursuitNeuralUCB  (Gap:045.0%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:6000, SCapacity=12000, Alloc=Dynamic]\n",
      "‚úì Experiment 2 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 8000 frames  <>  SCALED-CAPACITY: 16000 frames (CAPACITY:8000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=2 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for MARKOV Exp 3: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 3: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:8000, QubitAlloc=Dynamic, SC:16000 (Scale=2 x Cap=8000), Seed: 15164\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.4202961453677382], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 3: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 GNEURALUCB          : Reward=1471.96, Efficiency=046.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=16000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 3: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=1425.56, Efficiency=045.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=16000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 3: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=1538.67, Efficiency=048.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=16000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 3: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=1713.52, Efficiency=054.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=16000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 3: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:8000, QubitAlloc=Dynamic, SC:16000 (Scale=2 x Cap=8000), Seed: 15164\n",
      "\t-->üèÜ EXP3 Winner:iCPursuitNeuralUCB  (Gap:045.6%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:8000, SCapacity=16000, Alloc=Dynamic]\n",
      "‚úì Experiment 3 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 10000 frames  <>  SCALED-CAPACITY: 20000 frames (CAPACITY:10000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=3 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for MARKOV Exp 4: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 4: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:10000, QubitAlloc=Dynamic, SC:20000 (Scale=2 x Cap=10000), Seed: 14599\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.38852779914991686], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 4: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 GNEURALUCB          : Reward=1887.44, Efficiency=049.2% [Retries=3, Failed=0, < Threshold=3, SCapacity=20000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 4: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=1920.04, Efficiency=050.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=20000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 4: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=1879.95, Efficiency=049.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=20000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 4: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=2137.25, Efficiency=055.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=20000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 4: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:10000, QubitAlloc=Dynamic, SC:20000 (Scale=2 x Cap=10000), Seed: 14599\n",
      "\t-->üèÜ EXP4 Winner:iCPursuitNeuralUCB  (Gap:044.2%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:10000, SCapacity=20000, Alloc=Dynamic]\n",
      "‚úì Experiment 4 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 12000 frames  <>  SCALED-CAPACITY: 24000 frames (CAPACITY:12000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=4 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for MARKOV Exp 5: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 5: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:12000, QubitAlloc=Dynamic, SC:24000 (Scale=2 x Cap=12000), Seed: 14153\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.3579527263647335], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 5: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 GNEURALUCB          : Reward=2220.32, Efficiency=056.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=24000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 5: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=1958.34, Efficiency=050.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=24000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 5: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=2187.99, Efficiency=055.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=24000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 5: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=2474.06, Efficiency=063.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=24000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 5: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:12000, QubitAlloc=Dynamic, SC:24000 (Scale=2 x Cap=12000), Seed: 14153\n",
      "\t-->üèÜ EXP5 Winner:iCPursuitNeuralUCB  (Gap:036.7%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:12000, SCapacity=24000, Alloc=Dynamic]\n",
      "‚úì Experiment 5 completed successfully.\n",
      "Total experiment time: 752.3s\n",
      "Experiments completed for markov\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: ADAPTIVE ADVERSARIAL ATTACK\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: ADAPTIVE\n",
      "Category: Adaptive (Reactive Strategic)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 4000 frames  <>  SCALED-CAPACITY: 8000 frames (CAPACITY:4000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=0 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 1: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 1: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:4000, QubitAlloc=Dynamic, SC:8000 (Scale=2 x Cap=4000), Seed: 12509\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.38860510852297203], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 1: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 GNEURALUCB          : Reward=1058.16, Efficiency=069.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 1: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=1017.20, Efficiency=066.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 1: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=1068.45, Efficiency=070.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 1: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=1041.23, Efficiency=068.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=8000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 1: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:4000, QubitAlloc=Dynamic, SC:8000 (Scale=2 x Cap=4000), Seed: 12509\n",
      "\t-->üèÜ EXP1 Winner:CPursuitNeuralUCB   (Gap:029.7%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:4000, SCapacity=8000, Alloc=Dynamic]\n",
      "‚úì Experiment 1 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 6000 frames  <>  SCALED-CAPACITY: 12000 frames (CAPACITY:6000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=1 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 2: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 2: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:6000, QubitAlloc=Dynamic, SC:12000 (Scale=2 x Cap=6000), Seed: 21611\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.38722107258255484], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 2: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 GNEURALUCB          : Reward=1618.60, Efficiency=070.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 2: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=1546.63, Efficiency=067.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 2: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=1603.83, Efficiency=069.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 2: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=1604.04, Efficiency=069.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=12000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 2: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:6000, QubitAlloc=Dynamic, SC:12000 (Scale=2 x Cap=6000), Seed: 21611\n",
      "\t-->üèÜ EXP2 Winner:GNeuralUCB          (Gap:029.6%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:6000, SCapacity=12000, Alloc=Dynamic]\n",
      "‚úì Experiment 2 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 8000 frames  <>  SCALED-CAPACITY: 16000 frames (CAPACITY:8000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=2 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 3: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 3: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:8000, QubitAlloc=Dynamic, SC:16000 (Scale=2 x Cap=8000), Seed: 19675\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.38229009396593533], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 3: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 GNEURALUCB          : Reward=2124.58, Efficiency=070.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=16000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 3: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=2152.00, Efficiency=071.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=16000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 3: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=2137.37, Efficiency=070.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=16000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 3: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=2126.83, Efficiency=070.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=16000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 3: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:8000, QubitAlloc=Dynamic, SC:16000 (Scale=2 x Cap=8000), Seed: 19675\n",
      "\t-->üèÜ EXP3 Winner:EXPNeuralUCB        (Gap:028.9%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:8000, SCapacity=16000, Alloc=Dynamic]\n",
      "‚úì Experiment 3 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 10000 frames  <>  SCALED-CAPACITY: 20000 frames (CAPACITY:10000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=3 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 4: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 4: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:10000, QubitAlloc=Dynamic, SC:20000 (Scale=2 x Cap=10000), Seed: 20231\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.4202961453677382], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 4: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 GNEURALUCB          : Reward=2830.21, Efficiency=068.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=20000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 4: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=2916.66, Efficiency=070.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=20000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 4: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=2828.79, Efficiency=068.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=20000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 4: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=2807.28, Efficiency=068.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=20000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 4: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:10000, QubitAlloc=Dynamic, SC:20000 (Scale=2 x Cap=10000), Seed: 20231\n",
      "\t-->üèÜ EXP4 Winner:EXPNeuralUCB        (Gap:029.2%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:10000, SCapacity=20000, Alloc=Dynamic]\n",
      "‚úì Experiment 4 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 12000 frames  <>  SCALED-CAPACITY: 24000 frames (CAPACITY:12000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=4 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 5: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 5: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:12000, QubitAlloc=Dynamic, SC:24000 (Scale=2 x Cap=12000), Seed: 15657\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.4202961453677382], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 5: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 GNEURALUCB          : Reward=3329.19, Efficiency=070.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=24000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 5: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=3291.62, Efficiency=069.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=24000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 5: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=3429.29, Efficiency=072.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=24000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 5: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=3394.31, Efficiency=071.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=24000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 5: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:12000, QubitAlloc=Dynamic, SC:24000 (Scale=2 x Cap=12000), Seed: 15657\n",
      "\t-->üèÜ EXP5 Winner:CPursuitNeuralUCB   (Gap:027.9%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:12000, SCapacity=24000, Alloc=Dynamic]\n",
      "‚úì Experiment 5 completed successfully.\n",
      "Total experiment time: 860.5s\n",
      "Experiments completed for adaptive\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: ONLINE ADAPTIVE ATTACK\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: ONLINEADAPTIVE\n",
      "Category: Online Adaptive (Real-time Strategic)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 4000 frames  <>  SCALED-CAPACITY: 8000 frames (CAPACITY:4000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=0 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 1: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:4000, QubitAlloc=Dynamic, SC:8000 (Scale=2 x Cap=4000), Seed: 16665\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.38722107258255484], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 GNEURALUCB          : Reward=1027.32, Efficiency=067.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=1023.88, Efficiency=067.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=1012.04, Efficiency=066.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=1023.05, Efficiency=067.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=8000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:4000, QubitAlloc=Dynamic, SC:8000 (Scale=2 x Cap=4000), Seed: 16665\n",
      "\t-->üèÜ EXP1 Winner:GNeuralUCB          (Gap:032.1%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:4000, SCapacity=8000, Alloc=Dynamic]\n",
      "‚úì Experiment 1 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 6000 frames  <>  SCALED-CAPACITY: 12000 frames (CAPACITY:6000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=1 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 2: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:6000, QubitAlloc=Dynamic, SC:12000 (Scale=2 x Cap=6000), Seed: 21573\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.4012351376370454], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 GNEURALUCB          : Reward=1616.29, Efficiency=068.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=1547.04, Efficiency=065.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=1618.93, Efficiency=068.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=1648.16, Efficiency=069.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=12000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:6000, QubitAlloc=Dynamic, SC:12000 (Scale=2 x Cap=6000), Seed: 21573\n",
      "\t-->üèÜ EXP2 Winner:iCPursuitNeuralUCB  (Gap:030.6%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:6000, SCapacity=12000, Alloc=Dynamic]\n",
      "‚úì Experiment 2 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 8000 frames  <>  SCALED-CAPACITY: 16000 frames (CAPACITY:8000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=2 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 3: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:8000, QubitAlloc=Dynamic, SC:16000 (Scale=2 x Cap=8000), Seed: 14973\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.4202961453677382], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 GNEURALUCB          : Reward=2294.40, Efficiency=069.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=16000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=2152.46, Efficiency=064.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=16000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=2279.63, Efficiency=068.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=16000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=2241.88, Efficiency=067.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=16000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:8000, QubitAlloc=Dynamic, SC:16000 (Scale=2 x Cap=8000), Seed: 14973\n",
      "\t-->üèÜ EXP3 Winner:GNeuralUCB          (Gap:031.0%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:8000, SCapacity=16000, Alloc=Dynamic]\n",
      "‚úì Experiment 3 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 10000 frames  <>  SCALED-CAPACITY: 20000 frames (CAPACITY:10000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=3 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 4: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:10000, QubitAlloc=Dynamic, SC:20000 (Scale=2 x Cap=10000), Seed: 18379\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.4202961453677382], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 GNEURALUCB          : Reward=2776.12, Efficiency=067.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=20000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=2526.34, Efficiency=061.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=20000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=2776.06, Efficiency=067.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=20000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=2760.54, Efficiency=067.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=20000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:10000, QubitAlloc=Dynamic, SC:20000 (Scale=2 x Cap=10000), Seed: 18379\n",
      "\t-->üèÜ EXP4 Winner:GNeuralUCB          (Gap:032.1%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:10000, SCapacity=20000, Alloc=Dynamic]\n",
      "‚úì Experiment 4 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 12000 frames  <>  SCALED-CAPACITY: 24000 frames (CAPACITY:12000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=4 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 5: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:12000, QubitAlloc=Dynamic, SC:24000 (Scale=2 x Cap=12000), Seed: 14049\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.3739910434684815], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 GNEURALUCB          : Reward=3250.30, Efficiency=072.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=24000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=3386.02, Efficiency=075.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=24000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=3243.36, Efficiency=072.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=24000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=3273.88, Efficiency=073.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=24000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:12000, QubitAlloc=Dynamic, SC:24000 (Scale=2 x Cap=12000), Seed: 14049\n",
      "\t-->üèÜ EXP5 Winner:EXPNeuralUCB        (Gap:024.5%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:12000, SCapacity=24000, Alloc=Dynamic]\n",
      "‚úì Experiment 5 completed successfully.\n",
      "Total experiment time: 882.4s\n",
      "Experiments completed for onlineadaptive\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: BASELINE (OPTIMAL CONDITIONS)\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: NONE\n",
      "Category: Baseline (No Attacks)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 4000 frames  <>  SCALED-CAPACITY: 8000 frames (CAPACITY:4000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=0 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for NONE Exp 1: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 1: Env:Baseline (None), Attack:No, Rate:0.0, Frames:4000, QubitAlloc=Dynamic, SC:8000 (Scale=2 x Cap=4000), Seed: 19677\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.4004511016966282], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 1: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 GNEURALUCB          : Reward=1430.43, Efficiency=089.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 1: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=1451.54, Efficiency=090.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 1: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=1439.35, Efficiency=089.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 1: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=1443.49, Efficiency=090.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.712]\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 1: Env:Baseline (None), Attack:No, Rate:0.0, Frames:4000, QubitAlloc=Dynamic, SC:8000 (Scale=2 x Cap=4000), Seed: 19677\n",
      "\t-->üèÜ EXP1 Winner:EXPNeuralUCB        (Gap:009.4%) [Env:Baseline (None), Attack:No X Rate:0.0, Frames:4000, SCapacity=8000, Alloc=Dynamic]\n",
      "‚úì Experiment 1 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 6000 frames  <>  SCALED-CAPACITY: 12000 frames (CAPACITY:6000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=1 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for NONE Exp 2: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 2: Env:Baseline (None), Attack:No, Rate:0.0, Frames:6000, QubitAlloc=Dynamic, SC:12000 (Scale=2 x Cap=6000), Seed: 16724\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.38860510852297203], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 2: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 GNEURALUCB          : Reward=2163.45, Efficiency=092.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 2: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=2002.09, Efficiency=085.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 2: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=2158.16, Efficiency=092.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 2: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=2151.21, Efficiency=092.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.712]\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 2: Env:Baseline (None), Attack:No, Rate:0.0, Frames:6000, QubitAlloc=Dynamic, SC:12000 (Scale=2 x Cap=6000), Seed: 16724\n",
      "\t-->üèÜ EXP2 Winner:GNeuralUCB          (Gap:007.2%) [Env:Baseline (None), Attack:No X Rate:0.0, Frames:6000, SCapacity=12000, Alloc=Dynamic]\n",
      "‚úì Experiment 2 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 8000 frames  <>  SCALED-CAPACITY: 16000 frames (CAPACITY:8000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=2 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for NONE Exp 3: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 3: Env:Baseline (None), Attack:No, Rate:0.0, Frames:8000, QubitAlloc=Dynamic, SC:16000 (Scale=2 x Cap=8000), Seed: 16587\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.40706611625366484], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 3: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 GNEURALUCB          : Reward=3015.55, Efficiency=091.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=16000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 3: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=2698.94, Efficiency=081.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=16000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 3: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=2978.50, Efficiency=089.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=16000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 3: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=3012.68, Efficiency=090.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=16000, Threshold=0.712]\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 3: Env:Baseline (None), Attack:No, Rate:0.0, Frames:8000, QubitAlloc=Dynamic, SC:16000 (Scale=2 x Cap=8000), Seed: 16587\n",
      "\t-->üèÜ EXP3 Winner:GNeuralUCB          (Gap:009.0%) [Env:Baseline (None), Attack:No X Rate:0.0, Frames:8000, SCapacity=16000, Alloc=Dynamic]\n",
      "‚úì Experiment 3 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 10000 frames  <>  SCALED-CAPACITY: 20000 frames (CAPACITY:10000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=3 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for NONE Exp 4: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 4: Env:Baseline (None), Attack:No, Rate:0.0, Frames:10000, QubitAlloc=Dynamic, SC:20000 (Scale=2 x Cap=10000), Seed: 13579\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.4202961453677382], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 4: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 GNEURALUCB          : Reward=3823.88, Efficiency=091.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=20000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 4: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=4103.22, Efficiency=097.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=20000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 4: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=3814.89, Efficiency=090.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=20000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 4: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=3799.27, Efficiency=090.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=20000, Threshold=0.712]\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 4: Env:Baseline (None), Attack:No, Rate:0.0, Frames:10000, QubitAlloc=Dynamic, SC:20000 (Scale=2 x Cap=10000), Seed: 13579\n",
      "\t-->üèÜ EXP4 Winner:EXPNeuralUCB        (Gap:002.4%) [Env:Baseline (None), Attack:No X Rate:0.0, Frames:10000, SCapacity=20000, Alloc=Dynamic]\n",
      "‚úì Experiment 4 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 12000 frames  <>  SCALED-CAPACITY: 24000 frames (CAPACITY:12000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=4 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for NONE Exp 5: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 5: Env:Baseline (None), Attack:No, Rate:0.0, Frames:12000, QubitAlloc=Dynamic, SC:24000 (Scale=2 x Cap=12000), Seed: 15608\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.3570300357377887], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 5: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 GNEURALUCB          : Reward=4459.93, Efficiency=089.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=24000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 5: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=4186.32, Efficiency=084.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=24000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 5: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=4458.33, Efficiency=089.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=24000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 5: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=4495.93, Efficiency=090.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=24000, Threshold=0.712]\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 5: Env:Baseline (None), Attack:No, Rate:0.0, Frames:12000, QubitAlloc=Dynamic, SC:24000 (Scale=2 x Cap=12000), Seed: 15608\n",
      "\t-->üèÜ EXP5 Winner:iCPursuitNeuralUCB  (Gap:009.5%) [Env:Baseline (None), Attack:No X Rate:0.0, Frames:12000, SCapacity=24000, Alloc=Dynamic]\n",
      "‚úì Experiment 5 completed successfully.\n",
      "Total experiment time: 1004.5s\n",
      "Experiments completed for none\n",
      "‚úì Scenario 'stochastic' evaluation completed.\n",
      "‚úì Scenario 'markov' evaluation completed.\n",
      "‚úì Scenario 'adaptive' evaluation completed.\n",
      "‚úì Scenario 'onlineadaptive' evaluation completed.\n",
      "‚úì Scenario 'none' evaluation completed.\n",
      "\n",
      "======================================================================\n",
      "COMPREHENSIVE SCENARIO PERFORMANCE ANALYSIS\n",
      "======================================================================\n",
      "SCENARIO: STOCHASTIC\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: CPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 3180.83\n",
      "\t‚Ä¢ Winner Avg Gap: 0013.60%\n",
      "\t‚Ä¢ Winner Avg Reward: 2750.38\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0086.40%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 1 wins\n",
      "\t\t- EXPNeuralUCB: 2 wins\n",
      "\t\t- CPursuitNeuralUCB: 1 wins\n",
      "\t\t- iCPursuitNeuralUCB: 1 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: STOCHASTIC\n",
      "======================================================================\n",
      "SCENARIO: \tSTOCHASTIC RANDOM FAILURES\n",
      "----------------------------------------\n",
      "Recommended Model: \tCPursuitNeuralUCB (Won 1/5 experiments)\n",
      "\tWinner Avg Gap: \t013.6%\n",
      "\tWinner Avg Efficiency: \t086.4%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t086.4% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t086.3% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t086.2% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t084.8% Efficiency \t(Won 2/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: MARKOV\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 2947.96\n",
      "\t‚Ä¢ Winner Avg Gap: 0043.40%\n",
      "\t‚Ä¢ Winner Avg Reward: 1686.74\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0056.60%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 5 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: MARKOV\n",
      "======================================================================\n",
      "SCENARIO: \tMARKOV ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 5/5 experiments)\n",
      "\tWinner Avg Gap: \t043.4%\n",
      "\tWinner Avg Efficiency: \t056.6%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t056.6% Efficiency \t(Won 5/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t050.2% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t050.2% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t047.6% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: CPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 3143.66\n",
      "\t‚Ä¢ Winner Avg Gap: 0029.70%\n",
      "\t‚Ä¢ Winner Avg Reward: 2213.55\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0070.30%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 1 wins\n",
      "\t\t- EXPNeuralUCB: 2 wins\n",
      "\t\t- CPursuitNeuralUCB: 2 wins\n",
      "\t\t- iCPursuitNeuralUCB: 0 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tADAPTIVE ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tCPursuitNeuralUCB (Won 2/5 experiments)\n",
      "\tWinner Avg Gap: \t029.7%\n",
      "\tWinner Avg Efficiency: \t070.3%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t070.3% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t069.8% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t069.6% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t069.1% Efficiency \t(Won 2/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ONLINEADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: GNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 3156.63\n",
      "\t‚Ä¢ Winner Avg Gap: 0030.92%\n",
      "\t‚Ä¢ Winner Avg Reward: 2192.88\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0069.08%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 3 wins\n",
      "\t\t- EXPNeuralUCB: 1 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 1 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ONLINEADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tONLINE ADAPTIVE ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tGNeuralUCB (Won 3/5 experiments)\n",
      "\tWinner Avg Gap: \t030.9%\n",
      "\tWinner Avg Efficiency: \t069.1%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ GNeuralUCB     : \t069.1% Efficiency \t(Won 3/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t069.0% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t068.8% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t067.0% Efficiency \t(Won 1/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: NONE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 3283.79\n",
      "\t‚Ä¢ Winner Avg Gap: 0009.16%\n",
      "\t‚Ä¢ Winner Avg Reward: 2980.52\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0090.84%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 2 wins\n",
      "\t\t- EXPNeuralUCB: 2 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 1 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: NONE\n",
      "======================================================================\n",
      "SCENARIO: \tBASELINE (OPTIMAL CONDITIONS)\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 1/5 experiments)\n",
      "\tWinner Avg Gap: \t009.2%\n",
      "\tWinner Avg Efficiency: \t090.8%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t090.8% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t090.8% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t090.6% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t088.0% Efficiency \t(Won 2/5 experiments)\n",
      "======================================================================\n",
      "KEY INSIGHTS:\n",
      "Best Performing Model Analysis (CPursuitNeuralUCB):\n",
      "\t‚Ä¢ Stochastic Performance:    \t2750.385\n",
      "\t‚Ä¢ Baseline Performance:      \t2980.517\n",
      "\t‚Ä¢ Performance Retention:     \t092.3%\n",
      "\tGOOD:               \tAcceptable performance under stochastic conditions\n",
      "Statistical Analysis:\n",
      "\t‚Ä¢ Total models evaluated:     \t5\n",
      "\t‚Ä¢ Experiments per environment:\t5\n",
      "\t‚Ä¢ Quantum network simulation: \tComprehensive stochastic modeling\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "COMPREHENSIVE SCENARIO PERFORMANCE ANALYSIS\n",
      "======================================================================\n",
      "SCENARIO: STOCHASTIC\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: CPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 3180.83\n",
      "\t‚Ä¢ Winner Avg Gap: 0013.60%\n",
      "\t‚Ä¢ Winner Avg Reward: 2750.38\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0086.40%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 1 wins\n",
      "\t\t- EXPNeuralUCB: 2 wins\n",
      "\t\t- CPursuitNeuralUCB: 1 wins\n",
      "\t\t- iCPursuitNeuralUCB: 1 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: STOCHASTIC\n",
      "======================================================================\n",
      "SCENARIO: \tSTOCHASTIC RANDOM FAILURES\n",
      "----------------------------------------\n",
      "Recommended Model: \tCPursuitNeuralUCB (Won 1/5 experiments)\n",
      "\tWinner Avg Gap: \t013.6%\n",
      "\tWinner Avg Efficiency: \t086.4%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t086.4% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t086.3% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t086.2% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t084.8% Efficiency \t(Won 2/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: MARKOV\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 2947.96\n",
      "\t‚Ä¢ Winner Avg Gap: 0043.40%\n",
      "\t‚Ä¢ Winner Avg Reward: 1686.74\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0056.60%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 5 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: MARKOV\n",
      "======================================================================\n",
      "SCENARIO: \tMARKOV ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 5/5 experiments)\n",
      "\tWinner Avg Gap: \t043.4%\n",
      "\tWinner Avg Efficiency: \t056.6%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t056.6% Efficiency \t(Won 5/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t050.2% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t050.2% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t047.6% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: CPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 3143.66\n",
      "\t‚Ä¢ Winner Avg Gap: 0029.70%\n",
      "\t‚Ä¢ Winner Avg Reward: 2213.55\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0070.30%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 1 wins\n",
      "\t\t- EXPNeuralUCB: 2 wins\n",
      "\t\t- CPursuitNeuralUCB: 2 wins\n",
      "\t\t- iCPursuitNeuralUCB: 0 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tADAPTIVE ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tCPursuitNeuralUCB (Won 2/5 experiments)\n",
      "\tWinner Avg Gap: \t029.7%\n",
      "\tWinner Avg Efficiency: \t070.3%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t070.3% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t069.8% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t069.6% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t069.1% Efficiency \t(Won 2/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ONLINEADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: GNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 3156.63\n",
      "\t‚Ä¢ Winner Avg Gap: 0030.92%\n",
      "\t‚Ä¢ Winner Avg Reward: 2192.88\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0069.08%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 3 wins\n",
      "\t\t- EXPNeuralUCB: 1 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 1 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ONLINEADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tONLINE ADAPTIVE ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tGNeuralUCB (Won 3/5 experiments)\n",
      "\tWinner Avg Gap: \t030.9%\n",
      "\tWinner Avg Efficiency: \t069.1%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ GNeuralUCB     : \t069.1% Efficiency \t(Won 3/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t069.0% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t068.8% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t067.0% Efficiency \t(Won 1/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: NONE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 3283.79\n",
      "\t‚Ä¢ Winner Avg Gap: 0009.16%\n",
      "\t‚Ä¢ Winner Avg Reward: 2980.52\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0090.84%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 2 wins\n",
      "\t\t- EXPNeuralUCB: 2 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 1 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: NONE\n",
      "======================================================================\n",
      "SCENARIO: \tBASELINE (OPTIMAL CONDITIONS)\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 1/5 experiments)\n",
      "\tWinner Avg Gap: \t009.2%\n",
      "\tWinner Avg Efficiency: \t090.8%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t090.8% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t090.8% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t090.6% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t088.0% Efficiency \t(Won 2/5 experiments)\n",
      "======================================================================\n",
      "‚úÖ Evaluation completed!\n",
      "[Logging Redirect Stopped]\n",
      "\n",
      "üßπ Final cleanup for Dynamic\n",
      "\n",
      "======================================================================\n",
      "‚úÖ COMPLETED: Dynamic\n",
      "======================================================================\n",
      "\n",
      "Dynamic COMPLETED SUCCESSFULLY\n",
      "\n",
      "======================================================================\n",
      "RUNNING: ThompsonSampling on Paper 2 (Chaudhary et al. 2023 - Quantum MAB)\n",
      "======================================================================\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Preparing: ThompsonSampling at scale 1\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üîß Generating physics parameters for model: paper2\n",
      "\n",
      "===================== GET LOCAL REGISTRY =====================\n",
      "‚Üí Skipping local cache (force=True or file missing)\n",
      "\n",
      "===================== BUILD LOCAL REGISTRY =====================\n",
      "\n",
      "================================================================================\n",
      "üîç SCANNING LOCAL FILES\n",
      "================================================================================\n",
      "Parameters: load_to_drive=False, force=False\n",
      "\n",
      "üìÇ Checking DRIVE mode: /content/drive/Shareddrives/ai_quantum_computing/quantum_data_lake\n",
      "   ‚ö†Ô∏è  Path does not exist, skipping\n",
      "\n",
      "üìÇ Checking LOCAL mode: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config\n",
      "   ‚úÖ Path exists, starting walk...\n",
      "   üö∂ Walking directory tree: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config\n",
      "\n",
      "   üìÅ Directory: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201\n",
      "      Relative: framework_state/day_20260201\n",
      "      Component: framework_state\n",
      "      Date: day_20260201\n",
      "      üìÑ Processing 2540 files in framework_state/day_20260201\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "      üìä framework_state/day_20260201: 2514/2540 files processed\n",
      "      üìä framework_state/day_20260201: 0/2540 files skipped\n",
      "      üìä framework_state/day_20260201: 26/2540 files conflicted\n",
      "\n",
      "   üìÅ Directory: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/model_state/day_20260201\n",
      "      Relative: model_state/day_20260201\n",
      "      Component: model_state\n",
      "      Date: day_20260201\n",
      "      üìÑ Processing 9100 files in model_state/day_20260201\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "      üìä model_state/day_20260201: 9100/9100 files processed\n",
      "      üìä model_state/day_20260201: 0/9100 files skipped\n",
      "      üìä model_state/day_20260201: 0/9100 files conflicted\n",
      "\n",
      "   üìä Processed 2 directories\n",
      "\n",
      "================================================================================\n",
      "üì¶ BUILDING FINAL REGISTRY\n",
      "================================================================================\n",
      "Components found: ['framework_state', 'model_state']\n",
      "  ‚Ä¢ framework_state: 2514 files\n",
      "  ‚Ä¢ model_state: 9100 files\n",
      "\n",
      "‚úÖ SCAN COMPLETE\n",
      "Modes scanned: 1\n",
      "Total files in registry: 11614\n",
      "================================================================================\n",
      "\n",
      "\t‚Üí Filesystem scan found 11614 files\n",
      "\n",
      "===================== GET DRIVE REGISTRY =====================\n",
      "===================== REGISTRY BUILD COMPLETE =====================\n",
      "\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "\tüì¶ LocalBackupManager Registry Saved Locally in LOCAL\n",
      "BUILDING REGISTRY WITH 0 EXPECTED COMPONENTS KEYS\n",
      "\n",
      "===================== GET LOCAL REGISTRY =====================\n",
      "‚Üí Skipping local cache (force=True or file missing)\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "\tüì¶ LocalBackupManager Registry Saved Locally in LOCAL\n",
      "\n",
      "======================================================================\n",
      "üéØ AllocatorRunner initialized: ThompsonSampling\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "üöÄ STARTING ALLOCATOR: ThompsonSampling\n",
      "======================================================================\n",
      "\n",
      "üìä Physics Model: paper2\n",
      "\n",
      "üìã Allocator Config:\n",
      "   Type: ThompsonSampling\n",
      "   Testbed: paper2\n",
      "   Paths: 8\n",
      "   Total Qubits: 35\n",
      "   Min per route: 2\n",
      "   Seed: 42\n",
      "   Priors: Œ±=1.0, Œ≤=1.0\n",
      "‚úÖ Allocator created: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "‚úì Allocator: ThompsonSamplingAllocator (8 paths)\n",
      "   Initial allocation: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "Generated paper2 topology: 15 nodes, 51 edges\n",
      "üìä Paper2 Physics: Time-based decay\n",
      "   ‚úì Using MATLAB constants: r_dephase=10000, c_light=300000000.0\n",
      "\n",
      "======================================================================\n",
      "RUN 1 | Scale: 1 | Exp: 5\n",
      "======================================================================\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "No state found for MultiRunEvaluator, disabling resume for Experiment Runners\n",
      "Multi-Run Evaluator Initialized\n",
      "Environment Type: None\n",
      "Frame Range: 4000 -> 12000 (step: 2000)\n",
      "quantum_exps-ThompsonSampling(paper2)_alloc-all_envs-5_attacks-4000_2000-5_runs-S1T\n",
      "[Logging Redirect Initialized]\n",
      "Log File: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/quantum_logs/quantum_exps-ThompsonSampling(paper2)_alloc-all_envs-5_attacks-4000_2000-5_runs-S1T_20260201_log.txt\n",
      "‚öô Running evaluation...\n",
      "======================================================================\n",
      "SCENARIOS MODEL EVALUATION\n",
      "======================================================================\n",
      "Testing algorithm performance against:\n",
      "\t‚Ä¢ Stochastic:  \tNatural quantum decoherence and network failures\n",
      "\t‚Ä¢ Baseline:    \tOptimal conditions for validation\n",
      "======================================================================\n",
      "Models to Test:             \tOracle, GNeuralUCB, EXPNeuralUCB, CPursuitNeuralUCB, iCPursuitNeuralUCB\n",
      "Experiments per Scenario:   \t5\n",
      "======================================================================\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: STOCHASTIC RANDOM FAILURES\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: STOCHASTIC\n",
      "Category: Stochastic (Natural Random Failures)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 4000 frames  <>  SCALED-CAPACITY: 4000 frames (CAPACITY:4000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=0 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 1: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 1: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:4000, QubitAlloc=ThompsonSampling, SC:4000 (Scale=1 x Cap=4000), Seed: 19730\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.38852779914991686], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 1: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 GNEURALUCB          : Reward=1385.61, Efficiency=084.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=4000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 1: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=1429.95, Efficiency=086.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=4000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 1: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=1396.64, Efficiency=084.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=4000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 1: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=1382.21, Efficiency=083.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=4000, Threshold=0.712]\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 1: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:4000, QubitAlloc=ThompsonSampling, SC:4000 (Scale=1 x Cap=4000), Seed: 19730\n",
      "\t-->üèÜ EXP1 Winner:EXPNeuralUCB        (Gap:013.3%) [Env:Stochastic, Attack:Random X Rate:0.0625, Frames:4000, SCapacity=4000, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 1 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 6000 frames  <>  SCALED-CAPACITY: 6000 frames (CAPACITY:6000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=1 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 2: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 2: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:6000, QubitAlloc=ThompsonSampling, SC:6000 (Scale=1 x Cap=6000), Seed: 17421\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.38852779914991686], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 2: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 GNEURALUCB          : Reward=2039.52, Efficiency=087.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 2: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=2146.60, Efficiency=092.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 2: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=2038.43, Efficiency=087.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 2: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=2032.94, Efficiency=087.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.712]\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 2: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:6000, QubitAlloc=ThompsonSampling, SC:6000 (Scale=1 x Cap=6000), Seed: 17421\n",
      "\t-->üèÜ EXP2 Winner:EXPNeuralUCB        (Gap:007.8%) [Env:Stochastic, Attack:Random X Rate:0.0625, Frames:6000, SCapacity=6000, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 2 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 8000 frames  <>  SCALED-CAPACITY: 8000 frames (CAPACITY:8000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=2 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 3: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 3: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:8000, QubitAlloc=ThompsonSampling, SC:8000 (Scale=1 x Cap=8000), Seed: 17649\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.369660064851862], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 3: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 GNEURALUCB          : Reward=2588.23, Efficiency=086.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 3: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=2421.80, Efficiency=081.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 3: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=2612.19, Efficiency=087.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 3: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=2598.71, Efficiency=087.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.712]\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 3: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:8000, QubitAlloc=ThompsonSampling, SC:8000 (Scale=1 x Cap=8000), Seed: 17649\n",
      "\t-->üèÜ EXP3 Winner:CPursuitNeuralUCB   (Gap:012.3%) [Env:Stochastic, Attack:Random X Rate:0.0625, Frames:8000, SCapacity=8000, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 3 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 10000 frames  <>  SCALED-CAPACITY: 10000 frames (CAPACITY:10000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=3 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 4: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 4: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:10000, QubitAlloc=ThompsonSampling, SC:10000 (Scale=1 x Cap=10000), Seed: 20670\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.4202961453677382], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 4: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 GNEURALUCB          : Reward=3605.00, Efficiency=085.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=10000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 4: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=3357.83, Efficiency=080.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=10000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 4: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=3568.78, Efficiency=085.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=10000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 4: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=3588.73, Efficiency=085.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=10000, Threshold=0.712]\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 4: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:10000, QubitAlloc=ThompsonSampling, SC:10000 (Scale=1 x Cap=10000), Seed: 20670\n",
      "\t-->üèÜ EXP4 Winner:GNeuralUCB          (Gap:014.1%) [Env:Stochastic, Attack:Random X Rate:0.0625, Frames:10000, SCapacity=10000, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 4 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 12000 frames  <>  SCALED-CAPACITY: 12000 frames (CAPACITY:12000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=4 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 5: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 5: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:12000, QubitAlloc=ThompsonSampling, SC:12000 (Scale=1 x Cap=12000), Seed: 19632\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.4012351376370454], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 5: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 GNEURALUCB          : Reward=4135.48, Efficiency=087.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 5: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=3993.42, Efficiency=084.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 5: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=4135.88, Efficiency=087.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 5: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=4141.72, Efficiency=087.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.712]\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 5: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:12000, QubitAlloc=ThompsonSampling, SC:12000 (Scale=1 x Cap=12000), Seed: 19632\n",
      "\t-->üèÜ EXP5 Winner:iCPursuitNeuralUCB  (Gap:012.8%) [Env:Stochastic, Attack:Random X Rate:0.0625, Frames:12000, SCapacity=12000, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 5 completed successfully.\n",
      "Total experiment time: 873.0s\n",
      "Experiments completed for stochastic\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: MARKOV ADVERSARIAL ATTACK\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: MARKOV\n",
      "Category: Structured (Markov Chain Based)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 4000 frames  <>  SCALED-CAPACITY: 4000 frames (CAPACITY:4000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=0 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for MARKOV Exp 1: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 1: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:4000, QubitAlloc=ThompsonSampling, SC:4000 (Scale=1 x Cap=4000), Seed: 15617\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.40706611625366484], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 1: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 GNEURALUCB          : Reward=0764.39, Efficiency=049.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=4000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 1: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=0727.57, Efficiency=046.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=4000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 1: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=0753.74, Efficiency=048.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=4000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 1: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=0850.50, Efficiency=054.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=4000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 1: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:4000, QubitAlloc=ThompsonSampling, SC:4000 (Scale=1 x Cap=4000), Seed: 15617\n",
      "\t-->üèÜ EXP1 Winner:iCPursuitNeuralUCB  (Gap:045.4%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:4000, SCapacity=4000, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 1 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 6000 frames  <>  SCALED-CAPACITY: 6000 frames (CAPACITY:6000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=1 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for MARKOV Exp 2: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 2: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:6000, QubitAlloc=ThompsonSampling, SC:6000 (Scale=1 x Cap=6000), Seed: 15214\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.40706611625366484], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 2: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 GNEURALUCB          : Reward=1120.32, Efficiency=048.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=6000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 2: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=1053.67, Efficiency=046.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=6000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 2: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=1119.56, Efficiency=048.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=6000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 2: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=1258.38, Efficiency=055.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=6000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 2: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:6000, QubitAlloc=ThompsonSampling, SC:6000 (Scale=1 x Cap=6000), Seed: 15214\n",
      "\t-->üèÜ EXP2 Winner:iCPursuitNeuralUCB  (Gap:045.0%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:6000, SCapacity=6000, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 2 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 8000 frames  <>  SCALED-CAPACITY: 8000 frames (CAPACITY:8000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=2 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for MARKOV Exp 3: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 3: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:8000, QubitAlloc=ThompsonSampling, SC:8000 (Scale=1 x Cap=8000), Seed: 15164\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.4202961453677382], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 3: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 GNEURALUCB          : Reward=1471.96, Efficiency=046.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=8000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 3: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=1425.56, Efficiency=045.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=8000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 3: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=1538.67, Efficiency=048.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=8000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 3: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=1713.52, Efficiency=054.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=8000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 3: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:8000, QubitAlloc=ThompsonSampling, SC:8000 (Scale=1 x Cap=8000), Seed: 15164\n",
      "\t-->üèÜ EXP3 Winner:iCPursuitNeuralUCB  (Gap:045.6%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:8000, SCapacity=8000, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 3 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 10000 frames  <>  SCALED-CAPACITY: 10000 frames (CAPACITY:10000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=3 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for MARKOV Exp 4: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 4: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:10000, QubitAlloc=ThompsonSampling, SC:10000 (Scale=1 x Cap=10000), Seed: 14599\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.38852779914991686], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 4: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 GNEURALUCB          : Reward=1887.44, Efficiency=049.2% [Retries=3, Failed=0, < Threshold=3, SCapacity=10000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 4: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=1920.04, Efficiency=050.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=10000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 4: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=1879.95, Efficiency=049.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=10000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 4: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=2137.25, Efficiency=055.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=10000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 4: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:10000, QubitAlloc=ThompsonSampling, SC:10000 (Scale=1 x Cap=10000), Seed: 14599\n",
      "\t-->üèÜ EXP4 Winner:iCPursuitNeuralUCB  (Gap:044.2%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:10000, SCapacity=10000, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 4 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 12000 frames  <>  SCALED-CAPACITY: 12000 frames (CAPACITY:12000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=4 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for MARKOV Exp 5: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 5: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:12000, QubitAlloc=ThompsonSampling, SC:12000 (Scale=1 x Cap=12000), Seed: 14153\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.3579527263647335], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 5: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 GNEURALUCB          : Reward=2220.32, Efficiency=056.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=12000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 5: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=1958.34, Efficiency=050.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=12000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 5: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=2187.99, Efficiency=055.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=12000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 5: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=2474.06, Efficiency=063.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=12000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 5: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:12000, QubitAlloc=ThompsonSampling, SC:12000 (Scale=1 x Cap=12000), Seed: 14153\n",
      "\t-->üèÜ EXP5 Winner:iCPursuitNeuralUCB  (Gap:036.7%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:12000, SCapacity=12000, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 5 completed successfully.\n",
      "Total experiment time: 757.6s\n",
      "Experiments completed for markov\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: ADAPTIVE ADVERSARIAL ATTACK\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: ADAPTIVE\n",
      "Category: Adaptive (Reactive Strategic)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 4000 frames  <>  SCALED-CAPACITY: 4000 frames (CAPACITY:4000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=0 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 1: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 1: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:4000, QubitAlloc=ThompsonSampling, SC:4000 (Scale=1 x Cap=4000), Seed: 12509\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.38860510852297203], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 1: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 GNEURALUCB          : Reward=1058.16, Efficiency=069.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=4000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 1: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=1017.20, Efficiency=066.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=4000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 1: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=1068.45, Efficiency=070.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=4000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 1: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=1041.23, Efficiency=068.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=4000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 1: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:4000, QubitAlloc=ThompsonSampling, SC:4000 (Scale=1 x Cap=4000), Seed: 12509\n",
      "\t-->üèÜ EXP1 Winner:CPursuitNeuralUCB   (Gap:029.7%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:4000, SCapacity=4000, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 1 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 6000 frames  <>  SCALED-CAPACITY: 6000 frames (CAPACITY:6000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=1 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 2: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 2: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:6000, QubitAlloc=ThompsonSampling, SC:6000 (Scale=1 x Cap=6000), Seed: 21611\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.38722107258255484], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 2: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 GNEURALUCB          : Reward=1618.60, Efficiency=070.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 2: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=1546.63, Efficiency=067.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 2: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=1603.83, Efficiency=069.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 2: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=1604.04, Efficiency=069.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=6000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 2: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:6000, QubitAlloc=ThompsonSampling, SC:6000 (Scale=1 x Cap=6000), Seed: 21611\n",
      "\t-->üèÜ EXP2 Winner:GNeuralUCB          (Gap:029.6%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:6000, SCapacity=6000, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 2 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 8000 frames  <>  SCALED-CAPACITY: 8000 frames (CAPACITY:8000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=2 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 3: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 3: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:8000, QubitAlloc=ThompsonSampling, SC:8000 (Scale=1 x Cap=8000), Seed: 19675\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.38229009396593533], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 3: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 GNEURALUCB          : Reward=2124.58, Efficiency=070.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 3: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=2152.00, Efficiency=071.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 3: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=2137.37, Efficiency=070.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 3: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=2126.83, Efficiency=070.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=8000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 3: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:8000, QubitAlloc=ThompsonSampling, SC:8000 (Scale=1 x Cap=8000), Seed: 19675\n",
      "\t-->üèÜ EXP3 Winner:EXPNeuralUCB        (Gap:028.9%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:8000, SCapacity=8000, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 3 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 10000 frames  <>  SCALED-CAPACITY: 10000 frames (CAPACITY:10000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=3 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 4: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 4: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:10000, QubitAlloc=ThompsonSampling, SC:10000 (Scale=1 x Cap=10000), Seed: 20231\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.4202961453677382], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 4: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 GNEURALUCB          : Reward=2830.21, Efficiency=068.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=10000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 4: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=2916.66, Efficiency=070.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=10000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 4: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=2828.79, Efficiency=068.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=10000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 4: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=2807.28, Efficiency=068.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=10000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 4: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:10000, QubitAlloc=ThompsonSampling, SC:10000 (Scale=1 x Cap=10000), Seed: 20231\n",
      "\t-->üèÜ EXP4 Winner:EXPNeuralUCB        (Gap:029.2%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:10000, SCapacity=10000, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 4 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 12000 frames  <>  SCALED-CAPACITY: 12000 frames (CAPACITY:12000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=4 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 5: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 5: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:12000, QubitAlloc=ThompsonSampling, SC:12000 (Scale=1 x Cap=12000), Seed: 15657\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.4202961453677382], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 5: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 GNEURALUCB          : Reward=3329.19, Efficiency=070.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 5: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=3291.62, Efficiency=069.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 5: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=3429.29, Efficiency=072.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 5: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=3394.31, Efficiency=071.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 5: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:12000, QubitAlloc=ThompsonSampling, SC:12000 (Scale=1 x Cap=12000), Seed: 15657\n",
      "\t-->üèÜ EXP5 Winner:CPursuitNeuralUCB   (Gap:027.9%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:12000, SCapacity=12000, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 5 completed successfully.\n",
      "Total experiment time: 867.6s\n",
      "Experiments completed for adaptive\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: ONLINE ADAPTIVE ATTACK\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: ONLINEADAPTIVE\n",
      "Category: Online Adaptive (Real-time Strategic)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 4000 frames  <>  SCALED-CAPACITY: 4000 frames (CAPACITY:4000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=0 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 1: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:4000, QubitAlloc=ThompsonSampling, SC:4000 (Scale=1 x Cap=4000), Seed: 16665\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.38722107258255484], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 GNEURALUCB          : Reward=1027.32, Efficiency=067.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=4000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=1023.88, Efficiency=067.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=4000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=1012.04, Efficiency=066.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=4000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=1023.05, Efficiency=067.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=4000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:4000, QubitAlloc=ThompsonSampling, SC:4000 (Scale=1 x Cap=4000), Seed: 16665\n",
      "\t-->üèÜ EXP1 Winner:GNeuralUCB          (Gap:032.1%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:4000, SCapacity=4000, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 1 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 6000 frames  <>  SCALED-CAPACITY: 6000 frames (CAPACITY:6000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=1 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 2: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:6000, QubitAlloc=ThompsonSampling, SC:6000 (Scale=1 x Cap=6000), Seed: 21573\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.4012351376370454], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 GNEURALUCB          : Reward=1616.29, Efficiency=068.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=1547.04, Efficiency=065.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=1618.93, Efficiency=068.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=1648.16, Efficiency=069.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=6000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:6000, QubitAlloc=ThompsonSampling, SC:6000 (Scale=1 x Cap=6000), Seed: 21573\n",
      "\t-->üèÜ EXP2 Winner:iCPursuitNeuralUCB  (Gap:030.6%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:6000, SCapacity=6000, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 2 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 8000 frames  <>  SCALED-CAPACITY: 8000 frames (CAPACITY:8000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=2 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 3: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:8000, QubitAlloc=ThompsonSampling, SC:8000 (Scale=1 x Cap=8000), Seed: 14973\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.4202961453677382], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 GNEURALUCB          : Reward=2294.40, Efficiency=069.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=2152.46, Efficiency=064.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=2279.63, Efficiency=068.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=2241.88, Efficiency=067.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=8000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:8000, QubitAlloc=ThompsonSampling, SC:8000 (Scale=1 x Cap=8000), Seed: 14973\n",
      "\t-->üèÜ EXP3 Winner:GNeuralUCB          (Gap:031.0%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:8000, SCapacity=8000, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 3 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 10000 frames  <>  SCALED-CAPACITY: 10000 frames (CAPACITY:10000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=3 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 4: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:10000, QubitAlloc=ThompsonSampling, SC:10000 (Scale=1 x Cap=10000), Seed: 18379\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.4202961453677382], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 GNEURALUCB          : Reward=2776.12, Efficiency=067.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=10000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=2526.34, Efficiency=061.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=10000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=2776.06, Efficiency=067.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=10000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=2760.54, Efficiency=067.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=10000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:10000, QubitAlloc=ThompsonSampling, SC:10000 (Scale=1 x Cap=10000), Seed: 18379\n",
      "\t-->üèÜ EXP4 Winner:GNeuralUCB          (Gap:032.1%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:10000, SCapacity=10000, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 4 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 12000 frames  <>  SCALED-CAPACITY: 12000 frames (CAPACITY:12000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=4 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 5: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:12000, QubitAlloc=ThompsonSampling, SC:12000 (Scale=1 x Cap=12000), Seed: 14049\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.3739910434684815], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 GNEURALUCB          : Reward=3250.30, Efficiency=072.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=3386.02, Efficiency=075.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=3243.36, Efficiency=072.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=3273.88, Efficiency=073.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:12000, QubitAlloc=ThompsonSampling, SC:12000 (Scale=1 x Cap=12000), Seed: 14049\n",
      "\t-->üèÜ EXP5 Winner:EXPNeuralUCB        (Gap:024.5%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:12000, SCapacity=12000, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 5 completed successfully.\n",
      "Total experiment time: 1078.1s\n",
      "Experiments completed for onlineadaptive\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: BASELINE (OPTIMAL CONDITIONS)\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: NONE\n",
      "Category: Baseline (No Attacks)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 4000 frames  <>  SCALED-CAPACITY: 4000 frames (CAPACITY:4000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=0 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for NONE Exp 1: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 1: Env:Baseline (None), Attack:No, Rate:0.0, Frames:4000, QubitAlloc=ThompsonSampling, SC:4000 (Scale=1 x Cap=4000), Seed: 19677\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.4004511016966282], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 1: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 GNEURALUCB          : Reward=1430.43, Efficiency=089.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=4000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 1: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=1451.54, Efficiency=090.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=4000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 1: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=1439.35, Efficiency=089.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=4000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 1: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=1443.49, Efficiency=090.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=4000, Threshold=0.712]\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 1: Env:Baseline (None), Attack:No, Rate:0.0, Frames:4000, QubitAlloc=ThompsonSampling, SC:4000 (Scale=1 x Cap=4000), Seed: 19677\n",
      "\t-->üèÜ EXP1 Winner:EXPNeuralUCB        (Gap:009.4%) [Env:Baseline (None), Attack:No X Rate:0.0, Frames:4000, SCapacity=4000, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 1 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 6000 frames  <>  SCALED-CAPACITY: 6000 frames (CAPACITY:6000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=1 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for NONE Exp 2: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 2: Env:Baseline (None), Attack:No, Rate:0.0, Frames:6000, QubitAlloc=ThompsonSampling, SC:6000 (Scale=1 x Cap=6000), Seed: 16724\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.38860510852297203], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 2: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 GNEURALUCB          : Reward=2163.45, Efficiency=092.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 2: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=2002.09, Efficiency=085.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 2: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=2158.16, Efficiency=092.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 2: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=2151.21, Efficiency=092.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.712]\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 2: Env:Baseline (None), Attack:No, Rate:0.0, Frames:6000, QubitAlloc=ThompsonSampling, SC:6000 (Scale=1 x Cap=6000), Seed: 16724\n",
      "\t-->üèÜ EXP2 Winner:GNeuralUCB          (Gap:007.2%) [Env:Baseline (None), Attack:No X Rate:0.0, Frames:6000, SCapacity=6000, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 2 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 8000 frames  <>  SCALED-CAPACITY: 8000 frames (CAPACITY:8000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=2 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for NONE Exp 3: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 3: Env:Baseline (None), Attack:No, Rate:0.0, Frames:8000, QubitAlloc=ThompsonSampling, SC:8000 (Scale=1 x Cap=8000), Seed: 16587\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.40706611625366484], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 3: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 GNEURALUCB          : Reward=3015.55, Efficiency=091.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 3: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=2698.94, Efficiency=081.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 3: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=2978.50, Efficiency=089.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 3: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=3012.68, Efficiency=090.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.712]\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 3: Env:Baseline (None), Attack:No, Rate:0.0, Frames:8000, QubitAlloc=ThompsonSampling, SC:8000 (Scale=1 x Cap=8000), Seed: 16587\n",
      "\t-->üèÜ EXP3 Winner:GNeuralUCB          (Gap:009.0%) [Env:Baseline (None), Attack:No X Rate:0.0, Frames:8000, SCapacity=8000, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 3 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 10000 frames  <>  SCALED-CAPACITY: 10000 frames (CAPACITY:10000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=3 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for NONE Exp 4: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 4: Env:Baseline (None), Attack:No, Rate:0.0, Frames:10000, QubitAlloc=ThompsonSampling, SC:10000 (Scale=1 x Cap=10000), Seed: 13579\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.4202961453677382], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 4: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 GNEURALUCB          : Reward=3823.88, Efficiency=091.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=10000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 4: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=4103.22, Efficiency=097.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=10000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 4: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=3814.89, Efficiency=090.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=10000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 4: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=3799.27, Efficiency=090.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=10000, Threshold=0.712]\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 4: Env:Baseline (None), Attack:No, Rate:0.0, Frames:10000, QubitAlloc=ThompsonSampling, SC:10000 (Scale=1 x Cap=10000), Seed: 13579\n",
      "\t-->üèÜ EXP4 Winner:EXPNeuralUCB        (Gap:002.4%) [Env:Baseline (None), Attack:No X Rate:0.0, Frames:10000, SCapacity=10000, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 4 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 12000 frames  <>  SCALED-CAPACITY: 12000 frames (CAPACITY:12000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=4 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for NONE Exp 5: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 5: Env:Baseline (None), Attack:No, Rate:0.0, Frames:12000, QubitAlloc=ThompsonSampling, SC:12000 (Scale=1 x Cap=12000), Seed: 15608\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.3570300357377887], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 5: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 GNEURALUCB          : Reward=4459.93, Efficiency=089.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 5: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=4186.32, Efficiency=084.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 5: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=4458.33, Efficiency=089.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 5: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=4495.93, Efficiency=090.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.712]\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 5: Env:Baseline (None), Attack:No, Rate:0.0, Frames:12000, QubitAlloc=ThompsonSampling, SC:12000 (Scale=1 x Cap=12000), Seed: 15608\n",
      "\t-->üèÜ EXP5 Winner:iCPursuitNeuralUCB  (Gap:009.5%) [Env:Baseline (None), Attack:No X Rate:0.0, Frames:12000, SCapacity=12000, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 5 completed successfully.\n",
      "Total experiment time: 1651.9s\n",
      "Experiments completed for none\n",
      "‚úì Scenario 'stochastic' evaluation completed.\n",
      "‚úì Scenario 'markov' evaluation completed.\n",
      "‚úì Scenario 'adaptive' evaluation completed.\n",
      "‚úì Scenario 'onlineadaptive' evaluation completed.\n",
      "‚úì Scenario 'none' evaluation completed.\n",
      "\n",
      "======================================================================\n",
      "COMPREHENSIVE SCENARIO PERFORMANCE ANALYSIS\n",
      "======================================================================\n",
      "SCENARIO: STOCHASTIC\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: CPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 3180.83\n",
      "\t‚Ä¢ Winner Avg Gap: 0013.60%\n",
      "\t‚Ä¢ Winner Avg Reward: 2750.38\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0086.40%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 1 wins\n",
      "\t\t- EXPNeuralUCB: 2 wins\n",
      "\t\t- CPursuitNeuralUCB: 1 wins\n",
      "\t\t- iCPursuitNeuralUCB: 1 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: STOCHASTIC\n",
      "======================================================================\n",
      "SCENARIO: \tSTOCHASTIC RANDOM FAILURES\n",
      "----------------------------------------\n",
      "Recommended Model: \tCPursuitNeuralUCB (Won 1/5 experiments)\n",
      "\tWinner Avg Gap: \t013.6%\n",
      "\tWinner Avg Efficiency: \t086.4%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t086.4% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t086.3% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t086.2% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t084.8% Efficiency \t(Won 2/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: MARKOV\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 2947.96\n",
      "\t‚Ä¢ Winner Avg Gap: 0043.40%\n",
      "\t‚Ä¢ Winner Avg Reward: 1686.74\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0056.60%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 5 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: MARKOV\n",
      "======================================================================\n",
      "SCENARIO: \tMARKOV ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 5/5 experiments)\n",
      "\tWinner Avg Gap: \t043.4%\n",
      "\tWinner Avg Efficiency: \t056.6%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t056.6% Efficiency \t(Won 5/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t050.2% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t050.2% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t047.6% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: CPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 3143.66\n",
      "\t‚Ä¢ Winner Avg Gap: 0029.70%\n",
      "\t‚Ä¢ Winner Avg Reward: 2213.55\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0070.30%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 1 wins\n",
      "\t\t- EXPNeuralUCB: 2 wins\n",
      "\t\t- CPursuitNeuralUCB: 2 wins\n",
      "\t\t- iCPursuitNeuralUCB: 0 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tADAPTIVE ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tCPursuitNeuralUCB (Won 2/5 experiments)\n",
      "\tWinner Avg Gap: \t029.7%\n",
      "\tWinner Avg Efficiency: \t070.3%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t070.3% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t069.8% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t069.6% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t069.1% Efficiency \t(Won 2/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ONLINEADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: GNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 3156.63\n",
      "\t‚Ä¢ Winner Avg Gap: 0030.92%\n",
      "\t‚Ä¢ Winner Avg Reward: 2192.88\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0069.08%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 3 wins\n",
      "\t\t- EXPNeuralUCB: 1 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 1 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ONLINEADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tONLINE ADAPTIVE ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tGNeuralUCB (Won 3/5 experiments)\n",
      "\tWinner Avg Gap: \t030.9%\n",
      "\tWinner Avg Efficiency: \t069.1%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ GNeuralUCB     : \t069.1% Efficiency \t(Won 3/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t069.0% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t068.8% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t067.0% Efficiency \t(Won 1/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: NONE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 3283.79\n",
      "\t‚Ä¢ Winner Avg Gap: 0009.16%\n",
      "\t‚Ä¢ Winner Avg Reward: 2980.52\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0090.84%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 2 wins\n",
      "\t\t- EXPNeuralUCB: 2 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 1 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: NONE\n",
      "======================================================================\n",
      "SCENARIO: \tBASELINE (OPTIMAL CONDITIONS)\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 1/5 experiments)\n",
      "\tWinner Avg Gap: \t009.2%\n",
      "\tWinner Avg Efficiency: \t090.8%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t090.8% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t090.8% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t090.6% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t088.0% Efficiency \t(Won 2/5 experiments)\n",
      "======================================================================\n",
      "KEY INSIGHTS:\n",
      "Best Performing Model Analysis (CPursuitNeuralUCB):\n",
      "\t‚Ä¢ Stochastic Performance:    \t2750.385\n",
      "\t‚Ä¢ Baseline Performance:      \t2980.517\n",
      "\t‚Ä¢ Performance Retention:     \t092.3%\n",
      "\tGOOD:               \tAcceptable performance under stochastic conditions\n",
      "Statistical Analysis:\n",
      "\t‚Ä¢ Total models evaluated:     \t5\n",
      "\t‚Ä¢ Experiments per environment:\t5\n",
      "\t‚Ä¢ Quantum network simulation: \tComprehensive stochastic modeling\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "COMPREHENSIVE SCENARIO PERFORMANCE ANALYSIS\n",
      "======================================================================\n",
      "SCENARIO: STOCHASTIC\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: CPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 3180.83\n",
      "\t‚Ä¢ Winner Avg Gap: 0013.60%\n",
      "\t‚Ä¢ Winner Avg Reward: 2750.38\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0086.40%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 1 wins\n",
      "\t\t- EXPNeuralUCB: 2 wins\n",
      "\t\t- CPursuitNeuralUCB: 1 wins\n",
      "\t\t- iCPursuitNeuralUCB: 1 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: STOCHASTIC\n",
      "======================================================================\n",
      "SCENARIO: \tSTOCHASTIC RANDOM FAILURES\n",
      "----------------------------------------\n",
      "Recommended Model: \tCPursuitNeuralUCB (Won 1/5 experiments)\n",
      "\tWinner Avg Gap: \t013.6%\n",
      "\tWinner Avg Efficiency: \t086.4%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t086.4% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t086.3% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t086.2% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t084.8% Efficiency \t(Won 2/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: MARKOV\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 2947.96\n",
      "\t‚Ä¢ Winner Avg Gap: 0043.40%\n",
      "\t‚Ä¢ Winner Avg Reward: 1686.74\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0056.60%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 5 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: MARKOV\n",
      "======================================================================\n",
      "SCENARIO: \tMARKOV ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 5/5 experiments)\n",
      "\tWinner Avg Gap: \t043.4%\n",
      "\tWinner Avg Efficiency: \t056.6%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t056.6% Efficiency \t(Won 5/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t050.2% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t050.2% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t047.6% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: CPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 3143.66\n",
      "\t‚Ä¢ Winner Avg Gap: 0029.70%\n",
      "\t‚Ä¢ Winner Avg Reward: 2213.55\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0070.30%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 1 wins\n",
      "\t\t- EXPNeuralUCB: 2 wins\n",
      "\t\t- CPursuitNeuralUCB: 2 wins\n",
      "\t\t- iCPursuitNeuralUCB: 0 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tADAPTIVE ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tCPursuitNeuralUCB (Won 2/5 experiments)\n",
      "\tWinner Avg Gap: \t029.7%\n",
      "\tWinner Avg Efficiency: \t070.3%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t070.3% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t069.8% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t069.6% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t069.1% Efficiency \t(Won 2/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ONLINEADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: GNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 3156.63\n",
      "\t‚Ä¢ Winner Avg Gap: 0030.92%\n",
      "\t‚Ä¢ Winner Avg Reward: 2192.88\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0069.08%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 3 wins\n",
      "\t\t- EXPNeuralUCB: 1 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 1 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ONLINEADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tONLINE ADAPTIVE ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tGNeuralUCB (Won 3/5 experiments)\n",
      "\tWinner Avg Gap: \t030.9%\n",
      "\tWinner Avg Efficiency: \t069.1%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ GNeuralUCB     : \t069.1% Efficiency \t(Won 3/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t069.0% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t068.8% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t067.0% Efficiency \t(Won 1/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: NONE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 3283.79\n",
      "\t‚Ä¢ Winner Avg Gap: 0009.16%\n",
      "\t‚Ä¢ Winner Avg Reward: 2980.52\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0090.84%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 2 wins\n",
      "\t\t- EXPNeuralUCB: 2 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 1 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: NONE\n",
      "======================================================================\n",
      "SCENARIO: \tBASELINE (OPTIMAL CONDITIONS)\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 1/5 experiments)\n",
      "\tWinner Avg Gap: \t009.2%\n",
      "\tWinner Avg Efficiency: \t090.8%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t090.8% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t090.8% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t090.6% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t088.0% Efficiency \t(Won 2/5 experiments)\n",
      "======================================================================\n",
      "‚úÖ Evaluation completed!\n",
      "[Logging Redirect Stopped]\n",
      "\n",
      "üßπ Final cleanup for ThompsonSampling\n",
      "\n",
      "======================================================================\n",
      "‚úÖ COMPLETED: ThompsonSampling\n",
      "======================================================================\n",
      "\n",
      "ThompsonSampling COMPLETED SUCCESSFULLY\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Preparing: ThompsonSampling at scale 1.5\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üîß Generating physics parameters for model: paper2\n",
      "\n",
      "===================== GET LOCAL REGISTRY =====================\n",
      "‚Üí Skipping local cache (force=True or file missing)\n",
      "\n",
      "===================== BUILD LOCAL REGISTRY =====================\n",
      "\n",
      "================================================================================\n",
      "üîç SCANNING LOCAL FILES\n",
      "================================================================================\n",
      "Parameters: load_to_drive=False, force=False\n",
      "\n",
      "üìÇ Checking DRIVE mode: /content/drive/Shareddrives/ai_quantum_computing/quantum_data_lake\n",
      "   ‚ö†Ô∏è  Path does not exist, skipping\n",
      "\n",
      "üìÇ Checking LOCAL mode: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config\n",
      "   ‚úÖ Path exists, starting walk...\n",
      "   üö∂ Walking directory tree: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config\n",
      "\n",
      "   üìÅ Directory: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201\n",
      "      Relative: framework_state/day_20260201\n",
      "      Component: framework_state\n",
      "      Date: day_20260201\n",
      "      üìÑ Processing 2553 files in framework_state/day_20260201\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "      üìä framework_state/day_20260201: 2527/2553 files processed\n",
      "      üìä framework_state/day_20260201: 0/2553 files skipped\n",
      "      üìä framework_state/day_20260201: 26/2553 files conflicted\n",
      "\n",
      "   üìÅ Directory: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/model_state/day_20260201\n",
      "      Relative: model_state/day_20260201\n",
      "      Component: model_state\n",
      "      Date: day_20260201\n",
      "      üìÑ Processing 9221 files in model_state/day_20260201\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "      üìä model_state/day_20260201: 9221/9221 files processed\n",
      "      üìä model_state/day_20260201: 0/9221 files skipped\n",
      "      üìä model_state/day_20260201: 0/9221 files conflicted\n",
      "\n",
      "   üìä Processed 2 directories\n",
      "\n",
      "================================================================================\n",
      "üì¶ BUILDING FINAL REGISTRY\n",
      "================================================================================\n",
      "Components found: ['framework_state', 'model_state']\n",
      "  ‚Ä¢ framework_state: 2527 files\n",
      "  ‚Ä¢ model_state: 9221 files\n",
      "\n",
      "‚úÖ SCAN COMPLETE\n",
      "Modes scanned: 1\n",
      "Total files in registry: 11748\n",
      "================================================================================\n",
      "\n",
      "\t‚Üí Filesystem scan found 11748 files\n",
      "\n",
      "===================== GET DRIVE REGISTRY =====================\n",
      "===================== REGISTRY BUILD COMPLETE =====================\n",
      "\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "\tüì¶ LocalBackupManager Registry Saved Locally in LOCAL\n",
      "BUILDING REGISTRY WITH 0 EXPECTED COMPONENTS KEYS\n",
      "\n",
      "===================== GET LOCAL REGISTRY =====================\n",
      "‚Üí Skipping local cache (force=True or file missing)\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "\tüì¶ LocalBackupManager Registry Saved Locally in LOCAL\n",
      "\n",
      "======================================================================\n",
      "üéØ AllocatorRunner initialized: ThompsonSampling\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "üöÄ STARTING ALLOCATOR: ThompsonSampling\n",
      "======================================================================\n",
      "\n",
      "üìä Physics Model: paper2\n",
      "\n",
      "üìã Allocator Config:\n",
      "   Type: ThompsonSampling\n",
      "   Testbed: paper2\n",
      "   Paths: 8\n",
      "   Total Qubits: 35\n",
      "   Min per route: 2\n",
      "   Seed: 42\n",
      "   Priors: Œ±=1.0, Œ≤=1.0\n",
      "‚úÖ Allocator created: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "‚úì Allocator: ThompsonSamplingAllocator (8 paths)\n",
      "   Initial allocation: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "Generated paper2 topology: 15 nodes, 51 edges\n",
      "üìä Paper2 Physics: Time-based decay\n",
      "   ‚úì Using MATLAB constants: r_dephase=10000, c_light=300000000.0\n",
      "\n",
      "======================================================================\n",
      "RUN 1 | Scale: 1.5 | Exp: 5\n",
      "======================================================================\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "No state found for MultiRunEvaluator, disabling resume for Experiment Runners\n",
      "Multi-Run Evaluator Initialized\n",
      "Environment Type: None\n",
      "Frame Range: 4000 -> 12000 (step: 2000)\n",
      "quantum_exps-ThompsonSampling(paper2)_alloc-all_envs-5_attacks-4000_2000-5_runs-S1.5T\n",
      "[Logging Redirect Initialized]\n",
      "Log File: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/quantum_logs/quantum_exps-ThompsonSampling(paper2)_alloc-all_envs-5_attacks-4000_2000-5_runs-S1.5T_20260201_log.txt\n",
      "‚öô Running evaluation...\n",
      "======================================================================\n",
      "SCENARIOS MODEL EVALUATION\n",
      "======================================================================\n",
      "Testing algorithm performance against:\n",
      "\t‚Ä¢ Stochastic:  \tNatural quantum decoherence and network failures\n",
      "\t‚Ä¢ Baseline:    \tOptimal conditions for validation\n",
      "======================================================================\n",
      "Models to Test:             \tOracle, GNeuralUCB, EXPNeuralUCB, CPursuitNeuralUCB, iCPursuitNeuralUCB\n",
      "Experiments per Scenario:   \t5\n",
      "======================================================================\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: STOCHASTIC RANDOM FAILURES\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: STOCHASTIC\n",
      "Category: Stochastic (Natural Random Failures)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 4000 frames  <>  SCALED-CAPACITY: 6000.0 frames (CAPACITY:4000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=0 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 1: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 1: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:4000, QubitAlloc=ThompsonSampling, SC:6000 (Scale=1.5 x Cap=4000), Seed: 19730\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.38852779914991686], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 1: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 GNEURALUCB          : Reward=1385.61, Efficiency=084.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 1: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=1429.95, Efficiency=086.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 1: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=1396.64, Efficiency=084.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 1: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=1382.21, Efficiency=083.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.712]\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 1: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:4000, QubitAlloc=ThompsonSampling, SC:6000 (Scale=1.5 x Cap=4000), Seed: 19730\n",
      "\t-->üèÜ EXP1 Winner:EXPNeuralUCB        (Gap:013.3%) [Env:Stochastic, Attack:Random X Rate:0.0625, Frames:4000, SCapacity=6000, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 1 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 6000 frames  <>  SCALED-CAPACITY: 9000.0 frames (CAPACITY:6000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=1 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 2: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 2: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:6000, QubitAlloc=ThompsonSampling, SC:9000 (Scale=1.5 x Cap=6000), Seed: 17421\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.38852779914991686], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 2: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 GNEURALUCB          : Reward=2039.52, Efficiency=087.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=9000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 2: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=2146.60, Efficiency=092.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=9000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 2: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=2038.43, Efficiency=087.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=9000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 2: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=2032.94, Efficiency=087.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=9000, Threshold=0.712]\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 2: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:6000, QubitAlloc=ThompsonSampling, SC:9000 (Scale=1.5 x Cap=6000), Seed: 17421\n",
      "\t-->üèÜ EXP2 Winner:EXPNeuralUCB        (Gap:007.8%) [Env:Stochastic, Attack:Random X Rate:0.0625, Frames:6000, SCapacity=9000, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 2 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 8000 frames  <>  SCALED-CAPACITY: 12000.0 frames (CAPACITY:8000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=2 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 3: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 3: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:8000, QubitAlloc=ThompsonSampling, SC:12000 (Scale=1.5 x Cap=8000), Seed: 17649\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.369660064851862], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 3: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 GNEURALUCB          : Reward=2588.23, Efficiency=086.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 3: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=2421.80, Efficiency=081.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 3: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=2612.19, Efficiency=087.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 3: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=2598.71, Efficiency=087.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.712]\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 3: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:8000, QubitAlloc=ThompsonSampling, SC:12000 (Scale=1.5 x Cap=8000), Seed: 17649\n",
      "\t-->üèÜ EXP3 Winner:CPursuitNeuralUCB   (Gap:012.3%) [Env:Stochastic, Attack:Random X Rate:0.0625, Frames:8000, SCapacity=12000, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 3 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 10000 frames  <>  SCALED-CAPACITY: 15000.0 frames (CAPACITY:10000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=3 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 4: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 4: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:10000, QubitAlloc=ThompsonSampling, SC:15000 (Scale=1.5 x Cap=10000), Seed: 20670\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.4202961453677382], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 4: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 GNEURALUCB          : Reward=3605.00, Efficiency=085.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=15000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 4: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=3357.83, Efficiency=080.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=15000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 4: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=3568.78, Efficiency=085.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=15000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 4: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=3588.73, Efficiency=085.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=15000, Threshold=0.712]\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 4: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:10000, QubitAlloc=ThompsonSampling, SC:15000 (Scale=1.5 x Cap=10000), Seed: 20670\n",
      "\t-->üèÜ EXP4 Winner:GNeuralUCB          (Gap:014.1%) [Env:Stochastic, Attack:Random X Rate:0.0625, Frames:10000, SCapacity=15000, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 4 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 12000 frames  <>  SCALED-CAPACITY: 18000.0 frames (CAPACITY:12000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=4 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 5: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 5: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:12000, QubitAlloc=ThompsonSampling, SC:18000 (Scale=1.5 x Cap=12000), Seed: 19632\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.4012351376370454], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 5: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 GNEURALUCB          : Reward=4135.48, Efficiency=087.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=18000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 5: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=3993.42, Efficiency=084.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=18000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 5: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=4135.88, Efficiency=087.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=18000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 5: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=4141.72, Efficiency=087.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=18000, Threshold=0.712]\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 5: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:12000, QubitAlloc=ThompsonSampling, SC:18000 (Scale=1.5 x Cap=12000), Seed: 19632\n",
      "\t-->üèÜ EXP5 Winner:iCPursuitNeuralUCB  (Gap:012.8%) [Env:Stochastic, Attack:Random X Rate:0.0625, Frames:12000, SCapacity=18000, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 5 completed successfully.\n",
      "Total experiment time: 1116.8s\n",
      "Experiments completed for stochastic\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: MARKOV ADVERSARIAL ATTACK\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: MARKOV\n",
      "Category: Structured (Markov Chain Based)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 4000 frames  <>  SCALED-CAPACITY: 6000.0 frames (CAPACITY:4000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=0 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for MARKOV Exp 1: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 1: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:4000, QubitAlloc=ThompsonSampling, SC:6000 (Scale=1.5 x Cap=4000), Seed: 15617\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.40706611625366484], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 1: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 GNEURALUCB          : Reward=0764.39, Efficiency=049.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=6000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 1: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=0727.57, Efficiency=046.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=6000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 1: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=0753.74, Efficiency=048.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=6000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 1: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=0850.50, Efficiency=054.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=6000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 1: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:4000, QubitAlloc=ThompsonSampling, SC:6000 (Scale=1.5 x Cap=4000), Seed: 15617\n",
      "\t-->üèÜ EXP1 Winner:iCPursuitNeuralUCB  (Gap:045.4%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:4000, SCapacity=6000, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 1 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 6000 frames  <>  SCALED-CAPACITY: 9000.0 frames (CAPACITY:6000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=1 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for MARKOV Exp 2: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 2: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:6000, QubitAlloc=ThompsonSampling, SC:9000 (Scale=1.5 x Cap=6000), Seed: 15214\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.40706611625366484], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 2: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 GNEURALUCB          : Reward=1120.32, Efficiency=048.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=9000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 2: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=1053.67, Efficiency=046.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=9000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 2: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=1119.56, Efficiency=048.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=9000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 2: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=1258.38, Efficiency=055.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=9000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 2: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:6000, QubitAlloc=ThompsonSampling, SC:9000 (Scale=1.5 x Cap=6000), Seed: 15214\n",
      "\t-->üèÜ EXP2 Winner:iCPursuitNeuralUCB  (Gap:045.0%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:6000, SCapacity=9000, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 2 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 8000 frames  <>  SCALED-CAPACITY: 12000.0 frames (CAPACITY:8000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=2 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for MARKOV Exp 3: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 3: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:8000, QubitAlloc=ThompsonSampling, SC:12000 (Scale=1.5 x Cap=8000), Seed: 15164\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.4202961453677382], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 3: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 GNEURALUCB          : Reward=1471.96, Efficiency=046.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=12000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 3: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=1425.56, Efficiency=045.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=12000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 3: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=1538.67, Efficiency=048.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=12000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 3: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=1713.52, Efficiency=054.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=12000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 3: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:8000, QubitAlloc=ThompsonSampling, SC:12000 (Scale=1.5 x Cap=8000), Seed: 15164\n",
      "\t-->üèÜ EXP3 Winner:iCPursuitNeuralUCB  (Gap:045.6%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:8000, SCapacity=12000, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 3 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 10000 frames  <>  SCALED-CAPACITY: 15000.0 frames (CAPACITY:10000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=3 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for MARKOV Exp 4: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 4: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:10000, QubitAlloc=ThompsonSampling, SC:15000 (Scale=1.5 x Cap=10000), Seed: 14599\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.38852779914991686], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 4: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 GNEURALUCB          : Reward=1887.44, Efficiency=049.2% [Retries=3, Failed=0, < Threshold=3, SCapacity=15000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 4: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=1920.04, Efficiency=050.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=15000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 4: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=1879.95, Efficiency=049.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=15000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 4: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=2137.25, Efficiency=055.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=15000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 4: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:10000, QubitAlloc=ThompsonSampling, SC:15000 (Scale=1.5 x Cap=10000), Seed: 14599\n",
      "\t-->üèÜ EXP4 Winner:iCPursuitNeuralUCB  (Gap:044.2%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:10000, SCapacity=15000, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 4 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 12000 frames  <>  SCALED-CAPACITY: 18000.0 frames (CAPACITY:12000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=4 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for MARKOV Exp 5: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 5: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:12000, QubitAlloc=ThompsonSampling, SC:18000 (Scale=1.5 x Cap=12000), Seed: 14153\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.3579527263647335], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 5: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 GNEURALUCB          : Reward=2220.32, Efficiency=056.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=18000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 5: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=1958.34, Efficiency=050.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=18000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 5: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=2187.99, Efficiency=055.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=18000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 5: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=2474.06, Efficiency=063.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=18000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 5: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:12000, QubitAlloc=ThompsonSampling, SC:18000 (Scale=1.5 x Cap=12000), Seed: 14153\n",
      "\t-->üèÜ EXP5 Winner:iCPursuitNeuralUCB  (Gap:036.7%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:12000, SCapacity=18000, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 5 completed successfully.\n",
      "Total experiment time: 914.6s\n",
      "Experiments completed for markov\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: ADAPTIVE ADVERSARIAL ATTACK\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: ADAPTIVE\n",
      "Category: Adaptive (Reactive Strategic)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 4000 frames  <>  SCALED-CAPACITY: 6000.0 frames (CAPACITY:4000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=0 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 1: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 1: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:4000, QubitAlloc=ThompsonSampling, SC:6000 (Scale=1.5 x Cap=4000), Seed: 12509\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.38860510852297203], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 1: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 GNEURALUCB          : Reward=1058.16, Efficiency=069.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 1: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=1017.20, Efficiency=066.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 1: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=1068.45, Efficiency=070.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 1: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=1041.23, Efficiency=068.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=6000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 1: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:4000, QubitAlloc=ThompsonSampling, SC:6000 (Scale=1.5 x Cap=4000), Seed: 12509\n",
      "\t-->üèÜ EXP1 Winner:CPursuitNeuralUCB   (Gap:029.7%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:4000, SCapacity=6000, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 1 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 6000 frames  <>  SCALED-CAPACITY: 9000.0 frames (CAPACITY:6000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=1 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 2: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 2: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:6000, QubitAlloc=ThompsonSampling, SC:9000 (Scale=1.5 x Cap=6000), Seed: 21611\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.38722107258255484], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 2: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 GNEURALUCB          : Reward=1618.60, Efficiency=070.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=9000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 2: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=1546.63, Efficiency=067.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=9000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 2: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=1603.83, Efficiency=069.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=9000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 2: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=1604.04, Efficiency=069.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=9000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 2: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:6000, QubitAlloc=ThompsonSampling, SC:9000 (Scale=1.5 x Cap=6000), Seed: 21611\n",
      "\t-->üèÜ EXP2 Winner:GNeuralUCB          (Gap:029.6%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:6000, SCapacity=9000, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 2 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 8000 frames  <>  SCALED-CAPACITY: 12000.0 frames (CAPACITY:8000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=2 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 3: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 3: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:8000, QubitAlloc=ThompsonSampling, SC:12000 (Scale=1.5 x Cap=8000), Seed: 19675\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.38229009396593533], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 3: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 GNEURALUCB          : Reward=2124.58, Efficiency=070.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 3: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=2152.00, Efficiency=071.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 3: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=2137.37, Efficiency=070.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 3: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=2126.83, Efficiency=070.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=12000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 3: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:8000, QubitAlloc=ThompsonSampling, SC:12000 (Scale=1.5 x Cap=8000), Seed: 19675\n",
      "\t-->üèÜ EXP3 Winner:EXPNeuralUCB        (Gap:028.9%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:8000, SCapacity=12000, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 3 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 10000 frames  <>  SCALED-CAPACITY: 15000.0 frames (CAPACITY:10000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=3 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 4: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 4: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:10000, QubitAlloc=ThompsonSampling, SC:15000 (Scale=1.5 x Cap=10000), Seed: 20231\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.4202961453677382], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 4: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 GNEURALUCB          : Reward=2830.21, Efficiency=068.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=15000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 4: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=2916.66, Efficiency=070.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=15000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 4: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=2828.79, Efficiency=068.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=15000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 4: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=2807.28, Efficiency=068.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=15000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 4: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:10000, QubitAlloc=ThompsonSampling, SC:15000 (Scale=1.5 x Cap=10000), Seed: 20231\n",
      "\t-->üèÜ EXP4 Winner:EXPNeuralUCB        (Gap:029.2%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:10000, SCapacity=15000, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 4 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 12000 frames  <>  SCALED-CAPACITY: 18000.0 frames (CAPACITY:12000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=4 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 5: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 5: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:12000, QubitAlloc=ThompsonSampling, SC:18000 (Scale=1.5 x Cap=12000), Seed: 15657\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.4202961453677382], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 5: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 GNEURALUCB          : Reward=3329.19, Efficiency=070.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=18000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 5: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=3291.62, Efficiency=069.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=18000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 5: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=3429.29, Efficiency=072.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=18000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 5: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=3394.31, Efficiency=071.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=18000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 5: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:12000, QubitAlloc=ThompsonSampling, SC:18000 (Scale=1.5 x Cap=12000), Seed: 15657\n",
      "\t-->üèÜ EXP5 Winner:CPursuitNeuralUCB   (Gap:027.9%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:12000, SCapacity=18000, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 5 completed successfully.\n",
      "Total experiment time: 1112.0s\n",
      "Experiments completed for adaptive\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: ONLINE ADAPTIVE ATTACK\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: ONLINEADAPTIVE\n",
      "Category: Online Adaptive (Real-time Strategic)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 4000 frames  <>  SCALED-CAPACITY: 6000.0 frames (CAPACITY:4000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=0 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 1: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:4000, QubitAlloc=ThompsonSampling, SC:6000 (Scale=1.5 x Cap=4000), Seed: 16665\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.38722107258255484], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 GNEURALUCB          : Reward=1027.32, Efficiency=067.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=1023.88, Efficiency=067.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=1012.04, Efficiency=066.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=1023.05, Efficiency=067.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=6000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:4000, QubitAlloc=ThompsonSampling, SC:6000 (Scale=1.5 x Cap=4000), Seed: 16665\n",
      "\t-->üèÜ EXP1 Winner:GNeuralUCB          (Gap:032.1%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:4000, SCapacity=6000, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 1 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 6000 frames  <>  SCALED-CAPACITY: 9000.0 frames (CAPACITY:6000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=1 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 2: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:6000, QubitAlloc=ThompsonSampling, SC:9000 (Scale=1.5 x Cap=6000), Seed: 21573\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.4012351376370454], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 GNEURALUCB          : Reward=1616.29, Efficiency=068.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=9000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=1547.04, Efficiency=065.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=9000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=1618.93, Efficiency=068.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=9000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=1648.16, Efficiency=069.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=9000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:6000, QubitAlloc=ThompsonSampling, SC:9000 (Scale=1.5 x Cap=6000), Seed: 21573\n",
      "\t-->üèÜ EXP2 Winner:iCPursuitNeuralUCB  (Gap:030.6%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:6000, SCapacity=9000, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 2 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 8000 frames  <>  SCALED-CAPACITY: 12000.0 frames (CAPACITY:8000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=2 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 3: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:8000, QubitAlloc=ThompsonSampling, SC:12000 (Scale=1.5 x Cap=8000), Seed: 14973\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.4202961453677382], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 GNEURALUCB          : Reward=2294.40, Efficiency=069.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=2152.46, Efficiency=064.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=2279.63, Efficiency=068.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=2241.88, Efficiency=067.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=12000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:8000, QubitAlloc=ThompsonSampling, SC:12000 (Scale=1.5 x Cap=8000), Seed: 14973\n",
      "\t-->üèÜ EXP3 Winner:GNeuralUCB          (Gap:031.0%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:8000, SCapacity=12000, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 3 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 10000 frames  <>  SCALED-CAPACITY: 15000.0 frames (CAPACITY:10000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=3 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 4: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:10000, QubitAlloc=ThompsonSampling, SC:15000 (Scale=1.5 x Cap=10000), Seed: 18379\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.4202961453677382], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 GNEURALUCB          : Reward=2776.12, Efficiency=067.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=15000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=2526.34, Efficiency=061.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=15000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=2776.06, Efficiency=067.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=15000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=2760.54, Efficiency=067.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=15000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:10000, QubitAlloc=ThompsonSampling, SC:15000 (Scale=1.5 x Cap=10000), Seed: 18379\n",
      "\t-->üèÜ EXP4 Winner:GNeuralUCB          (Gap:032.1%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:10000, SCapacity=15000, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 4 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 12000 frames  <>  SCALED-CAPACITY: 18000.0 frames (CAPACITY:12000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=4 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 5: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:12000, QubitAlloc=ThompsonSampling, SC:18000 (Scale=1.5 x Cap=12000), Seed: 14049\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.3739910434684815], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 GNEURALUCB          : Reward=3250.30, Efficiency=072.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=18000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=3386.02, Efficiency=075.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=18000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=3243.36, Efficiency=072.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=18000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=3273.88, Efficiency=073.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=18000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:12000, QubitAlloc=ThompsonSampling, SC:18000 (Scale=1.5 x Cap=12000), Seed: 14049\n",
      "\t-->üèÜ EXP5 Winner:EXPNeuralUCB        (Gap:024.5%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:12000, SCapacity=18000, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 5 completed successfully.\n",
      "Total experiment time: 1075.3s\n",
      "Experiments completed for onlineadaptive\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: BASELINE (OPTIMAL CONDITIONS)\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: NONE\n",
      "Category: Baseline (No Attacks)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 4000 frames  <>  SCALED-CAPACITY: 6000.0 frames (CAPACITY:4000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=0 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for NONE Exp 1: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 1: Env:Baseline (None), Attack:No, Rate:0.0, Frames:4000, QubitAlloc=ThompsonSampling, SC:6000 (Scale=1.5 x Cap=4000), Seed: 19677\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.4004511016966282], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 1: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 GNEURALUCB          : Reward=1430.43, Efficiency=089.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 1: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=1451.54, Efficiency=090.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 1: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=1439.35, Efficiency=089.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 1: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=1443.49, Efficiency=090.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.712]\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 1: Env:Baseline (None), Attack:No, Rate:0.0, Frames:4000, QubitAlloc=ThompsonSampling, SC:6000 (Scale=1.5 x Cap=4000), Seed: 19677\n",
      "\t-->üèÜ EXP1 Winner:EXPNeuralUCB        (Gap:009.4%) [Env:Baseline (None), Attack:No X Rate:0.0, Frames:4000, SCapacity=6000, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 1 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 6000 frames  <>  SCALED-CAPACITY: 9000.0 frames (CAPACITY:6000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=1 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for NONE Exp 2: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 2: Env:Baseline (None), Attack:No, Rate:0.0, Frames:6000, QubitAlloc=ThompsonSampling, SC:9000 (Scale=1.5 x Cap=6000), Seed: 16724\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.38860510852297203], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 2: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 GNEURALUCB          : Reward=2163.45, Efficiency=092.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=9000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 2: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=2002.09, Efficiency=085.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=9000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 2: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=2158.16, Efficiency=092.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=9000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 2: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=2151.21, Efficiency=092.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=9000, Threshold=0.712]\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 2: Env:Baseline (None), Attack:No, Rate:0.0, Frames:6000, QubitAlloc=ThompsonSampling, SC:9000 (Scale=1.5 x Cap=6000), Seed: 16724\n",
      "\t-->üèÜ EXP2 Winner:GNeuralUCB          (Gap:007.2%) [Env:Baseline (None), Attack:No X Rate:0.0, Frames:6000, SCapacity=9000, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 2 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 8000 frames  <>  SCALED-CAPACITY: 12000.0 frames (CAPACITY:8000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=2 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for NONE Exp 3: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 3: Env:Baseline (None), Attack:No, Rate:0.0, Frames:8000, QubitAlloc=ThompsonSampling, SC:12000 (Scale=1.5 x Cap=8000), Seed: 16587\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.40706611625366484], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 3: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 GNEURALUCB          : Reward=3015.55, Efficiency=091.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 3: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=2698.94, Efficiency=081.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 3: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=2978.50, Efficiency=089.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 3: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=3012.68, Efficiency=090.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.712]\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 3: Env:Baseline (None), Attack:No, Rate:0.0, Frames:8000, QubitAlloc=ThompsonSampling, SC:12000 (Scale=1.5 x Cap=8000), Seed: 16587\n",
      "\t-->üèÜ EXP3 Winner:GNeuralUCB          (Gap:009.0%) [Env:Baseline (None), Attack:No X Rate:0.0, Frames:8000, SCapacity=12000, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 3 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 10000 frames  <>  SCALED-CAPACITY: 15000.0 frames (CAPACITY:10000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=3 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for NONE Exp 4: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 4: Env:Baseline (None), Attack:No, Rate:0.0, Frames:10000, QubitAlloc=ThompsonSampling, SC:15000 (Scale=1.5 x Cap=10000), Seed: 13579\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.4202961453677382], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 4: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 GNEURALUCB          : Reward=3823.88, Efficiency=091.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=15000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 4: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=4103.22, Efficiency=097.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=15000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 4: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=3814.89, Efficiency=090.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=15000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 4: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=3799.27, Efficiency=090.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=15000, Threshold=0.712]\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 4: Env:Baseline (None), Attack:No, Rate:0.0, Frames:10000, QubitAlloc=ThompsonSampling, SC:15000 (Scale=1.5 x Cap=10000), Seed: 13579\n",
      "\t-->üèÜ EXP4 Winner:EXPNeuralUCB        (Gap:002.4%) [Env:Baseline (None), Attack:No X Rate:0.0, Frames:10000, SCapacity=15000, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 4 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 12000 frames  <>  SCALED-CAPACITY: 18000.0 frames (CAPACITY:12000 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=4 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for NONE Exp 5: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 5: Env:Baseline (None), Attack:No, Rate:0.0, Frames:12000, QubitAlloc=ThompsonSampling, SC:18000 (Scale=1.5 x Cap=12000), Seed: 15608\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.3570300357377887], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 5: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 GNEURALUCB          : Reward=4459.93, Efficiency=089.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=18000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 5: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=4186.32, Efficiency=084.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=18000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 5: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=4458.33, Efficiency=089.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=18000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 5: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=4495.93, Efficiency=090.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=18000, Threshold=0.712]\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 5: Env:Baseline (None), Attack:No, Rate:0.0, Frames:12000, QubitAlloc=ThompsonSampling, SC:18000 (Scale=1.5 x Cap=12000), Seed: 15608\n",
      "\t-->üèÜ EXP5 Winner:iCPursuitNeuralUCB  (Gap:009.5%) [Env:Baseline (None), Attack:No X Rate:0.0, Frames:12000, SCapacity=18000, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 5 completed successfully.\n",
      "Total experiment time: 1213.8s\n",
      "Experiments completed for none\n",
      "‚úì Scenario 'stochastic' evaluation completed.\n",
      "‚úì Scenario 'markov' evaluation completed.\n",
      "‚úì Scenario 'adaptive' evaluation completed.\n",
      "‚úì Scenario 'onlineadaptive' evaluation completed.\n",
      "‚úì Scenario 'none' evaluation completed.\n",
      "\n",
      "======================================================================\n",
      "COMPREHENSIVE SCENARIO PERFORMANCE ANALYSIS\n",
      "======================================================================\n",
      "SCENARIO: STOCHASTIC\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: CPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 3180.83\n",
      "\t‚Ä¢ Winner Avg Gap: 0013.60%\n",
      "\t‚Ä¢ Winner Avg Reward: 2750.38\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0086.40%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 1 wins\n",
      "\t\t- EXPNeuralUCB: 2 wins\n",
      "\t\t- CPursuitNeuralUCB: 1 wins\n",
      "\t\t- iCPursuitNeuralUCB: 1 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: STOCHASTIC\n",
      "======================================================================\n",
      "SCENARIO: \tSTOCHASTIC RANDOM FAILURES\n",
      "----------------------------------------\n",
      "Recommended Model: \tCPursuitNeuralUCB (Won 1/5 experiments)\n",
      "\tWinner Avg Gap: \t013.6%\n",
      "\tWinner Avg Efficiency: \t086.4%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t086.4% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t086.3% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t086.2% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t084.8% Efficiency \t(Won 2/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: MARKOV\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 2947.96\n",
      "\t‚Ä¢ Winner Avg Gap: 0043.40%\n",
      "\t‚Ä¢ Winner Avg Reward: 1686.74\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0056.60%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 5 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: MARKOV\n",
      "======================================================================\n",
      "SCENARIO: \tMARKOV ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 5/5 experiments)\n",
      "\tWinner Avg Gap: \t043.4%\n",
      "\tWinner Avg Efficiency: \t056.6%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t056.6% Efficiency \t(Won 5/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t050.2% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t050.2% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t047.6% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: CPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 3143.66\n",
      "\t‚Ä¢ Winner Avg Gap: 0029.70%\n",
      "\t‚Ä¢ Winner Avg Reward: 2213.55\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0070.30%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 1 wins\n",
      "\t\t- EXPNeuralUCB: 2 wins\n",
      "\t\t- CPursuitNeuralUCB: 2 wins\n",
      "\t\t- iCPursuitNeuralUCB: 0 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tADAPTIVE ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tCPursuitNeuralUCB (Won 2/5 experiments)\n",
      "\tWinner Avg Gap: \t029.7%\n",
      "\tWinner Avg Efficiency: \t070.3%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t070.3% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t069.8% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t069.6% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t069.1% Efficiency \t(Won 2/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ONLINEADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: GNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 3156.63\n",
      "\t‚Ä¢ Winner Avg Gap: 0030.92%\n",
      "\t‚Ä¢ Winner Avg Reward: 2192.88\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0069.08%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 3 wins\n",
      "\t\t- EXPNeuralUCB: 1 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 1 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ONLINEADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tONLINE ADAPTIVE ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tGNeuralUCB (Won 3/5 experiments)\n",
      "\tWinner Avg Gap: \t030.9%\n",
      "\tWinner Avg Efficiency: \t069.1%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ GNeuralUCB     : \t069.1% Efficiency \t(Won 3/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t069.0% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t068.8% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t067.0% Efficiency \t(Won 1/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: NONE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 3283.79\n",
      "\t‚Ä¢ Winner Avg Gap: 0009.16%\n",
      "\t‚Ä¢ Winner Avg Reward: 2980.52\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0090.84%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 2 wins\n",
      "\t\t- EXPNeuralUCB: 2 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 1 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: NONE\n",
      "======================================================================\n",
      "SCENARIO: \tBASELINE (OPTIMAL CONDITIONS)\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 1/5 experiments)\n",
      "\tWinner Avg Gap: \t009.2%\n",
      "\tWinner Avg Efficiency: \t090.8%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t090.8% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t090.8% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t090.6% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t088.0% Efficiency \t(Won 2/5 experiments)\n",
      "======================================================================\n",
      "KEY INSIGHTS:\n",
      "Best Performing Model Analysis (CPursuitNeuralUCB):\n",
      "\t‚Ä¢ Stochastic Performance:    \t2750.385\n",
      "\t‚Ä¢ Baseline Performance:      \t2980.517\n",
      "\t‚Ä¢ Performance Retention:     \t092.3%\n",
      "\tGOOD:               \tAcceptable performance under stochastic conditions\n",
      "Statistical Analysis:\n",
      "\t‚Ä¢ Total models evaluated:     \t5\n",
      "\t‚Ä¢ Experiments per environment:\t5\n",
      "\t‚Ä¢ Quantum network simulation: \tComprehensive stochastic modeling\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "COMPREHENSIVE SCENARIO PERFORMANCE ANALYSIS\n",
      "======================================================================\n",
      "SCENARIO: STOCHASTIC\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: CPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 3180.83\n",
      "\t‚Ä¢ Winner Avg Gap: 0013.60%\n",
      "\t‚Ä¢ Winner Avg Reward: 2750.38\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0086.40%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 1 wins\n",
      "\t\t- EXPNeuralUCB: 2 wins\n",
      "\t\t- CPursuitNeuralUCB: 1 wins\n",
      "\t\t- iCPursuitNeuralUCB: 1 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: STOCHASTIC\n",
      "======================================================================\n",
      "SCENARIO: \tSTOCHASTIC RANDOM FAILURES\n",
      "----------------------------------------\n",
      "Recommended Model: \tCPursuitNeuralUCB (Won 1/5 experiments)\n",
      "\tWinner Avg Gap: \t013.6%\n",
      "\tWinner Avg Efficiency: \t086.4%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t086.4% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t086.3% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t086.2% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t084.8% Efficiency \t(Won 2/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: MARKOV\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 2947.96\n",
      "\t‚Ä¢ Winner Avg Gap: 0043.40%\n",
      "\t‚Ä¢ Winner Avg Reward: 1686.74\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0056.60%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 5 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: MARKOV\n",
      "======================================================================\n",
      "SCENARIO: \tMARKOV ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 5/5 experiments)\n",
      "\tWinner Avg Gap: \t043.4%\n",
      "\tWinner Avg Efficiency: \t056.6%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t056.6% Efficiency \t(Won 5/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t050.2% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t050.2% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t047.6% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: CPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 3143.66\n",
      "\t‚Ä¢ Winner Avg Gap: 0029.70%\n",
      "\t‚Ä¢ Winner Avg Reward: 2213.55\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0070.30%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 1 wins\n",
      "\t\t- EXPNeuralUCB: 2 wins\n",
      "\t\t- CPursuitNeuralUCB: 2 wins\n",
      "\t\t- iCPursuitNeuralUCB: 0 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tADAPTIVE ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tCPursuitNeuralUCB (Won 2/5 experiments)\n",
      "\tWinner Avg Gap: \t029.7%\n",
      "\tWinner Avg Efficiency: \t070.3%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t070.3% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t069.8% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t069.6% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t069.1% Efficiency \t(Won 2/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ONLINEADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: GNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 3156.63\n",
      "\t‚Ä¢ Winner Avg Gap: 0030.92%\n",
      "\t‚Ä¢ Winner Avg Reward: 2192.88\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0069.08%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 3 wins\n",
      "\t\t- EXPNeuralUCB: 1 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 1 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ONLINEADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tONLINE ADAPTIVE ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tGNeuralUCB (Won 3/5 experiments)\n",
      "\tWinner Avg Gap: \t030.9%\n",
      "\tWinner Avg Efficiency: \t069.1%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ GNeuralUCB     : \t069.1% Efficiency \t(Won 3/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t069.0% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t068.8% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t067.0% Efficiency \t(Won 1/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: NONE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 3283.79\n",
      "\t‚Ä¢ Winner Avg Gap: 0009.16%\n",
      "\t‚Ä¢ Winner Avg Reward: 2980.52\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0090.84%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 2 wins\n",
      "\t\t- EXPNeuralUCB: 2 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 1 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: NONE\n",
      "======================================================================\n",
      "SCENARIO: \tBASELINE (OPTIMAL CONDITIONS)\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 1/5 experiments)\n",
      "\tWinner Avg Gap: \t009.2%\n",
      "\tWinner Avg Efficiency: \t090.8%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t090.8% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t090.8% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t090.6% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t088.0% Efficiency \t(Won 2/5 experiments)\n",
      "======================================================================\n",
      "‚úÖ Evaluation completed!\n",
      "[Logging Redirect Stopped]\n",
      "\n",
      "üßπ Final cleanup for ThompsonSampling\n",
      "\n",
      "======================================================================\n",
      "‚úÖ COMPLETED: ThompsonSampling\n",
      "======================================================================\n",
      "\n",
      "ThompsonSampling COMPLETED SUCCESSFULLY\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Preparing: ThompsonSampling at scale 2\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üîß Generating physics parameters for model: paper2\n",
      "\n",
      "===================== GET LOCAL REGISTRY =====================\n",
      "‚Üí Skipping local cache (force=True or file missing)\n",
      "\n",
      "===================== BUILD LOCAL REGISTRY =====================\n",
      "\n",
      "================================================================================\n",
      "üîç SCANNING LOCAL FILES\n",
      "================================================================================\n",
      "Parameters: load_to_drive=False, force=False\n",
      "\n",
      "üìÇ Checking DRIVE mode: /content/drive/Shareddrives/ai_quantum_computing/quantum_data_lake\n",
      "   ‚ö†Ô∏è  Path does not exist, skipping\n",
      "\n",
      "üìÇ Checking LOCAL mode: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config\n",
      "   ‚úÖ Path exists, starting walk...\n",
      "   üö∂ Walking directory tree: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config\n",
      "\n",
      "   üìÅ Directory: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201\n",
      "      Relative: framework_state/day_20260201\n",
      "      Component: framework_state\n",
      "      Date: day_20260201\n",
      "      üìÑ Processing 2568 files in framework_state/day_20260201\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "      üìä framework_state/day_20260201: 2542/2568 files processed\n",
      "      üìä framework_state/day_20260201: 0/2568 files skipped\n",
      "      üìä framework_state/day_20260201: 26/2568 files conflicted\n",
      "\n",
      "   üìÅ Directory: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/model_state/day_20260201\n",
      "      Relative: model_state/day_20260201\n",
      "      Component: model_state\n",
      "      Date: day_20260201\n",
      "      üìÑ Processing 9285 files in model_state/day_20260201\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "      üìä model_state/day_20260201: 9285/9285 files processed\n",
      "      üìä model_state/day_20260201: 0/9285 files skipped\n",
      "      üìä model_state/day_20260201: 0/9285 files conflicted\n",
      "\n",
      "   üìä Processed 2 directories\n",
      "\n",
      "================================================================================\n",
      "üì¶ BUILDING FINAL REGISTRY\n",
      "================================================================================\n",
      "Components found: ['framework_state', 'model_state']\n",
      "  ‚Ä¢ framework_state: 2542 files\n",
      "  ‚Ä¢ model_state: 9285 files\n",
      "\n",
      "‚úÖ SCAN COMPLETE\n",
      "Modes scanned: 1\n",
      "Total files in registry: 11827\n",
      "================================================================================\n",
      "\n",
      "\t‚Üí Filesystem scan found 11827 files\n",
      "\n",
      "===================== GET DRIVE REGISTRY =====================\n",
      "===================== REGISTRY BUILD COMPLETE =====================\n",
      "\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "\tüì¶ LocalBackupManager Registry Saved Locally in LOCAL\n",
      "BUILDING REGISTRY WITH 0 EXPECTED COMPONENTS KEYS\n",
      "\n",
      "===================== GET LOCAL REGISTRY =====================\n",
      "‚Üí Skipping local cache (force=True or file missing)\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "\tüì¶ LocalBackupManager Registry Saved Locally in LOCAL\n",
      "\n",
      "======================================================================\n",
      "üéØ AllocatorRunner initialized: ThompsonSampling\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "üöÄ STARTING ALLOCATOR: ThompsonSampling\n",
      "======================================================================\n",
      "\n",
      "üìä Physics Model: paper2\n",
      "\n",
      "üìã Allocator Config:\n",
      "   Type: ThompsonSampling\n",
      "   Testbed: paper2\n",
      "   Paths: 8\n",
      "   Total Qubits: 35\n",
      "   Min per route: 2\n",
      "   Seed: 42\n",
      "   Priors: Œ±=1.0, Œ≤=1.0\n",
      "‚úÖ Allocator created: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "‚úì Allocator: ThompsonSamplingAllocator (8 paths)\n",
      "   Initial allocation: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "Generated paper2 topology: 15 nodes, 51 edges\n",
      "üìä Paper2 Physics: Time-based decay\n",
      "   ‚úì Using MATLAB constants: r_dephase=10000, c_light=300000000.0\n",
      "\n",
      "======================================================================\n",
      "RUN 1 | Scale: 2 | Exp: 5\n",
      "======================================================================\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "No state found for MultiRunEvaluator, disabling resume for Experiment Runners\n",
      "Multi-Run Evaluator Initialized\n",
      "Environment Type: None\n",
      "Frame Range: 4000 -> 12000 (step: 2000)\n",
      "quantum_exps-ThompsonSampling(paper2)_alloc-all_envs-5_attacks-4000_2000-5_runs-S2T\n",
      "[Logging Redirect Initialized]\n",
      "Log File: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/quantum_logs/quantum_exps-ThompsonSampling(paper2)_alloc-all_envs-5_attacks-4000_2000-5_runs-S2T_20260201_log.txt\n",
      "‚öô Running evaluation...\n",
      "======================================================================\n",
      "SCENARIOS MODEL EVALUATION\n",
      "======================================================================\n",
      "Testing algorithm performance against:\n",
      "\t‚Ä¢ Stochastic:  \tNatural quantum decoherence and network failures\n",
      "\t‚Ä¢ Baseline:    \tOptimal conditions for validation\n",
      "======================================================================\n",
      "Models to Test:             \tOracle, GNeuralUCB, EXPNeuralUCB, CPursuitNeuralUCB, iCPursuitNeuralUCB\n",
      "Experiments per Scenario:   \t5\n",
      "======================================================================\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: STOCHASTIC RANDOM FAILURES\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: STOCHASTIC\n",
      "Category: Stochastic (Natural Random Failures)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 4000 frames  <>  SCALED-CAPACITY: 8000 frames (CAPACITY:4000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=0 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 1: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 1: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:4000, QubitAlloc=ThompsonSampling, SC:8000 (Scale=2 x Cap=4000), Seed: 19730\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.38852779914991686], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 1: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 GNEURALUCB          : Reward=1385.61, Efficiency=084.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 1: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=1429.95, Efficiency=086.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 1: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=1396.64, Efficiency=084.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 1: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=1382.21, Efficiency=083.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.712]\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 1: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:4000, QubitAlloc=ThompsonSampling, SC:8000 (Scale=2 x Cap=4000), Seed: 19730\n",
      "\t-->üèÜ EXP1 Winner:EXPNeuralUCB        (Gap:013.3%) [Env:Stochastic, Attack:Random X Rate:0.0625, Frames:4000, SCapacity=8000, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 1 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 6000 frames  <>  SCALED-CAPACITY: 12000 frames (CAPACITY:6000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=1 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 2: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 2: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:6000, QubitAlloc=ThompsonSampling, SC:12000 (Scale=2 x Cap=6000), Seed: 17421\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.38852779914991686], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 2: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 GNEURALUCB          : Reward=2039.52, Efficiency=087.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 2: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=2146.60, Efficiency=092.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 2: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=2038.43, Efficiency=087.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 2: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=2032.94, Efficiency=087.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.712]\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 2: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:6000, QubitAlloc=ThompsonSampling, SC:12000 (Scale=2 x Cap=6000), Seed: 17421\n",
      "\t-->üèÜ EXP2 Winner:EXPNeuralUCB        (Gap:007.8%) [Env:Stochastic, Attack:Random X Rate:0.0625, Frames:6000, SCapacity=12000, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 2 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 8000 frames  <>  SCALED-CAPACITY: 16000 frames (CAPACITY:8000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=2 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 3: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 3: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:8000, QubitAlloc=ThompsonSampling, SC:16000 (Scale=2 x Cap=8000), Seed: 17649\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.369660064851862], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 3: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 GNEURALUCB          : Reward=2588.23, Efficiency=086.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=16000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 3: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=2421.80, Efficiency=081.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=16000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 3: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=2612.19, Efficiency=087.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=16000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 3: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=2598.71, Efficiency=087.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=16000, Threshold=0.712]\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 3: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:8000, QubitAlloc=ThompsonSampling, SC:16000 (Scale=2 x Cap=8000), Seed: 17649\n",
      "\t-->üèÜ EXP3 Winner:CPursuitNeuralUCB   (Gap:012.3%) [Env:Stochastic, Attack:Random X Rate:0.0625, Frames:8000, SCapacity=16000, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 3 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 10000 frames  <>  SCALED-CAPACITY: 20000 frames (CAPACITY:10000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=3 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 4: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 4: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:10000, QubitAlloc=ThompsonSampling, SC:20000 (Scale=2 x Cap=10000), Seed: 20670\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.4202961453677382], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 4: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 GNEURALUCB          : Reward=3605.00, Efficiency=085.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=20000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 4: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=3357.83, Efficiency=080.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=20000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 4: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=3568.78, Efficiency=085.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=20000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 4: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=3588.73, Efficiency=085.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=20000, Threshold=0.712]\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 4: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:10000, QubitAlloc=ThompsonSampling, SC:20000 (Scale=2 x Cap=10000), Seed: 20670\n",
      "\t-->üèÜ EXP4 Winner:GNeuralUCB          (Gap:014.1%) [Env:Stochastic, Attack:Random X Rate:0.0625, Frames:10000, SCapacity=20000, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 4 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 12000 frames  <>  SCALED-CAPACITY: 24000 frames (CAPACITY:12000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=4 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 5: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 5: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:12000, QubitAlloc=ThompsonSampling, SC:24000 (Scale=2 x Cap=12000), Seed: 19632\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.4012351376370454], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 5: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 GNEURALUCB          : Reward=4135.48, Efficiency=087.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=24000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 5: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=3993.42, Efficiency=084.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=24000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 5: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=4135.88, Efficiency=087.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=24000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 5: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=4141.72, Efficiency=087.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=24000, Threshold=0.712]\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 5: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:12000, QubitAlloc=ThompsonSampling, SC:24000 (Scale=2 x Cap=12000), Seed: 19632\n",
      "\t-->üèÜ EXP5 Winner:iCPursuitNeuralUCB  (Gap:012.8%) [Env:Stochastic, Attack:Random X Rate:0.0625, Frames:12000, SCapacity=24000, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 5 completed successfully.\n",
      "Total experiment time: 1077.9s\n",
      "Experiments completed for stochastic\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: MARKOV ADVERSARIAL ATTACK\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: MARKOV\n",
      "Category: Structured (Markov Chain Based)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 4000 frames  <>  SCALED-CAPACITY: 8000 frames (CAPACITY:4000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=0 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for MARKOV Exp 1: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 1: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:4000, QubitAlloc=ThompsonSampling, SC:8000 (Scale=2 x Cap=4000), Seed: 15617\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.40706611625366484], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 1: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 GNEURALUCB          : Reward=0764.39, Efficiency=049.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=8000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 1: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=0727.57, Efficiency=046.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=8000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 1: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=0753.74, Efficiency=048.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=8000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 1: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=0850.50, Efficiency=054.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=8000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 1: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:4000, QubitAlloc=ThompsonSampling, SC:8000 (Scale=2 x Cap=4000), Seed: 15617\n",
      "\t-->üèÜ EXP1 Winner:iCPursuitNeuralUCB  (Gap:045.4%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:4000, SCapacity=8000, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 1 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 6000 frames  <>  SCALED-CAPACITY: 12000 frames (CAPACITY:6000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=1 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for MARKOV Exp 2: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 2: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:6000, QubitAlloc=ThompsonSampling, SC:12000 (Scale=2 x Cap=6000), Seed: 15214\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.40706611625366484], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 2: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 GNEURALUCB          : Reward=1120.32, Efficiency=048.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=12000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 2: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=1053.67, Efficiency=046.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=12000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 2: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=1119.56, Efficiency=048.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=12000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 2: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=1258.38, Efficiency=055.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=12000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 2: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:6000, QubitAlloc=ThompsonSampling, SC:12000 (Scale=2 x Cap=6000), Seed: 15214\n",
      "\t-->üèÜ EXP2 Winner:iCPursuitNeuralUCB  (Gap:045.0%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:6000, SCapacity=12000, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 2 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 8000 frames  <>  SCALED-CAPACITY: 16000 frames (CAPACITY:8000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=2 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for MARKOV Exp 3: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 3: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:8000, QubitAlloc=ThompsonSampling, SC:16000 (Scale=2 x Cap=8000), Seed: 15164\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.4202961453677382], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 3: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 GNEURALUCB          : Reward=1471.96, Efficiency=046.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=16000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 3: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=1425.56, Efficiency=045.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=16000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 3: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=1538.67, Efficiency=048.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=16000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 3: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=1713.52, Efficiency=054.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=16000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 3: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:8000, QubitAlloc=ThompsonSampling, SC:16000 (Scale=2 x Cap=8000), Seed: 15164\n",
      "\t-->üèÜ EXP3 Winner:iCPursuitNeuralUCB  (Gap:045.6%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:8000, SCapacity=16000, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 3 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 10000 frames  <>  SCALED-CAPACITY: 20000 frames (CAPACITY:10000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=3 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for MARKOV Exp 4: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 4: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:10000, QubitAlloc=ThompsonSampling, SC:20000 (Scale=2 x Cap=10000), Seed: 14599\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.38852779914991686], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 4: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 GNEURALUCB          : Reward=1887.44, Efficiency=049.2% [Retries=3, Failed=0, < Threshold=3, SCapacity=20000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 4: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=1920.04, Efficiency=050.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=20000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 4: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=1879.95, Efficiency=049.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=20000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 4: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=2137.25, Efficiency=055.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=20000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 4: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:10000, QubitAlloc=ThompsonSampling, SC:20000 (Scale=2 x Cap=10000), Seed: 14599\n",
      "\t-->üèÜ EXP4 Winner:iCPursuitNeuralUCB  (Gap:044.2%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:10000, SCapacity=20000, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 4 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 12000 frames  <>  SCALED-CAPACITY: 24000 frames (CAPACITY:12000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=4 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for MARKOV Exp 5: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 5: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:12000, QubitAlloc=ThompsonSampling, SC:24000 (Scale=2 x Cap=12000), Seed: 14153\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.3579527263647335], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 5: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 GNEURALUCB          : Reward=2220.32, Efficiency=056.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=24000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 5: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=1958.34, Efficiency=050.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=24000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 5: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=2187.99, Efficiency=055.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=24000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 5: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=2474.06, Efficiency=063.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=24000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 5: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:12000, QubitAlloc=ThompsonSampling, SC:24000 (Scale=2 x Cap=12000), Seed: 14153\n",
      "\t-->üèÜ EXP5 Winner:iCPursuitNeuralUCB  (Gap:036.7%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:12000, SCapacity=24000, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 5 completed successfully.\n",
      "Total experiment time: 782.1s\n",
      "Experiments completed for markov\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: ADAPTIVE ADVERSARIAL ATTACK\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: ADAPTIVE\n",
      "Category: Adaptive (Reactive Strategic)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 4000 frames  <>  SCALED-CAPACITY: 8000 frames (CAPACITY:4000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=0 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 1: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 1: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:4000, QubitAlloc=ThompsonSampling, SC:8000 (Scale=2 x Cap=4000), Seed: 12509\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.38860510852297203], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 1: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 GNEURALUCB          : Reward=1058.16, Efficiency=069.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 1: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=1017.20, Efficiency=066.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 1: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=1068.45, Efficiency=070.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 1: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=1041.23, Efficiency=068.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=8000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 1: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:4000, QubitAlloc=ThompsonSampling, SC:8000 (Scale=2 x Cap=4000), Seed: 12509\n",
      "\t-->üèÜ EXP1 Winner:CPursuitNeuralUCB   (Gap:029.7%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:4000, SCapacity=8000, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 1 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 6000 frames  <>  SCALED-CAPACITY: 12000 frames (CAPACITY:6000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=1 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 2: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 2: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:6000, QubitAlloc=ThompsonSampling, SC:12000 (Scale=2 x Cap=6000), Seed: 21611\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.38722107258255484], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 2: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 GNEURALUCB          : Reward=1618.60, Efficiency=070.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 2: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=1546.63, Efficiency=067.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 2: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=1603.83, Efficiency=069.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 2: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=1604.04, Efficiency=069.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=12000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 2: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:6000, QubitAlloc=ThompsonSampling, SC:12000 (Scale=2 x Cap=6000), Seed: 21611\n",
      "\t-->üèÜ EXP2 Winner:GNeuralUCB          (Gap:029.6%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:6000, SCapacity=12000, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 2 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 8000 frames  <>  SCALED-CAPACITY: 16000 frames (CAPACITY:8000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=2 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 3: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 3: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:8000, QubitAlloc=ThompsonSampling, SC:16000 (Scale=2 x Cap=8000), Seed: 19675\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.38229009396593533], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 3: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 GNEURALUCB          : Reward=2124.58, Efficiency=070.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=16000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 3: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=2152.00, Efficiency=071.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=16000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 3: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=2137.37, Efficiency=070.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=16000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 3: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=2126.83, Efficiency=070.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=16000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 3: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:8000, QubitAlloc=ThompsonSampling, SC:16000 (Scale=2 x Cap=8000), Seed: 19675\n",
      "\t-->üèÜ EXP3 Winner:EXPNeuralUCB        (Gap:028.9%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:8000, SCapacity=16000, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 3 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 10000 frames  <>  SCALED-CAPACITY: 20000 frames (CAPACITY:10000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=3 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 4: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 4: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:10000, QubitAlloc=ThompsonSampling, SC:20000 (Scale=2 x Cap=10000), Seed: 20231\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.4202961453677382], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 4: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 GNEURALUCB          : Reward=2830.21, Efficiency=068.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=20000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 4: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=2916.66, Efficiency=070.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=20000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 4: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=2828.79, Efficiency=068.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=20000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 4: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=2807.28, Efficiency=068.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=20000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 4: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:10000, QubitAlloc=ThompsonSampling, SC:20000 (Scale=2 x Cap=10000), Seed: 20231\n",
      "\t-->üèÜ EXP4 Winner:EXPNeuralUCB        (Gap:029.2%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:10000, SCapacity=20000, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 4 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 12000 frames  <>  SCALED-CAPACITY: 24000 frames (CAPACITY:12000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=4 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 5: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 5: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:12000, QubitAlloc=ThompsonSampling, SC:24000 (Scale=2 x Cap=12000), Seed: 15657\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.4202961453677382], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 5: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 GNEURALUCB          : Reward=3329.19, Efficiency=070.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=24000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 5: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=3291.62, Efficiency=069.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=24000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 5: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=3429.29, Efficiency=072.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=24000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 5: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=3394.31, Efficiency=071.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=24000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 5: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:12000, QubitAlloc=ThompsonSampling, SC:24000 (Scale=2 x Cap=12000), Seed: 15657\n",
      "\t-->üèÜ EXP5 Winner:CPursuitNeuralUCB   (Gap:027.9%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:12000, SCapacity=24000, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 5 completed successfully.\n",
      "Total experiment time: 893.1s\n",
      "Experiments completed for adaptive\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: ONLINE ADAPTIVE ATTACK\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: ONLINEADAPTIVE\n",
      "Category: Online Adaptive (Real-time Strategic)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 4000 frames  <>  SCALED-CAPACITY: 8000 frames (CAPACITY:4000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=0 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 1: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:4000, QubitAlloc=ThompsonSampling, SC:8000 (Scale=2 x Cap=4000), Seed: 16665\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.38722107258255484], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 GNEURALUCB          : Reward=1027.32, Efficiency=067.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=1023.88, Efficiency=067.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=1012.04, Efficiency=066.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=1023.05, Efficiency=067.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=8000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:4000, QubitAlloc=ThompsonSampling, SC:8000 (Scale=2 x Cap=4000), Seed: 16665\n",
      "\t-->üèÜ EXP1 Winner:GNeuralUCB          (Gap:032.1%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:4000, SCapacity=8000, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 1 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 6000 frames  <>  SCALED-CAPACITY: 12000 frames (CAPACITY:6000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=1 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 2: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:6000, QubitAlloc=ThompsonSampling, SC:12000 (Scale=2 x Cap=6000), Seed: 21573\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.4012351376370454], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 GNEURALUCB          : Reward=1616.29, Efficiency=068.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=1547.04, Efficiency=065.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=1618.93, Efficiency=068.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=1648.16, Efficiency=069.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=12000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:6000, QubitAlloc=ThompsonSampling, SC:12000 (Scale=2 x Cap=6000), Seed: 21573\n",
      "\t-->üèÜ EXP2 Winner:iCPursuitNeuralUCB  (Gap:030.6%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:6000, SCapacity=12000, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 2 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 8000 frames  <>  SCALED-CAPACITY: 16000 frames (CAPACITY:8000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=2 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 3: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:8000, QubitAlloc=ThompsonSampling, SC:16000 (Scale=2 x Cap=8000), Seed: 14973\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.4202961453677382], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 GNEURALUCB          : Reward=2294.40, Efficiency=069.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=16000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=2152.46, Efficiency=064.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=16000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=2279.63, Efficiency=068.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=16000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=2241.88, Efficiency=067.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=16000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:8000, QubitAlloc=ThompsonSampling, SC:16000 (Scale=2 x Cap=8000), Seed: 14973\n",
      "\t-->üèÜ EXP3 Winner:GNeuralUCB          (Gap:031.0%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:8000, SCapacity=16000, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 3 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 10000 frames  <>  SCALED-CAPACITY: 20000 frames (CAPACITY:10000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=3 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 4: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:10000, QubitAlloc=ThompsonSampling, SC:20000 (Scale=2 x Cap=10000), Seed: 18379\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.4202961453677382], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 GNEURALUCB          : Reward=2776.12, Efficiency=067.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=20000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=2526.34, Efficiency=061.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=20000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=2776.06, Efficiency=067.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=20000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=2760.54, Efficiency=067.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=20000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:10000, QubitAlloc=ThompsonSampling, SC:20000 (Scale=2 x Cap=10000), Seed: 18379\n",
      "\t-->üèÜ EXP4 Winner:GNeuralUCB          (Gap:032.1%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:10000, SCapacity=20000, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 4 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 12000 frames  <>  SCALED-CAPACITY: 24000 frames (CAPACITY:12000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=4 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 5: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:12000, QubitAlloc=ThompsonSampling, SC:24000 (Scale=2 x Cap=12000), Seed: 14049\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.3739910434684815], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 GNEURALUCB          : Reward=3250.30, Efficiency=072.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=24000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=3386.02, Efficiency=075.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=24000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=3243.36, Efficiency=072.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=24000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=3273.88, Efficiency=073.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=24000, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:12000, QubitAlloc=ThompsonSampling, SC:24000 (Scale=2 x Cap=12000), Seed: 14049\n",
      "\t-->üèÜ EXP5 Winner:EXPNeuralUCB        (Gap:024.5%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:12000, SCapacity=24000, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 5 completed successfully.\n",
      "Total experiment time: 959.3s\n",
      "Experiments completed for onlineadaptive\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: BASELINE (OPTIMAL CONDITIONS)\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: NONE\n",
      "Category: Baseline (No Attacks)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 4000 frames  <>  SCALED-CAPACITY: 8000 frames (CAPACITY:4000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=0 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for NONE Exp 1: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 1: Env:Baseline (None), Attack:No, Rate:0.0, Frames:4000, QubitAlloc=ThompsonSampling, SC:8000 (Scale=2 x Cap=4000), Seed: 19677\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.4004511016966282], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 1: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 GNEURALUCB          : Reward=1430.43, Efficiency=089.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 1: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=1451.54, Efficiency=090.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 1: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=1439.35, Efficiency=089.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 1: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=1443.49, Efficiency=090.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.712]\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 1: Env:Baseline (None), Attack:No, Rate:0.0, Frames:4000, QubitAlloc=ThompsonSampling, SC:8000 (Scale=2 x Cap=4000), Seed: 19677\n",
      "\t-->üèÜ EXP1 Winner:EXPNeuralUCB        (Gap:009.4%) [Env:Baseline (None), Attack:No X Rate:0.0, Frames:4000, SCapacity=8000, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 1 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 6000 frames  <>  SCALED-CAPACITY: 12000 frames (CAPACITY:6000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=1 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for NONE Exp 2: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 2: Env:Baseline (None), Attack:No, Rate:0.0, Frames:6000, QubitAlloc=ThompsonSampling, SC:12000 (Scale=2 x Cap=6000), Seed: 16724\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.38860510852297203], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 2: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 GNEURALUCB          : Reward=2163.45, Efficiency=092.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 2: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=2002.09, Efficiency=085.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 2: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=2158.16, Efficiency=092.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 2: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=2151.21, Efficiency=092.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=12000, Threshold=0.712]\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 2: Env:Baseline (None), Attack:No, Rate:0.0, Frames:6000, QubitAlloc=ThompsonSampling, SC:12000 (Scale=2 x Cap=6000), Seed: 16724\n",
      "\t-->üèÜ EXP2 Winner:GNeuralUCB          (Gap:007.2%) [Env:Baseline (None), Attack:No X Rate:0.0, Frames:6000, SCapacity=12000, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 2 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 8000 frames  <>  SCALED-CAPACITY: 16000 frames (CAPACITY:8000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=2 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for NONE Exp 3: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 3: Env:Baseline (None), Attack:No, Rate:0.0, Frames:8000, QubitAlloc=ThompsonSampling, SC:16000 (Scale=2 x Cap=8000), Seed: 16587\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.40706611625366484], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 3: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 GNEURALUCB          : Reward=3015.55, Efficiency=091.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=16000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 3: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=2698.94, Efficiency=081.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=16000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 3: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=2978.50, Efficiency=089.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=16000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 3: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=3012.68, Efficiency=090.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=16000, Threshold=0.712]\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 3: Env:Baseline (None), Attack:No, Rate:0.0, Frames:8000, QubitAlloc=ThompsonSampling, SC:16000 (Scale=2 x Cap=8000), Seed: 16587\n",
      "\t-->üèÜ EXP3 Winner:GNeuralUCB          (Gap:009.0%) [Env:Baseline (None), Attack:No X Rate:0.0, Frames:8000, SCapacity=16000, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 3 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 10000 frames  <>  SCALED-CAPACITY: 20000 frames (CAPACITY:10000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=3 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for NONE Exp 4: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 4: Env:Baseline (None), Attack:No, Rate:0.0, Frames:10000, QubitAlloc=ThompsonSampling, SC:20000 (Scale=2 x Cap=10000), Seed: 13579\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.4202961453677382], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 4: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 GNEURALUCB          : Reward=3823.88, Efficiency=091.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=20000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 4: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=4103.22, Efficiency=097.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=20000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 4: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=3814.89, Efficiency=090.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=20000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 4: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=3799.27, Efficiency=090.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=20000, Threshold=0.712]\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 4: Env:Baseline (None), Attack:No, Rate:0.0, Frames:10000, QubitAlloc=ThompsonSampling, SC:20000 (Scale=2 x Cap=10000), Seed: 13579\n",
      "\t-->üèÜ EXP4 Winner:EXPNeuralUCB        (Gap:002.4%) [Env:Baseline (None), Attack:No X Rate:0.0, Frames:10000, SCapacity=20000, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 4 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 12000 frames  <>  SCALED-CAPACITY: 24000 frames (CAPACITY:12000 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=4 (uniform init) ‚Üí allocation=(5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîß Allocated qubits for NONE Exp 5: (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 4, 4, 4, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 5: Env:Baseline (None), Attack:No, Rate:0.0, Frames:12000, QubitAlloc=ThompsonSampling, SC:24000 (Scale=2 x Cap=12000), Seed: 15608\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.3570300357377887], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 5: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 GNEURALUCB          : Reward=4459.93, Efficiency=089.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=24000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 5: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=4186.32, Efficiency=084.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=24000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 5: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=4458.33, Efficiency=089.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=24000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 5: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=4495.93, Efficiency=090.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=24000, Threshold=0.712]\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 5: Env:Baseline (None), Attack:No, Rate:0.0, Frames:12000, QubitAlloc=ThompsonSampling, SC:24000 (Scale=2 x Cap=12000), Seed: 15608\n",
      "\t-->üèÜ EXP5 Winner:iCPursuitNeuralUCB  (Gap:009.5%) [Env:Baseline (None), Attack:No X Rate:0.0, Frames:12000, SCapacity=24000, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 5 completed successfully.\n",
      "Total experiment time: 1005.5s\n",
      "Experiments completed for none\n",
      "‚úì Scenario 'stochastic' evaluation completed.\n",
      "‚úì Scenario 'markov' evaluation completed.\n",
      "‚úì Scenario 'adaptive' evaluation completed.\n",
      "‚úì Scenario 'onlineadaptive' evaluation completed.\n",
      "‚úì Scenario 'none' evaluation completed.\n",
      "\n",
      "======================================================================\n",
      "COMPREHENSIVE SCENARIO PERFORMANCE ANALYSIS\n",
      "======================================================================\n",
      "SCENARIO: STOCHASTIC\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: CPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 3180.83\n",
      "\t‚Ä¢ Winner Avg Gap: 0013.60%\n",
      "\t‚Ä¢ Winner Avg Reward: 2750.38\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0086.40%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 1 wins\n",
      "\t\t- EXPNeuralUCB: 2 wins\n",
      "\t\t- CPursuitNeuralUCB: 1 wins\n",
      "\t\t- iCPursuitNeuralUCB: 1 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: STOCHASTIC\n",
      "======================================================================\n",
      "SCENARIO: \tSTOCHASTIC RANDOM FAILURES\n",
      "----------------------------------------\n",
      "Recommended Model: \tCPursuitNeuralUCB (Won 1/5 experiments)\n",
      "\tWinner Avg Gap: \t013.6%\n",
      "\tWinner Avg Efficiency: \t086.4%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t086.4% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t086.3% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t086.2% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t084.8% Efficiency \t(Won 2/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: MARKOV\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 2947.96\n",
      "\t‚Ä¢ Winner Avg Gap: 0043.40%\n",
      "\t‚Ä¢ Winner Avg Reward: 1686.74\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0056.60%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 5 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: MARKOV\n",
      "======================================================================\n",
      "SCENARIO: \tMARKOV ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 5/5 experiments)\n",
      "\tWinner Avg Gap: \t043.4%\n",
      "\tWinner Avg Efficiency: \t056.6%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t056.6% Efficiency \t(Won 5/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t050.2% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t050.2% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t047.6% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: CPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 3143.66\n",
      "\t‚Ä¢ Winner Avg Gap: 0029.70%\n",
      "\t‚Ä¢ Winner Avg Reward: 2213.55\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0070.30%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 1 wins\n",
      "\t\t- EXPNeuralUCB: 2 wins\n",
      "\t\t- CPursuitNeuralUCB: 2 wins\n",
      "\t\t- iCPursuitNeuralUCB: 0 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tADAPTIVE ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tCPursuitNeuralUCB (Won 2/5 experiments)\n",
      "\tWinner Avg Gap: \t029.7%\n",
      "\tWinner Avg Efficiency: \t070.3%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t070.3% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t069.8% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t069.6% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t069.1% Efficiency \t(Won 2/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ONLINEADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: GNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 3156.63\n",
      "\t‚Ä¢ Winner Avg Gap: 0030.92%\n",
      "\t‚Ä¢ Winner Avg Reward: 2192.88\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0069.08%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 3 wins\n",
      "\t\t- EXPNeuralUCB: 1 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 1 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ONLINEADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tONLINE ADAPTIVE ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tGNeuralUCB (Won 3/5 experiments)\n",
      "\tWinner Avg Gap: \t030.9%\n",
      "\tWinner Avg Efficiency: \t069.1%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ GNeuralUCB     : \t069.1% Efficiency \t(Won 3/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t069.0% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t068.8% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t067.0% Efficiency \t(Won 1/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: NONE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 3283.79\n",
      "\t‚Ä¢ Winner Avg Gap: 0009.16%\n",
      "\t‚Ä¢ Winner Avg Reward: 2980.52\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0090.84%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 2 wins\n",
      "\t\t- EXPNeuralUCB: 2 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 1 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: NONE\n",
      "======================================================================\n",
      "SCENARIO: \tBASELINE (OPTIMAL CONDITIONS)\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 1/5 experiments)\n",
      "\tWinner Avg Gap: \t009.2%\n",
      "\tWinner Avg Efficiency: \t090.8%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t090.8% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t090.8% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t090.6% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t088.0% Efficiency \t(Won 2/5 experiments)\n",
      "======================================================================\n",
      "KEY INSIGHTS:\n",
      "Best Performing Model Analysis (CPursuitNeuralUCB):\n",
      "\t‚Ä¢ Stochastic Performance:    \t2750.385\n",
      "\t‚Ä¢ Baseline Performance:      \t2980.517\n",
      "\t‚Ä¢ Performance Retention:     \t092.3%\n",
      "\tGOOD:               \tAcceptable performance under stochastic conditions\n",
      "Statistical Analysis:\n",
      "\t‚Ä¢ Total models evaluated:     \t5\n",
      "\t‚Ä¢ Experiments per environment:\t5\n",
      "\t‚Ä¢ Quantum network simulation: \tComprehensive stochastic modeling\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "COMPREHENSIVE SCENARIO PERFORMANCE ANALYSIS\n",
      "======================================================================\n",
      "SCENARIO: STOCHASTIC\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: CPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 3180.83\n",
      "\t‚Ä¢ Winner Avg Gap: 0013.60%\n",
      "\t‚Ä¢ Winner Avg Reward: 2750.38\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0086.40%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 1 wins\n",
      "\t\t- EXPNeuralUCB: 2 wins\n",
      "\t\t- CPursuitNeuralUCB: 1 wins\n",
      "\t\t- iCPursuitNeuralUCB: 1 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: STOCHASTIC\n",
      "======================================================================\n",
      "SCENARIO: \tSTOCHASTIC RANDOM FAILURES\n",
      "----------------------------------------\n",
      "Recommended Model: \tCPursuitNeuralUCB (Won 1/5 experiments)\n",
      "\tWinner Avg Gap: \t013.6%\n",
      "\tWinner Avg Efficiency: \t086.4%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t086.4% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t086.3% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t086.2% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t084.8% Efficiency \t(Won 2/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: MARKOV\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 2947.96\n",
      "\t‚Ä¢ Winner Avg Gap: 0043.40%\n",
      "\t‚Ä¢ Winner Avg Reward: 1686.74\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0056.60%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 5 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: MARKOV\n",
      "======================================================================\n",
      "SCENARIO: \tMARKOV ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 5/5 experiments)\n",
      "\tWinner Avg Gap: \t043.4%\n",
      "\tWinner Avg Efficiency: \t056.6%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t056.6% Efficiency \t(Won 5/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t050.2% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t050.2% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t047.6% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: CPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 3143.66\n",
      "\t‚Ä¢ Winner Avg Gap: 0029.70%\n",
      "\t‚Ä¢ Winner Avg Reward: 2213.55\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0070.30%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 1 wins\n",
      "\t\t- EXPNeuralUCB: 2 wins\n",
      "\t\t- CPursuitNeuralUCB: 2 wins\n",
      "\t\t- iCPursuitNeuralUCB: 0 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tADAPTIVE ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tCPursuitNeuralUCB (Won 2/5 experiments)\n",
      "\tWinner Avg Gap: \t029.7%\n",
      "\tWinner Avg Efficiency: \t070.3%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t070.3% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t069.8% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t069.6% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t069.1% Efficiency \t(Won 2/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ONLINEADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: GNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 3156.63\n",
      "\t‚Ä¢ Winner Avg Gap: 0030.92%\n",
      "\t‚Ä¢ Winner Avg Reward: 2192.88\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0069.08%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 3 wins\n",
      "\t\t- EXPNeuralUCB: 1 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 1 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ONLINEADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tONLINE ADAPTIVE ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tGNeuralUCB (Won 3/5 experiments)\n",
      "\tWinner Avg Gap: \t030.9%\n",
      "\tWinner Avg Efficiency: \t069.1%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ GNeuralUCB     : \t069.1% Efficiency \t(Won 3/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t069.0% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t068.8% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t067.0% Efficiency \t(Won 1/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: NONE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 3283.79\n",
      "\t‚Ä¢ Winner Avg Gap: 0009.16%\n",
      "\t‚Ä¢ Winner Avg Reward: 2980.52\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0090.84%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 2 wins\n",
      "\t\t- EXPNeuralUCB: 2 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 1 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: NONE\n",
      "======================================================================\n",
      "SCENARIO: \tBASELINE (OPTIMAL CONDITIONS)\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 1/5 experiments)\n",
      "\tWinner Avg Gap: \t009.2%\n",
      "\tWinner Avg Efficiency: \t090.8%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t090.8% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t090.8% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t090.6% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t088.0% Efficiency \t(Won 2/5 experiments)\n",
      "======================================================================\n",
      "‚úÖ Evaluation completed!\n",
      "[Logging Redirect Stopped]\n",
      "\n",
      "üßπ Final cleanup for ThompsonSampling\n",
      "\n",
      "======================================================================\n",
      "‚úÖ COMPLETED: ThompsonSampling\n",
      "======================================================================\n",
      "\n",
      "ThompsonSampling COMPLETED SUCCESSFULLY\n",
      "\n",
      "======================================================================\n",
      "RUNNING: Random on Paper 2 (Chaudhary et al. 2023 - Quantum MAB)\n",
      "======================================================================\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Preparing: Random at scale 1\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üîß Generating physics parameters for model: paper2\n",
      "\n",
      "===================== GET LOCAL REGISTRY =====================\n",
      "‚Üí Skipping local cache (force=True or file missing)\n",
      "\n",
      "===================== BUILD LOCAL REGISTRY =====================\n",
      "\n",
      "================================================================================\n",
      "üîç SCANNING LOCAL FILES\n",
      "================================================================================\n",
      "Parameters: load_to_drive=False, force=False\n",
      "\n",
      "üìÇ Checking DRIVE mode: /content/drive/Shareddrives/ai_quantum_computing/quantum_data_lake\n",
      "   ‚ö†Ô∏è  Path does not exist, skipping\n",
      "\n",
      "üìÇ Checking LOCAL mode: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config\n",
      "   ‚úÖ Path exists, starting walk...\n",
      "   üö∂ Walking directory tree: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config\n",
      "\n",
      "   üìÅ Directory: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201\n",
      "      Relative: framework_state/day_20260201\n",
      "      Component: framework_state\n",
      "      Date: day_20260201\n",
      "      üìÑ Processing 2568 files in framework_state/day_20260201\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "      üìä framework_state/day_20260201: 2542/2568 files processed\n",
      "      üìä framework_state/day_20260201: 0/2568 files skipped\n",
      "      üìä framework_state/day_20260201: 26/2568 files conflicted\n",
      "\n",
      "   üìÅ Directory: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/model_state/day_20260201\n",
      "      Relative: model_state/day_20260201\n",
      "      Component: model_state\n",
      "      Date: day_20260201\n",
      "      üìÑ Processing 9308 files in model_state/day_20260201\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "      üìä model_state/day_20260201: 9308/9308 files processed\n",
      "      üìä model_state/day_20260201: 0/9308 files skipped\n",
      "      üìä model_state/day_20260201: 0/9308 files conflicted\n",
      "\n",
      "   üìä Processed 2 directories\n",
      "\n",
      "================================================================================\n",
      "üì¶ BUILDING FINAL REGISTRY\n",
      "================================================================================\n",
      "Components found: ['framework_state', 'model_state']\n",
      "  ‚Ä¢ framework_state: 2542 files\n",
      "  ‚Ä¢ model_state: 9308 files\n",
      "\n",
      "‚úÖ SCAN COMPLETE\n",
      "Modes scanned: 1\n",
      "Total files in registry: 11850\n",
      "================================================================================\n",
      "\n",
      "\t‚Üí Filesystem scan found 11850 files\n",
      "\n",
      "===================== GET DRIVE REGISTRY =====================\n",
      "===================== REGISTRY BUILD COMPLETE =====================\n",
      "\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "\tüì¶ LocalBackupManager Registry Saved Locally in LOCAL\n",
      "BUILDING REGISTRY WITH 0 EXPECTED COMPONENTS KEYS\n",
      "\n",
      "===================== GET LOCAL REGISTRY =====================\n",
      "‚Üí Skipping local cache (force=True or file missing)\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "\tüì¶ LocalBackupManager Registry Saved Locally in LOCAL\n",
      "\n",
      "======================================================================\n",
      "üéØ AllocatorRunner initialized: Random\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "üöÄ STARTING ALLOCATOR: Random\n",
      "======================================================================\n",
      "\n",
      "üìä Physics Model: paper2\n",
      "\n",
      "üìã Allocator Config:\n",
      "   Type: Random\n",
      "   Testbed: paper2\n",
      "   Paths: 8\n",
      "   Total Qubits: 35\n",
      "   Min per route: 2\n",
      "   Seed: 42\n",
      "   Epsilon: 1.0, Decay: 1.0\n",
      "‚úÖ Allocator created: (9, 4, 4, 3, 2, 2, 7, 4)\n",
      "‚úì Allocator: RandomQubitAllocator (8 paths)\n",
      "   Initial allocation: (14, 5, 4, 2, 2, 3, 3, 2)\n",
      "Generated paper2 topology: 15 nodes, 51 edges\n",
      "üìä Paper2 Physics: Time-based decay\n",
      "   ‚úì Using MATLAB constants: r_dephase=10000, c_light=300000000.0\n",
      "\n",
      "======================================================================\n",
      "RUN 1 | Scale: 1 | Exp: 5\n",
      "======================================================================\n",
      "üîÑ Random Dynamic Allocation (Initial): (3, 9, 3, 5, 4, 5, 4, 2)\n",
      "No state found for MultiRunEvaluator, disabling resume for Experiment Runners\n",
      "Multi-Run Evaluator Initialized\n",
      "Environment Type: None\n",
      "Frame Range: 4000 -> 12000 (step: 2000)\n",
      "quantum_exps-Random(paper2)_alloc-all_envs-5_attacks-4000_2000-5_runs-S1T\n",
      "[Logging Redirect Initialized]\n",
      "Log File: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/quantum_logs/quantum_exps-Random(paper2)_alloc-all_envs-5_attacks-4000_2000-5_runs-S1T_20260201_log.txt\n",
      "‚öô Running evaluation...\n",
      "======================================================================\n",
      "SCENARIOS MODEL EVALUATION\n",
      "======================================================================\n",
      "Testing algorithm performance against:\n",
      "\t‚Ä¢ Stochastic:  \tNatural quantum decoherence and network failures\n",
      "\t‚Ä¢ Baseline:    \tOptimal conditions for validation\n",
      "======================================================================\n",
      "Models to Test:             \tOracle, GNeuralUCB, EXPNeuralUCB, CPursuitNeuralUCB, iCPursuitNeuralUCB\n",
      "Experiments per Scenario:   \t5\n",
      "======================================================================\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: STOCHASTIC RANDOM FAILURES\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: STOCHASTIC\n",
      "Category: Stochastic (Natural Random Failures)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 4000 frames  <>  SCALED-CAPACITY: 4000 frames (CAPACITY:4000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[RandomAllocator Œµ=1.000] timestep=0 mode=random ‚Üí allocation=(3, 9, 3, 5, 4, 5, 4, 2)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 1: (3, 9, 3, 5, 4, 5, 4, 2)\n",
      "üîÑ Random Dynamic Allocation (Initial): (3, 2, 5, 6, 4, 2, 4, 9)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 1: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:4000, QubitAlloc=Random, SC:4000 (Scale=1 x Cap=4000), Seed: 19730\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.38852779914991686], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 1: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 GNEURALUCB          : Reward=1385.61, Efficiency=084.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=4000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 1: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=1429.95, Efficiency=086.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=4000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 1: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=1396.64, Efficiency=084.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=4000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 1: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=1382.21, Efficiency=083.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=4000, Threshold=0.712]\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 1: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:4000, QubitAlloc=Random, SC:4000 (Scale=1 x Cap=4000), Seed: 19730\n",
      "\t-->üèÜ EXP1 Winner:EXPNeuralUCB        (Gap:013.3%) [Env:Stochastic, Attack:Random X Rate:0.0625, Frames:4000, SCapacity=4000, Alloc=Random]\n",
      "‚úì Experiment 1 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 6000 frames  <>  SCALED-CAPACITY: 6000 frames (CAPACITY:6000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[RandomAllocator Œµ=1.000] timestep=1 mode=random ‚Üí allocation=(3, 2, 5, 6, 4, 2, 4, 9)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 2: (3, 2, 5, 6, 4, 2, 4, 9)\n",
      "üîÑ Random Dynamic Allocation (Initial): (8, 4, 4, 2, 8, 2, 4, 3)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 2: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:6000, QubitAlloc=Random, SC:6000 (Scale=1 x Cap=6000), Seed: 17421\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.38852779914991686], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 2: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 GNEURALUCB          : Reward=2039.52, Efficiency=087.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 2: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=2146.60, Efficiency=092.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 2: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=2038.43, Efficiency=087.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.634]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 2: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=2032.94, Efficiency=087.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=6000, Threshold=0.712]\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 2: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:6000, QubitAlloc=Random, SC:6000 (Scale=1 x Cap=6000), Seed: 17421\n",
      "\t-->üèÜ EXP2 Winner:EXPNeuralUCB        (Gap:007.8%) [Env:Stochastic, Attack:Random X Rate:0.0625, Frames:6000, SCapacity=6000, Alloc=Random]\n",
      "‚úì Experiment 2 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 8000 frames  <>  SCALED-CAPACITY: 8000 frames (CAPACITY:8000 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[RandomAllocator Œµ=1.000] timestep=2 mode=random ‚Üí allocation=(8, 4, 4, 2, 8, 2, 4, 3)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 3: (8, 4, 4, 2, 8, 2, 4, 3)\n",
      "üîÑ Random Dynamic Allocation (Initial): (5, 7, 2, 3, 3, 3, 5, 7)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 3: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:8000, QubitAlloc=Random, SC:8000 (Scale=1 x Cap=8000), Seed: 17649\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 8\n",
      "\t   First reward: [0.369660064851862], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 3: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 GNEURALUCB          : Reward=2588.23, Efficiency=086.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.582]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 3: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=2421.80, Efficiency=081.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=8000, Threshold=0.628]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 3: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Cell 2: Allocator + ExperimentConfiguration for Paper #2\n",
    "# ============================================================\n",
    "importlib.reload(qubit_allocator)\n",
    "importlib.reload(experiment_config)\n",
    "importlib.reload(multi_run_evaluator)\n",
    "\n",
    "from daqr.core.quantum_physics              import *\n",
    "from daqr.core.qubit_allocator              import (\n",
    "                                                QubitAllocator,\n",
    "                                                RandomQubitAllocator,\n",
    "                                                DynamicQubitAllocator,\n",
    "                                                ThompsonSamplingAllocator\n",
    "                                            )\n",
    "\n",
    "from daqr.evaluation.allocator_runner       import AllocatorRunner\n",
    "from daqr.evaluation.multi_run_evaluator    import MultiRunEvaluator\n",
    "from daqr.config.experiment_config          import ExperimentConfiguration\n",
    "\n",
    "\n",
    "\n",
    "print(\"=\" * 70, \"\\nPAPER #2 QUANTUM MAB MODELS EVALUATION FRAMEWORK - STOCHASTIC FOCUS\\n\", \"=\" * 70)\n",
    "# ------------------------------------------------------------\n",
    "# 1) Allocator selection (Paper #2: start with fixed baseline)\n",
    "# ------------------------------------------------------------\n",
    "# You can swap these as needed:\n",
    "# allocator = RandomQubitAllocator(epsilon=0.5, seed=42)        # 50-50 mix\n",
    "# allocator = RandomQubitAllocator(epsilon=0.1, seed=42)        # mostly baseline\n",
    "# allocator = RandomQubitAllocator(epsilon=0.0, seed=42)        # deterministic\n",
    "# allocator = DynamicQubitAllocator(seed=42)                    # dynamic UCB\n",
    "# allocator = ThompsonSamplingAllocator(seed=42)                # Thompson\n",
    "\n",
    "allocator_type =    \"Default\"\n",
    "ALLOCATORS = [\"Default\"]\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2) Derive run parameters from FRAMEWORK_CONFIG (Cell 1)\n",
    "# ------------------------------------------------------------\n",
    "# current_frames      = FRAMEWORK_CONFIG['base_frames'] \n",
    "# frame_step          = FRAMEWORK_CONFIG['frame_step']\n",
    "# attack_intensity    = FRAMEWORK_CONFIG['intensity']\n",
    "# current_experiments = FRAMEWORK_CONFIG['exp_num']\n",
    "\n",
    "attack_intensity    = FRAMEWORK_CONFIG['intensity']\n",
    "current_frames      = 50\n",
    "frame_step          = 50\n",
    "current_experiments = 1\n",
    "last_backup         = False\n",
    "base_cap            = False\n",
    "overwrite           = False\n",
    "\n",
    "# PHYSICS_MODELS = ['paper2', 'default']  # Set to ['default', 'paper2'] to test both\n",
    "ATTACK_SCENARIOS = ['stochastic']  # Start simple, expand later\n",
    "PHYSICS_MODELS = ['paper2']\n",
    "# PHYSICS_MODELS = ['default']\n",
    "ALLOCATORS = ['Default', 'Dynamic', 'ThompsonSampling', 'Random']\n",
    "SCALES = [1, 1.5, 2]\n",
    "RUNS = [5]\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70, \"\\nüéØ QUANTUM ROUTING ALLOCATOR EVALUATION\\n\", \"=\" * 70)\n",
    "print(f\"Total Allocators to Test:   {len(ALLOCATORS)}\")\n",
    "print(f\"Physics Models:             {PHYSICS_MODELS}\")\n",
    "print(f\"Allocators:                 {ALLOCATORS}\")\n",
    "print(f\"Scales:                     {SCALES}\")\n",
    "print(f\"Runs:                       {RUNS}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Run allocator\n",
    "for allocator_type in ALLOCATORS:\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"RUNNING: {allocator_type} on Paper 2 (Chaudhary et al. 2023 - Quantum MAB)\")\n",
    "    print('='*70)\n",
    "\n",
    "    for scale in SCALES:\n",
    "        print(f\"\\n{'-'*70}\")\n",
    "        print(f\"Preparing: {allocator_type} at scale {scale}\")\n",
    "        print(f\"{'-'*70}\")\n",
    "\n",
    "        for physics_model in PHYSICS_MODELS:\n",
    "            print(f\"\\nüîß Generating physics parameters for model: {physics_model}\") \n",
    "            try:\n",
    "                # Create isolated runner instance\n",
    "                custom_config = ExperimentConfiguration(\n",
    "                    env_type=FRAMEWORK_CONFIG['main_env'],\n",
    "                    scenarios=test_scenarios,\n",
    "                    use_last_backup=last_backup,\n",
    "                    models=models,\n",
    "                    attack_intensity=attack_intensity,\n",
    "                    scale=scale,\n",
    "                    base_capacity=base_cap,\n",
    "                    overwrite=overwrite\n",
    "                )\n",
    "\n",
    "                alloc_runner = AllocatorRunner(\n",
    "                    allocator_type=allocator_type,\n",
    "                    physics_models=[physics_model],\n",
    "                    framework_config=FRAMEWORK_CONFIG,\n",
    "                    scales=[scale],\n",
    "                    runs=RUNS,\n",
    "                    models=models,\n",
    "                    test_scenarios=test_scenarios,\n",
    "                    config=custom_config\n",
    "                )\n",
    "\n",
    "                # Run with Paper 12 physics\n",
    "                alloc_runner.run(get_physics_params_func=get_physics_params)\n",
    "                print(f\"\\n{allocator_type} COMPLETED SUCCESSFULLY\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"\\n{allocator_type} FAILED: {e}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ALL ALLOCATORS COMPLETE!\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "robustness-analysis",
    "outputId": "d5bf77ec-ed26-474f-b68b-650ab683fece"
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Cell 2: Allocator + ExperimentConfiguration for Paper #2\n",
    "# ============================================================\n",
    "importlib.reload(qubit_allocator)\n",
    "importlib.reload(experiment_config)\n",
    "importlib.reload(multi_run_evaluator)\n",
    "\n",
    "from daqr.core.quantum_physics              import *\n",
    "from daqr.core.qubit_allocator              import (\n",
    "                                                QubitAllocator,\n",
    "                                                RandomQubitAllocator,\n",
    "                                                DynamicQubitAllocator,\n",
    "                                                ThompsonSamplingAllocator\n",
    "                                            )\n",
    "\n",
    "from daqr.evaluation.allocator_runner       import AllocatorRunner\n",
    "from daqr.evaluation.multi_run_evaluator    import MultiRunEvaluator\n",
    "from daqr.config.experiment_config          import ExperimentConfiguration\n",
    "\n",
    "\n",
    "\n",
    "print(\"=\" * 70, \"\\nPAPER #2 QUANTUM MAB MODELS EVALUATION FRAMEWORK - STOCHASTIC FOCUS\\n\", \"=\" * 70)\n",
    "# ------------------------------------------------------------\n",
    "# 1) Allocator selection (Paper #2: start with fixed baseline)\n",
    "# ------------------------------------------------------------\n",
    "# You can swap these as needed:\n",
    "# allocator = RandomQubitAllocator(epsilon=0.5, seed=42)        # 50-50 mix\n",
    "# allocator = RandomQubitAllocator(epsilon=0.1, seed=42)        # mostly baseline\n",
    "# allocator = RandomQubitAllocator(epsilon=0.0, seed=42)        # deterministic\n",
    "# allocator = DynamicQubitAllocator(seed=42)                    # dynamic UCB\n",
    "# allocator = ThompsonSamplingAllocator(seed=42)                # Thompson\n",
    "\n",
    "allocator_type =    \"Dynamic\"\n",
    "ALLOCATORS = [\"Dynamic\"]\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2) Derive run parameters from FRAMEWORK_CONFIG (Cell 1)\n",
    "# ------------------------------------------------------------\n",
    "# current_frames      = FRAMEWORK_CONFIG['base_frames'] \n",
    "# frame_step          = FRAMEWORK_CONFIG['frame_step']\n",
    "# attack_intensity    = FRAMEWORK_CONFIG['intensity']\n",
    "# current_experiments = FRAMEWORK_CONFIG['exp_num']\n",
    "\n",
    "attack_intensity    = FRAMEWORK_CONFIG['intensity']\n",
    "current_frames      = 50\n",
    "frame_step          = 50\n",
    "current_experiments = 1\n",
    "last_backup         = False\n",
    "base_cap            = False\n",
    "overwrite           = False\n",
    "\n",
    "# PHYSICS_MODELS = ['paper2', 'default']  # Set to ['default', 'paper2'] to test both\n",
    "ATTACK_SCENARIOS = ['stochastic']  # Start simple, expand later\n",
    "PHYSICS_MODELS = ['paper2']\n",
    "# PHYSICS_MODELS = ['default']\n",
    "ALLOCATORS = ['Default', 'Dynamic', 'ThompsonSampling', 'Random']\n",
    "SCALES = [1, 1.5, 2]\n",
    "RUNS = [5]\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70, \"\\nüéØ QUANTUM ROUTING ALLOCATOR EVALUATION\\n\", \"=\" * 70)\n",
    "print(f\"Total Allocators to Test:   {len(ALLOCATORS)}\")\n",
    "print(f\"Physics Models:             {PHYSICS_MODELS}\")\n",
    "print(f\"Allocators:                 {ALLOCATORS}\")\n",
    "print(f\"Scales:                     {SCALES}\")\n",
    "print(f\"Runs:                       {RUNS}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Run allocator\n",
    "for allocator_type in ALLOCATORS:\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"RUNNING: {allocator_type} on Paper 2 (Chaudhary et al. 2023 - Quantum MAB)\")\n",
    "    print('='*70)\n",
    "\n",
    "    for scale in SCALES:\n",
    "        print(f\"\\n{'-'*70}\")\n",
    "        print(f\"Preparing: {allocator_type} at scale {scale}\")\n",
    "        print(f\"{'-'*70}\")\n",
    "\n",
    "        for physics_model in PHYSICS_MODELS:\n",
    "            print(f\"\\nüîß Generating physics parameters for model: {physics_model}\") \n",
    "            try:\n",
    "                # Create isolated runner instance\n",
    "                custom_config = ExperimentConfiguration(\n",
    "                    env_type=FRAMEWORK_CONFIG['main_env'],\n",
    "                    scenarios=test_scenarios,\n",
    "                    use_last_backup=last_backup,\n",
    "                    models=models,\n",
    "                    attack_intensity=attack_intensity,\n",
    "                    scale=scale,\n",
    "                    base_capacity=base_cap,\n",
    "                    overwrite=overwrite\n",
    "                )\n",
    "\n",
    "                alloc_runner = AllocatorRunner(\n",
    "                    allocator_type=allocator_type,\n",
    "                    physics_models=[physics_model],\n",
    "                    framework_config=FRAMEWORK_CONFIG,\n",
    "                    scales=[scale],\n",
    "                    runs=RUNS,\n",
    "                    models=models,\n",
    "                    test_scenarios=test_scenarios,\n",
    "                    config=custom_config\n",
    "                )\n",
    "\n",
    "                # Run with Paper 12 physics\n",
    "                alloc_runner.run(get_physics_params_func=get_physics_params)\n",
    "                print(f\"\\n{allocator_type} COMPLETED SUCCESSFULLY\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"\\n{allocator_type} FAILED: {e}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ALL ALLOCATORS COMPLETE!\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Cell 2: Allocator + ExperimentConfiguration for Paper #2\n",
    "# ============================================================\n",
    "importlib.reload(qubit_allocator)\n",
    "importlib.reload(experiment_config)\n",
    "importlib.reload(multi_run_evaluator)\n",
    "\n",
    "from daqr.core.quantum_physics              import *\n",
    "from daqr.core.qubit_allocator              import (\n",
    "                                                QubitAllocator,\n",
    "                                                RandomQubitAllocator,\n",
    "                                                DynamicQubitAllocator,\n",
    "                                                ThompsonSamplingAllocator\n",
    "                                            )\n",
    "\n",
    "from daqr.evaluation.allocator_runner       import AllocatorRunner\n",
    "from daqr.evaluation.multi_run_evaluator    import MultiRunEvaluator\n",
    "from daqr.config.experiment_config          import ExperimentConfiguration\n",
    "\n",
    "\n",
    "\n",
    "print(\"=\" * 70, \"\\nPAPER #2 QUANTUM MAB MODELS EVALUATION FRAMEWORK - STOCHASTIC FOCUS\\n\", \"=\" * 70)\n",
    "# ------------------------------------------------------------\n",
    "# 1) Allocator selection (Paper #2: start with fixed baseline)\n",
    "# ------------------------------------------------------------\n",
    "# You can swap these as needed:\n",
    "# allocator = RandomQubitAllocator(epsilon=0.5, seed=42)        # 50-50 mix\n",
    "# allocator = RandomQubitAllocator(epsilon=0.1, seed=42)        # mostly baseline\n",
    "# allocator = RandomQubitAllocator(epsilon=0.0, seed=42)        # deterministic\n",
    "# allocator = DynamicQubitAllocator(seed=42)                    # dynamic UCB\n",
    "# allocator = ThompsonSamplingAllocator(seed=42)                # Thompson\n",
    "\n",
    "allocator_type =    \"ThompsonSampling\"\n",
    "ALLOCATORS = [\"ThompsonSampling\"]\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2) Derive run parameters from FRAMEWORK_CONFIG (Cell 1)\n",
    "# ------------------------------------------------------------\n",
    "# current_frames      = FRAMEWORK_CONFIG['base_frames'] \n",
    "# frame_step          = FRAMEWORK_CONFIG['frame_step']\n",
    "# attack_intensity    = FRAMEWORK_CONFIG['intensity']\n",
    "# current_experiments = FRAMEWORK_CONFIG['exp_num']\n",
    "\n",
    "attack_intensity    = FRAMEWORK_CONFIG['intensity']\n",
    "current_frames      = 50\n",
    "frame_step          = 50\n",
    "current_experiments = 1\n",
    "last_backup         = False\n",
    "base_cap            = False\n",
    "overwrite           = False\n",
    "\n",
    "# PHYSICS_MODELS = ['paper2', 'default']  # Set to ['default', 'paper2'] to test both\n",
    "ATTACK_SCENARIOS = ['stochastic']  # Start simple, expand later\n",
    "PHYSICS_MODELS = ['paper2']\n",
    "# PHYSICS_MODELS = ['default']\n",
    "ALLOCATORS = ['Default', 'Dynamic', 'ThompsonSampling', 'Random']\n",
    "SCALES = [1, 1.5, 2]\n",
    "RUNS = [5]\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70, \"\\nüéØ QUANTUM ROUTING ALLOCATOR EVALUATION\\n\", \"=\" * 70)\n",
    "print(f\"Total Allocators to Test:   {len(ALLOCATORS)}\")\n",
    "print(f\"Physics Models:             {PHYSICS_MODELS}\")\n",
    "print(f\"Allocators:                 {ALLOCATORS}\")\n",
    "print(f\"Scales:                     {SCALES}\")\n",
    "print(f\"Runs:                       {RUNS}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Run allocator\n",
    "for allocator_type in ALLOCATORS:\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"RUNNING: {allocator_type} on Paper 2 (Chaudhary et al. 2023 - Quantum MAB)\")\n",
    "    print('='*70)\n",
    "\n",
    "    for scale in SCALES:\n",
    "        print(f\"\\n{'-'*70}\")\n",
    "        print(f\"Preparing: {allocator_type} at scale {scale}\")\n",
    "        print(f\"{'-'*70}\")\n",
    "\n",
    "        for physics_model in PHYSICS_MODELS:\n",
    "            print(f\"\\nüîß Generating physics parameters for model: {physics_model}\") \n",
    "            try:\n",
    "                # Create isolated runner instance\n",
    "                custom_config = ExperimentConfiguration(\n",
    "                    env_type=FRAMEWORK_CONFIG['main_env'],\n",
    "                    scenarios=test_scenarios,\n",
    "                    use_last_backup=last_backup,\n",
    "                    models=models,\n",
    "                    attack_intensity=attack_intensity,\n",
    "                    scale=scale,\n",
    "                    base_capacity=base_cap,\n",
    "                    overwrite=overwrite\n",
    "                )\n",
    "\n",
    "                alloc_runner = AllocatorRunner(\n",
    "                    allocator_type=allocator_type,\n",
    "                    physics_models=[physics_model],\n",
    "                    framework_config=FRAMEWORK_CONFIG,\n",
    "                    scales=[scale],\n",
    "                    runs=RUNS,\n",
    "                    models=models,\n",
    "                    test_scenarios=test_scenarios,\n",
    "                    config=custom_config\n",
    "                )\n",
    "\n",
    "                # Run with Paper 12 physics\n",
    "                alloc_runner.run(get_physics_params_func=get_physics_params)\n",
    "                print(f\"\\n{allocator_type} COMPLETED SUCCESSFULLY\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"\\n{allocator_type} FAILED: {e}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ALL ALLOCATORS COMPLETE!\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Cell 2: Allocator + ExperimentConfiguration for Paper #2\n",
    "# ============================================================\n",
    "importlib.reload(qubit_allocator)\n",
    "importlib.reload(experiment_config)\n",
    "importlib.reload(multi_run_evaluator)\n",
    "\n",
    "from daqr.core.quantum_physics              import *\n",
    "from daqr.core.qubit_allocator              import (\n",
    "                                                QubitAllocator,\n",
    "                                                RandomQubitAllocator,\n",
    "                                                DynamicQubitAllocator,\n",
    "                                                ThompsonSamplingAllocator\n",
    "                                            )\n",
    "\n",
    "from daqr.evaluation.allocator_runner       import AllocatorRunner\n",
    "from daqr.evaluation.multi_run_evaluator    import MultiRunEvaluator\n",
    "from daqr.config.experiment_config          import ExperimentConfiguration\n",
    "\n",
    "\n",
    "\n",
    "print(\"=\" * 70, \"\\nPAPER #2 QUANTUM MAB MODELS EVALUATION FRAMEWORK - STOCHASTIC FOCUS\\n\", \"=\" * 70)\n",
    "# ------------------------------------------------------------\n",
    "# 1) Allocator selection (Paper #2: start with fixed baseline)\n",
    "# ------------------------------------------------------------\n",
    "# You can swap these as needed:\n",
    "# allocator = RandomQubitAllocator(epsilon=0.5, seed=42)        # 50-50 mix\n",
    "# allocator = RandomQubitAllocator(epsilon=0.1, seed=42)        # mostly baseline\n",
    "# allocator = RandomQubitAllocator(epsilon=0.0, seed=42)        # deterministic\n",
    "# allocator = DynamicQubitAllocator(seed=42)                    # dynamic UCB\n",
    "# allocator = ThompsonSamplingAllocator(seed=42)                # Thompson\n",
    "\n",
    "allocator_type =    \"Random\"\n",
    "ALLOCATORS = [\"Random\"]\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2) Derive run parameters from FRAMEWORK_CONFIG (Cell 1)\n",
    "# ------------------------------------------------------------\n",
    "# current_frames      = FRAMEWORK_CONFIG['base_frames'] \n",
    "# frame_step          = FRAMEWORK_CONFIG['frame_step']\n",
    "# attack_intensity    = FRAMEWORK_CONFIG['intensity']\n",
    "# current_experiments = FRAMEWORK_CONFIG['exp_num']\n",
    "\n",
    "attack_intensity    = FRAMEWORK_CONFIG['intensity']\n",
    "current_frames      = 50\n",
    "frame_step          = 50\n",
    "current_experiments = 1\n",
    "last_backup         = False\n",
    "base_cap            = False\n",
    "overwrite           = False\n",
    "\n",
    "# PHYSICS_MODELS = ['paper2', 'default']  # Set to ['default', 'paper2'] to test both\n",
    "ATTACK_SCENARIOS = ['stochastic']  # Start simple, expand later\n",
    "PHYSICS_MODELS = ['paper2']\n",
    "# PHYSICS_MODELS = ['default']\n",
    "ALLOCATORS = ['Default', 'Dynamic', 'ThompsonSampling', 'Random']\n",
    "SCALES = [1, 1.5, 2]\n",
    "RUNS = [5]\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70, \"\\nüéØ QUANTUM ROUTING ALLOCATOR EVALUATION\\n\", \"=\" * 70)\n",
    "print(f\"Total Allocators to Test:   {len(ALLOCATORS)}\")\n",
    "print(f\"Physics Models:             {PHYSICS_MODELS}\")\n",
    "print(f\"Allocators:                 {ALLOCATORS}\")\n",
    "print(f\"Scales:                     {SCALES}\")\n",
    "print(f\"Runs:                       {RUNS}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Run allocator\n",
    "for allocator_type in ALLOCATORS:\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"RUNNING: {allocator_type} on Paper 2 (Chaudhary et al. 2023 - Quantum MAB)\")\n",
    "    print('='*70)\n",
    "\n",
    "    for scale in SCALES:\n",
    "        print(f\"\\n{'-'*70}\")\n",
    "        print(f\"Preparing: {allocator_type} at scale {scale}\")\n",
    "        print(f\"{'-'*70}\")\n",
    "\n",
    "        for physics_model in PHYSICS_MODELS:\n",
    "            print(f\"\\nüîß Generating physics parameters for model: {physics_model}\") \n",
    "            try:\n",
    "                # Create isolated runner instance\n",
    "                custom_config = ExperimentConfiguration(\n",
    "                    env_type=FRAMEWORK_CONFIG['main_env'],\n",
    "                    scenarios=test_scenarios,\n",
    "                    use_last_backup=last_backup,\n",
    "                    models=models,\n",
    "                    attack_intensity=attack_intensity,\n",
    "                    scale=scale,\n",
    "                    base_capacity=base_cap,\n",
    "                    overwrite=overwrite\n",
    "                )\n",
    "\n",
    "                alloc_runner = AllocatorRunner(\n",
    "                    allocator_type=allocator_type,\n",
    "                    physics_models=[physics_model],\n",
    "                    framework_config=FRAMEWORK_CONFIG,\n",
    "                    scales=[scale],\n",
    "                    runs=RUNS,\n",
    "                    models=models,\n",
    "                    test_scenarios=test_scenarios,\n",
    "                    config=custom_config\n",
    "                )\n",
    "\n",
    "                # Run with Paper 12 physics\n",
    "                alloc_runner.run(get_physics_params_func=get_physics_params)\n",
    "                print(f\"\\n{allocator_type} COMPLETED SUCCESSFULLY\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"\\n{allocator_type} FAILED: {e}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ALL ALLOCATORS COMPLETE!\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "comprehensive-evaluation"
   },
   "source": [
    "## Multi-Environment Performance Analysis\n",
    "\n",
    "### Complete Evaluation Matrix\n",
    "\n",
    "This research extends beyond the primary stochastic-adversarial comparison to provide comprehensive algorithm assessment across the complete spectrum of operational environments, establishing a thorough empirical foundation for robustness evaluation.\n",
    "\n",
    "### Environmental Test Framework\n",
    "\n",
    "| Environment | Classification | Threat Characteristics | Analytical Purpose |\n",
    "|-------------|---------------|----------------------|-------------------|\n",
    "| `none` | Baseline | Deterministic optimal conditions | Theoretical performance ceiling |\n",
    "| `stochastic` | Probabilistic | Uniform random failures | Standard operational baseline |\n",
    "| `markov` | Adversarial | Memory-dependent strategic attacks | Oblivious adversarial model |\n",
    "| `adaptive` | Adversarial | Feedback-driven strategic attacks | Responsive adversarial model |\n",
    "| `onlineadaptive` | Adversarial | Real-time adaptive strategic attacks | Sophisticated adversarial model |\n",
    "\n",
    "### Research Contributions\n",
    "\n",
    "**Comprehensive Threat Model Coverage**\n",
    "The evaluation framework addresses the complete spectrum of operational conditions, from optimal deterministic environments through increasingly sophisticated adversarial scenarios, providing unprecedented coverage of realistic deployment conditions.\n",
    "\n",
    "**Graduated Adversarial Complexity Analysis**  \n",
    "The systematic progression from oblivious to sophisticated adversarial models enables precise quantification of algorithm performance degradation as threat sophistication increases, revealing critical robustness thresholds.\n",
    "\n",
    "**Cross-Environment Validation Protocol**\n",
    "Consistent algorithm ranking across multiple environments validates robustness claims and identifies algorithms with stable performance characteristics independent of operational conditions.\n",
    "\n",
    "**Empirical Robustness Quantification**\n",
    "The multi-environment approach enables precise measurement of performance degradation rates, establishing quantitative robustness metrics that support theoretical predictions and practical deployment decisions.\n",
    "\n",
    "### Methodological Significance\n",
    "\n",
    "This comprehensive evaluation protocol addresses limitations in existing literature where algorithm assessment often focuses on narrow operational scenarios, providing the empirical foundation necessary for robust algorithm deployment in practical quantum network environments."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1rknAIThhNzWIoGwNHJR_N0F6hBb7T3e-",
     "timestamp": 1759053280580
    }
   ]
  },
  "kernelspec": {
   "display_name": ".quantum (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
