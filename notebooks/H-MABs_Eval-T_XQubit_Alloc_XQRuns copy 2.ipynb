{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "title-cell"
   },
   "source": [
    "# Neural Bandit Algorithm Evaluation Framework\n",
    "\n",
    "## Graduate Research Project\n",
    "**AI & Quantum Computing Laboratory**  \n",
    "**Rochester Institute of Technology**\n",
    "\n",
    "---\n",
    "\n",
    "## Research Framework Overview\n",
    "\n",
    "This comprehensive evaluation framework provides rigorous analysis of neural bandit algorithms with clear categorical distinction between different operational environments:\n",
    "\n",
    "- **Baseline Environment**: Optimal performance benchmark (Oracle)\n",
    "- **Stochastic Environment**: Natural random failures and network noise\n",
    "- **Adversarial Environment**: Strategic intelligent attacks and malicious targeting\n",
    "\n",
    "## Primary Research Questions\n",
    "\n",
    "1. **Algorithm Robustness**: How do neural bandit algorithms perform across different threat models?\n",
    "2. **Comparative Analysis**: Which algorithms demonstrate superior performance in specific scenarios?\n",
    "3. **Quantified Performance**: What are the exact degradation metrics under adversarial conditions?\n",
    "4. **Theoretical Validation**: Do experimental results align with established regret bounds?\n",
    "\n",
    "## Key Research Contributions\n",
    "\n",
    "- **Systematic Environment Categorization**: Clear baseline/stochastic/adversarial taxonomy\n",
    "- **Multi-Algorithm Comparative Testing**: Comprehensive evaluation across 6+ algorithms\n",
    "- **Quantified Robustness Metrics**: Precise performance degradation measurements\n",
    "- **Publication-Ready Analysis**: Academic-quality visualizations and statistical validation\n",
    "\n",
    "## Evaluation Methodology\n",
    "\n",
    "The framework implements standardized testing protocols across three distinct categories:\n",
    "- **Baseline**: Oracle performance establishing theoretical upper bounds\n",
    "- **Stochastic**: Random environmental perturbations modeling realistic conditions  \n",
    "- **Adversarial**: Strategic attack scenarios simulating malicious interference\n",
    "\n",
    "Each algorithm undergoes identical testing conditions enabling direct performance comparison and robustness quantification across all operational environments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "framework-overview"
   },
   "source": [
    "## Threat Model Classification Framework\n",
    "\n",
    "### Systematic Environment Taxonomy\n",
    "\n",
    "This research framework establishes precise categorical distinctions for quantum network evaluation environments, addressing previous ambiguity in threat model classification:\n",
    "\n",
    "### Environmental Categories\n",
    "\n",
    "| Environment | Implementation | Threat Characteristic | Research Application |\n",
    "|-------------|----------------|----------------------|---------------------|\n",
    "| **Baseline** | `none` | Deterministic optimal performance | Theoretical upper bound |\n",
    "| **Stochastic** | `stochastic`/`random` | Natural random failures | Realistic network conditions |\n",
    "| **Adversarial** | `markov` | Oblivious strategic attacks | Pattern-based targeting |\n",
    "| **Adversarial** | `adaptive` | Responsive strategic attacks | Feedback-driven targeting |\n",
    "| **Adversarial** | `onlineadaptive` | Real-time strategic attacks | Dynamic threat adaptation |\n",
    "\n",
    "### Research Contribution\n",
    "\n",
    "This framework addresses a critical gap in existing literature where random network failures were often conflated with intentional adversarial attacks. The systematic categorization enables:\n",
    "\n",
    "- **Precise Robustness Quantification**: Exact performance degradation measurements across threat categories\n",
    "- **Comparative Algorithm Analysis**: Direct performance comparison under identical threat conditions\n",
    "- **Theoretical Validation**: Empirical verification of regret bounds across different adversarial models\n",
    "- **Reproducible Research Standards**: Standardized evaluation protocols for quantum network algorithms\n",
    "\n",
    "### Methodological Significance\n",
    "\n",
    "Previous research often lacked clear distinction between stochastic and adversarial environments, limiting the ability to assess true algorithm robustness under intentional attacks versus natural network degradation. This framework provides the necessary precision for rigorous academic evaluation of quantum routing algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup-cell"
   },
   "source": [
    "## Environment Setup & Library Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 58,
     "status": "ok",
     "timestamp": 1758879388611,
     "user": {
      "displayName": "Piter Garcia",
      "userId": "06279433864365870614"
     },
     "user_tz": 240
    },
    "id": "theoretical-setup",
    "outputId": "a6c0fc57-a152-45e1-9da6-5113e519b8fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: notebooks\n",
      "Running locally (not in Colab)\n",
      "Now working from: notebooks\n",
      "Framework dependencies installed successfully\n",
      "Python version: 3.12.11\n",
      "PyTorch version: 2.8.0\n",
      "NumPy version: 1.26.4\n",
      "NetworkX version: 3.5\n",
      "Matplotlib version: 3.10.6\n",
      "Quantum MAB Models Evaluation Framework - Ready for Paper 7 (QBGP) testing\n",
      "\n",
      "üöø Running cleanup script at: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/cleanup_state_duplicates.py\n",
      "\n",
      "===== CLEANUP STDOUT =====\n",
      " Script dir: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework\n",
      "Project root: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework\n",
      "\n",
      "State roots:\n",
      "  ‚úÖ /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state\n",
      "  ‚úÖ /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/model_state\n",
      "  ‚ùå /content/drive/Shareddrives/ai_quantum_computing/quantum_data_lake/framework_state\n",
      "  ‚ùå /content/drive/Shareddrives/ai_quantum_computing/quantum_data_lake/model_state\n",
      "\n",
      "========== STARTING CLEANUP ==========\n",
      "\n",
      "[CLEANUP] Removing .0 float artifacts from filenames...\n",
      "[‚úì] Float artifacts fixed: 0\n",
      "\n",
      "--- Cleaning: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state ---\n",
      "[CLEAN] /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state\n",
      "[‚úì] /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state: removed 0 duplicates\n",
      "\n",
      "--- Cleaning: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/model_state ---\n",
      "[CLEAN] /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/model_state\n",
      "[‚úì] /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/model_state: removed 0 duplicates\n",
      "\n",
      "--- Cleaning: /content/drive/Shareddrives/ai_quantum_computing/quantum_data_lake/framework_state ---\n",
      "[SKIP] Missing path ‚Üí /content/drive/Shareddrives/ai_quantum_computing/quantum_data_lake/framework_state\n",
      "\n",
      "--- Cleaning: /content/drive/Shareddrives/ai_quantum_computing/quantum_data_lake/model_state ---\n",
      "[SKIP] Missing path ‚Üí /content/drive/Shareddrives/ai_quantum_computing/quantum_data_lake/model_state\n",
      "\n",
      "\n",
      "========== CONSOLIDATION: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state ==========\n",
      "Target date directory: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201\n",
      "[‚úì] Consolidation finished for /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state: moved 0 files, removed 0 directories.\n",
      "\n",
      "\n",
      "========== CONSOLIDATION: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/model_state ==========\n",
      "Target date directory: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/model_state/day_20260201\n",
      "[‚úì] Consolidation finished for /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/model_state: moved 0 files, removed 0 directories.\n",
      "[SKIP] Missing path ‚Üí /content/drive/Shareddrives/ai_quantum_computing/quantum_data_lake/framework_state\n",
      "[SKIP] Missing path ‚Üí /content/drive/Shareddrives/ai_quantum_computing/quantum_data_lake/model_state\n",
      "\n",
      "[UPDATE] Updating registry: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/local_backup_registry.json\n",
      "[DEBUG] State roots passed in:\n",
      "        - /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state  (exists=True)\n",
      "        - /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/model_state  (exists=True)\n",
      "\n",
      "[DEBUG] COMPONENT: framework_state\n",
      "        root = /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state\n",
      "[SKIP]     Not a directory: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/.DS_Store\n",
      "\n",
      "[DEBUG] COMPONENT: model_state\n",
      "        root = /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/model_state\n",
      "[SKIP]     Not a directory: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/model_state/.DS_Store\n",
      "[‚úì] Registry updated: 11356 corrected, 0 added\n",
      "\n",
      "[UPDATE] Updating registry: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/drive_backup_registry.json\n",
      "[DEBUG] State roots passed in:\n",
      "        - /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state  (exists=True)\n",
      "        - /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/model_state  (exists=True)\n",
      "\n",
      "[DEBUG] COMPONENT: framework_state\n",
      "        root = /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state\n",
      "[SKIP]     Not a directory: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/.DS_Store\n",
      "\n",
      "[DEBUG] COMPONENT: model_state\n",
      "        root = /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/model_state\n",
      "[SKIP]     Not a directory: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/model_state/.DS_Store\n",
      "[‚úì] Registry updated: 11356 corrected, 0 added\n",
      "[INFO] Registry not found, skipping update: /content/drive/Shareddrives/ai_quantum_computing/quantum_data_lake/backup_registry.json\n",
      "\n",
      "========== DONE ==========\n",
      "\n",
      "\n",
      "===== CLEANUP STDERR =====\n",
      " /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/cleanup_state_duplicates.py:1338: SyntaxWarning: invalid escape sequence '\\('\n",
      "  \"scenario_cat\": re.split(\"\\(|\\)\", scenario_cat)[-2],\n",
      "\n",
      "‚úì Deep cleanup complete (memory cleared)\n",
      "PyTorch version: 2.8.0\n",
      "NumPy version: 1.26.4\n",
      "Using device: cpu\n",
      "PyTorch version: 2.8.0\n",
      "NumPy version: 1.26.4\n",
      "Using device: cpu\n",
      "‚úì All modules reloaded successfully (Paper 7 environment ready)\n",
      "PyTorch version: 2.8.0\n",
      "NumPy version: 1.26.4\n",
      "Using device: cpu\n",
      "PyTorch version: 2.8.0\n",
      "NumPy version: 1.26.4\n",
      "Using device: cpu\n",
      "\n",
      "===================== GET LOCAL REGISTRY =====================\n",
      "‚Üí Skipping local cache (force=True or file missing)\n",
      "\n",
      "===================== BUILD LOCAL REGISTRY =====================\n",
      "\n",
      "================================================================================\n",
      "üîç SCANNING LOCAL FILES\n",
      "================================================================================\n",
      "Parameters: load_to_drive=False, force=False\n",
      "\n",
      "üìÇ Checking DRIVE mode: /content/drive/Shareddrives/ai_quantum_computing/quantum_data_lake\n",
      "   ‚ö†Ô∏è  Path does not exist, skipping\n",
      "\n",
      "üìÇ Checking LOCAL mode: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config\n",
      "   ‚úÖ Path exists, starting walk...\n",
      "   üö∂ Walking directory tree: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config\n",
      "\n",
      "   üìÅ Directory: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201\n",
      "      Relative: framework_state/day_20260201\n",
      "      Component: framework_state\n",
      "      Date: day_20260201\n",
      "      üìÑ Processing 2514 files in framework_state/day_20260201\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "      üìä framework_state/day_20260201: 2488/2514 files processed\n",
      "      üìä framework_state/day_20260201: 0/2514 files skipped\n",
      "      üìä framework_state/day_20260201: 26/2514 files conflicted\n",
      "\n",
      "   üìÅ Directory: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/model_state/day_20260201\n",
      "      Relative: model_state/day_20260201\n",
      "      Component: model_state\n",
      "      Date: day_20260201\n",
      "      üìÑ Processing 8842 files in model_state/day_20260201\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "      üìä model_state/day_20260201: 8842/8842 files processed\n",
      "      üìä model_state/day_20260201: 0/8842 files skipped\n",
      "      üìä model_state/day_20260201: 0/8842 files conflicted\n",
      "\n",
      "   üìä Processed 2 directories\n",
      "\n",
      "================================================================================\n",
      "üì¶ BUILDING FINAL REGISTRY\n",
      "================================================================================\n",
      "Components found: ['framework_state', 'model_state']\n",
      "  ‚Ä¢ framework_state: 2488 files\n",
      "  ‚Ä¢ model_state: 8842 files\n",
      "\n",
      "‚úÖ SCAN COMPLETE\n",
      "Modes scanned: 1\n",
      "Total files in registry: 11330\n",
      "================================================================================\n",
      "\n",
      "\t‚Üí Filesystem scan found 11330 files\n",
      "\n",
      "===================== GET DRIVE REGISTRY =====================\n",
      "===================== REGISTRY BUILD COMPLETE =====================\n",
      "\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "\tüì¶ LocalBackupManager Registry Saved Locally in LOCAL\n",
      "BUILDING REGISTRY WITH 0 EXPECTED COMPONENTS KEYS\n",
      "\n",
      "===================== GET LOCAL REGISTRY =====================\n",
      "‚Üí Skipping local cache (force=True or file missing)\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "\tüì¶ LocalBackupManager Registry Saved Locally in LOCAL\n",
      "======================================================================\n",
      "DYNAMIC ROUTING EVALUATION FRAMEWORK - MULTI-TESTBED CONFIGURATION\n",
      "======================================================================\n",
      "Available Testbeds:\n",
      "  ‚Ä¢ Paper 2 (Chaudhary 2023) - Exact replication + Extended version\n",
      "  ‚Ä¢ Paper 7 (Liu 2024) - QBGP Multi-ISP Routing\n",
      "  ‚Ä¢ Paper 12 (Wang 2024) - QuARC Fusion-based Allocation\n",
      "\n",
      "Paper 2 Configurations:\n",
      "  ‚Ä¢ 'paper2': Exact MATLAB replication (8 paths, all original params)\n",
      "  ‚Ä¢ 'paper2_extended': Enhanced version (memory decay, async swapping)\n",
      "\n",
      "Models to evaluate: 5 total\n",
      "\n",
      "‚úì Configuration loaded successfully - Ready for evaluation\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Setup: Quantum MAB Framework (Paper 7 QBGP Testbed)\n",
    "# ============================================================\n",
    "\n",
    "# --- Install Dependencies ---\n",
    "!pip install -q torch torchvision numpy matplotlib seaborn pandas tqdm scipy scikit-learn pmdarima networkx\n",
    "\n",
    "# --- Core Imports ---\n",
    "import os, sys, gc, warnings, importlib, subprocess\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import networkx as nx\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- Path Setup ---\n",
    "print(f\"Current working directory: {os.getcwd().split('/')[-1]}\")\n",
    "try:\n",
    "    import google.colab\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    project_dir = '/content/drive/MyDrive/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework'\n",
    "    os.chdir(project_dir)\n",
    "    print(\"Running in Google Colab\")\n",
    "except ImportError:\n",
    "    print(\"Running locally (not in Colab)\")\n",
    "\n",
    "sys.path.append(os.path.join(os.getcwd(), 'src'))\n",
    "print(f\"Now working from: {os.getcwd().split('/')[-1]}\")\n",
    "\n",
    "# --- Framework Verification ---\n",
    "print(\"Framework dependencies installed successfully\")\n",
    "print(f\"Python version: {sys.version.split()[0]}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"NetworkX version: {nx.__version__}\")\n",
    "print(f\"Matplotlib version: {plt.matplotlib.__version__}\")\n",
    "print(\"Quantum MAB Models Evaluation Framework - Ready for Paper 7 (QBGP) testing\")\n",
    "\n",
    "# --- Cleanup Script Execution ---\n",
    "root = os.path.abspath(\"../..\")\n",
    "cleanup_script = os.path.join(root, \"cleanup_state_duplicates.py\")\n",
    "if os.path.exists(cleanup_script):\n",
    "    print(f\"\\nüöø Running cleanup script at: {cleanup_script}\\n\")\n",
    "    result = subprocess.run([\"python3\", cleanup_script], text=True, capture_output=True)\n",
    "    print(\"===== CLEANUP STDOUT =====\\n\", result.stdout)\n",
    "    print(\"===== CLEANUP STDERR =====\\n\", result.stderr)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Cleanup script not found, skipping...\")\n",
    "\n",
    "# --- Deep Cleanup ---\n",
    "def deep_cleanup():\n",
    "    to_clear = [\"oracle\", \"gneuralucb\", \"expneuralucb\", \"cpursuitneuralucb\",\n",
    "                \"icpursuitneuralucb\", \"evaluator\", \"results\"]\n",
    "    for name in to_clear:\n",
    "        if name in globals():\n",
    "            obj = globals().get(name)\n",
    "            if hasattr(obj, \"cleanup\"): obj.cleanup(verbose=False)\n",
    "            globals().pop(name, None)\n",
    "    gc.collect()\n",
    "    torch.set_default_dtype(torch.float32)\n",
    "    if torch.cuda.is_available(): torch.cuda.empty_cache()\n",
    "    print(\"‚úì Deep cleanup complete (memory cleared)\")\n",
    "\n",
    "deep_cleanup()\n",
    "\n",
    "# Ensure daqr package is discoverable\n",
    "PARENT_DIR = os.path.abspath(\"..\")\n",
    "if PARENT_DIR not in sys.path:\n",
    "    sys.path.insert(0, PARENT_DIR)\n",
    "\n",
    "# --- Final Module Setup ---\n",
    "from daqr.core.qubit_allocator              import (QubitAllocator, RandomQubitAllocator, DynamicQubitAllocator, ThompsonSamplingAllocator)\n",
    "from daqr.core.quantum_physics              import (MemoryNoiseModel, FullPaper2FidelityCalculator, Paper2RewardFunction)\n",
    "from daqr.evaluation                        import experiment_runner, multi_run_evaluator, visualizer, allocator_runner\n",
    "from daqr.config                            import experiment_config, gd_backup_manager, local_backup_manager\n",
    "from daqr.algorithms                        import base_bandit, neural_bandits, predictive_bandits\n",
    "from daqr.core                              import network_environment, qubit_allocator\n",
    "from daqr.evaluation.visualizer             import QuantumEvaluatorVisualizer\n",
    "from daqr.config.gd_backup_manager          import GoogleDriveBackupManager\n",
    "from daqr.config.experiment_config          import ExperimentConfiguration\n",
    "from experiments                            import stochastic_evaluation\n",
    "from daqr.config.local_backup_manager       import LocalBackupManager\n",
    "from daqr.core.network_environment          import *\n",
    "from daqr.core.qubit_allocator              import *\n",
    "from daqr.algorithms.base_bandit            import *\n",
    "from daqr.algorithms.neural_bandits         import *\n",
    "from daqr.algorithms.predictive_bandits     import *\n",
    "from daqr.evaluation.multi_run_evaluator    import *\n",
    "from daqr.evaluation.experiment_runner      import *\n",
    "\n",
    "# ============================================================================\n",
    "# PAPER-SPECIFIC IMPORTS\n",
    "# ============================================================================\n",
    "from daqr.core.topology_generator           import Paper2TopologyGenerator\n",
    "from daqr.core.topology_generator           import Paper7ASTopologyGenerator  # üÜï Paper 7\n",
    "from daqr.core.topology_generator           import Paper12WaxmanTopologyGenerator\n",
    "from daqr.core.quantum_physics              import FiberLossNoiseModel, CascadedFidelityCalculator\n",
    "from daqr.core.quantum_physics              import FusionNoiseModel, FusionFidelityCalculator, QuARCRewardFunction\n",
    "from daqr.core.quantum_physics              import Paper12RetryFidelityCalculator\n",
    "from daqr.core.quantum_physics              import Paper7RewardFunction  # üÜï Paper 7\n",
    "from daqr.core                              import attack_strategy\n",
    "\n",
    "print(\"‚úì All modules reloaded successfully (Paper 7 environment ready)\")\n",
    "\n",
    "# --- Config & Model Setup ---\n",
    "for module in [experiment_config, network_environment, qubit_allocator, attack_strategy, base_bandit, \n",
    "               neural_bandits, predictive_bandits, experiment_runner, multi_run_evaluator, visualizer, \n",
    "               stochastic_evaluation]:\n",
    "    importlib.reload(module)\n",
    "\n",
    "config = ExperimentConfiguration()\n",
    "models = config.NEURAL_MODELS\n",
    "\n",
    "# ============================================================================\n",
    "# FRAMEWORK CONFIGURATION\n",
    "# ============================================================================\n",
    "FRAMEWORK_CONFIG = {\n",
    "    'exp_num': 5,\n",
    "    'test_mode': True,\n",
    "    'base_frames': 4000,\n",
    "    'frame_step': 2000,\n",
    "    'models': models,\n",
    "    'intensity': 0.25,\n",
    "    'routing_strategy': 'fixed',\n",
    "    'capacity': 10000,\n",
    "    'main_env': 'stochastic',\n",
    "\n",
    "    # Environment parameters\n",
    "    'env_attrs': {\n",
    "        'intensity': 0.25,\n",
    "        'base_seed': 12345,\n",
    "        'reproducible': True\n",
    "    },\n",
    "\n",
    "    'default': {\n",
    "        'num_paths': 4,\n",
    "        'total_qubits': 35,\n",
    "        'min_qubits_per_route': 2,\n",
    "        'exploration_bonus': 2.0,\n",
    "        'epsilon': 1.0,\n",
    "        'seed': 42\n",
    "    },\n",
    "    \n",
    "    # ========================================================================\n",
    "    # Paper #2 (Chaudhary et al. 2023) - EXACT REPLICATION\n",
    "    # ========================================================================\n",
    "    # This configuration matches the original MATLAB code exactly\n",
    "    'paper2': {\n",
    "        # Topology & Paths (from QNetworkGraph_LearningAlgo.m)\n",
    "        'num_paths': 8,              # ‚úÖ CRITICAL: Original uses No_of_arms = 8\n",
    "        'num_nodes': 15,             # No_of_nodes = 15\n",
    "        'source_node': 1,            # Configurable (original uses 2)\n",
    "        'dest_node': 14,             # Configurable (original uses 15)\n",
    "        'total_qubits': 35,\n",
    "        \n",
    "        # Core Physics Parameters (from QNetworkGraph_LearningAlgo.m lines 80-88)\n",
    "        'p_init': 0.00001,           # ‚úÖ Probability of loss after generation\n",
    "        'f_attenuation': 0.05,       # ‚úÖ Fiber loss attenuation (dB/km)\n",
    "        'p_BSM': 0.2,                # ‚úÖ BSM operation error probability\n",
    "        'p_GateErrors': 0.2,         # ‚úÖ Gate error probability\n",
    "        \n",
    "        # Physical Constants (from QNetworkGraph_LearningAlgo.m)\n",
    "        'r_dephase': 10000,          # ‚úÖ Memory dephasing rate\n",
    "        'c_light': 3.0e8,            # ‚úÖ Speed of light (m/s)\n",
    "        't_BSM': 10e-9,              # ‚úÖ BSM operation time (10 ns)\n",
    "        't_d': 10e-9,                # ‚úÖ Gate operation time (10 ns)\n",
    "        'refractive_index': 1.5,     # ‚úÖ Fiber refractive index\n",
    "        \n",
    "        # Framework Parameters\n",
    "        'exploration_bonus': 2.0,\n",
    "        'min_qubits_per_route': 2,\n",
    "        'use_paper2_rewards': True,\n",
    "        \n",
    "        # Experiment Parameters (from QNetworkGraph_LearningAlgo.m lines 110-111)\n",
    "        'rounds': 1200,              # ‚úÖ Original experiment length\n",
    "        'experiments': 100,          # ‚úÖ Original number of experiments\n",
    "        \n",
    "        # State Management\n",
    "        'testbed': 'paper2',\n",
    "    },\n",
    "    \n",
    "    # ========================================================================\n",
    "    # Paper #2 Extended (Your Enhanced Version)\n",
    "    # ========================================================================\n",
    "    # This version includes your extensions: memory decay, async swapping, etc.\n",
    "    'paper2_extended': {\n",
    "        # Topology & Paths\n",
    "        'num_paths': 8,\n",
    "        'num_nodes': 15,\n",
    "        'source_node': 1,\n",
    "        'dest_node': 14,\n",
    "        'total_qubits': 75,          # Extended capacity\n",
    "        \n",
    "        # Core Physics (from original Paper 2)\n",
    "        'p_init': 0.00001,\n",
    "        'f_attenuation': 0.05,\n",
    "        'p_BSM': 0.2,\n",
    "        'p_GateErrors': 0.2,\n",
    "        \n",
    "        # Physical Constants (from original Paper 2)\n",
    "        'r_dephase': 10000,\n",
    "        'c_light': 3.0e8,\n",
    "        't_BSM': 10e-9,\n",
    "        't_d': 10e-9,\n",
    "        'refractive_index': 1.5,\n",
    "        \n",
    "        # ‚ö†Ô∏è YOUR EXTENSIONS (not in original Paper 2)\n",
    "        'p_depol': 0.1,              # ‚ö†Ô∏è Added: Depolarization noise\n",
    "        'memory_T2': 5000,           # ‚ö†Ô∏è Added: T2 coherence time\n",
    "        'swap_mode': 'async',        # ‚ö†Ô∏è Added: Asynchronous swapping\n",
    "        'swap_delay_per_link': 100,  # ‚ö†Ô∏è Added: Per-link swap delay\n",
    "        'gate_error_rate': 0.02,     # ‚ö†Ô∏è Added: Additional gate errors\n",
    "        'use_gate_error': True,      # ‚ö†Ô∏è Added: Enable gate error model\n",
    "        'use_memory_decay': True,    # ‚ö†Ô∏è Added: Enable memory decay\n",
    "        \n",
    "        # State Configuration\n",
    "        'testbed': 'paper2_extended',\n",
    "        'initial_state': 'idle',\n",
    "        'state_total_qubits': {'busy': 35, 'idle': 43},\n",
    "        \n",
    "        # Bandit Algorithm\n",
    "        'exploration_bonus': 2.0,\n",
    "        'min_qubits_per_route': 2,\n",
    "        'transition_trigger': True,\n",
    "        'paper2_transition_interval': 50,\n",
    "        'entanglement_success_factor': 4000,\n",
    "        'use_paper2_rewards': True,\n",
    "    },\n",
    "    \n",
    "    # ========================================================================\n",
    "    # Paper #7 (Liu et al. 2024 - QBGP)\n",
    "    # ========================================================================\n",
    "    'paper7': {\n",
    "        # Topology Configuration\n",
    "        'k': 5,                      # k-shortest paths per ISP pair\n",
    "        'n_qisps': 3,                # Number of quantum ISP nodes\n",
    "        'num_paths': 15,             # Total paths for framework compatibility\n",
    "        'max_nodes': 50,             # AS subgraph size (30-80 for testing, None for full)\n",
    "        'network_scale': 'small',    # 'small' (30-50), 'medium' (100-200), 'large' (full)\n",
    "        'topology_path': '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/core/topology_data/as20000101.txt',\n",
    "        \n",
    "        # Framework Parameters\n",
    "        'total_qubits': 75,\n",
    "        'min_qubits_per_route': 2,\n",
    "        'exploration_bonus': 2.0,\n",
    "        \n",
    "        # Context & Reward Configuration\n",
    "        'use_context_rewards': True,      # Enable context-aware reward function\n",
    "        'reward_mode': 'neg_hop',         # Options: 'neg_hop', 'neg_degree', 'neg_length'\n",
    "        'use_synthetic': False,           # Force synthetic topology (ignore topology_path)\n",
    "        \n",
    "        # Topology Processing\n",
    "        'largest_cc_only': True,          # Use largest connected component\n",
    "        'relabel_to_int': True,           # Relabel nodes to integers\n",
    "        \n",
    "        # Synthetic Fallback (if topology_path fails or use_synthetic=True)\n",
    "        'synthetic_kind': 'barabasi_albert',\n",
    "        'synthetic_params': {\n",
    "            'n': 50,                      # Number of nodes\n",
    "            'm': 3                        # Edges per new node\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    # ========================================================================\n",
    "    # Paper #12 (Wang et al. 2024 - QuARC)\n",
    "    # ========================================================================\n",
    "    'paper12': {\n",
    "        # Topology\n",
    "        'n_nodes': 100,\n",
    "        'avg_degree': 6,\n",
    "        'waxman_beta': 0.2,\n",
    "        'waxman_alpha': 0.4,\n",
    "        'topology_type': 'waxman',\n",
    "        \n",
    "        # Physical parameters\n",
    "        'channel_width': 3,\n",
    "        'fusion_prob': 0.9,\n",
    "        'qubits_per_node': 12,\n",
    "        'entanglement_prob': 0.6,\n",
    "        \n",
    "        # Simulation parameters\n",
    "        'num_sd_pairs': 10,\n",
    "        'epoch_length': 500,\n",
    "        'total_timeslots': 7000,\n",
    "        \n",
    "        # QuARC-specific\n",
    "        'split_constant': 4,\n",
    "        'enable_clustering': True,\n",
    "        'enable_secondary_fusions': True,\n",
    "        \n",
    "        # Framework mapping\n",
    "        'num_paths': 4,\n",
    "        'total_qubits': 120,\n",
    "        'exploration_bonus': 1.5,\n",
    "        'min_qubits_per_route': 3,\n",
    "        'use_fusion_rewards': True,\n",
    "\n",
    "        'time_decay_physics': {\n",
    "            'memory_lifetime': 0.5\n",
    "        },\n",
    "\n",
    "        # Retry parameters\n",
    "        'retry_threshold': 0.7,\n",
    "        'max_retry_attempts': 3,\n",
    "        'retry_decay_rate': 0.95,\n",
    "        'enable_retry_logging': True,\n",
    "        'retry_cost_per_attempt': 0.1,\n",
    "    }\n",
    "}\n",
    "\n",
    "# --- Test Scenarios ---\n",
    "if FRAMEWORK_CONFIG['main_env'] == 'stochastic':\n",
    "    test_scenarios = {\n",
    "        'none': 'Baseline (Optimal Conditions)',\n",
    "        'stochastic': 'Stochastic Random Failures',\n",
    "        'markov': 'Markov Adversarial Attack',\n",
    "        'adaptive': 'Adaptive Adversarial Attack',\n",
    "        'onlineadaptive': 'Online Adaptive Attack'\n",
    "    }\n",
    "    evaluation_type = \"STOCHASTIC-FOCUSED\"\n",
    "else:\n",
    "    test_scenarios = {\n",
    "        'stochastic': 'Stochastic (Natural Network Failures)',\n",
    "        'adaptive': 'Adversarial (Strategic Attacks)'\n",
    "    }\n",
    "    evaluation_type = \"COMPARATIVE\"\n",
    "\n",
    "# --- Display Configuration ---\n",
    "print(\"=\" * 70)\n",
    "print(\"DYNAMIC ROUTING EVALUATION FRAMEWORK - MULTI-TESTBED CONFIGURATION\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Available Testbeds:\")\n",
    "print(f\"  ‚Ä¢ Paper 2 (Chaudhary 2023) - Exact replication + Extended version\")\n",
    "print(f\"  ‚Ä¢ Paper 7 (Liu 2024) - QBGP Multi-ISP Routing\")\n",
    "print(f\"  ‚Ä¢ Paper 12 (Wang 2024) - QuARC Fusion-based Allocation\")\n",
    "print(f\"\\nPaper 2 Configurations:\")\n",
    "print(f\"  ‚Ä¢ 'paper2': Exact MATLAB replication (8 paths, all original params)\")\n",
    "print(f\"  ‚Ä¢ 'paper2_extended': Enhanced version (memory decay, async swapping)\")\n",
    "print(f\"\\nModels to evaluate: {len(models)} total\")\n",
    "print(\"\\n‚úì Configuration loaded successfully - Ready for evaluation\")\n",
    "print(\"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "stochastic-vs-adversarial"
   },
   "source": [
    "## Comparative Analysis Framework: Stochastic versus Adversarial Environments\n",
    "\n",
    "### Research Focus\n",
    "\n",
    "This evaluation constitutes the primary empirical contribution of the research: systematic quantification of algorithm performance across fundamentally different operational conditions that distinguish between natural system failures and intentional strategic attacks.\n",
    "\n",
    "### Environmental Characterization\n",
    "\n",
    "**Stochastic Environment**\n",
    "- **Operational Model**: Natural random failures representing realistic network degradation patterns\n",
    "- **Attack Distribution**: Probabilistic failures following uniform random distribution\n",
    "- **Research Significance**: Establishes baseline performance metrics under standard operational conditions\n",
    "\n",
    "**Adversarial Environment**  \n",
    "- **Operational Model**: Strategic intelligent attacks systematically targeting algorithmic decision-making processes\n",
    "- **Attack Distribution**: Adaptive targeting mechanisms that dynamically respond to observed algorithm behavior\n",
    "- **Research Significance**: Evaluates robustness under worst-case strategic threat scenarios\n",
    "\n",
    "### Experimental Predictions\n",
    "\n",
    "Based on the theoretical analysis and algorithm architecture, the following empirical outcomes are anticipated:\n",
    "\n",
    "**Performance Superiority Hypothesis**\n",
    "EXPNeuralUCB will demonstrate measurably superior performance retention in adversarial environments relative to baseline neural bandit algorithms lacking specialized adversarial robustness mechanisms.\n",
    "\n",
    "**Bounded Degradation Hypothesis**\n",
    "Performance degradation under adversarial conditions will remain within acceptable operational limits, specifically maintaining performance within 85% of stochastic environment baselines.\n",
    "\n",
    "**Stability Hypothesis**\n",
    "Algorithm performance rankings will exhibit stability across varying adversarial attack intensities, indicating consistent robustness characteristics rather than scenario-dependent performance fluctuations.\n",
    "\n",
    "### Research Methodology\n",
    "\n",
    "The comparative analysis employs identical experimental conditions across both environments, enabling precise quantification of performance degradation attributable to adversarial targeting while controlling for environmental variables and maintaining statistical rigor in the evaluation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üîç PAPER 7 QUICK VALIDATION\n",
      "======================================================================\n",
      "üìä Paper7 Topology: Real AS (as20000101.txt)\n",
      "üìä Paper7 Paths: 15 paths from 5-shortest between 3 ISPs\n",
      "üìä Paper7 Contexts: 15 context vectors generated\n",
      "üìä Paper7 Rewards: Context-aware (mode=neg_hop)\n",
      "‚è±Ô∏è  get_physics_params_paper7() time: 4.1 ms\n",
      "‚úÖ Topology: 50 nodes, 141 edges\n",
      "‚úÖ Contexts: 15 paths\n",
      "‚úÖ Rewards: Enabled\n",
      "\n",
      "‚úì Paper 7 integration validated successfully\n",
      "======================================================================\n",
      "\n",
      "üöÄ Ready to run Paper 7 (QBGP) experiments!\n",
      "   Example: PHYSICS_MODELS = ['paper7']\n",
      "            ALLOCATORS = ['ThompsonSampling', 'DynamicUCB']\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# PAPER 7 HELPER FUNCTIONS\n",
    "# ============================================================================\n",
    "\n",
    "def generate_paper7_paths(topology, k: int, n_qisps: int, seed: int):\n",
    "    \"\"\"\n",
    "    Generate k-shortest paths between n_qisps quantum ISP nodes.\n",
    "    \n",
    "    Args:\n",
    "        topology: NetworkX graph (AS-level topology)\n",
    "        k: Number of shortest paths per ISP pair\n",
    "        n_qisps: Number of quantum ISP nodes\n",
    "        seed: Random seed\n",
    "        \n",
    "    Returns:\n",
    "        List of paths (each path is a list of nodes)\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    nodes = list(topology.nodes())\n",
    "\n",
    "    if len(nodes) < n_qisps:\n",
    "        raise ValueError(f\"Topology has {len(nodes)} nodes, need {n_qisps} for ISPs\")\n",
    "    \n",
    "    # Select ISP nodes (prefer high-degree nodes like real BGP)\n",
    "    degrees = dict(topology.degree())\n",
    "    sorted_nodes = sorted(nodes, key=lambda n: degrees[n], reverse=True)\n",
    "    isp_nodes = sorted_nodes[:n_qisps]  # Take top-degree nodes\n",
    "    \n",
    "    all_paths = []\n",
    "    for src, dst in itertools.combinations(isp_nodes, 2):\n",
    "        try:\n",
    "            path_generator = nx.shortest_simple_paths(topology, src, dst, weight='distance')\n",
    "            paths = list(itertools.islice(path_generator, k))\n",
    "            all_paths.extend(paths)\n",
    "        except nx.NetworkXNoPath:\n",
    "            continue\n",
    "    \n",
    "    if not all_paths:\n",
    "        raise RuntimeError(f\"Could not find any paths between {n_qisps} ISP nodes\")\n",
    "    \n",
    "    return all_paths\n",
    "\n",
    "\n",
    "def generate_paper7_contexts(paths, topology):\n",
    "    \"\"\"\n",
    "    Generate context vectors for each path: [hop_count, avg_degree, path_length].\n",
    "    \n",
    "    Args:\n",
    "        paths: List of paths (each path is a list of nodes)\n",
    "        topology: NetworkX graph\n",
    "        \n",
    "    Returns:\n",
    "        List of context arrays, one per path (shape: [1, 3])\n",
    "    \"\"\"\n",
    "    contexts = []\n",
    "    \n",
    "    for path in paths:\n",
    "        # Feature 1: Hop count (AS path length)\n",
    "        hop_count = len(path) - 1\n",
    "        \n",
    "        # Feature 2: Average node degree (bottleneck indicator)\n",
    "        degrees = [topology.degree(node) for node in path]\n",
    "        avg_degree = sum(degrees) / len(degrees) if degrees else 0.0\n",
    "\n",
    "        # Feature 3: Physical path length (sum of edge distances)\n",
    "        path_length = 0.0\n",
    "        for i in range(len(path) - 1):\n",
    "            edge_data = topology.get_edge_data(path[i], path[i+1])\n",
    "            path_length += edge_data.get('distance', 1.0)\n",
    "\n",
    "        # Context vector: [hop_count, avg_degree, path_length]\n",
    "        context_vector = np.array([hop_count, avg_degree, path_length], dtype=float)\n",
    "        contexts.append([context_vector])  # Wrap in list for framework compatibility\n",
    "    \n",
    "    return contexts\n",
    "\n",
    "\n",
    "def get_physics_params(\n",
    "    physics_model: str = \"default\",\n",
    "    current_frames: int = 4000,\n",
    "    base_seed: int = 42,\n",
    "    qubit_cap=None,\n",
    "    *,\n",
    "    topology: \"nx.Graph | None\" = None,\n",
    "    topology_model: str | None = None,\n",
    "    topology_path: str | Path | None = None,\n",
    "    topology_max_nodes: int | None = None,\n",
    "    topology_largest_cc_only: bool = True,\n",
    "    topology_relabel_to_int: bool = True,\n",
    "    synthetic_kind: str = \"barabasi_albert\",\n",
    "    synthetic_params: dict | None = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Unified physics parameter generator for all testbeds.\n",
    "    \n",
    "    Returns:\n",
    "        dict: {noise_model, fidelity_calculator, external_topology, \n",
    "               external_contexts, external_rewards}\n",
    "    \"\"\"\n",
    "    \n",
    "    # ============================================================================\n",
    "    # üéØ PAPER 7 (QBGP) - PRIMARY TESTBED\n",
    "    # ============================================================================\n",
    "    if physics_model == \"paper7\":\n",
    "        import time\n",
    "        start_time = time.time()\n",
    "        \n",
    "        paper7_cfg = FRAMEWORK_CONFIG['paper7']\n",
    "        node_num = paper7_cfg.get('max_nodes')\n",
    "\n",
    "        # --- Topology Generation ---\n",
    "        if topology is not None:\n",
    "            final_topology = topology\n",
    "            print(f\"üìä Paper7 Topology: User-provided ({len(topology.nodes())} nodes)\")\n",
    "        else:\n",
    "            # Determine if using synthetic or real AS data\n",
    "            if paper7_cfg.get('use_synthetic', False) or not paper7_cfg.get('topology_path'):\n",
    "                # Synthetic fallback\n",
    "                synth_params = synthetic_params or paper7_cfg.get('synthetic_params', {'n': 50, 'm': 3})\n",
    "                topo_gen = Paper7ASTopologyGenerator(\n",
    "                    edge_list_path=\"dummy_nonexistent.txt\",\n",
    "                    max_nodes=topology_max_nodes or node_num,\n",
    "                    seed=base_seed,\n",
    "                    synthetic_fallback=True,\n",
    "                    synthetic_kind=paper7_cfg.get('synthetic_kind', 'barabasi_albert'),\n",
    "                    synthetic_params=synth_params\n",
    "                )\n",
    "                print(f\"üìä Paper7 Topology: Synthetic ({paper7_cfg.get('synthetic_kind')}, n={synth_params.get('n', 50)})\")\n",
    "            else:\n",
    "                # Real AS topology\n",
    "                topo_gen = Paper7ASTopologyGenerator(\n",
    "                    edge_list_path=paper7_cfg['topology_path'],\n",
    "                    max_nodes=node_num,\n",
    "                    seed=base_seed,\n",
    "                    relabel_to_integers=paper7_cfg.get('relabel_to_int', True),\n",
    "                    largest_cc_only=paper7_cfg.get('largest_cc_only', True),\n",
    "                    synthetic_fallback=True\n",
    "                )\n",
    "                topo_path_short = paper7_cfg['topology_path'].split('/')[-1]\n",
    "                print(f\"üìä Paper7 Topology: Real AS ({topo_path_short})\")\n",
    "            \n",
    "            final_topology = topo_gen.generate()\n",
    "\n",
    "        # --- Path Generation ---\n",
    "        k = paper7_cfg[\"k\"]\n",
    "        n_qisps = paper7_cfg[\"n_qisps\"]\n",
    "        paths = generate_paper7_paths(final_topology, k, n_qisps, base_seed)\n",
    "        contexts = generate_paper7_contexts(paths, final_topology)\n",
    "        \n",
    "        elapsed_ms = (time.time() - start_time) * 1000\n",
    "        print(f\"üìä Paper7 Paths: {len(paths)} paths from {k}-shortest between {n_qisps} ISPs\")\n",
    "        print(f\"üìä Paper7 Contexts: {len(contexts)} context vectors generated\")\n",
    "\n",
    "        # --- Reward Function (Optional) ---\n",
    "        external_rewards = None\n",
    "        if paper7_cfg.get('use_context_rewards', False):\n",
    "            reward_mode = paper7_cfg.get('reward_mode', 'neg_hop')\n",
    "            reward_func = Paper7RewardFunction(mode=reward_mode)\n",
    "            external_rewards = []\n",
    "            for ctx_list in contexts:\n",
    "                path_rewards = [reward_func.compute(ctx) for ctx in ctx_list]\n",
    "                external_rewards.append(path_rewards)\n",
    "            print(f\"üìä Paper7 Rewards: Context-aware (mode={reward_mode})\")\n",
    "        else:\n",
    "            print(f\"üìä Paper7 Rewards: Using default framework rewards\")\n",
    "\n",
    "        print(f\"‚è±Ô∏è  get_physics_params_paper7() time: {elapsed_ms:.1f} ms\")\n",
    "        \n",
    "        return {\n",
    "            \"noise_model\": None,\n",
    "            \"fidelity_calculator\": None,\n",
    "            \"external_topology\": final_topology,\n",
    "            \"external_contexts\": contexts,\n",
    "            \"external_rewards\": external_rewards\n",
    "        }\n",
    "    \n",
    "    # ============================================================================\n",
    "    # PAPER 2 (Huang et al.)\n",
    "    # ============================================================================\n",
    "    elif physics_model == \"paper2\":\n",
    "        p2_config = FRAMEWORK_CONFIG[\"paper2\"]\n",
    "        topo_gen = Paper2TopologyGenerator(num_nodes=p2_config[\"num_nodes\"], seed=base_seed)\n",
    "        topo = topo_gen.generate()\n",
    "        \n",
    "        try:\n",
    "            path_generator = nx.shortest_simple_paths(\n",
    "                topo, p2_config[\"source_node\"], p2_config[\"dest_node\"], weight=\"distance\"\n",
    "            )\n",
    "            paths = list(itertools.islice(path_generator, p2_config[\"num_paths\"]))\n",
    "        except nx.NetworkXNoPath:\n",
    "            paths = [[p2_config[\"source_node\"], p2_config[\"dest_node\"]]] * p2_config[\"num_paths\"]\n",
    "        \n",
    "        # Stochastic noise model\n",
    "        noise_model = FiberLossNoiseModel(\n",
    "            topology=topo,\n",
    "            paths=paths,\n",
    "            p_init=p2_config.get(\"p_init\", 0.00001),\n",
    "            f_attenuation=p2_config.get(\"f_attenuation\", 0.05)\n",
    "        )\n",
    "        \n",
    "        # Fidelity calculator with optional memory decay\n",
    "        if p2_config.get('use_memory_decay', False):\n",
    "            memory_model = MemoryNoiseModel(\n",
    "                T2=p2_config.get(\"memory_T2\", 5000),\n",
    "                swap_delay_per_link=p2_config.get(\"swap_delay_per_link\", 100)\n",
    "            )\n",
    "            if p2_config.get(\"swap_mode\", \"sync\") == \"sync\":\n",
    "                memory_model = None\n",
    "        else:\n",
    "            memory_model = None\n",
    "        \n",
    "        fidelity_calc = FullPaper2FidelityCalculator(\n",
    "            gate_error_rate=p2_config.get(\"gate_error_rate\", 0.02) if p2_config.get('use_gate_error', False) else 0.0,\n",
    "            memory_model=memory_model\n",
    "        )\n",
    "        \n",
    "        print(f\"üìä Paper2 Physics: Fiber Loss + {'Memory Decay' if memory_model else 'No Memory'}\")\n",
    "        \n",
    "        return {\n",
    "            \"noise_model\": noise_model,\n",
    "            \"fidelity_calculator\": fidelity_calc,\n",
    "            \"external_topology\": topo,\n",
    "            \"external_contexts\": None,\n",
    "            \"external_rewards\": None\n",
    "        }\n",
    "\n",
    "    # ============================================================================\n",
    "    # PAPER 12 (Wang et al. - QuARC)\n",
    "    # ============================================================================\n",
    "    elif physics_model == 'paper12':\n",
    "        p12config = FRAMEWORK_CONFIG['paper12']\n",
    "        \n",
    "        # Get base Paper12 physics\n",
    "        physics_params = get_physics_params_paper12(p12config, seed=base_seed, qubit_cap=qubit_cap)\n",
    "        base_fidelity_calc = physics_params['fidelity_calculator']\n",
    "        \n",
    "        # Wrap with retry logic\n",
    "        fidelity_calc = Paper12RetryFidelityCalculator(\n",
    "            base_calculator=base_fidelity_calc,\n",
    "            threshold=p12config['retry_threshold'],\n",
    "            max_attempts=p12config['max_retry_attempts'],\n",
    "            decay_rate=p12config['retry_decay_rate']\n",
    "        )\n",
    "        \n",
    "        physics_params['fidelity_calculator'] = fidelity_calc\n",
    "        \n",
    "        # Add metadata\n",
    "        metadata = {\n",
    "            'paper': 'Wang2024Paper12',\n",
    "            'retry_enabled': True,\n",
    "            'retry_threshold': p12config['retry_threshold'],\n",
    "            'max_attempts': p12config['max_retry_attempts'],\n",
    "            'decay_rate': p12config['retry_decay_rate'],\n",
    "        }\n",
    "        physics_params['metadata'] = metadata\n",
    "        \n",
    "        print(f\"üìä Paper12 Physics: Fusion (prob={p12config['fusion_prob']}) + Retry Logic\")\n",
    "        \n",
    "        return physics_params\n",
    "    \n",
    "    # ============================================================================\n",
    "    # DEFAULT (No special physics)\n",
    "    # ============================================================================\n",
    "    else:\n",
    "        return {\n",
    "            \"noise_model\": None,\n",
    "            \"fidelity_calculator\": None,\n",
    "            \"external_topology\": topology,\n",
    "            \"external_contexts\": None,\n",
    "            \"external_rewards\": None\n",
    "        }\n",
    "\n",
    "\n",
    "def get_physics_params_paper12(config, seed, qubit_cap, num_paths = 4):\n",
    "    \"\"\"Paper #12 (Waxman + QuARC) physics adapter.\"\"\"\n",
    "    topology = Paper12WaxmanTopologyGenerator().generate()\n",
    "    num_paths = num_paths\n",
    "    nodes = list(topology.nodes())\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    # Find 4 paths\n",
    "    paths = []\n",
    "    attempts = 0\n",
    "    max_attempts = 10 * num_paths\n",
    "    \n",
    "    while len(paths) < num_paths and attempts < max_attempts:\n",
    "        attempts += 1\n",
    "        src, dst = rng.choice(nodes, 2, replace=False)\n",
    "        try:\n",
    "            path = nx.shortest_path(topology, src, dst)\n",
    "            if path not in paths:\n",
    "                paths.append(path)\n",
    "        except nx.NetworkXNoPath:\n",
    "            continue\n",
    "    \n",
    "    if len(paths) < num_paths:\n",
    "        raise RuntimeError(f\"Could not find {num_paths} valid paths in Waxman topology\")\n",
    "\n",
    "    # Physics models\n",
    "    fusion_prob = float(config.get(\"fusion_prob\", 0.9))\n",
    "    entanglement_prob = float(config.get(\"entanglement_prob\", 0.6))\n",
    "    noise_model = FusionNoiseModel(\n",
    "        topology=topology, paths=paths, fusion_prob=fusion_prob, entanglement_prob=entanglement_prob\n",
    "    )\n",
    "    fidelity_calc = FusionFidelityCalculator()\n",
    "    reward_func = QuARCRewardFunction()\n",
    "\n",
    "    # Contexts: 4 arrays with shapes (8,3), (10,3), (8,3), (9,3)\n",
    "    external_contexts = []\n",
    "    arms_per_path = [8, 10, 8, 9]\n",
    "    degrees = dict(topology.degree())\n",
    "    max_degree = max(degrees.values()) if degrees else 1.0\n",
    "\n",
    "    for p_idx, K in enumerate(arms_per_path):\n",
    "        path = paths[p_idx]\n",
    "        hop_count = len(path) - 1\n",
    "        path_degrees = [degrees[n] for n in path]\n",
    "        avg_degree = float(sum(path_degrees) / len(path_degrees))\n",
    "        f2_deg_norm = avg_degree / max_degree if max_degree > 0 else 0.0\n",
    "        ctx = np.full((K, 3), [float(hop_count), f2_deg_norm, fusion_prob], dtype=float)\n",
    "        external_contexts.append(ctx)\n",
    "\n",
    "    # Rewards: 4 lists with lengths [8,10,8,9]\n",
    "    external_rewards = []\n",
    "    for p_idx, K in enumerate(arms_per_path):\n",
    "        path = paths[p_idx]\n",
    "        err_info = noise_model.get_error_rates(p_idx)\n",
    "        base_fidelity = fidelity_calc.compute_path_fidelity(err_info, context=None, fusion_prob=fusion_prob)\n",
    "        base_fidelity = float(np.clip(base_fidelity, 0.0, 1.0))\n",
    "\n",
    "        path_rewards = []\n",
    "        for _ in range(K):\n",
    "            success = rng.random() < base_fidelity\n",
    "            r = reward_func.compute_reward(success=success, aggregate_throughput=1)\n",
    "            path_rewards.append(float(r))\n",
    "        \n",
    "        external_rewards.append(path_rewards)\n",
    "    \n",
    "    return {\n",
    "        \"external_topology\": topology,\n",
    "        \"external_contexts\": external_contexts,\n",
    "        \"external_rewards\": external_rewards,\n",
    "        \"noise_model\": noise_model,\n",
    "        \"fidelity_calculator\": fidelity_calc,\n",
    "    }\n",
    "\n",
    "\n",
    "def force_release_resources(evaluator=None, verbose=True):\n",
    "    \"\"\"Force release of ALL resources that could block. Call AFTER each allocator completes.\"\"\"\n",
    "    cleanup_log = []\n",
    "\n",
    "    # 1. Stop logging and close file handles\n",
    "    if evaluator is not None:\n",
    "        try:\n",
    "            if hasattr(evaluator, 'configs') and hasattr(evaluator.configs, 'backup_mgr'):\n",
    "                backup_mgr = evaluator.configs.backup_mgr\n",
    "                if hasattr(backup_mgr, 'stop_logging_redirect'):\n",
    "                    backup_mgr.stop_logging_redirect()\n",
    "                if hasattr(backup_mgr, '_log_file'):\n",
    "                    try:\n",
    "                        backup_mgr._log_file.close()\n",
    "                    except:\n",
    "                        pass\n",
    "                if hasattr(backup_mgr, 'backup_registry'):\n",
    "                    backup_mgr.backup_registry.clear()\n",
    "            cleanup_log.append(\"‚úÖ Backup manager cleaned\")\n",
    "        except Exception as e:\n",
    "            cleanup_log.append(f\"‚ö†Ô∏è Backup cleanup: {e}\")\n",
    "\n",
    "    # 2. Clear environment graphs\n",
    "    if evaluator is not None:\n",
    "        try:\n",
    "            if hasattr(evaluator, 'configs') and hasattr(evaluator.configs, 'environment'):\n",
    "                env = evaluator.configs.environment\n",
    "                if hasattr(env, 'topology') and hasattr(env.topology, 'clear'):\n",
    "                    env.topology.clear()\n",
    "                    del env.topology\n",
    "                if hasattr(env, 'paths'):\n",
    "                    env.paths = []\n",
    "            cleanup_log.append(\"‚úÖ Environment graphs cleared\")\n",
    "        except Exception as e:\n",
    "            cleanup_log.append(f\"‚ö†Ô∏è Environment cleanup: {e}\")\n",
    "\n",
    "    # 3. Break circular references\n",
    "    if evaluator is not None:\n",
    "        try:\n",
    "            if hasattr(evaluator, 'configs'):\n",
    "                if hasattr(evaluator.configs, 'backup_mgr'):\n",
    "                    evaluator.configs.backup_mgr = None\n",
    "                if hasattr(evaluator.configs, 'environment'):\n",
    "                    evaluator.configs.environment = None\n",
    "                evaluator.configs = None\n",
    "            cleanup_log.append(\"‚úÖ Circular references broken\")\n",
    "        except Exception as e:\n",
    "            cleanup_log.append(f\"‚ö†Ô∏è Reference cleanup: {e}\")\n",
    "\n",
    "    # 4. Clear model registries\n",
    "    try:\n",
    "        import sys\n",
    "        for mod_name in list(sys.modules.keys()):\n",
    "            if 'bandit' in mod_name.lower() or 'neural' in mod_name.lower():\n",
    "                mod = sys.modules[mod_name]\n",
    "                if hasattr(mod, '_model_registry'):\n",
    "                    mod._model_registry.clear()\n",
    "                if hasattr(mod, '_global_models'):\n",
    "                    mod._global_models.clear()\n",
    "        cleanup_log.append(\"‚úÖ Model registries cleared\")\n",
    "    except Exception as e:\n",
    "        cleanup_log.append(f\"‚ö†Ô∏è Registry cleanup: {e}\")\n",
    "\n",
    "    # 5. Torch cleanup\n",
    "    try:\n",
    "        import torch\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "            torch.cuda.synchronize()\n",
    "        cleanup_log.append(\"‚úÖ Torch CUDA cleared\")\n",
    "    except Exception as e:\n",
    "        cleanup_log.append(f\"‚ö†Ô∏è Torch cleanup: {e}\")\n",
    "\n",
    "    # 6. Garbage collection\n",
    "    collected = [gc.collect() for _ in range(3)]\n",
    "    cleanup_log.append(f\"‚úÖ GC collected: {sum(collected)} objects\")\n",
    "\n",
    "    # 7. Close file descriptors\n",
    "    try:\n",
    "        import psutil\n",
    "        process = psutil.Process()\n",
    "        for f in process.open_files():\n",
    "            if any(ext in f.path for ext in ['.pkl', '.log', '.csv']):\n",
    "                try:\n",
    "                    os.close(f.fd)\n",
    "                except:\n",
    "                    pass\n",
    "        cleanup_log.append(\"‚úÖ File descriptors closed\")\n",
    "    except Exception as e:\n",
    "        cleanup_log.append(f\"‚ö†Ô∏è FD cleanup: {e}\")\n",
    "\n",
    "    # 8. Delete evaluator and final collection\n",
    "    if evaluator is not None:\n",
    "        del evaluator\n",
    "    gc.collect(2)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"üßπ FORCED RESOURCE RELEASE\")\n",
    "        print(\"=\"*70)\n",
    "        for log in cleanup_log:\n",
    "            print(log)\n",
    "        print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# VALIDATION: Quick Paper 7 Sanity Check\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üîç PAPER 7 QUICK VALIDATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "try:\n",
    "    # Test Paper 7 physics generation\n",
    "    test_params = get_physics_params(\n",
    "        physics_model='paper7',\n",
    "        base_seed=42\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ Topology: {len(test_params['external_topology'].nodes())} nodes, \"\n",
    "          f\"{len(test_params['external_topology'].edges())} edges\")\n",
    "    print(f\"‚úÖ Contexts: {len(test_params['external_contexts'])} paths\")\n",
    "    print(f\"‚úÖ Rewards: {'Enabled' if test_params['external_rewards'] else 'Disabled'}\")\n",
    "    print(\"\\n‚úì Paper 7 integration validated successfully\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Validation failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "print(\"üöÄ Ready to run Paper 7 (QBGP) experiments!\")\n",
    "print(\"   Example: PHYSICS_MODELS = ['paper7']\")\n",
    "print(\"            ALLOCATORS = ['ThompsonSampling', 'DynamicUCB']\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "VERIFYING NEURAL BANDIT FIXES ARE LOADED\n",
      "======================================================================\n",
      "‚úÖ NeuralUCB CLAMPING FIX detected\n",
      "‚úÖ EXPNeuralUCB PROBABILITY FIX detected\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Verification: Check that fixes are in place\n",
    "print(\"=\" * 70)\n",
    "print(\"VERIFYING NEURAL BANDIT FIXES ARE LOADED\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Check NeuralUCB clamping fix\n",
    "from daqr.algorithms.base_bandit import NeuralUCB\n",
    "import inspect\n",
    "source = inspect.getsource(NeuralUCB.take_action)\n",
    "if \"np.maximum(p, 0.0)\" in source:\n",
    "    print(\"‚úÖ NeuralUCB CLAMPING FIX detected\")\n",
    "else:\n",
    "    print(\"‚ùå NeuralUCB CLAMPING FIX NOT found - reload failed!\")\n",
    "\n",
    "# Check EXPNeuralUCB probability fix  \n",
    "from daqr.algorithms.neural_bandits import EXPNeuralUCB\n",
    "source = inspect.getsource(EXPNeuralUCB._calculate_group_probabilities)\n",
    "if \"log_sum_exp\" in source or \"max_exponent\" in source:\n",
    "    print(\"‚úÖ EXPNeuralUCB PROBABILITY FIX detected\")\n",
    "else:\n",
    "    print(\"‚ùå EXPNeuralUCB PROBABILITY FIX NOT found - reload failed!\")\n",
    "\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "DETAILED DEBUG: Enhanced error tracing\n",
      "======================================================================\n",
      "\n",
      "üóëÔ∏è CLEARING CACHED MODEL FILES...\n",
      "\n",
      "‚úÖ Enhanced debugging enabled\n"
     ]
    }
   ],
   "source": [
    "# Debug cell: Detailed traceback for GNeuralUCB error\n",
    "print(\"=\" * 70)\n",
    "print(\"DETAILED DEBUG: Enhanced error tracing\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "import traceback\n",
    "import sys\n",
    "import shutil\n",
    "\n",
    "# Patch numpy.random.choice to catch bad probability arrays\n",
    "original_choice = np.random.choice\n",
    "\n",
    "def debug_choice(a, size=None, replace=True, p=None, **kwargs):\n",
    "    if p is not None:\n",
    "        p_arr = np.asarray(p)\n",
    "        if np.any(p_arr < 0):\n",
    "            print(f\"\\n  [DEBUG-CHOICE] ‚ùå CAUGHT BAD PROBABILITIES!\")\n",
    "            print(f\"  [DEBUG-CHOICE]    p values: {p_arr}\")\n",
    "            print(f\"  [DEBUG-CHOICE]    min: {np.min(p_arr)}, max: {np.max(p_arr)}\")\n",
    "            print(f\"  [DEBUG-CHOICE]    sum: {np.sum(p_arr)}\")\n",
    "            print(f\"  [DEBUG-CHOICE]    Stack trace:\")\n",
    "            traceback.print_stack()\n",
    "            raise ValueError(\"probabilities are not non-negative\")\n",
    "    return original_choice(a, size=size, replace=replace, p=p, **kwargs)\n",
    "\n",
    "np.random.choice = debug_choice\n",
    "\n",
    "# Clear cache\n",
    "print(\"\\nüóëÔ∏è CLEARING CACHED MODEL FILES...\")\n",
    "cache_dirs = ['model_state', 'framework_state', 'quantum_logs', '.cache', '__pycache__']\n",
    "for cache_dir in cache_dirs:\n",
    "    try:\n",
    "        if os.path.exists(cache_dir):\n",
    "            shutil.rmtree(cache_dir)\n",
    "            print(f\"   ‚úÖ Cleared: {cache_dir}\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ö†Ô∏è  Could not clear {cache_dir}: {e}\")\n",
    "\n",
    "print(\"\\n‚úÖ Enhanced debugging enabled\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üóëÔ∏è CLEARING ALL CACHED MODEL FILES\n",
      "======================================================================\n",
      "‚ÑπÔ∏è  Not found: daqr/config/model_state\n",
      "‚ÑπÔ∏è  Not found: daqr/config/framework_state\n",
      "‚ÑπÔ∏è  Not found: daqr/config/quantum_logs\n",
      "\n",
      "‚úÖ Cache fully cleared - models will be fresh from fixed code\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CRITICAL: Clear All Cached Models Before Running Test\n",
    "# ============================================================\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"üóëÔ∏è CLEARING ALL CACHED MODEL FILES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Specific cache directories used by the framework\n",
    "cache_paths = [\n",
    "    'daqr/config/model_state',\n",
    "    'daqr/config/framework_state',\n",
    "    'daqr/config/quantum_logs'\n",
    "]\n",
    "\n",
    "for cache_path in cache_paths:\n",
    "    if os.path.exists(cache_path):\n",
    "        try:\n",
    "            shutil.rmtree(cache_path)\n",
    "            print(f\"‚úÖ Cleared: {cache_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è  Error clearing {cache_path}: {e}\")\n",
    "    else:\n",
    "        print(f\"‚ÑπÔ∏è  Not found: {cache_path}\")\n",
    "\n",
    "print(\"\\n‚úÖ Cache fully cleared - models will be fresh from fixed code\")\n",
    "print(\"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "PAPER #7 (QBGP) QUANTUM ROUTING EVALUATION - SINGLE ALLOCATOR TEST\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "üéØ PAPER 7 ALLOCATOR EVALUATION\n",
      "======================================================================\n",
      "Allocator:                  Default\n",
      "Physics Model:              paper7\n",
      "Attack Scenarios:           ['stochastic']\n",
      "Scales:                     [1, 1.5, 2]\n",
      "Runs per Scale:             [5]\n",
      "Total Frames:               50\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "RUNNING: Default on Paper 7 (QBGP)\n",
      "======================================================================\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Preparing: Default at scale 1\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üîß Generating physics parameters for model: paper7\n",
      "\n",
      "===================== GET LOCAL REGISTRY =====================\n",
      "‚Üí Skipping local cache (force=True or file missing)\n",
      "\n",
      "===================== BUILD LOCAL REGISTRY =====================\n",
      "\n",
      "================================================================================\n",
      "üîç SCANNING LOCAL FILES\n",
      "================================================================================\n",
      "Parameters: load_to_drive=False, force=False\n",
      "\n",
      "üìÇ Checking DRIVE mode: /content/drive/Shareddrives/ai_quantum_computing/quantum_data_lake\n",
      "   ‚ö†Ô∏è  Path does not exist, skipping\n",
      "\n",
      "üìÇ Checking LOCAL mode: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config\n",
      "   ‚úÖ Path exists, starting walk...\n",
      "   üö∂ Walking directory tree: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config\n",
      "\n",
      "   üìÅ Directory: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201\n",
      "      Relative: framework_state/day_20260201\n",
      "      Component: framework_state\n",
      "      Date: day_20260201\n",
      "      üìÑ Processing 2514 files in framework_state/day_20260201\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "      üìä framework_state/day_20260201: 2488/2514 files processed\n",
      "      üìä framework_state/day_20260201: 0/2514 files skipped\n",
      "      üìä framework_state/day_20260201: 26/2514 files conflicted\n",
      "\n",
      "   üìÅ Directory: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/model_state/day_20260201\n",
      "      Relative: model_state/day_20260201\n",
      "      Component: model_state\n",
      "      Date: day_20260201\n",
      "      üìÑ Processing 8842 files in model_state/day_20260201\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "      üìä model_state/day_20260201: 8842/8842 files processed\n",
      "      üìä model_state/day_20260201: 0/8842 files skipped\n",
      "      üìä model_state/day_20260201: 0/8842 files conflicted\n",
      "\n",
      "   üìä Processed 2 directories\n",
      "\n",
      "================================================================================\n",
      "üì¶ BUILDING FINAL REGISTRY\n",
      "================================================================================\n",
      "Components found: ['framework_state', 'model_state']\n",
      "  ‚Ä¢ framework_state: 2488 files\n",
      "  ‚Ä¢ model_state: 8842 files\n",
      "\n",
      "‚úÖ SCAN COMPLETE\n",
      "Modes scanned: 1\n",
      "Total files in registry: 11330\n",
      "================================================================================\n",
      "\n",
      "\t‚Üí Filesystem scan found 11330 files\n",
      "\n",
      "===================== GET DRIVE REGISTRY =====================\n",
      "===================== REGISTRY BUILD COMPLETE =====================\n",
      "\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "\tüì¶ LocalBackupManager Registry Saved Locally in LOCAL\n",
      "BUILDING REGISTRY WITH 0 EXPECTED COMPONENTS KEYS\n",
      "\n",
      "===================== GET LOCAL REGISTRY =====================\n",
      "‚Üí Skipping local cache (force=True or file missing)\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "\tüì¶ LocalBackupManager Registry Saved Locally in LOCAL\n",
      "\n",
      "======================================================================\n",
      "üéØ AllocatorRunner initialized: Default\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "üöÄ STARTING ALLOCATOR: Default\n",
      "======================================================================\n",
      "\n",
      "üìä Physics Model: paper7\n",
      "\n",
      "üìã Allocator Config:\n",
      "   Type: Default\n",
      "   Testbed: default\n",
      "   Paths: 15\n",
      "   Total Qubits: 75\n",
      "   Min per route: 2\n",
      "   Seed: 42\n",
      "‚úÖ Allocator created: (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "‚úì Allocator: QubitAllocator (15 paths)\n",
      "   Initial allocation: (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üìä Paper7 Topology: Real AS (as20000101.txt)\n",
      "üìä Paper7 Paths: 15 paths from 5-shortest between 3 ISPs\n",
      "üìä Paper7 Contexts: 15 context vectors generated\n",
      "üìä Paper7 Rewards: Context-aware (mode=neg_hop)\n",
      "‚è±Ô∏è  get_physics_params_paper7() time: 2.3 ms\n",
      "\n",
      "======================================================================\n",
      "RUN 1 | Scale: 1 | Exp: 5\n",
      "======================================================================\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "\n",
      "\tüîÑ Resume: MultiRunEvaluator\n",
      "\n",
      "=====================================================\n",
      "üîç GENERATING EXPECTED KEYS FROM EVALUATOR\n",
      "=====================================================\n",
      "  ‚Ä¢ Evaluator filename: MultiRunEvaluator_50-Default_All_All-50_50_5_S1T_paper7.pkl\n",
      "\n",
      "üß© PARSED COMPONENTS\n",
      "  ‚Ä¢ cap_id:        50\n",
      "  ‚Ä¢ allocator_id:  Default\n",
      "  ‚Ä¢ env_id:        All\n",
      "  ‚Ä¢ attack_id:     All\n",
      "  ‚Ä¢ base_frames:   50\n",
      "  ‚Ä¢ frame_step:    50\n",
      "  ‚Ä¢ runs_id:       5\n",
      "\n",
      "=====================================================\n",
      "üß™ GENERATING KEYS FOR EACH RUN\n",
      "=====================================================\n",
      "\n",
      "--- Run 1/5 -----------------------\n",
      "\n",
      "=====================================================\n",
      "üì¶ FINAL EXPECTED KEYS\n",
      "=====================================================\n",
      "  ‚Ä¢ Runner keys: 11\n",
      "\n",
      "  ‚Ä¢ Model keys: 50\n",
      "\n",
      "--- Run 2/5 -----------------------\n",
      "\n",
      "=====================================================\n",
      "üì¶ FINAL EXPECTED KEYS\n",
      "=====================================================\n",
      "  ‚Ä¢ Runner keys: 21\n",
      "\n",
      "  ‚Ä¢ Model keys: 100\n",
      "\n",
      "--- Run 3/5 -----------------------\n",
      "\n",
      "=====================================================\n",
      "üì¶ FINAL EXPECTED KEYS\n",
      "=====================================================\n",
      "  ‚Ä¢ Runner keys: 31\n",
      "\n",
      "  ‚Ä¢ Model keys: 150\n",
      "\n",
      "--- Run 4/5 -----------------------\n",
      "\n",
      "=====================================================\n",
      "üì¶ FINAL EXPECTED KEYS\n",
      "=====================================================\n",
      "  ‚Ä¢ Runner keys: 41\n",
      "\n",
      "  ‚Ä¢ Model keys: 200\n",
      "\n",
      "--- Run 5/5 -----------------------\n",
      "\n",
      "=====================================================\n",
      "üì¶ FINAL EXPECTED KEYS\n",
      "=====================================================\n",
      "  ‚Ä¢ Runner keys: 51\n",
      "\n",
      "  ‚Ä¢ Model keys: 250\n",
      "\n",
      "EXPECTED KEY GENERATION COMPLETE\n",
      "\n",
      "RESTORING FROM DRIVE 1\n",
      "RESTORING FROM DRIVE 2\n",
      "\t‚ö†Ô∏è Registry exists ‚Üí aborting restore\n",
      "\t‚úì MultiRunEvaluator Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/MultiRunEvaluator_50-Default_All_All-50_50_5_S1T_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/MultiRunEvaluator_50-Default_All_All-50_50_5_S1T_paper7.pkl\n",
      "\t   File exists: True, size: 4183594\n",
      "EQUAL METHOD\n",
      "Multi-Run Evaluator Initialized\n",
      "Environment Type: None\n",
      "Frame Range: 50 -> 250 (step: 50)\n",
      "quantum_exps-Default(paper7)_alloc-all_envs-5_attacks-50_50-5_runs-S1T\n",
      "[Logging Redirect Initialized]\n",
      "Log File: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/quantum_logs/quantum_exps-Default(paper7)_alloc-all_envs-5_attacks-50_50-5_runs-S1T_20260201_log.txt\n",
      "‚öô Running evaluation...\n",
      "======================================================================\n",
      "SCENARIOS MODEL EVALUATION\n",
      "======================================================================\n",
      "Testing algorithm performance against:\n",
      "\t‚Ä¢ Stochastic:  \tNatural quantum decoherence and network failures\n",
      "\t‚Ä¢ Baseline:    \tOptimal conditions for validation\n",
      "======================================================================\n",
      "Models to Test:             \tOracle, GNeuralUCB, EXPNeuralUCB, CPursuitNeuralUCB, iCPursuitNeuralUCB\n",
      "Experiments per Scenario:   \t5\n",
      "======================================================================\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: BASELINE (OPTIMAL CONDITIONS)\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: NONE\n",
      "Category: Baseline (No Attacks)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 50 frames  <>  SCALED-CAPACITY: 50 frames (CAPACITY:50 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=0 ‚Üí allocation=(5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîß Allocated qubits for NONE Exp 1: (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 1: Env:Baseline (None), Attack:No, Rate:0.0, Frames:50, QubitAlloc=Default, SC:50 (Scale=1 x Cap=50), Seed: 15373\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_1\n",
      "\t‚úì QuantumExperimentRunner_1 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_50-Default_Baseline (None)_No-50_1_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_50-Default_Baseline (None)_No-50_1_paper7.pkl\n",
      "\t   File exists: True, size: 37474\n",
      "‚è© SKIPPING EXPERIMENT 1: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 1 GNEURALUCB          : Reward=0396.00, Efficiency=088.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=50, Threshold=0.582]\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=0398.00, Efficiency=088.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=50, Threshold=0.628]\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=0396.00, Efficiency=088.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=50, Threshold=0.634]\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=0450.00, Efficiency=100.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=50, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP1 Winner:iCPursuitNeuralUCB  (Gap:000.0%) [Env:Baseline (None), Attack:No X Rate:0.25, Frames:50, SCapacity=50, Alloc=Default]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 100 frames  <>  SCALED-CAPACITY: 100 frames (CAPACITY:100 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=1 ‚Üí allocation=(5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîß Allocated qubits for NONE Exp 2: (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 2: Env:Baseline (None), Attack:No, Rate:0.0, Frames:100, QubitAlloc=Default, SC:100 (Scale=1 x Cap=100), Seed: 12644\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_2\n",
      "\t‚úì QuantumExperimentRunner_2 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_100-Default_Baseline (None)_No-100_2_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_100-Default_Baseline (None)_No-100_2_paper7.pkl\n",
      "\t   File exists: True, size: 64110\n",
      "‚è© SKIPPING EXPERIMENT 2: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 2 GNEURALUCB          : Reward=0794.00, Efficiency=088.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=100, Threshold=0.582]\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=0814.00, Efficiency=090.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=100, Threshold=0.628]\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=0794.00, Efficiency=088.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=100, Threshold=0.634]\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=0900.00, Efficiency=100.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=100, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP2 Winner:iCPursuitNeuralUCB  (Gap:000.0%) [Env:Baseline (None), Attack:No X Rate:0.25, Frames:100, SCapacity=100, Alloc=Default]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 150 frames  <>  SCALED-CAPACITY: 150 frames (CAPACITY:150 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=2 ‚Üí allocation=(5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîß Allocated qubits for NONE Exp 3: (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 3: Env:Baseline (None), Attack:No, Rate:0.0, Frames:150, QubitAlloc=Default, SC:150 (Scale=1 x Cap=150), Seed: 20257\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_3\n",
      "\t‚úì QuantumExperimentRunner_3 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_150-Default_Baseline (None)_No-150_3_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_150-Default_Baseline (None)_No-150_3_paper7.pkl\n",
      "\t   File exists: True, size: 90719\n",
      "‚è© SKIPPING EXPERIMENT 3: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 3 GNEURALUCB          : Reward=1190.00, Efficiency=088.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=150, Threshold=0.582]\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=1146.00, Efficiency=084.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=150, Threshold=0.628]\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=1190.00, Efficiency=088.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=150, Threshold=0.634]\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=1350.00, Efficiency=100.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=150, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP3 Winner:iCPursuitNeuralUCB  (Gap:000.0%) [Env:Baseline (None), Attack:No X Rate:0.25, Frames:150, SCapacity=150, Alloc=Default]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 200 frames  <>  SCALED-CAPACITY: 200 frames (CAPACITY:200 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=3 ‚Üí allocation=(5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîß Allocated qubits for NONE Exp 4: (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 4: Env:Baseline (None), Attack:No, Rate:0.0, Frames:200, QubitAlloc=Default, SC:200 (Scale=1 x Cap=200), Seed: 20031\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_4\n",
      "\t‚úì QuantumExperimentRunner_4 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_200-Default_Baseline (None)_No-200_4_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_200-Default_Baseline (None)_No-200_4_paper7.pkl\n",
      "\t   File exists: True, size: 117319\n",
      "‚è© SKIPPING EXPERIMENT 4: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 4 GNEURALUCB          : Reward=1586.00, Efficiency=088.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=200, Threshold=0.582]\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=1455.00, Efficiency=080.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=200, Threshold=0.628]\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=1586.00, Efficiency=088.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=200, Threshold=0.634]\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=1800.00, Efficiency=100.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=200, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP4 Winner:iCPursuitNeuralUCB  (Gap:000.0%) [Env:Baseline (None), Attack:No X Rate:0.25, Frames:200, SCapacity=200, Alloc=Default]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 250 frames  <>  SCALED-CAPACITY: 250 frames (CAPACITY:250 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=4 ‚Üí allocation=(5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîß Allocated qubits for NONE Exp 5: (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 5: Env:Baseline (None), Attack:No, Rate:0.0, Frames:250, QubitAlloc=Default, SC:250 (Scale=1 x Cap=250), Seed: 17303\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_5\n",
      "\t‚úì QuantumExperimentRunner_5 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_250-Default_Baseline (None)_No-250_5_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_250-Default_Baseline (None)_No-250_5_paper7.pkl\n",
      "\t   File exists: True, size: 143928\n",
      "‚è© SKIPPING EXPERIMENT 5: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 5 GNEURALUCB          : Reward=1984.00, Efficiency=088.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=250, Threshold=0.582]\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=2013.00, Efficiency=089.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=250, Threshold=0.628]\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=1984.00, Efficiency=088.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=250, Threshold=0.634]\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=2250.00, Efficiency=100.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=250, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP5 Winner:iCPursuitNeuralUCB  (Gap:000.0%) [Env:Baseline (None), Attack:No X Rate:0.25, Frames:250, SCapacity=250, Alloc=Default]\n",
      "\n",
      "Total experiment time: 015.1s\n",
      "Experiments completed for none\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: STOCHASTIC RANDOM FAILURES\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: STOCHASTIC\n",
      "Category: Stochastic (Natural Random Failures)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 50 frames  <>  SCALED-CAPACITY: 50 frames (CAPACITY:50 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=0 ‚Üí allocation=(5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 1: (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 1: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:50, QubitAlloc=Default, SC:50 (Scale=1 x Cap=50), Seed: 15729\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_1\n",
      "\t‚úì QuantumExperimentRunner_1 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_50-Default_Stochastic_Random-50_1_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_50-Default_Stochastic_Random-50_1_paper7.pkl\n",
      "\t   File exists: True, size: 37478\n",
      "‚è© SKIPPING EXPERIMENT 1: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 1 GNEURALUCB          : Reward=0383.00, Efficiency=085.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=50, Threshold=0.582]\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=0347.00, Efficiency=077.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=50, Threshold=0.628]\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=0383.00, Efficiency=085.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=50, Threshold=0.634]\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=0423.00, Efficiency=094.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=50, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP1 Winner:iCPursuitNeuralUCB  (Gap:006.0%) [Env:Stochastic, Attack:Random X Rate:0.25, Frames:50, SCapacity=50, Alloc=Default]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 100 frames  <>  SCALED-CAPACITY: 100 frames (CAPACITY:100 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=1 ‚Üí allocation=(5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 2: (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 2: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:100, QubitAlloc=Default, SC:100 (Scale=1 x Cap=100), Seed: 19894\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_2\n",
      "\t‚úì QuantumExperimentRunner_2 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_100-Default_Stochastic_Random-100_2_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_100-Default_Stochastic_Random-100_2_paper7.pkl\n",
      "\t   File exists: True, size: 64114\n",
      "‚è© SKIPPING EXPERIMENT 2: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 2 GNEURALUCB          : Reward=0730.00, Efficiency=081.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=100, Threshold=0.582]\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=0725.00, Efficiency=080.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=100, Threshold=0.628]\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=0730.00, Efficiency=081.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=100, Threshold=0.634]\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=0873.00, Efficiency=097.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=100, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP2 Winner:iCPursuitNeuralUCB  (Gap:003.0%) [Env:Stochastic, Attack:Random X Rate:0.25, Frames:100, SCapacity=100, Alloc=Default]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 150 frames  <>  SCALED-CAPACITY: 150 frames (CAPACITY:150 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=2 ‚Üí allocation=(5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 3: (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 3: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:150, QubitAlloc=Default, SC:150 (Scale=1 x Cap=150), Seed: 16736\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_3\n",
      "\t‚úì QuantumExperimentRunner_3 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_150-Default_Stochastic_Random-150_3_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_150-Default_Stochastic_Random-150_3_paper7.pkl\n",
      "\t   File exists: True, size: 90723\n",
      "‚è© SKIPPING EXPERIMENT 3: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 3 GNEURALUCB          : Reward=1122.00, Efficiency=083.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=150, Threshold=0.582]\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=1084.00, Efficiency=080.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=150, Threshold=0.628]\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=1122.00, Efficiency=083.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=150, Threshold=0.634]\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=1314.00, Efficiency=097.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=150, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP3 Winner:iCPursuitNeuralUCB  (Gap:002.7%) [Env:Stochastic, Attack:Random X Rate:0.25, Frames:150, SCapacity=150, Alloc=Default]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 200 frames  <>  SCALED-CAPACITY: 200 frames (CAPACITY:200 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=3 ‚Üí allocation=(5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 4: (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 4: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:200, QubitAlloc=Default, SC:200 (Scale=1 x Cap=200), Seed: 12981\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_4\n",
      "\t‚úì QuantumExperimentRunner_4 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_200-Default_Stochastic_Random-200_4_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_200-Default_Stochastic_Random-200_4_paper7.pkl\n",
      "\t   File exists: True, size: 117323\n",
      "‚è© SKIPPING EXPERIMENT 4: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 4 GNEURALUCB          : Reward=1481.00, Efficiency=082.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=200, Threshold=0.582]\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=1532.00, Efficiency=085.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=200, Threshold=0.628]\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=1481.00, Efficiency=082.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=200, Threshold=0.634]\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=1692.00, Efficiency=094.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=200, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP4 Winner:iCPursuitNeuralUCB  (Gap:005.9%) [Env:Stochastic, Attack:Random X Rate:0.25, Frames:200, SCapacity=200, Alloc=Default]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 250 frames  <>  SCALED-CAPACITY: 250 frames (CAPACITY:250 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=4 ‚Üí allocation=(5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 5: (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 5: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:250, QubitAlloc=Default, SC:250 (Scale=1 x Cap=250), Seed: 17091\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_5\n",
      "\t‚úì QuantumExperimentRunner_5 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_250-Default_Stochastic_Random-250_5_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_250-Default_Stochastic_Random-250_5_paper7.pkl\n",
      "\t   File exists: True, size: 143932\n",
      "‚è© SKIPPING EXPERIMENT 5: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 5 GNEURALUCB          : Reward=1835.00, Efficiency=081.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=250, Threshold=0.582]\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=1848.00, Efficiency=082.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=250, Threshold=0.628]\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=1835.00, Efficiency=081.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=250, Threshold=0.634]\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=2115.00, Efficiency=094.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=250, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP5 Winner:iCPursuitNeuralUCB  (Gap:006.0%) [Env:Stochastic, Attack:Random X Rate:0.25, Frames:250, SCapacity=250, Alloc=Default]\n",
      "\n",
      "Total experiment time: 014.1s\n",
      "Experiments completed for stochastic\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: MARKOV ADVERSARIAL ATTACK\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: MARKOV\n",
      "Category: Structured (Markov Chain Based)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 50 frames  <>  SCALED-CAPACITY: 50 frames (CAPACITY:50 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=0 ‚Üí allocation=(5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîß Allocated qubits for MARKOV Exp 1: (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 1: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:50, QubitAlloc=Default, SC:50 (Scale=1 x Cap=50), Seed: 14132\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_1\n",
      "\t‚úì QuantumExperimentRunner_1 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_50-Default_Adversarial_Markov-50_1_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_50-Default_Adversarial_Markov-50_1_paper7.pkl\n",
      "\t   File exists: True, size: 37476\n",
      "‚è© SKIPPING EXPERIMENT 1: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 1 GNEURALUCB          : Reward=0182.00, Efficiency=041.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=50, Threshold=0.582]\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=0201.00, Efficiency=046.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=50, Threshold=0.628]\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=0182.00, Efficiency=041.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=50, Threshold=0.634]\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=0133.00, Efficiency=030.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=50, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP1 Winner:EXPNeuralUCB        (Gap:053.7%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:50, SCapacity=50, Alloc=Default]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 100 frames  <>  SCALED-CAPACITY: 100 frames (CAPACITY:100 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=1 ‚Üí allocation=(5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîß Allocated qubits for MARKOV Exp 2: (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 2: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:100, QubitAlloc=Default, SC:100 (Scale=1 x Cap=100), Seed: 22231\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_2\n",
      "\t‚úì QuantumExperimentRunner_2 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_100-Default_Adversarial_Markov-100_2_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_100-Default_Adversarial_Markov-100_2_paper7.pkl\n",
      "\t   File exists: True, size: 64112\n",
      "‚è© SKIPPING EXPERIMENT 2: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 2 GNEURALUCB          : Reward=0436.00, Efficiency=049.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=100, Threshold=0.582]\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=0362.00, Efficiency=041.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=100, Threshold=0.628]\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=0436.00, Efficiency=049.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=100, Threshold=0.634]\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=0432.00, Efficiency=049.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=100, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP2 Winner:GNeuralUCB          (Gap:050.1%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:100, SCapacity=100, Alloc=Default]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 150 frames  <>  SCALED-CAPACITY: 150 frames (CAPACITY:150 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=2 ‚Üí allocation=(5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîß Allocated qubits for MARKOV Exp 3: (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 3: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:150, QubitAlloc=Default, SC:150 (Scale=1 x Cap=150), Seed: 20747\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_3\n",
      "\t‚úì QuantumExperimentRunner_3 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_150-Default_Adversarial_Markov-150_3_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_150-Default_Adversarial_Markov-150_3_paper7.pkl\n",
      "\t   File exists: True, size: 90721\n",
      "‚è© SKIPPING EXPERIMENT 3: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 3 GNEURALUCB          : Reward=0714.00, Efficiency=054.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=150, Threshold=0.582]\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=0489.00, Efficiency=037.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=150, Threshold=0.628]\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=0714.00, Efficiency=054.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=150, Threshold=0.634]\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=0585.00, Efficiency=045.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=150, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP3 Winner:GNeuralUCB          (Gap:045.1%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:150, SCapacity=150, Alloc=Default]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 200 frames  <>  SCALED-CAPACITY: 200 frames (CAPACITY:200 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=3 ‚Üí allocation=(5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîß Allocated qubits for MARKOV Exp 4: (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 4: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:200, QubitAlloc=Default, SC:200 (Scale=1 x Cap=200), Seed: 15410\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_4\n",
      "\t‚úì QuantumExperimentRunner_4 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_200-Default_Adversarial_Markov-200_4_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_200-Default_Adversarial_Markov-200_4_paper7.pkl\n",
      "\t   File exists: True, size: 117321\n",
      "‚è© SKIPPING EXPERIMENT 4: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 4 GNEURALUCB          : Reward=0875.00, Efficiency=050.2% [Retries=3, Failed=0, < Threshold=3, SCapacity=200, Threshold=0.582]\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=0873.00, Efficiency=050.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=200, Threshold=0.628]\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=0875.00, Efficiency=050.2% [Retries=3, Failed=0, < Threshold=3, SCapacity=200, Threshold=0.634]\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=0747.00, Efficiency=042.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=200, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP4 Winner:GNeuralUCB          (Gap:049.8%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:200, SCapacity=200, Alloc=Default]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 250 frames  <>  SCALED-CAPACITY: 250 frames (CAPACITY:250 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=4 ‚Üí allocation=(5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîß Allocated qubits for MARKOV Exp 5: (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 5: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:250, QubitAlloc=Default, SC:250 (Scale=1 x Cap=250), Seed: 22674\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_5\n",
      "\t‚úì QuantumExperimentRunner_5 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_250-Default_Adversarial_Markov-250_5_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_250-Default_Adversarial_Markov-250_5_paper7.pkl\n",
      "\t   File exists: True, size: 143930\n",
      "‚è© SKIPPING EXPERIMENT 5: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 5 GNEURALUCB          : Reward=1117.00, Efficiency=050.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=250, Threshold=0.582]\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=1166.00, Efficiency=052.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=250, Threshold=0.628]\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=1117.00, Efficiency=050.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=250, Threshold=0.634]\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=1032.00, Efficiency=046.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=250, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP5 Winner:EXPNeuralUCB        (Gap:047.1%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:250, SCapacity=250, Alloc=Default]\n",
      "\n",
      "Total experiment time: 013.8s\n",
      "Experiments completed for markov\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: ADAPTIVE ADVERSARIAL ATTACK\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: ADAPTIVE\n",
      "Category: Adaptive (Reactive Strategic)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 50 frames  <>  SCALED-CAPACITY: 50 frames (CAPACITY:50 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=0 ‚Üí allocation=(5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 1: (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 1: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:50, QubitAlloc=Default, SC:50 (Scale=1 x Cap=50), Seed: 21427\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_1\n",
      "\t‚úì QuantumExperimentRunner_1 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_50-Default_Adversarial_Adaptive-50_1_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_50-Default_Adversarial_Adaptive-50_1_paper7.pkl\n",
      "\t   File exists: True, size: 37482\n",
      "‚è© SKIPPING EXPERIMENT 1: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 1 GNEURALUCB          : Reward=0281.00, Efficiency=062.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=50, Threshold=0.582]\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=0254.00, Efficiency=056.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=50, Threshold=0.628]\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=0281.00, Efficiency=062.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=50, Threshold=0.634]\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=0378.00, Efficiency=084.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=50, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP1 Winner:iCPursuitNeuralUCB  (Gap:015.6%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:50, SCapacity=50, Alloc=Default]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 100 frames  <>  SCALED-CAPACITY: 100 frames (CAPACITY:100 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=1 ‚Üí allocation=(5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 2: (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 2: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:100, QubitAlloc=Default, SC:100 (Scale=1 x Cap=100), Seed: 13200\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_2\n",
      "\t‚úì QuantumExperimentRunner_2 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_100-Default_Adversarial_Adaptive-100_2_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_100-Default_Adversarial_Adaptive-100_2_paper7.pkl\n",
      "\t   File exists: True, size: 64118\n",
      "‚è© SKIPPING EXPERIMENT 2: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 2 GNEURALUCB          : Reward=0562.00, Efficiency=062.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=100, Threshold=0.582]\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=0679.00, Efficiency=076.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=100, Threshold=0.628]\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=0562.00, Efficiency=062.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=100, Threshold=0.634]\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=0693.00, Efficiency=077.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=100, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP2 Winner:iCPursuitNeuralUCB  (Gap:022.5%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:100, SCapacity=100, Alloc=Default]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 150 frames  <>  SCALED-CAPACITY: 150 frames (CAPACITY:150 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=2 ‚Üí allocation=(5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 3: (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 3: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:150, QubitAlloc=Default, SC:150 (Scale=1 x Cap=150), Seed: 18005\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_3\n",
      "\t‚úì QuantumExperimentRunner_3 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_150-Default_Adversarial_Adaptive-150_3_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_150-Default_Adversarial_Adaptive-150_3_paper7.pkl\n",
      "\t   File exists: True, size: 90727\n",
      "‚è© SKIPPING EXPERIMENT 3: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 3 GNEURALUCB          : Reward=0882.00, Efficiency=065.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=150, Threshold=0.582]\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=0879.00, Efficiency=065.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=150, Threshold=0.628]\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=0882.00, Efficiency=065.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=150, Threshold=0.634]\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=1053.00, Efficiency=078.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=150, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP3 Winner:iCPursuitNeuralUCB  (Gap:021.6%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:150, SCapacity=150, Alloc=Default]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 200 frames  <>  SCALED-CAPACITY: 200 frames (CAPACITY:200 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=3 ‚Üí allocation=(5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 4: (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 4: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:200, QubitAlloc=Default, SC:200 (Scale=1 x Cap=200), Seed: 12955\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_4\n",
      "\t‚úì QuantumExperimentRunner_4 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_200-Default_Adversarial_Adaptive-200_4_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_200-Default_Adversarial_Adaptive-200_4_paper7.pkl\n",
      "\t   File exists: True, size: 117327\n",
      "‚è© SKIPPING EXPERIMENT 4: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 4 GNEURALUCB          : Reward=1272.00, Efficiency=071.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=200, Threshold=0.582]\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=1157.00, Efficiency=064.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=200, Threshold=0.628]\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=1272.00, Efficiency=071.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=200, Threshold=0.634]\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=1350.00, Efficiency=075.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=200, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP4 Winner:iCPursuitNeuralUCB  (Gap:024.5%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:200, SCapacity=200, Alloc=Default]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 250 frames  <>  SCALED-CAPACITY: 250 frames (CAPACITY:250 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=4 ‚Üí allocation=(5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 5: (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 5: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:250, QubitAlloc=Default, SC:250 (Scale=1 x Cap=250), Seed: 14950\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_5\n",
      "\t‚úì QuantumExperimentRunner_5 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_250-Default_Adversarial_Adaptive-250_5_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_250-Default_Adversarial_Adaptive-250_5_paper7.pkl\n",
      "\t   File exists: True, size: 143936\n",
      "‚è© SKIPPING EXPERIMENT 5: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 5 GNEURALUCB          : Reward=1516.00, Efficiency=067.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=250, Threshold=0.582]\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=1464.00, Efficiency=065.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=250, Threshold=0.628]\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=1516.00, Efficiency=067.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=250, Threshold=0.634]\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=1656.00, Efficiency=074.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=250, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP5 Winner:iCPursuitNeuralUCB  (Gap:025.9%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:250, SCapacity=250, Alloc=Default]\n",
      "\n",
      "Total experiment time: 015.8s\n",
      "Experiments completed for adaptive\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: ONLINE ADAPTIVE ATTACK\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: ONLINEADAPTIVE\n",
      "Category: Online Adaptive (Real-time Strategic)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 50 frames  <>  SCALED-CAPACITY: 50 frames (CAPACITY:50 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=0 ‚Üí allocation=(5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 1: (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:50, QubitAlloc=Default, SC:50 (Scale=1 x Cap=50), Seed: 14732\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_1\n",
      "\t‚úì QuantumExperimentRunner_1 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_50-Default_Adversarial_OnlineAdaptive-50_1_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_50-Default_Adversarial_OnlineAdaptive-50_1_paper7.pkl\n",
      "\t   File exists: True, size: 37500\n",
      "‚è© SKIPPING EXPERIMENT 1: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 1 GNEURALUCB          : Reward=0355.00, Efficiency=079.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=50, Threshold=0.582]\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=0360.00, Efficiency=080.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=50, Threshold=0.628]\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=0355.00, Efficiency=079.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=50, Threshold=0.634]\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=0351.00, Efficiency=078.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=50, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP1 Winner:EXPNeuralUCB        (Gap:019.5%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:50, SCapacity=50, Alloc=Default]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 100 frames  <>  SCALED-CAPACITY: 100 frames (CAPACITY:100 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=1 ‚Üí allocation=(5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 2: (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:100, QubitAlloc=Default, SC:100 (Scale=1 x Cap=100), Seed: 14647\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_2\n",
      "\t‚úì QuantumExperimentRunner_2 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_100-Default_Adversarial_OnlineAdaptive-100_2_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_100-Default_Adversarial_OnlineAdaptive-100_2_paper7.pkl\n",
      "\t   File exists: True, size: 64136\n",
      "‚è© SKIPPING EXPERIMENT 2: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 2 GNEURALUCB          : Reward=0583.00, Efficiency=065.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=100, Threshold=0.582]\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=0632.00, Efficiency=070.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=100, Threshold=0.628]\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=0583.00, Efficiency=065.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=100, Threshold=0.634]\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=0684.00, Efficiency=076.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=100, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP2 Winner:iCPursuitNeuralUCB  (Gap:023.3%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:100, SCapacity=100, Alloc=Default]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 150 frames  <>  SCALED-CAPACITY: 150 frames (CAPACITY:150 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=2 ‚Üí allocation=(5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 3: (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:150, QubitAlloc=Default, SC:150 (Scale=1 x Cap=150), Seed: 21138\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_3\n",
      "\t‚úì QuantumExperimentRunner_3 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_150-Default_Adversarial_OnlineAdaptive-150_3_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_150-Default_Adversarial_OnlineAdaptive-150_3_paper7.pkl\n",
      "\t   File exists: True, size: 90745\n",
      "‚è© SKIPPING EXPERIMENT 3: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 3 GNEURALUCB          : Reward=0909.00, Efficiency=067.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=150, Threshold=0.582]\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=0967.00, Efficiency=072.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=150, Threshold=0.628]\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=0909.00, Efficiency=067.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=150, Threshold=0.634]\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=1026.00, Efficiency=076.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=150, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP3 Winner:iCPursuitNeuralUCB  (Gap:023.4%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:150, SCapacity=150, Alloc=Default]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 200 frames  <>  SCALED-CAPACITY: 200 frames (CAPACITY:200 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=3 ‚Üí allocation=(5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 4: (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:200, QubitAlloc=Default, SC:200 (Scale=1 x Cap=200), Seed: 16677\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_4\n",
      "\t‚úì QuantumExperimentRunner_4 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_200-Default_Adversarial_OnlineAdaptive-200_4_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_200-Default_Adversarial_OnlineAdaptive-200_4_paper7.pkl\n",
      "\t   File exists: True, size: 117345\n",
      "‚è© SKIPPING EXPERIMENT 4: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 4 GNEURALUCB          : Reward=1135.00, Efficiency=063.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=200, Threshold=0.582]\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=1180.00, Efficiency=065.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=200, Threshold=0.628]\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=1135.00, Efficiency=063.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=200, Threshold=0.634]\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=1332.00, Efficiency=074.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=200, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP4 Winner:iCPursuitNeuralUCB  (Gap:025.6%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:200, SCapacity=200, Alloc=Default]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 250 frames  <>  SCALED-CAPACITY: 250 frames (CAPACITY:250 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=4 ‚Üí allocation=(5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 5: (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:250, QubitAlloc=Default, SC:250 (Scale=1 x Cap=250), Seed: 22447\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_5\n",
      "\t‚úì QuantumExperimentRunner_5 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_250-Default_Adversarial_OnlineAdaptive-250_5_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_250-Default_Adversarial_OnlineAdaptive-250_5_paper7.pkl\n",
      "\t   File exists: True, size: 143954\n",
      "‚è© SKIPPING EXPERIMENT 5: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 5 GNEURALUCB          : Reward=1573.00, Efficiency=070.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=250, Threshold=0.582]\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=1500.00, Efficiency=067.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=250, Threshold=0.628]\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=1573.00, Efficiency=070.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=250, Threshold=0.634]\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=1728.00, Efficiency=077.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=250, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP5 Winner:iCPursuitNeuralUCB  (Gap:022.6%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:250, SCapacity=250, Alloc=Default]\n",
      "\n",
      "Total experiment time: 016.4s\n",
      "Experiments completed for onlineadaptive\n",
      "‚úì Scenario 'none' evaluation completed.\n",
      "‚úì Scenario 'stochastic' evaluation completed.\n",
      "‚úì Scenario 'markov' evaluation completed.\n",
      "‚úì Scenario 'adaptive' evaluation completed.\n",
      "‚úì Scenario 'onlineadaptive' evaluation completed.\n",
      "\n",
      "======================================================================\n",
      "COMPREHENSIVE SCENARIO PERFORMANCE ANALYSIS\n",
      "======================================================================\n",
      "SCENARIO: NONE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 1350.00\n",
      "\t‚Ä¢ Winner Avg Gap: 0000.00%\n",
      "\t‚Ä¢ Winner Avg Reward: 1350.00\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0100.00%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 5 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: NONE\n",
      "======================================================================\n",
      "SCENARIO: \tBASELINE (OPTIMAL CONDITIONS)\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 5/5 experiments)\n",
      "\tWinner Avg Gap: \t000.0%\n",
      "\tWinner Avg Efficiency: \t100.0%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t100.0% Efficiency \t(Won 5/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t088.1% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t088.1% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t086.8% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: STOCHASTIC\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 1349.60\n",
      "\t‚Ä¢ Winner Avg Gap: 0004.71%\n",
      "\t‚Ä¢ Winner Avg Reward: 1283.40\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0095.29%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 5 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: STOCHASTIC\n",
      "======================================================================\n",
      "SCENARIO: \tSTOCHASTIC RANDOM FAILURES\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 5/5 experiments)\n",
      "\tWinner Avg Gap: \t004.7%\n",
      "\tWinner Avg Efficiency: \t095.3%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t095.3% Efficiency \t(Won 5/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t082.6% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t082.6% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t081.1% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: MARKOV\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: GNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 1311.00\n",
      "\t‚Ä¢ Winner Avg Gap: 0050.48%\n",
      "\t‚Ä¢ Winner Avg Reward: 0664.80\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0049.52%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 3 wins\n",
      "\t\t- EXPNeuralUCB: 2 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 0 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: MARKOV\n",
      "======================================================================\n",
      "SCENARIO: \tMARKOV ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tGNeuralUCB (Won 3/5 experiments)\n",
      "\tWinner Avg Gap: \t050.5%\n",
      "\tWinner Avg Efficiency: \t049.5%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ GNeuralUCB     : \t049.5% Efficiency \t(Won 3/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t049.5% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t045.7% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t043.0% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 1341.20\n",
      "\t‚Ä¢ Winner Avg Gap: 0022.01%\n",
      "\t‚Ä¢ Winner Avg Reward: 1026.00\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0077.99%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 5 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tADAPTIVE ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 5/5 experiments)\n",
      "\tWinner Avg Gap: \t022.0%\n",
      "\tWinner Avg Efficiency: \t078.0%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t078.0% Efficiency \t(Won 5/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t066.1% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t066.1% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t065.7% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ONLINEADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 1340.40\n",
      "\t‚Ä¢ Winner Avg Gap: 0023.28%\n",
      "\t‚Ä¢ Winner Avg Reward: 1024.20\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0076.72%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 1 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 4 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ONLINEADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tONLINE ADAPTIVE ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 4/5 experiments)\n",
      "\tWinner Avg Gap: \t023.3%\n",
      "\tWinner Avg Efficiency: \t076.7%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t076.7% Efficiency \t(Won 4/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t071.3% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t069.3% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t069.3% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "KEY INSIGHTS:\n",
      "Best Performing Model Analysis (iCPursuitNeuralUCB):\n",
      "\t‚Ä¢ Stochastic Performance:    \t1283.400\n",
      "\t‚Ä¢ Baseline Performance:      \t1350.000\n",
      "\t‚Ä¢ Performance Retention:     \t095.1%\n",
      "\tEXCELLENT:          \tMinimal performance loss under realistic conditions\n",
      "Statistical Analysis:\n",
      "\t‚Ä¢ Total models evaluated:     \t5\n",
      "\t‚Ä¢ Experiments per environment:\t5\n",
      "\t‚Ä¢ Quantum network simulation: \tComprehensive stochastic modeling\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "COMPREHENSIVE SCENARIO PERFORMANCE ANALYSIS\n",
      "======================================================================\n",
      "SCENARIO: NONE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 1350.00\n",
      "\t‚Ä¢ Winner Avg Gap: 0000.00%\n",
      "\t‚Ä¢ Winner Avg Reward: 1350.00\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0100.00%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 5 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: NONE\n",
      "======================================================================\n",
      "SCENARIO: \tBASELINE (OPTIMAL CONDITIONS)\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 5/5 experiments)\n",
      "\tWinner Avg Gap: \t000.0%\n",
      "\tWinner Avg Efficiency: \t100.0%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t100.0% Efficiency \t(Won 5/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t088.1% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t088.1% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t086.8% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: STOCHASTIC\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 1349.60\n",
      "\t‚Ä¢ Winner Avg Gap: 0004.71%\n",
      "\t‚Ä¢ Winner Avg Reward: 1283.40\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0095.29%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 5 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: STOCHASTIC\n",
      "======================================================================\n",
      "SCENARIO: \tSTOCHASTIC RANDOM FAILURES\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 5/5 experiments)\n",
      "\tWinner Avg Gap: \t004.7%\n",
      "\tWinner Avg Efficiency: \t095.3%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t095.3% Efficiency \t(Won 5/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t082.6% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t082.6% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t081.1% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: MARKOV\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: GNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 1311.00\n",
      "\t‚Ä¢ Winner Avg Gap: 0050.48%\n",
      "\t‚Ä¢ Winner Avg Reward: 0664.80\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0049.52%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 3 wins\n",
      "\t\t- EXPNeuralUCB: 2 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 0 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: MARKOV\n",
      "======================================================================\n",
      "SCENARIO: \tMARKOV ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tGNeuralUCB (Won 3/5 experiments)\n",
      "\tWinner Avg Gap: \t050.5%\n",
      "\tWinner Avg Efficiency: \t049.5%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ GNeuralUCB     : \t049.5% Efficiency \t(Won 3/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t049.5% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t045.7% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t043.0% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 1341.20\n",
      "\t‚Ä¢ Winner Avg Gap: 0022.01%\n",
      "\t‚Ä¢ Winner Avg Reward: 1026.00\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0077.99%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 5 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tADAPTIVE ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 5/5 experiments)\n",
      "\tWinner Avg Gap: \t022.0%\n",
      "\tWinner Avg Efficiency: \t078.0%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t078.0% Efficiency \t(Won 5/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t066.1% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t066.1% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t065.7% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ONLINEADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 1340.40\n",
      "\t‚Ä¢ Winner Avg Gap: 0023.28%\n",
      "\t‚Ä¢ Winner Avg Reward: 1024.20\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0076.72%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 1 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 4 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ONLINEADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tONLINE ADAPTIVE ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 4/5 experiments)\n",
      "\tWinner Avg Gap: \t023.3%\n",
      "\tWinner Avg Efficiency: \t076.7%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t076.7% Efficiency \t(Won 4/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t071.3% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t069.3% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t069.3% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "‚úÖ Evaluation completed!\n",
      "[Logging Redirect Stopped]\n",
      "\n",
      "üßπ Final cleanup for Default\n",
      "\n",
      "======================================================================\n",
      "‚úÖ COMPLETED: Default\n",
      "======================================================================\n",
      "\n",
      "Default COMPLETED SUCCESSFULLY\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Preparing: Default at scale 1.5\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üîß Generating physics parameters for model: paper7\n",
      "\n",
      "===================== GET LOCAL REGISTRY =====================\n",
      "‚Üí Skipping local cache (force=True or file missing)\n",
      "\n",
      "===================== BUILD LOCAL REGISTRY =====================\n",
      "\n",
      "================================================================================\n",
      "üîç SCANNING LOCAL FILES\n",
      "================================================================================\n",
      "Parameters: load_to_drive=False, force=False\n",
      "\n",
      "üìÇ Checking DRIVE mode: /content/drive/Shareddrives/ai_quantum_computing/quantum_data_lake\n",
      "   ‚ö†Ô∏è  Path does not exist, skipping\n",
      "\n",
      "üìÇ Checking LOCAL mode: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config\n",
      "   ‚úÖ Path exists, starting walk...\n",
      "   üö∂ Walking directory tree: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config\n",
      "\n",
      "   üìÅ Directory: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201\n",
      "      Relative: framework_state/day_20260201\n",
      "      Component: framework_state\n",
      "      Date: day_20260201\n",
      "      üìÑ Processing 2514 files in framework_state/day_20260201\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "      üìä framework_state/day_20260201: 2488/2514 files processed\n",
      "      üìä framework_state/day_20260201: 0/2514 files skipped\n",
      "      üìä framework_state/day_20260201: 26/2514 files conflicted\n",
      "\n",
      "   üìÅ Directory: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/model_state/day_20260201\n",
      "      Relative: model_state/day_20260201\n",
      "      Component: model_state\n",
      "      Date: day_20260201\n",
      "      üìÑ Processing 8842 files in model_state/day_20260201\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "      üìä model_state/day_20260201: 8842/8842 files processed\n",
      "      üìä model_state/day_20260201: 0/8842 files skipped\n",
      "      üìä model_state/day_20260201: 0/8842 files conflicted\n",
      "\n",
      "   üìä Processed 2 directories\n",
      "\n",
      "================================================================================\n",
      "üì¶ BUILDING FINAL REGISTRY\n",
      "================================================================================\n",
      "Components found: ['framework_state', 'model_state']\n",
      "  ‚Ä¢ framework_state: 2488 files\n",
      "  ‚Ä¢ model_state: 8842 files\n",
      "\n",
      "‚úÖ SCAN COMPLETE\n",
      "Modes scanned: 1\n",
      "Total files in registry: 11330\n",
      "================================================================================\n",
      "\n",
      "\t‚Üí Filesystem scan found 11330 files\n",
      "\n",
      "===================== GET DRIVE REGISTRY =====================\n",
      "===================== REGISTRY BUILD COMPLETE =====================\n",
      "\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "\tüì¶ LocalBackupManager Registry Saved Locally in LOCAL\n",
      "BUILDING REGISTRY WITH 0 EXPECTED COMPONENTS KEYS\n",
      "\n",
      "===================== GET LOCAL REGISTRY =====================\n",
      "‚Üí Skipping local cache (force=True or file missing)\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "\tüì¶ LocalBackupManager Registry Saved Locally in LOCAL\n",
      "\n",
      "======================================================================\n",
      "üéØ AllocatorRunner initialized: Default\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "üöÄ STARTING ALLOCATOR: Default\n",
      "======================================================================\n",
      "\n",
      "üìä Physics Model: paper7\n",
      "\n",
      "üìã Allocator Config:\n",
      "   Type: Default\n",
      "   Testbed: default\n",
      "   Paths: 15\n",
      "   Total Qubits: 75\n",
      "   Min per route: 2\n",
      "   Seed: 42\n",
      "‚úÖ Allocator created: (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "‚úì Allocator: QubitAllocator (15 paths)\n",
      "   Initial allocation: (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üìä Paper7 Topology: Real AS (as20000101.txt)\n",
      "üìä Paper7 Paths: 15 paths from 5-shortest between 3 ISPs\n",
      "üìä Paper7 Contexts: 15 context vectors generated\n",
      "üìä Paper7 Rewards: Context-aware (mode=neg_hop)\n",
      "‚è±Ô∏è  get_physics_params_paper7() time: 3.3 ms\n",
      "\n",
      "======================================================================\n",
      "RUN 1 | Scale: 1.5 | Exp: 5\n",
      "======================================================================\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "\n",
      "\tüîÑ Resume: MultiRunEvaluator\n",
      "\n",
      "=====================================================\n",
      "üîç GENERATING EXPECTED KEYS FROM EVALUATOR\n",
      "=====================================================\n",
      "  ‚Ä¢ Evaluator filename: MultiRunEvaluator_75-Default_All_All-50_50_5_S1_5T_paper7.pkl\n",
      "\n",
      "üß© PARSED COMPONENTS\n",
      "  ‚Ä¢ cap_id:        75\n",
      "  ‚Ä¢ allocator_id:  Default\n",
      "  ‚Ä¢ env_id:        All\n",
      "  ‚Ä¢ attack_id:     All\n",
      "  ‚Ä¢ base_frames:   50\n",
      "  ‚Ä¢ frame_step:    50\n",
      "  ‚Ä¢ runs_id:       5\n",
      "\n",
      "=====================================================\n",
      "üß™ GENERATING KEYS FOR EACH RUN\n",
      "=====================================================\n",
      "\n",
      "--- Run 1/5 -----------------------\n",
      "\n",
      "=====================================================\n",
      "üì¶ FINAL EXPECTED KEYS\n",
      "=====================================================\n",
      "  ‚Ä¢ Runner keys: 11\n",
      "\n",
      "  ‚Ä¢ Model keys: 50\n",
      "\n",
      "--- Run 2/5 -----------------------\n",
      "\n",
      "=====================================================\n",
      "üì¶ FINAL EXPECTED KEYS\n",
      "=====================================================\n",
      "  ‚Ä¢ Runner keys: 21\n",
      "\n",
      "  ‚Ä¢ Model keys: 100\n",
      "\n",
      "--- Run 3/5 -----------------------\n",
      "\n",
      "=====================================================\n",
      "üì¶ FINAL EXPECTED KEYS\n",
      "=====================================================\n",
      "  ‚Ä¢ Runner keys: 31\n",
      "\n",
      "  ‚Ä¢ Model keys: 150\n",
      "\n",
      "--- Run 4/5 -----------------------\n",
      "\n",
      "=====================================================\n",
      "üì¶ FINAL EXPECTED KEYS\n",
      "=====================================================\n",
      "  ‚Ä¢ Runner keys: 41\n",
      "\n",
      "  ‚Ä¢ Model keys: 200\n",
      "\n",
      "--- Run 5/5 -----------------------\n",
      "\n",
      "=====================================================\n",
      "üì¶ FINAL EXPECTED KEYS\n",
      "=====================================================\n",
      "  ‚Ä¢ Runner keys: 51\n",
      "\n",
      "  ‚Ä¢ Model keys: 250\n",
      "\n",
      "EXPECTED KEY GENERATION COMPLETE\n",
      "\n",
      "RESTORING FROM DRIVE 1\n",
      "RESTORING FROM DRIVE 2\n",
      "\t‚ö†Ô∏è Registry exists ‚Üí aborting restore\n",
      "\t‚úì MultiRunEvaluator Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/MultiRunEvaluator_75-Default_All_All-50_50_5_S1_5T_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/MultiRunEvaluator_75-Default_All_All-50_50_5_S1_5T_paper7.pkl\n",
      "\t   File exists: True, size: 1087548\n",
      "EQUAL METHOD\n",
      "Multi-Run Evaluator Initialized\n",
      "Environment Type: None\n",
      "Frame Range: 50 -> 250 (step: 50)\n",
      "quantum_exps-Default(paper7)_alloc-all_envs-5_attacks-50_50-5_runs-S1.5T\n",
      "[Logging Redirect Initialized]\n",
      "Log File: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/quantum_logs/quantum_exps-Default(paper7)_alloc-all_envs-5_attacks-50_50-5_runs-S1.5T_20260201_log.txt\n",
      "‚öô Running evaluation...\n",
      "======================================================================\n",
      "SCENARIOS MODEL EVALUATION\n",
      "======================================================================\n",
      "Testing algorithm performance against:\n",
      "\t‚Ä¢ Stochastic:  \tNatural quantum decoherence and network failures\n",
      "\t‚Ä¢ Baseline:    \tOptimal conditions for validation\n",
      "======================================================================\n",
      "Models to Test:             \tOracle, GNeuralUCB, EXPNeuralUCB, CPursuitNeuralUCB, iCPursuitNeuralUCB\n",
      "Experiments per Scenario:   \t5\n",
      "======================================================================\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: BASELINE (OPTIMAL CONDITIONS)\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: NONE\n",
      "Category: Baseline (No Attacks)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 50 frames  <>  SCALED-CAPACITY: 75.0 frames (CAPACITY:50 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=0 ‚Üí allocation=(5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîß Allocated qubits for NONE Exp 1: (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 1: Env:Baseline (None), Attack:No, Rate:0.0, Frames:50, QubitAlloc=Default, SC:75 (Scale=1.5 x Cap=50), Seed: 15373\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_1\n",
      "\t‚úì QuantumExperimentRunner_1 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_75-Default_Baseline (None)_No-50_1_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_75-Default_Baseline (None)_No-50_1_paper7.pkl\n",
      "\t   File exists: True, size: 37474\n",
      "‚è© SKIPPING EXPERIMENT 1: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 1 GNEURALUCB          : Reward=0396.00, Efficiency=088.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=75.0, Threshold=0.582]\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=0400.00, Efficiency=088.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=75.0, Threshold=0.628]\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=0396.00, Efficiency=088.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=75.0, Threshold=0.634]\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=0450.00, Efficiency=100.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=75.0, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP1 Winner:iCPursuitNeuralUCB  (Gap:000.0%) [Env:Baseline (None), Attack:No X Rate:0.25, Frames:50, SCapacity=75.0, Alloc=Default]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 100 frames  <>  SCALED-CAPACITY: 150.0 frames (CAPACITY:100 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=1 ‚Üí allocation=(5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîß Allocated qubits for NONE Exp 2: (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 2: Env:Baseline (None), Attack:No, Rate:0.0, Frames:100, QubitAlloc=Default, SC:150 (Scale=1.5 x Cap=100), Seed: 12644\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_2\n",
      "\t‚úì QuantumExperimentRunner_2 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_150-Default_Baseline (None)_No-100_2_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_150-Default_Baseline (None)_No-100_2_paper7.pkl\n",
      "\t   File exists: True, size: 64110\n",
      "‚è© SKIPPING EXPERIMENT 2: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 2 GNEURALUCB          : Reward=0794.00, Efficiency=088.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=150.0, Threshold=0.582]\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=0768.00, Efficiency=085.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=150.0, Threshold=0.628]\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=0794.00, Efficiency=088.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=150.0, Threshold=0.634]\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=0900.00, Efficiency=100.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=150.0, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP2 Winner:iCPursuitNeuralUCB  (Gap:000.0%) [Env:Baseline (None), Attack:No X Rate:0.25, Frames:100, SCapacity=150.0, Alloc=Default]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 150 frames  <>  SCALED-CAPACITY: 225.0 frames (CAPACITY:150 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=2 ‚Üí allocation=(5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîß Allocated qubits for NONE Exp 3: (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 3: Env:Baseline (None), Attack:No, Rate:0.0, Frames:150, QubitAlloc=Default, SC:225 (Scale=1.5 x Cap=150), Seed: 20257\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_3\n",
      "\t‚úì QuantumExperimentRunner_3 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_225-Default_Baseline (None)_No-150_3_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_225-Default_Baseline (None)_No-150_3_paper7.pkl\n",
      "\t   File exists: True, size: 90719\n",
      "‚è© SKIPPING EXPERIMENT 3: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 3 GNEURALUCB          : Reward=1190.00, Efficiency=088.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=225.0, Threshold=0.582]\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=1205.00, Efficiency=089.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=225.0, Threshold=0.628]\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=1190.00, Efficiency=088.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=225.0, Threshold=0.634]\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=1350.00, Efficiency=100.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=225.0, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP3 Winner:iCPursuitNeuralUCB  (Gap:000.0%) [Env:Baseline (None), Attack:No X Rate:0.25, Frames:150, SCapacity=225.0, Alloc=Default]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 200 frames  <>  SCALED-CAPACITY: 300.0 frames (CAPACITY:200 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=3 ‚Üí allocation=(5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîß Allocated qubits for NONE Exp 4: (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 4: Env:Baseline (None), Attack:No, Rate:0.0, Frames:200, QubitAlloc=Default, SC:300 (Scale=1.5 x Cap=200), Seed: 20031\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_4\n",
      "\t‚úì QuantumExperimentRunner_4 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_300-Default_Baseline (None)_No-200_4_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_300-Default_Baseline (None)_No-200_4_paper7.pkl\n",
      "\t   File exists: True, size: 117320\n",
      "‚è© SKIPPING EXPERIMENT 4: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 4 GNEURALUCB          : Reward=1586.00, Efficiency=088.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=300.0, Threshold=0.582]\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=1599.00, Efficiency=088.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=300.0, Threshold=0.628]\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=1586.00, Efficiency=088.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=300.0, Threshold=0.634]\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=1800.00, Efficiency=100.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=300.0, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP4 Winner:iCPursuitNeuralUCB  (Gap:000.0%) [Env:Baseline (None), Attack:No X Rate:0.25, Frames:200, SCapacity=300.0, Alloc=Default]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 250 frames  <>  SCALED-CAPACITY: 375.0 frames (CAPACITY:250 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=4 ‚Üí allocation=(5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîß Allocated qubits for NONE Exp 5: (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 5: Env:Baseline (None), Attack:No, Rate:0.0, Frames:250, QubitAlloc=Default, SC:375 (Scale=1.5 x Cap=250), Seed: 17303\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_5\n",
      "\t‚úì QuantumExperimentRunner_5 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_375-Default_Baseline (None)_No-250_5_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_375-Default_Baseline (None)_No-250_5_paper7.pkl\n",
      "\t   File exists: True, size: 143929\n",
      "‚è© SKIPPING EXPERIMENT 5: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 5 GNEURALUCB          : Reward=1984.00, Efficiency=088.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=375.0, Threshold=0.582]\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=2022.00, Efficiency=089.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=375.0, Threshold=0.628]\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=1984.00, Efficiency=088.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=375.0, Threshold=0.634]\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=2250.00, Efficiency=100.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=375.0, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP5 Winner:iCPursuitNeuralUCB  (Gap:000.0%) [Env:Baseline (None), Attack:No X Rate:0.25, Frames:250, SCapacity=375.0, Alloc=Default]\n",
      "\n",
      "Total experiment time: 012.9s\n",
      "Experiments completed for none\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: STOCHASTIC RANDOM FAILURES\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: STOCHASTIC\n",
      "Category: Stochastic (Natural Random Failures)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 50 frames  <>  SCALED-CAPACITY: 75.0 frames (CAPACITY:50 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=0 ‚Üí allocation=(5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 1: (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 1: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:50, QubitAlloc=Default, SC:75 (Scale=1.5 x Cap=50), Seed: 15729\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_1\n",
      "\t‚úì QuantumExperimentRunner_1 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_75-Default_Stochastic_Random-50_1_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_75-Default_Stochastic_Random-50_1_paper7.pkl\n",
      "\t   File exists: True, size: 37478\n",
      "‚è© SKIPPING EXPERIMENT 1: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 1 GNEURALUCB          : Reward=0373.00, Efficiency=082.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=75.0, Threshold=0.582]\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=0333.00, Efficiency=074.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=75.0, Threshold=0.628]\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=0373.00, Efficiency=082.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=75.0, Threshold=0.634]\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=0432.00, Efficiency=096.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=75.0, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP1 Winner:iCPursuitNeuralUCB  (Gap:004.0%) [Env:Stochastic, Attack:Random X Rate:0.25, Frames:50, SCapacity=75.0, Alloc=Default]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 100 frames  <>  SCALED-CAPACITY: 150.0 frames (CAPACITY:100 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=1 ‚Üí allocation=(5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 2: (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 2: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:100, QubitAlloc=Default, SC:150 (Scale=1.5 x Cap=100), Seed: 19894\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_2\n",
      "\t‚úì QuantumExperimentRunner_2 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_150-Default_Stochastic_Random-100_2_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_150-Default_Stochastic_Random-100_2_paper7.pkl\n",
      "\t   File exists: True, size: 64114\n",
      "‚è© SKIPPING EXPERIMENT 2: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 2 GNEURALUCB          : Reward=0744.00, Efficiency=082.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=150.0, Threshold=0.582]\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=0701.00, Efficiency=077.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=150.0, Threshold=0.628]\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=0744.00, Efficiency=082.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=150.0, Threshold=0.634]\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=0882.00, Efficiency=098.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=150.0, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP2 Winner:iCPursuitNeuralUCB  (Gap:002.0%) [Env:Stochastic, Attack:Random X Rate:0.25, Frames:100, SCapacity=150.0, Alloc=Default]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 150 frames  <>  SCALED-CAPACITY: 225.0 frames (CAPACITY:150 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=2 ‚Üí allocation=(5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 3: (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 3: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:150, QubitAlloc=Default, SC:225 (Scale=1.5 x Cap=150), Seed: 16736\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_3\n",
      "\t‚úì QuantumExperimentRunner_3 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_225-Default_Stochastic_Random-150_3_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_225-Default_Stochastic_Random-150_3_paper7.pkl\n",
      "\t   File exists: True, size: 90723\n",
      "‚è© SKIPPING EXPERIMENT 3: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 3 GNEURALUCB          : Reward=1109.00, Efficiency=082.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=225.0, Threshold=0.582]\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=1113.00, Efficiency=082.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=225.0, Threshold=0.628]\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=1109.00, Efficiency=082.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=225.0, Threshold=0.634]\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=1233.00, Efficiency=091.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=225.0, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP3 Winner:iCPursuitNeuralUCB  (Gap:008.7%) [Env:Stochastic, Attack:Random X Rate:0.25, Frames:150, SCapacity=225.0, Alloc=Default]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 200 frames  <>  SCALED-CAPACITY: 300.0 frames (CAPACITY:200 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=3 ‚Üí allocation=(5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 4: (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 4: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:200, QubitAlloc=Default, SC:300 (Scale=1.5 x Cap=200), Seed: 12981\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_4\n",
      "\t‚úì QuantumExperimentRunner_4 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_300-Default_Stochastic_Random-200_4_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_300-Default_Stochastic_Random-200_4_paper7.pkl\n",
      "\t   File exists: True, size: 117324\n",
      "‚è© SKIPPING EXPERIMENT 4: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 4 GNEURALUCB          : Reward=1503.00, Efficiency=083.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=300.0, Threshold=0.582]\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=1377.00, Efficiency=076.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=300.0, Threshold=0.628]\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=1503.00, Efficiency=083.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=300.0, Threshold=0.634]\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=1656.00, Efficiency=092.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=300.0, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP4 Winner:iCPursuitNeuralUCB  (Gap:007.9%) [Env:Stochastic, Attack:Random X Rate:0.25, Frames:200, SCapacity=300.0, Alloc=Default]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 250 frames  <>  SCALED-CAPACITY: 375.0 frames (CAPACITY:250 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=4 ‚Üí allocation=(5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 5: (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 5: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:250, QubitAlloc=Default, SC:375 (Scale=1.5 x Cap=250), Seed: 17091\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_5\n",
      "\t‚úì QuantumExperimentRunner_5 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_375-Default_Stochastic_Random-250_5_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_375-Default_Stochastic_Random-250_5_paper7.pkl\n",
      "\t   File exists: True, size: 143933\n",
      "\tGetting Oracle Rewards ...\n",
      "\tGNeuralUCB WAS ALREADY PROCESSED\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 5: Starting GNeuralUCB           in sequence...\n",
      "\tEXP 5 GNEURALUCB          : Reward=1859.00, Efficiency=082.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=375, Threshold=0.582]\n",
      "\tEXPNeuralUCB WAS ALREADY PROCESSED\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 5: Starting EXPNeuralUCB         in sequence...\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=1893.00, Efficiency=084.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=375, Threshold=0.628]\n",
      "\tCPursuitNeuralUCB WAS ALREADY PROCESSED\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 5: Starting CPursuitNeuralUCB    in sequence...\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=1859.00, Efficiency=082.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=375, Threshold=0.634]\n",
      "\tiCPursuitNeuralUCB WAS ALREADY PROCESSED\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 5: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=2142.00, Efficiency=095.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=375, Threshold=0.712]\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 5: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:250, QubitAlloc=Default, SC:375 (Scale=1.5 x Cap=250), Seed: 14218\n",
      "\t-->üèÜ EXP5 Winner:iCPursuitNeuralUCB  (Gap:004.8%) [Env:Stochastic, Attack:Random X Rate:0.0625, Frames:250, SCapacity=375, Alloc=Default]\n",
      "‚úì Experiment 5 completed successfully.\n",
      "Total experiment time: 013.9s\n",
      "Experiments completed for stochastic\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: MARKOV ADVERSARIAL ATTACK\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: MARKOV\n",
      "Category: Structured (Markov Chain Based)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 50 frames  <>  SCALED-CAPACITY: 75.0 frames (CAPACITY:50 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=0 ‚Üí allocation=(5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîß Allocated qubits for MARKOV Exp 1: (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 1: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:50, QubitAlloc=Default, SC:75 (Scale=1.5 x Cap=50), Seed: 14132\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_1\n",
      "\t‚úì QuantumExperimentRunner_1 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_75-Default_Adversarial_Markov-50_1_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_75-Default_Adversarial_Markov-50_1_paper7.pkl\n",
      "\t   File exists: True, size: 37476\n",
      "\tGetting Oracle Rewards ...\n",
      "\tGNeuralUCB WAS ALREADY PROCESSED\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 1: Starting GNeuralUCB           in sequence...\n",
      "\tEXP 1 GNEURALUCB          : Reward=0200.00, Efficiency=045.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=75, Threshold=0.582]\n",
      "\tEXPNeuralUCB WAS ALREADY PROCESSED\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 1: Starting EXPNeuralUCB         in sequence...\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=0218.00, Efficiency=050.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=75, Threshold=0.628]\n",
      "\tCPursuitNeuralUCB WAS ALREADY PROCESSED\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 1: Starting CPursuitNeuralUCB    in sequence...\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=0200.00, Efficiency=045.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=75, Threshold=0.634]\n",
      "\tiCPursuitNeuralUCB WAS ALREADY PROCESSED\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 1: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=0125.00, Efficiency=028.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=75, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 1: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:50, QubitAlloc=Default, SC:75 (Scale=1.5 x Cap=50), Seed: 19370\n",
      "\t-->üèÜ EXP1 Winner:EXPNeuralUCB        (Gap:050.0%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:50, SCapacity=75, Alloc=Default]\n",
      "‚úì Experiment 1 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 100 frames  <>  SCALED-CAPACITY: 150.0 frames (CAPACITY:100 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=1 ‚Üí allocation=(5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîß Allocated qubits for MARKOV Exp 2: (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 2: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:100, QubitAlloc=Default, SC:150 (Scale=1.5 x Cap=100), Seed: 22231\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_2\n",
      "\t‚úì QuantumExperimentRunner_2 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_150-Default_Adversarial_Markov-100_2_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_150-Default_Adversarial_Markov-100_2_paper7.pkl\n",
      "\t   File exists: True, size: 64112\n",
      "\tGetting Oracle Rewards ...\n",
      "\tGNeuralUCB WAS ALREADY PROCESSED\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 2: Starting GNeuralUCB           in sequence...\n",
      "\tEXP 2 GNEURALUCB          : Reward=0366.00, Efficiency=041.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=150, Threshold=0.582]\n",
      "\tEXPNeuralUCB WAS ALREADY PROCESSED\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 2: Starting EXPNeuralUCB         in sequence...\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=0490.00, Efficiency=055.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=150, Threshold=0.628]\n",
      "\tCPursuitNeuralUCB WAS ALREADY PROCESSED\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 2: Starting CPursuitNeuralUCB    in sequence...\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=0366.00, Efficiency=041.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=150, Threshold=0.634]\n",
      "\tiCPursuitNeuralUCB WAS ALREADY PROCESSED\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 2: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=0540.00, Efficiency=061.2% [Retries=3, Failed=0, < Threshold=3, SCapacity=150, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 2: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:100, QubitAlloc=Default, SC:150 (Scale=1.5 x Cap=100), Seed: 20983\n",
      "\t-->üèÜ EXP2 Winner:iCPursuitNeuralUCB  (Gap:038.8%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:100, SCapacity=150, Alloc=Default]\n",
      "‚úì Experiment 2 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 150 frames  <>  SCALED-CAPACITY: 225.0 frames (CAPACITY:150 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=2 ‚Üí allocation=(5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîß Allocated qubits for MARKOV Exp 3: (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 3: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:150, QubitAlloc=Default, SC:225 (Scale=1.5 x Cap=150), Seed: 20747\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_3\n",
      "\t‚úì QuantumExperimentRunner_3 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_225-Default_Adversarial_Markov-150_3_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_225-Default_Adversarial_Markov-150_3_paper7.pkl\n",
      "\t   File exists: True, size: 90721\n",
      "\tGetting Oracle Rewards ...\n",
      "\tGNeuralUCB WAS ALREADY PROCESSED\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 3: Starting GNeuralUCB           in sequence...\n",
      "\tEXP 3 GNEURALUCB          : Reward=0555.00, Efficiency=042.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=225, Threshold=0.582]\n",
      "\tEXPNeuralUCB WAS ALREADY PROCESSED\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 3: Starting EXPNeuralUCB         in sequence...\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=0555.00, Efficiency=042.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=225, Threshold=0.628]\n",
      "\tCPursuitNeuralUCB WAS ALREADY PROCESSED\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 3: Starting CPursuitNeuralUCB    in sequence...\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=0555.00, Efficiency=042.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=225, Threshold=0.634]\n",
      "\tiCPursuitNeuralUCB WAS ALREADY PROCESSED\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 3: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=0574.00, Efficiency=043.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=225, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 3: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:150, QubitAlloc=Default, SC:225 (Scale=1.5 x Cap=150), Seed: 12632\n",
      "\t-->üèÜ EXP3 Winner:iCPursuitNeuralUCB  (Gap:056.2%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:150, SCapacity=225, Alloc=Default]\n",
      "‚úì Experiment 3 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 200 frames  <>  SCALED-CAPACITY: 300.0 frames (CAPACITY:200 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=3 ‚Üí allocation=(5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîß Allocated qubits for MARKOV Exp 4: (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 4: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:200, QubitAlloc=Default, SC:300 (Scale=1.5 x Cap=200), Seed: 15410\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_4\n",
      "\t‚úì QuantumExperimentRunner_4 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_300-Default_Adversarial_Markov-200_4_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_300-Default_Adversarial_Markov-200_4_paper7.pkl\n",
      "\t   File exists: True, size: 117322\n",
      "\tGetting Oracle Rewards ...\n",
      "\tGNeuralUCB WAS ALREADY PROCESSED\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 4: Starting GNeuralUCB           in sequence...\n",
      "\tEXP 4 GNEURALUCB          : Reward=0907.00, Efficiency=051.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=300, Threshold=0.582]\n",
      "\tEXPNeuralUCB WAS ALREADY PROCESSED\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 4: Starting EXPNeuralUCB         in sequence...\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=0882.00, Efficiency=050.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=300, Threshold=0.628]\n",
      "\tCPursuitNeuralUCB WAS ALREADY PROCESSED\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 4: Starting CPursuitNeuralUCB    in sequence...\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=0907.00, Efficiency=051.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=300, Threshold=0.634]\n",
      "\tiCPursuitNeuralUCB WAS ALREADY PROCESSED\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 4: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=0801.00, Efficiency=045.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=300, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 4: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:200, QubitAlloc=Default, SC:300 (Scale=1.5 x Cap=200), Seed: 14060\n",
      "\t-->üèÜ EXP4 Winner:GNeuralUCB          (Gap:048.2%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:200, SCapacity=300, Alloc=Default]\n",
      "‚úì Experiment 4 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 250 frames  <>  SCALED-CAPACITY: 375.0 frames (CAPACITY:250 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=4 ‚Üí allocation=(5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîß Allocated qubits for MARKOV Exp 5: (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 5: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:250, QubitAlloc=Default, SC:375 (Scale=1.5 x Cap=250), Seed: 22674\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_5\n",
      "\t‚úì QuantumExperimentRunner_5 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_375-Default_Adversarial_Markov-250_5_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_375-Default_Adversarial_Markov-250_5_paper7.pkl\n",
      "\t   File exists: True, size: 143931\n",
      "\tGetting Oracle Rewards ...\n",
      "\tGNeuralUCB WAS ALREADY PROCESSED\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 5: Starting GNeuralUCB           in sequence...\n",
      "\tEXP 5 GNEURALUCB          : Reward=1035.00, Efficiency=047.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=375, Threshold=0.582]\n",
      "\tEXPNeuralUCB WAS ALREADY PROCESSED\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 5: Starting EXPNeuralUCB         in sequence...\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=0872.00, Efficiency=040.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=375, Threshold=0.628]\n",
      "\tCPursuitNeuralUCB WAS ALREADY PROCESSED\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 5: Starting CPursuitNeuralUCB    in sequence...\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=1035.00, Efficiency=047.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=375, Threshold=0.634]\n",
      "\tiCPursuitNeuralUCB WAS ALREADY PROCESSED\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 5: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=0936.00, Efficiency=043.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=375, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 5: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:250, QubitAlloc=Default, SC:375 (Scale=1.5 x Cap=250), Seed: 16815\n",
      "\t-->üèÜ EXP5 Winner:GNeuralUCB          (Gap:052.4%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:250, SCapacity=375, Alloc=Default]\n",
      "‚úì Experiment 5 completed successfully.\n",
      "Total experiment time: 014.4s\n",
      "Experiments completed for markov\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: ADAPTIVE ADVERSARIAL ATTACK\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: ADAPTIVE\n",
      "Category: Adaptive (Reactive Strategic)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 50 frames  <>  SCALED-CAPACITY: 75.0 frames (CAPACITY:50 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=0 ‚Üí allocation=(5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 1: (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 1: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:50, QubitAlloc=Default, SC:75 (Scale=1.5 x Cap=50), Seed: 21427\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_1\n",
      "\t‚úì QuantumExperimentRunner_1 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_75-Default_Adversarial_Adaptive-50_1_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_75-Default_Adversarial_Adaptive-50_1_paper7.pkl\n",
      "\t   File exists: True, size: 37482\n",
      "\tGetting Oracle Rewards ...\n",
      "\tGNeuralUCB WAS ALREADY PROCESSED\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 1: Starting GNeuralUCB           in sequence...\n",
      "\tEXP 1 GNEURALUCB          : Reward=0319.00, Efficiency=071.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=75, Threshold=0.582]\n",
      "\tEXPNeuralUCB WAS ALREADY PROCESSED\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 1: Starting EXPNeuralUCB         in sequence...\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=0264.00, Efficiency=059.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=75, Threshold=0.628]\n",
      "\tCPursuitNeuralUCB WAS ALREADY PROCESSED\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 1: Starting CPursuitNeuralUCB    in sequence...\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=0319.00, Efficiency=071.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=75, Threshold=0.634]\n",
      "\tiCPursuitNeuralUCB WAS ALREADY PROCESSED\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 1: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=0333.00, Efficiency=074.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=75, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 1: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:50, QubitAlloc=Default, SC:75 (Scale=1.5 x Cap=50), Seed: 20660\n",
      "\t-->üèÜ EXP1 Winner:iCPursuitNeuralUCB  (Gap:025.5%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:50, SCapacity=75, Alloc=Default]\n",
      "‚úì Experiment 1 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 100 frames  <>  SCALED-CAPACITY: 150.0 frames (CAPACITY:100 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=1 ‚Üí allocation=(5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 2: (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 2: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:100, QubitAlloc=Default, SC:150 (Scale=1.5 x Cap=100), Seed: 13200\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_2\n",
      "\t‚úì QuantumExperimentRunner_2 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_150-Default_Adversarial_Adaptive-100_2_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_150-Default_Adversarial_Adaptive-100_2_paper7.pkl\n",
      "\t   File exists: True, size: 64118\n",
      "\tGetting Oracle Rewards ...\n",
      "\tGNeuralUCB WAS ALREADY PROCESSED\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 2: Starting GNeuralUCB           in sequence...\n",
      "\tEXP 2 GNEURALUCB          : Reward=0591.00, Efficiency=066.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=150, Threshold=0.582]\n",
      "\tEXPNeuralUCB WAS ALREADY PROCESSED\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 2: Starting EXPNeuralUCB         in sequence...\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=0588.00, Efficiency=065.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=150, Threshold=0.628]\n",
      "\tCPursuitNeuralUCB WAS ALREADY PROCESSED\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 2: Starting CPursuitNeuralUCB    in sequence...\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=0591.00, Efficiency=066.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=150, Threshold=0.634]\n",
      "\tiCPursuitNeuralUCB WAS ALREADY PROCESSED\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 2: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=0576.00, Efficiency=064.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=150, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 2: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:100, QubitAlloc=Default, SC:150 (Scale=1.5 x Cap=100), Seed: 13752\n",
      "\t-->üèÜ EXP2 Winner:GNeuralUCB          (Gap:033.8%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:100, SCapacity=150, Alloc=Default]\n",
      "‚úì Experiment 2 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 150 frames  <>  SCALED-CAPACITY: 225.0 frames (CAPACITY:150 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=2 ‚Üí allocation=(5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 3: (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 3: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:150, QubitAlloc=Default, SC:225 (Scale=1.5 x Cap=150), Seed: 18005\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_3\n",
      "\t‚úì QuantumExperimentRunner_3 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_225-Default_Adversarial_Adaptive-150_3_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_225-Default_Adversarial_Adaptive-150_3_paper7.pkl\n",
      "\t   File exists: True, size: 90727\n",
      "\tGetting Oracle Rewards ...\n",
      "\tGNeuralUCB WAS ALREADY PROCESSED\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 3: Starting GNeuralUCB           in sequence...\n",
      "\tEXP 3 GNEURALUCB          : Reward=0903.00, Efficiency=067.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=225, Threshold=0.582]\n",
      "\tEXPNeuralUCB WAS ALREADY PROCESSED\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 3: Starting EXPNeuralUCB         in sequence...\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=0911.00, Efficiency=067.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=225, Threshold=0.628]\n",
      "\tCPursuitNeuralUCB WAS ALREADY PROCESSED\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 3: Starting CPursuitNeuralUCB    in sequence...\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=0903.00, Efficiency=067.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=225, Threshold=0.634]\n",
      "\tiCPursuitNeuralUCB WAS ALREADY PROCESSED\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 3: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=0928.00, Efficiency=069.2% [Retries=3, Failed=0, < Threshold=3, SCapacity=225, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 3: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:150, QubitAlloc=Default, SC:225 (Scale=1.5 x Cap=150), Seed: 17275\n",
      "\t-->üèÜ EXP3 Winner:iCPursuitNeuralUCB  (Gap:030.8%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:150, SCapacity=225, Alloc=Default]\n",
      "‚úì Experiment 3 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 200 frames  <>  SCALED-CAPACITY: 300.0 frames (CAPACITY:200 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=3 ‚Üí allocation=(5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 4: (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 4: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:200, QubitAlloc=Default, SC:300 (Scale=1.5 x Cap=200), Seed: 12955\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_4\n",
      "\t‚úì QuantumExperimentRunner_4 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_300-Default_Adversarial_Adaptive-200_4_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_300-Default_Adversarial_Adaptive-200_4_paper7.pkl\n",
      "\t   File exists: True, size: 117328\n",
      "\tGetting Oracle Rewards ...\n",
      "\tGNeuralUCB WAS ALREADY PROCESSED\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 4: Starting GNeuralUCB           in sequence...\n",
      "\tEXP 4 GNEURALUCB          : Reward=1240.00, Efficiency=069.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=300, Threshold=0.582]\n",
      "\tEXPNeuralUCB WAS ALREADY PROCESSED\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 4: Starting EXPNeuralUCB         in sequence...\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=1142.00, Efficiency=063.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=300, Threshold=0.628]\n",
      "\tCPursuitNeuralUCB WAS ALREADY PROCESSED\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 4: Starting CPursuitNeuralUCB    in sequence...\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=1240.00, Efficiency=069.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=300, Threshold=0.634]\n",
      "\tiCPursuitNeuralUCB WAS ALREADY PROCESSED\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 4: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=1050.00, Efficiency=058.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=300, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 4: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:200, QubitAlloc=Default, SC:300 (Scale=1.5 x Cap=200), Seed: 22459\n",
      "\t-->üèÜ EXP4 Winner:GNeuralUCB          (Gap:030.8%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:200, SCapacity=300, Alloc=Default]\n",
      "‚úì Experiment 4 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 250 frames  <>  SCALED-CAPACITY: 375.0 frames (CAPACITY:250 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=4 ‚Üí allocation=(5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 5: (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 5: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:250, QubitAlloc=Default, SC:375 (Scale=1.5 x Cap=250), Seed: 14950\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_5\n",
      "\t‚úì QuantumExperimentRunner_5 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_375-Default_Adversarial_Adaptive-250_5_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_375-Default_Adversarial_Adaptive-250_5_paper7.pkl\n",
      "\t   File exists: True, size: 143937\n",
      "\tGetting Oracle Rewards ...\n",
      "\tGNeuralUCB WAS ALREADY PROCESSED\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 5: Starting GNeuralUCB           in sequence...\n",
      "\tEXP 5 GNEURALUCB          : Reward=1481.00, Efficiency=066.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=375, Threshold=0.582]\n",
      "\tEXPNeuralUCB WAS ALREADY PROCESSED\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 5: Starting EXPNeuralUCB         in sequence...\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=1424.00, Efficiency=063.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=375, Threshold=0.628]\n",
      "\tCPursuitNeuralUCB WAS ALREADY PROCESSED\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 5: Starting CPursuitNeuralUCB    in sequence...\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=1481.00, Efficiency=066.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=375, Threshold=0.634]\n",
      "\tiCPursuitNeuralUCB WAS ALREADY PROCESSED\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 5: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=1674.00, Efficiency=075.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=375, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 5: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:250, QubitAlloc=Default, SC:375 (Scale=1.5 x Cap=250), Seed: 13063\n",
      "\t-->üèÜ EXP5 Winner:iCPursuitNeuralUCB  (Gap:024.9%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:250, SCapacity=375, Alloc=Default]\n",
      "‚úì Experiment 5 completed successfully.\n",
      "Total experiment time: 016.1s\n",
      "Experiments completed for adaptive\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: ONLINE ADAPTIVE ATTACK\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: ONLINEADAPTIVE\n",
      "Category: Online Adaptive (Real-time Strategic)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 50 frames  <>  SCALED-CAPACITY: 75.0 frames (CAPACITY:50 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=0 ‚Üí allocation=(5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 1: (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:50, QubitAlloc=Default, SC:75 (Scale=1.5 x Cap=50), Seed: 14732\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_1\n",
      "\t‚úì QuantumExperimentRunner_1 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_75-Default_Adversarial_OnlineAdaptive-50_1_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_75-Default_Adversarial_OnlineAdaptive-50_1_paper7.pkl\n",
      "\t   File exists: True, size: 37500\n",
      "\tGetting Oracle Rewards ...\n",
      "\tGNeuralUCB WAS ALREADY PROCESSED\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Starting GNeuralUCB           in sequence...\n",
      "\tEXP 1 GNEURALUCB          : Reward=0303.00, Efficiency=067.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=75, Threshold=0.582]\n",
      "\tEXPNeuralUCB WAS ALREADY PROCESSED\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Starting EXPNeuralUCB         in sequence...\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=0316.00, Efficiency=070.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=75, Threshold=0.628]\n",
      "\tCPursuitNeuralUCB WAS ALREADY PROCESSED\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Starting CPursuitNeuralUCB    in sequence...\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=0303.00, Efficiency=067.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=75, Threshold=0.634]\n",
      "\tiCPursuitNeuralUCB WAS ALREADY PROCESSED\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=0256.00, Efficiency=057.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=75, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:50, QubitAlloc=Default, SC:75 (Scale=1.5 x Cap=50), Seed: 20782\n",
      "\t-->üèÜ EXP1 Winner:EXPNeuralUCB        (Gap:029.5%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:50, SCapacity=75, Alloc=Default]\n",
      "‚úì Experiment 1 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 100 frames  <>  SCALED-CAPACITY: 150.0 frames (CAPACITY:100 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=1 ‚Üí allocation=(5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 2: (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:100, QubitAlloc=Default, SC:150 (Scale=1.5 x Cap=100), Seed: 14647\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_2\n",
      "\t‚úì QuantumExperimentRunner_2 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_150-Default_Adversarial_OnlineAdaptive-100_2_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_150-Default_Adversarial_OnlineAdaptive-100_2_paper7.pkl\n",
      "\t   File exists: True, size: 64136\n",
      "\tGetting Oracle Rewards ...\n",
      "\tGNeuralUCB WAS ALREADY PROCESSED\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Starting GNeuralUCB           in sequence...\n",
      "\tEXP 2 GNEURALUCB          : Reward=0603.00, Efficiency=067.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=150, Threshold=0.582]\n",
      "\tEXPNeuralUCB WAS ALREADY PROCESSED\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Starting EXPNeuralUCB         in sequence...\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=0569.00, Efficiency=063.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=150, Threshold=0.628]\n",
      "\tCPursuitNeuralUCB WAS ALREADY PROCESSED\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Starting CPursuitNeuralUCB    in sequence...\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=0603.00, Efficiency=067.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=150, Threshold=0.634]\n",
      "\tiCPursuitNeuralUCB WAS ALREADY PROCESSED\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=0666.00, Efficiency=074.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=150, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:100, QubitAlloc=Default, SC:150 (Scale=1.5 x Cap=100), Seed: 12662\n",
      "\t-->üèÜ EXP2 Winner:iCPursuitNeuralUCB  (Gap:025.3%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:100, SCapacity=150, Alloc=Default]\n",
      "‚úì Experiment 2 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 150 frames  <>  SCALED-CAPACITY: 225.0 frames (CAPACITY:150 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=2 ‚Üí allocation=(5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 3: (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:150, QubitAlloc=Default, SC:225 (Scale=1.5 x Cap=150), Seed: 21138\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_3\n",
      "\t‚úì QuantumExperimentRunner_3 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_225-Default_Adversarial_OnlineAdaptive-150_3_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_225-Default_Adversarial_OnlineAdaptive-150_3_paper7.pkl\n",
      "\t   File exists: True, size: 90745\n",
      "\tGetting Oracle Rewards ...\n",
      "\tGNeuralUCB WAS ALREADY PROCESSED\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Starting GNeuralUCB           in sequence...\n",
      "\tEXP 3 GNEURALUCB          : Reward=0886.00, Efficiency=066.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=225, Threshold=0.582]\n",
      "\tEXPNeuralUCB WAS ALREADY PROCESSED\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Starting EXPNeuralUCB         in sequence...\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=0894.00, Efficiency=066.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=225, Threshold=0.628]\n",
      "\tCPursuitNeuralUCB WAS ALREADY PROCESSED\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Starting CPursuitNeuralUCB    in sequence...\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=0886.00, Efficiency=066.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=225, Threshold=0.634]\n",
      "\tiCPursuitNeuralUCB WAS ALREADY PROCESSED\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=0888.00, Efficiency=066.2% [Retries=3, Failed=0, < Threshold=3, SCapacity=225, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:150, QubitAlloc=Default, SC:225 (Scale=1.5 x Cap=150), Seed: 20365\n",
      "\t-->üèÜ EXP3 Winner:EXPNeuralUCB        (Gap:033.3%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:150, SCapacity=225, Alloc=Default]\n",
      "‚úì Experiment 3 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 200 frames  <>  SCALED-CAPACITY: 300.0 frames (CAPACITY:200 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=3 ‚Üí allocation=(5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 4: (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:200, QubitAlloc=Default, SC:300 (Scale=1.5 x Cap=200), Seed: 16677\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_4\n",
      "\t‚úì QuantumExperimentRunner_4 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_300-Default_Adversarial_OnlineAdaptive-200_4_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_300-Default_Adversarial_OnlineAdaptive-200_4_paper7.pkl\n",
      "\t   File exists: True, size: 117346\n",
      "\tGetting Oracle Rewards ...\n",
      "\tGNeuralUCB WAS ALREADY PROCESSED\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Starting GNeuralUCB           in sequence...\n",
      "\tEXP 4 GNEURALUCB          : Reward=1259.00, Efficiency=070.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=300, Threshold=0.582]\n",
      "\tEXPNeuralUCB WAS ALREADY PROCESSED\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Starting EXPNeuralUCB         in sequence...\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=1256.00, Efficiency=070.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=300, Threshold=0.628]\n",
      "\tCPursuitNeuralUCB WAS ALREADY PROCESSED\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Starting CPursuitNeuralUCB    in sequence...\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=1259.00, Efficiency=070.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=300, Threshold=0.634]\n",
      "\tiCPursuitNeuralUCB WAS ALREADY PROCESSED\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=1413.00, Efficiency=079.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=300, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:200, QubitAlloc=Default, SC:300 (Scale=1.5 x Cap=200), Seed: 19582\n",
      "\t-->üèÜ EXP4 Winner:iCPursuitNeuralUCB  (Gap:020.9%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:200, SCapacity=300, Alloc=Default]\n",
      "‚úì Experiment 4 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 250 frames  <>  SCALED-CAPACITY: 375.0 frames (CAPACITY:250 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=4 ‚Üí allocation=(5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 5: (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:250, QubitAlloc=Default, SC:375 (Scale=1.5 x Cap=250), Seed: 22447\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_5\n",
      "\t‚úì QuantumExperimentRunner_5 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_375-Default_Adversarial_OnlineAdaptive-250_5_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_375-Default_Adversarial_OnlineAdaptive-250_5_paper7.pkl\n",
      "\t   File exists: True, size: 143955\n",
      "\tGetting Oracle Rewards ...\n",
      "\tGNeuralUCB WAS ALREADY PROCESSED\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Starting GNeuralUCB           in sequence...\n",
      "\tEXP 5 GNEURALUCB          : Reward=1389.00, Efficiency=062.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=375, Threshold=0.582]\n",
      "\tEXPNeuralUCB WAS ALREADY PROCESSED\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Starting EXPNeuralUCB         in sequence...\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=1518.00, Efficiency=068.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=375, Threshold=0.628]\n",
      "\tCPursuitNeuralUCB WAS ALREADY PROCESSED\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Starting CPursuitNeuralUCB    in sequence...\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=1389.00, Efficiency=062.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=375, Threshold=0.634]\n",
      "\tiCPursuitNeuralUCB WAS ALREADY PROCESSED\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=1528.00, Efficiency=068.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=375, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:250, QubitAlloc=Default, SC:375 (Scale=1.5 x Cap=250), Seed: 20848\n",
      "\t-->üèÜ EXP5 Winner:iCPursuitNeuralUCB  (Gap:031.4%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:250, SCapacity=375, Alloc=Default]\n",
      "‚úì Experiment 5 completed successfully.\n",
      "Total experiment time: 016.2s\n",
      "Experiments completed for onlineadaptive\n",
      "‚úì Scenario 'none' evaluation completed.\n",
      "‚úì Scenario 'stochastic' evaluation completed.\n",
      "‚úì Scenario 'markov' evaluation completed.\n",
      "‚úì Scenario 'adaptive' evaluation completed.\n",
      "‚úì Scenario 'onlineadaptive' evaluation completed.\n",
      "\n",
      "======================================================================\n",
      "COMPREHENSIVE SCENARIO PERFORMANCE ANALYSIS\n",
      "======================================================================\n",
      "SCENARIO: NONE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 1350.00\n",
      "\t‚Ä¢ Winner Avg Gap: 0000.00%\n",
      "\t‚Ä¢ Winner Avg Reward: 1350.00\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0100.00%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 5 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: NONE\n",
      "======================================================================\n",
      "SCENARIO: \tBASELINE (OPTIMAL CONDITIONS)\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 5/5 experiments)\n",
      "\tWinner Avg Gap: \t000.0%\n",
      "\tWinner Avg Efficiency: \t100.0%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t100.0% Efficiency \t(Won 5/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t088.4% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t088.1% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t088.1% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: STOCHASTIC\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 1349.60\n",
      "\t‚Ä¢ Winner Avg Gap: 0005.47%\n",
      "\t‚Ä¢ Winner Avg Reward: 1269.00\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0094.53%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 5 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: STOCHASTIC\n",
      "======================================================================\n",
      "SCENARIO: \tSTOCHASTIC RANDOM FAILURES\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 5/5 experiments)\n",
      "\tWinner Avg Gap: \t005.5%\n",
      "\tWinner Avg Efficiency: \t094.5%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t094.5% Efficiency \t(Won 5/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t082.8% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t082.8% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t079.0% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: MARKOV\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: EXPNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 1310.80\n",
      "\t‚Ä¢ Winner Avg Gap: 0052.33%\n",
      "\t‚Ä¢ Winner Avg Reward: 0603.40\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0047.67%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 2 wins\n",
      "\t\t- EXPNeuralUCB: 1 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 2 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: MARKOV\n",
      "======================================================================\n",
      "SCENARIO: \tMARKOV ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tEXPNeuralUCB (Won 1/5 experiments)\n",
      "\tWinner Avg Gap: \t052.3%\n",
      "\tWinner Avg Efficiency: \t047.7%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t047.7% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t045.8% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t045.8% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t044.5% Efficiency \t(Won 2/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 1340.40\n",
      "\t‚Ä¢ Winner Avg Gap: 0031.62%\n",
      "\t‚Ä¢ Winner Avg Reward: 0912.20\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0068.38%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 2 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 3 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tADAPTIVE ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 3/5 experiments)\n",
      "\tWinner Avg Gap: \t031.6%\n",
      "\tWinner Avg Efficiency: \t068.4%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t068.4% Efficiency \t(Won 3/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t068.1% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t068.1% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t064.1% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ONLINEADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 1339.20\n",
      "\t‚Ä¢ Winner Avg Gap: 0030.85%\n",
      "\t‚Ä¢ Winner Avg Reward: 0950.20\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0069.15%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 2 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 3 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ONLINEADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tONLINE ADAPTIVE ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 3/5 experiments)\n",
      "\tWinner Avg Gap: \t030.9%\n",
      "\tWinner Avg Efficiency: \t069.1%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t069.1% Efficiency \t(Won 3/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t067.9% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t066.8% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t066.8% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "KEY INSIGHTS:\n",
      "Best Performing Model Analysis (iCPursuitNeuralUCB):\n",
      "\t‚Ä¢ Stochastic Performance:    \t1269.000\n",
      "\t‚Ä¢ Baseline Performance:      \t1350.000\n",
      "\t‚Ä¢ Performance Retention:     \t094.0%\n",
      "\tGOOD:               \tAcceptable performance under stochastic conditions\n",
      "Statistical Analysis:\n",
      "\t‚Ä¢ Total models evaluated:     \t5\n",
      "\t‚Ä¢ Experiments per environment:\t5\n",
      "\t‚Ä¢ Quantum network simulation: \tComprehensive stochastic modeling\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "COMPREHENSIVE SCENARIO PERFORMANCE ANALYSIS\n",
      "======================================================================\n",
      "SCENARIO: NONE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 1350.00\n",
      "\t‚Ä¢ Winner Avg Gap: 0000.00%\n",
      "\t‚Ä¢ Winner Avg Reward: 1350.00\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0100.00%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 5 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: NONE\n",
      "======================================================================\n",
      "SCENARIO: \tBASELINE (OPTIMAL CONDITIONS)\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 5/5 experiments)\n",
      "\tWinner Avg Gap: \t000.0%\n",
      "\tWinner Avg Efficiency: \t100.0%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t100.0% Efficiency \t(Won 5/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t088.4% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t088.1% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t088.1% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: STOCHASTIC\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 1349.60\n",
      "\t‚Ä¢ Winner Avg Gap: 0005.47%\n",
      "\t‚Ä¢ Winner Avg Reward: 1269.00\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0094.53%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 5 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: STOCHASTIC\n",
      "======================================================================\n",
      "SCENARIO: \tSTOCHASTIC RANDOM FAILURES\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 5/5 experiments)\n",
      "\tWinner Avg Gap: \t005.5%\n",
      "\tWinner Avg Efficiency: \t094.5%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t094.5% Efficiency \t(Won 5/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t082.8% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t082.8% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t079.0% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: MARKOV\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: EXPNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 1310.80\n",
      "\t‚Ä¢ Winner Avg Gap: 0052.33%\n",
      "\t‚Ä¢ Winner Avg Reward: 0603.40\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0047.67%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 2 wins\n",
      "\t\t- EXPNeuralUCB: 1 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 2 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: MARKOV\n",
      "======================================================================\n",
      "SCENARIO: \tMARKOV ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tEXPNeuralUCB (Won 1/5 experiments)\n",
      "\tWinner Avg Gap: \t052.3%\n",
      "\tWinner Avg Efficiency: \t047.7%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t047.7% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t045.8% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t045.8% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t044.5% Efficiency \t(Won 2/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 1340.40\n",
      "\t‚Ä¢ Winner Avg Gap: 0031.62%\n",
      "\t‚Ä¢ Winner Avg Reward: 0912.20\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0068.38%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 2 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 3 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tADAPTIVE ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 3/5 experiments)\n",
      "\tWinner Avg Gap: \t031.6%\n",
      "\tWinner Avg Efficiency: \t068.4%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t068.4% Efficiency \t(Won 3/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t068.1% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t068.1% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t064.1% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ONLINEADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 1339.20\n",
      "\t‚Ä¢ Winner Avg Gap: 0030.85%\n",
      "\t‚Ä¢ Winner Avg Reward: 0950.20\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0069.15%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 2 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 3 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ONLINEADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tONLINE ADAPTIVE ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 3/5 experiments)\n",
      "\tWinner Avg Gap: \t030.9%\n",
      "\tWinner Avg Efficiency: \t069.1%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t069.1% Efficiency \t(Won 3/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t067.9% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t066.8% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t066.8% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "‚úÖ Evaluation completed!\n",
      "[Logging Redirect Stopped]\n",
      "\n",
      "üßπ Final cleanup for Default\n",
      "\n",
      "======================================================================\n",
      "‚úÖ COMPLETED: Default\n",
      "======================================================================\n",
      "\n",
      "Default COMPLETED SUCCESSFULLY\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Preparing: Default at scale 2\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üîß Generating physics parameters for model: paper7\n",
      "\n",
      "===================== GET LOCAL REGISTRY =====================\n",
      "‚Üí Skipping local cache (force=True or file missing)\n",
      "\n",
      "===================== BUILD LOCAL REGISTRY =====================\n",
      "\n",
      "================================================================================\n",
      "üîç SCANNING LOCAL FILES\n",
      "================================================================================\n",
      "Parameters: load_to_drive=False, force=False\n",
      "\n",
      "üìÇ Checking DRIVE mode: /content/drive/Shareddrives/ai_quantum_computing/quantum_data_lake\n",
      "   ‚ö†Ô∏è  Path does not exist, skipping\n",
      "\n",
      "üìÇ Checking LOCAL mode: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config\n",
      "   ‚úÖ Path exists, starting walk...\n",
      "   üö∂ Walking directory tree: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config\n",
      "\n",
      "   üìÅ Directory: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201\n",
      "      Relative: framework_state/day_20260201\n",
      "      Component: framework_state\n",
      "      Date: day_20260201\n",
      "      üìÑ Processing 2514 files in framework_state/day_20260201\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "      üìä framework_state/day_20260201: 2488/2514 files processed\n",
      "      üìä framework_state/day_20260201: 0/2514 files skipped\n",
      "      üìä framework_state/day_20260201: 26/2514 files conflicted\n",
      "\n",
      "   üìÅ Directory: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/model_state/day_20260201\n",
      "      Relative: model_state/day_20260201\n",
      "      Component: model_state\n",
      "      Date: day_20260201\n",
      "      üìÑ Processing 8842 files in model_state/day_20260201\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "      üìä model_state/day_20260201: 8842/8842 files processed\n",
      "      üìä model_state/day_20260201: 0/8842 files skipped\n",
      "      üìä model_state/day_20260201: 0/8842 files conflicted\n",
      "\n",
      "   üìä Processed 2 directories\n",
      "\n",
      "================================================================================\n",
      "üì¶ BUILDING FINAL REGISTRY\n",
      "================================================================================\n",
      "Components found: ['framework_state', 'model_state']\n",
      "  ‚Ä¢ framework_state: 2488 files\n",
      "  ‚Ä¢ model_state: 8842 files\n",
      "\n",
      "‚úÖ SCAN COMPLETE\n",
      "Modes scanned: 1\n",
      "Total files in registry: 11330\n",
      "================================================================================\n",
      "\n",
      "\t‚Üí Filesystem scan found 11330 files\n",
      "\n",
      "===================== GET DRIVE REGISTRY =====================\n",
      "===================== REGISTRY BUILD COMPLETE =====================\n",
      "\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "\tüì¶ LocalBackupManager Registry Saved Locally in LOCAL\n",
      "BUILDING REGISTRY WITH 0 EXPECTED COMPONENTS KEYS\n",
      "\n",
      "===================== GET LOCAL REGISTRY =====================\n",
      "‚Üí Skipping local cache (force=True or file missing)\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "\tüì¶ LocalBackupManager Registry Saved Locally in LOCAL\n",
      "\n",
      "======================================================================\n",
      "üéØ AllocatorRunner initialized: Default\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "üöÄ STARTING ALLOCATOR: Default\n",
      "======================================================================\n",
      "\n",
      "üìä Physics Model: paper7\n",
      "\n",
      "üìã Allocator Config:\n",
      "   Type: Default\n",
      "   Testbed: default\n",
      "   Paths: 15\n",
      "   Total Qubits: 75\n",
      "   Min per route: 2\n",
      "   Seed: 42\n",
      "‚úÖ Allocator created: (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "‚úì Allocator: QubitAllocator (15 paths)\n",
      "   Initial allocation: (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üìä Paper7 Topology: Real AS (as20000101.txt)\n",
      "üìä Paper7 Paths: 15 paths from 5-shortest between 3 ISPs\n",
      "üìä Paper7 Contexts: 15 context vectors generated\n",
      "üìä Paper7 Rewards: Context-aware (mode=neg_hop)\n",
      "‚è±Ô∏è  get_physics_params_paper7() time: 2.1 ms\n",
      "\n",
      "======================================================================\n",
      "RUN 1 | Scale: 2 | Exp: 5\n",
      "======================================================================\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "\n",
      "\tüîÑ Resume: MultiRunEvaluator\n",
      "\n",
      "=====================================================\n",
      "üîç GENERATING EXPECTED KEYS FROM EVALUATOR\n",
      "=====================================================\n",
      "  ‚Ä¢ Evaluator filename: MultiRunEvaluator_100-Default_All_All-50_50_5_S2T_paper7.pkl\n",
      "\n",
      "üß© PARSED COMPONENTS\n",
      "  ‚Ä¢ cap_id:        100\n",
      "  ‚Ä¢ allocator_id:  Default\n",
      "  ‚Ä¢ env_id:        All\n",
      "  ‚Ä¢ attack_id:     All\n",
      "  ‚Ä¢ base_frames:   50\n",
      "  ‚Ä¢ frame_step:    50\n",
      "  ‚Ä¢ runs_id:       5\n",
      "\n",
      "=====================================================\n",
      "üß™ GENERATING KEYS FOR EACH RUN\n",
      "=====================================================\n",
      "\n",
      "--- Run 1/5 -----------------------\n",
      "\n",
      "=====================================================\n",
      "üì¶ FINAL EXPECTED KEYS\n",
      "=====================================================\n",
      "  ‚Ä¢ Runner keys: 11\n",
      "\n",
      "  ‚Ä¢ Model keys: 50\n",
      "\n",
      "--- Run 2/5 -----------------------\n",
      "\n",
      "=====================================================\n",
      "üì¶ FINAL EXPECTED KEYS\n",
      "=====================================================\n",
      "  ‚Ä¢ Runner keys: 21\n",
      "\n",
      "  ‚Ä¢ Model keys: 100\n",
      "\n",
      "--- Run 3/5 -----------------------\n",
      "\n",
      "=====================================================\n",
      "üì¶ FINAL EXPECTED KEYS\n",
      "=====================================================\n",
      "  ‚Ä¢ Runner keys: 31\n",
      "\n",
      "  ‚Ä¢ Model keys: 150\n",
      "\n",
      "--- Run 4/5 -----------------------\n",
      "\n",
      "=====================================================\n",
      "üì¶ FINAL EXPECTED KEYS\n",
      "=====================================================\n",
      "  ‚Ä¢ Runner keys: 41\n",
      "\n",
      "  ‚Ä¢ Model keys: 200\n",
      "\n",
      "--- Run 5/5 -----------------------\n",
      "\n",
      "=====================================================\n",
      "üì¶ FINAL EXPECTED KEYS\n",
      "=====================================================\n",
      "  ‚Ä¢ Runner keys: 51\n",
      "\n",
      "  ‚Ä¢ Model keys: 250\n",
      "\n",
      "EXPECTED KEY GENERATION COMPLETE\n",
      "\n",
      "RESTORING FROM DRIVE 1\n",
      "RESTORING FROM DRIVE 2\n",
      "\t‚ö†Ô∏è Registry exists ‚Üí aborting restore\n",
      "\t‚úì MultiRunEvaluator Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/MultiRunEvaluator_100-Default_All_All-50_50_5_S2T_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/MultiRunEvaluator_100-Default_All_All-50_50_5_S2T_paper7.pkl\n",
      "\t   File exists: True, size: 4183595\n",
      "EQUAL METHOD\n",
      "Multi-Run Evaluator Initialized\n",
      "Environment Type: None\n",
      "Frame Range: 50 -> 250 (step: 50)\n",
      "quantum_exps-Default(paper7)_alloc-all_envs-5_attacks-50_50-5_runs-S2T\n",
      "[Logging Redirect Initialized]\n",
      "Log File: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/quantum_logs/quantum_exps-Default(paper7)_alloc-all_envs-5_attacks-50_50-5_runs-S2T_20260201_log.txt\n",
      "‚öô Running evaluation...\n",
      "======================================================================\n",
      "SCENARIOS MODEL EVALUATION\n",
      "======================================================================\n",
      "Testing algorithm performance against:\n",
      "\t‚Ä¢ Stochastic:  \tNatural quantum decoherence and network failures\n",
      "\t‚Ä¢ Baseline:    \tOptimal conditions for validation\n",
      "======================================================================\n",
      "Models to Test:             \tOracle, GNeuralUCB, EXPNeuralUCB, CPursuitNeuralUCB, iCPursuitNeuralUCB\n",
      "Experiments per Scenario:   \t5\n",
      "======================================================================\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: BASELINE (OPTIMAL CONDITIONS)\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: NONE\n",
      "Category: Baseline (No Attacks)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 50 frames  <>  SCALED-CAPACITY: 100 frames (CAPACITY:50 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=0 ‚Üí allocation=(5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîß Allocated qubits for NONE Exp 1: (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 1: Env:Baseline (None), Attack:No, Rate:0.0, Frames:50, QubitAlloc=Default, SC:100 (Scale=2 x Cap=50), Seed: 15373\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_1\n",
      "\t‚úì QuantumExperimentRunner_1 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_100-Default_Baseline (None)_No-50_1_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_100-Default_Baseline (None)_No-50_1_paper7.pkl\n",
      "\t   File exists: True, size: 37475\n",
      "‚è© SKIPPING EXPERIMENT 1: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 1 GNEURALUCB          : Reward=0396.00, Efficiency=088.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=100, Threshold=0.582]\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=0391.00, Efficiency=086.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=100, Threshold=0.628]\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=0396.00, Efficiency=088.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=100, Threshold=0.634]\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=0450.00, Efficiency=100.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=100, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP1 Winner:iCPursuitNeuralUCB  (Gap:000.0%) [Env:Baseline (None), Attack:No X Rate:0.25, Frames:50, SCapacity=100, Alloc=Default]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 100 frames  <>  SCALED-CAPACITY: 200 frames (CAPACITY:100 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=1 ‚Üí allocation=(5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîß Allocated qubits for NONE Exp 2: (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 2: Env:Baseline (None), Attack:No, Rate:0.0, Frames:100, QubitAlloc=Default, SC:200 (Scale=2 x Cap=100), Seed: 12644\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_2\n",
      "\t‚úì QuantumExperimentRunner_2 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_200-Default_Baseline (None)_No-100_2_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_200-Default_Baseline (None)_No-100_2_paper7.pkl\n",
      "\t   File exists: True, size: 64110\n",
      "‚è© SKIPPING EXPERIMENT 2: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 2 GNEURALUCB          : Reward=0794.00, Efficiency=088.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=200, Threshold=0.582]\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=0830.00, Efficiency=092.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=200, Threshold=0.628]\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=0794.00, Efficiency=088.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=200, Threshold=0.634]\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=0900.00, Efficiency=100.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=200, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP2 Winner:iCPursuitNeuralUCB  (Gap:000.0%) [Env:Baseline (None), Attack:No X Rate:0.25, Frames:100, SCapacity=200, Alloc=Default]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 150 frames  <>  SCALED-CAPACITY: 300 frames (CAPACITY:150 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=2 ‚Üí allocation=(5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîß Allocated qubits for NONE Exp 3: (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 3: Env:Baseline (None), Attack:No, Rate:0.0, Frames:150, QubitAlloc=Default, SC:300 (Scale=2 x Cap=150), Seed: 20257\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_3\n",
      "\t‚úì QuantumExperimentRunner_3 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_300-Default_Baseline (None)_No-150_3_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_300-Default_Baseline (None)_No-150_3_paper7.pkl\n",
      "\t   File exists: True, size: 90720\n",
      "‚è© SKIPPING EXPERIMENT 3: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 3 GNEURALUCB          : Reward=1190.00, Efficiency=088.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=300, Threshold=0.582]\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=1184.00, Efficiency=087.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=300, Threshold=0.628]\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=1190.00, Efficiency=088.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=300, Threshold=0.634]\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=1350.00, Efficiency=100.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=300, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP3 Winner:iCPursuitNeuralUCB  (Gap:000.0%) [Env:Baseline (None), Attack:No X Rate:0.25, Frames:150, SCapacity=300, Alloc=Default]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 200 frames  <>  SCALED-CAPACITY: 400 frames (CAPACITY:200 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=3 ‚Üí allocation=(5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîß Allocated qubits for NONE Exp 4: (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 4: Env:Baseline (None), Attack:No, Rate:0.0, Frames:200, QubitAlloc=Default, SC:400 (Scale=2 x Cap=200), Seed: 20031\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_4\n",
      "\t‚úì QuantumExperimentRunner_4 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_400-Default_Baseline (None)_No-200_4_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_400-Default_Baseline (None)_No-200_4_paper7.pkl\n",
      "\t   File exists: True, size: 117320\n",
      "‚è© SKIPPING EXPERIMENT 4: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 4 GNEURALUCB          : Reward=1586.00, Efficiency=088.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=400, Threshold=0.582]\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=1600.00, Efficiency=088.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=400, Threshold=0.628]\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=1586.00, Efficiency=088.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=400, Threshold=0.634]\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=1800.00, Efficiency=100.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=400, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP4 Winner:iCPursuitNeuralUCB  (Gap:000.0%) [Env:Baseline (None), Attack:No X Rate:0.25, Frames:200, SCapacity=400, Alloc=Default]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 250 frames  <>  SCALED-CAPACITY: 500 frames (CAPACITY:250 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=4 ‚Üí allocation=(5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîß Allocated qubits for NONE Exp 5: (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 5: Env:Baseline (None), Attack:No, Rate:0.0, Frames:250, QubitAlloc=Default, SC:500 (Scale=2 x Cap=250), Seed: 17303\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_5\n",
      "\t‚úì QuantumExperimentRunner_5 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_500-Default_Baseline (None)_No-250_5_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_500-Default_Baseline (None)_No-250_5_paper7.pkl\n",
      "\t   File exists: True, size: 143929\n",
      "‚è© SKIPPING EXPERIMENT 5: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 5 GNEURALUCB          : Reward=1984.00, Efficiency=088.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=500, Threshold=0.582]\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=1993.00, Efficiency=088.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=500, Threshold=0.628]\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=1984.00, Efficiency=088.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=500, Threshold=0.634]\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=2250.00, Efficiency=100.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=500, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP5 Winner:iCPursuitNeuralUCB  (Gap:000.0%) [Env:Baseline (None), Attack:No X Rate:0.25, Frames:250, SCapacity=500, Alloc=Default]\n",
      "\n",
      "Total experiment time: 014.5s\n",
      "Experiments completed for none\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: STOCHASTIC RANDOM FAILURES\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: STOCHASTIC\n",
      "Category: Stochastic (Natural Random Failures)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 50 frames  <>  SCALED-CAPACITY: 100 frames (CAPACITY:50 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=0 ‚Üí allocation=(5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 1: (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 1: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:50, QubitAlloc=Default, SC:100 (Scale=2 x Cap=50), Seed: 15729\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_1\n",
      "\t‚úì QuantumExperimentRunner_1 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_100-Default_Stochastic_Random-50_1_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_100-Default_Stochastic_Random-50_1_paper7.pkl\n",
      "\t   File exists: True, size: 37479\n",
      "‚è© SKIPPING EXPERIMENT 1: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 1 GNEURALUCB          : Reward=0381.00, Efficiency=084.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=100, Threshold=0.582]\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=0356.00, Efficiency=079.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=100, Threshold=0.628]\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=0381.00, Efficiency=084.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=100, Threshold=0.634]\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=0441.00, Efficiency=098.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=100, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP1 Winner:iCPursuitNeuralUCB  (Gap:002.0%) [Env:Stochastic, Attack:Random X Rate:0.25, Frames:50, SCapacity=100, Alloc=Default]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 100 frames  <>  SCALED-CAPACITY: 200 frames (CAPACITY:100 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=1 ‚Üí allocation=(5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 2: (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 2: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:100, QubitAlloc=Default, SC:200 (Scale=2 x Cap=100), Seed: 19894\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_2\n",
      "\t‚úì QuantumExperimentRunner_2 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_200-Default_Stochastic_Random-100_2_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_200-Default_Stochastic_Random-100_2_paper7.pkl\n",
      "\t   File exists: True, size: 64114\n",
      "‚è© SKIPPING EXPERIMENT 2: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 2 GNEURALUCB          : Reward=0749.00, Efficiency=083.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=200, Threshold=0.582]\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=0671.00, Efficiency=074.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=200, Threshold=0.628]\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=0749.00, Efficiency=083.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=200, Threshold=0.634]\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=0801.00, Efficiency=089.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=200, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP2 Winner:iCPursuitNeuralUCB  (Gap:011.0%) [Env:Stochastic, Attack:Random X Rate:0.25, Frames:100, SCapacity=200, Alloc=Default]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 150 frames  <>  SCALED-CAPACITY: 300 frames (CAPACITY:150 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=2 ‚Üí allocation=(5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 3: (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 3: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:150, QubitAlloc=Default, SC:300 (Scale=2 x Cap=150), Seed: 16736\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_3\n",
      "\t‚úì QuantumExperimentRunner_3 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_300-Default_Stochastic_Random-150_3_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_300-Default_Stochastic_Random-150_3_paper7.pkl\n",
      "\t   File exists: True, size: 90724\n",
      "‚è© SKIPPING EXPERIMENT 3: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 3 GNEURALUCB          : Reward=1121.00, Efficiency=083.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=300, Threshold=0.582]\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=1176.00, Efficiency=087.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=300, Threshold=0.628]\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=1121.00, Efficiency=083.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=300, Threshold=0.634]\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=1242.00, Efficiency=092.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=300, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP3 Winner:iCPursuitNeuralUCB  (Gap:007.9%) [Env:Stochastic, Attack:Random X Rate:0.25, Frames:150, SCapacity=300, Alloc=Default]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 200 frames  <>  SCALED-CAPACITY: 400 frames (CAPACITY:200 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=3 ‚Üí allocation=(5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 4: (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 4: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:200, QubitAlloc=Default, SC:400 (Scale=2 x Cap=200), Seed: 12981\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_4\n",
      "\t‚úì QuantumExperimentRunner_4 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_400-Default_Stochastic_Random-200_4_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_400-Default_Stochastic_Random-200_4_paper7.pkl\n",
      "\t   File exists: True, size: 117324\n",
      "‚è© SKIPPING EXPERIMENT 4: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 4 GNEURALUCB          : Reward=1473.00, Efficiency=081.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=400, Threshold=0.582]\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=1588.00, Efficiency=088.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=400, Threshold=0.628]\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=1473.00, Efficiency=081.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=400, Threshold=0.634]\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=1674.00, Efficiency=093.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=400, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP4 Winner:iCPursuitNeuralUCB  (Gap:007.0%) [Env:Stochastic, Attack:Random X Rate:0.25, Frames:200, SCapacity=400, Alloc=Default]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 250 frames  <>  SCALED-CAPACITY: 500 frames (CAPACITY:250 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=4 ‚Üí allocation=(5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 5: (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 5: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:250, QubitAlloc=Default, SC:500 (Scale=2 x Cap=250), Seed: 17091\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_5\n",
      "\t‚úì QuantumExperimentRunner_5 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_500-Default_Stochastic_Random-250_5_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_500-Default_Stochastic_Random-250_5_paper7.pkl\n",
      "\t   File exists: True, size: 143933\n",
      "‚è© SKIPPING EXPERIMENT 5: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 5 GNEURALUCB          : Reward=1876.00, Efficiency=083.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=500, Threshold=0.582]\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=1676.00, Efficiency=074.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=500, Threshold=0.628]\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=1876.00, Efficiency=083.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=500, Threshold=0.634]\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=2187.00, Efficiency=097.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=500, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP5 Winner:iCPursuitNeuralUCB  (Gap:002.8%) [Env:Stochastic, Attack:Random X Rate:0.25, Frames:250, SCapacity=500, Alloc=Default]\n",
      "\n",
      "Total experiment time: 013.6s\n",
      "Experiments completed for stochastic\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: MARKOV ADVERSARIAL ATTACK\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: MARKOV\n",
      "Category: Structured (Markov Chain Based)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 50 frames  <>  SCALED-CAPACITY: 100 frames (CAPACITY:50 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=0 ‚Üí allocation=(5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîß Allocated qubits for MARKOV Exp 1: (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 1: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:50, QubitAlloc=Default, SC:100 (Scale=2 x Cap=50), Seed: 14132\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_1\n",
      "\t‚úì QuantumExperimentRunner_1 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_100-Default_Adversarial_Markov-50_1_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_100-Default_Adversarial_Markov-50_1_paper7.pkl\n",
      "\t   File exists: True, size: 37474\n",
      "‚è© SKIPPING EXPERIMENT 1: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 1 GNEURALUCB          : Reward=0239.00, Efficiency=055.2% [Retries=3, Failed=0, < Threshold=3, SCapacity=100, Threshold=0.582]\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=0143.00, Efficiency=033.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=100, Threshold=0.628]\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=0239.00, Efficiency=055.2% [Retries=3, Failed=0, < Threshold=3, SCapacity=100, Threshold=0.634]\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=0198.00, Efficiency=045.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=100, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP1 Winner:GNeuralUCB          (Gap:044.8%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:50, SCapacity=100, Alloc=Default]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 100 frames  <>  SCALED-CAPACITY: 200 frames (CAPACITY:100 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=1 ‚Üí allocation=(5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîß Allocated qubits for MARKOV Exp 2: (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 2: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:100, QubitAlloc=Default, SC:200 (Scale=2 x Cap=100), Seed: 22231\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_2\n",
      "\t‚úì QuantumExperimentRunner_2 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_200-Default_Adversarial_Markov-100_2_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_200-Default_Adversarial_Markov-100_2_paper7.pkl\n",
      "\t   File exists: True, size: 64112\n",
      "‚è© SKIPPING EXPERIMENT 2: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 2 GNEURALUCB          : Reward=0434.00, Efficiency=049.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=200, Threshold=0.582]\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=0330.00, Efficiency=037.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=200, Threshold=0.628]\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=0434.00, Efficiency=049.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=200, Threshold=0.634]\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=0408.00, Efficiency=046.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=200, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP2 Winner:GNeuralUCB          (Gap:050.5%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:100, SCapacity=200, Alloc=Default]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 150 frames  <>  SCALED-CAPACITY: 300 frames (CAPACITY:150 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=2 ‚Üí allocation=(5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîß Allocated qubits for MARKOV Exp 3: (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 3: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:150, QubitAlloc=Default, SC:300 (Scale=2 x Cap=150), Seed: 20747\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_3\n",
      "\t‚úì QuantumExperimentRunner_3 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_300-Default_Adversarial_Markov-150_3_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_300-Default_Adversarial_Markov-150_3_paper7.pkl\n",
      "\t   File exists: True, size: 90722\n",
      "‚è© SKIPPING EXPERIMENT 3: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 3 GNEURALUCB          : Reward=0654.00, Efficiency=050.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=300, Threshold=0.582]\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=0553.00, Efficiency=042.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=300, Threshold=0.628]\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=0654.00, Efficiency=050.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=300, Threshold=0.634]\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=0752.00, Efficiency=057.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=300, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP3 Winner:iCPursuitNeuralUCB  (Gap:042.5%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:150, SCapacity=300, Alloc=Default]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 200 frames  <>  SCALED-CAPACITY: 400 frames (CAPACITY:200 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=3 ‚Üí allocation=(5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîß Allocated qubits for MARKOV Exp 4: (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 4: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:200, QubitAlloc=Default, SC:400 (Scale=2 x Cap=200), Seed: 15410\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_4\n",
      "\t‚úì QuantumExperimentRunner_4 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_400-Default_Adversarial_Markov-200_4_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_400-Default_Adversarial_Markov-200_4_paper7.pkl\n",
      "\t   File exists: True, size: 117322\n",
      "‚è© SKIPPING EXPERIMENT 4: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 4 GNEURALUCB          : Reward=0896.00, Efficiency=051.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=400, Threshold=0.582]\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=0870.00, Efficiency=050.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=400, Threshold=0.628]\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=0896.00, Efficiency=051.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=400, Threshold=0.634]\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=0918.00, Efficiency=052.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=400, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP4 Winner:iCPursuitNeuralUCB  (Gap:047.3%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:200, SCapacity=400, Alloc=Default]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 250 frames  <>  SCALED-CAPACITY: 500 frames (CAPACITY:250 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=4 ‚Üí allocation=(5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîß Allocated qubits for MARKOV Exp 5: (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 5: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:250, QubitAlloc=Default, SC:500 (Scale=2 x Cap=250), Seed: 22674\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_5\n",
      "\t‚úì QuantumExperimentRunner_5 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_500-Default_Adversarial_Markov-250_5_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_500-Default_Adversarial_Markov-250_5_paper7.pkl\n",
      "\t   File exists: True, size: 143931\n",
      "‚è© SKIPPING EXPERIMENT 5: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 5 GNEURALUCB          : Reward=1150.00, Efficiency=052.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=500, Threshold=0.582]\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=1028.00, Efficiency=047.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=500, Threshold=0.628]\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=1150.00, Efficiency=052.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=500, Threshold=0.634]\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=1071.00, Efficiency=049.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=500, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP5 Winner:GNeuralUCB          (Gap:047.4%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:250, SCapacity=500, Alloc=Default]\n",
      "\n",
      "Total experiment time: 014.1s\n",
      "Experiments completed for markov\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: ADAPTIVE ADVERSARIAL ATTACK\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: ADAPTIVE\n",
      "Category: Adaptive (Reactive Strategic)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 50 frames  <>  SCALED-CAPACITY: 100 frames (CAPACITY:50 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=0 ‚Üí allocation=(5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 1: (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 1: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:50, QubitAlloc=Default, SC:100 (Scale=2 x Cap=50), Seed: 21427\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_1\n",
      "\t‚úì QuantumExperimentRunner_1 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_100-Default_Adversarial_Adaptive-50_1_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_100-Default_Adversarial_Adaptive-50_1_paper7.pkl\n",
      "\t   File exists: True, size: 37483\n",
      "‚è© SKIPPING EXPERIMENT 1: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 1 GNEURALUCB          : Reward=0271.00, Efficiency=060.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=100, Threshold=0.582]\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=0269.00, Efficiency=060.2% [Retries=3, Failed=0, < Threshold=3, SCapacity=100, Threshold=0.628]\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=0271.00, Efficiency=060.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=100, Threshold=0.634]\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=0280.00, Efficiency=062.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=100, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP1 Winner:iCPursuitNeuralUCB  (Gap:037.4%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:50, SCapacity=100, Alloc=Default]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 100 frames  <>  SCALED-CAPACITY: 200 frames (CAPACITY:100 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=1 ‚Üí allocation=(5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 2: (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 2: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:100, QubitAlloc=Default, SC:200 (Scale=2 x Cap=100), Seed: 13200\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_2\n",
      "\t‚úì QuantumExperimentRunner_2 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_200-Default_Adversarial_Adaptive-100_2_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_200-Default_Adversarial_Adaptive-100_2_paper7.pkl\n",
      "\t   File exists: True, size: 64118\n",
      "‚è© SKIPPING EXPERIMENT 2: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 2 GNEURALUCB          : Reward=0625.00, Efficiency=069.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=200, Threshold=0.582]\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=0555.00, Efficiency=062.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=200, Threshold=0.628]\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=0625.00, Efficiency=069.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=200, Threshold=0.634]\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=0711.00, Efficiency=079.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=200, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP2 Winner:iCPursuitNeuralUCB  (Gap:020.6%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:100, SCapacity=200, Alloc=Default]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 150 frames  <>  SCALED-CAPACITY: 300 frames (CAPACITY:150 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=2 ‚Üí allocation=(5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 3: (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 3: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:150, QubitAlloc=Default, SC:300 (Scale=2 x Cap=150), Seed: 18005\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_3\n",
      "\t‚úì QuantumExperimentRunner_3 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_300-Default_Adversarial_Adaptive-150_3_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_300-Default_Adversarial_Adaptive-150_3_paper7.pkl\n",
      "\t   File exists: True, size: 90728\n",
      "‚è© SKIPPING EXPERIMENT 3: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 3 GNEURALUCB          : Reward=0911.00, Efficiency=068.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=300, Threshold=0.582]\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=0843.00, Efficiency=063.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=300, Threshold=0.628]\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=0911.00, Efficiency=068.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=300, Threshold=0.634]\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=0918.00, Efficiency=068.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=300, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP3 Winner:iCPursuitNeuralUCB  (Gap:031.3%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:150, SCapacity=300, Alloc=Default]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 200 frames  <>  SCALED-CAPACITY: 400 frames (CAPACITY:200 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=3 ‚Üí allocation=(5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 4: (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 4: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:200, QubitAlloc=Default, SC:400 (Scale=2 x Cap=200), Seed: 12955\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_4\n",
      "\t‚úì QuantumExperimentRunner_4 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_400-Default_Adversarial_Adaptive-200_4_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_400-Default_Adversarial_Adaptive-200_4_paper7.pkl\n",
      "\t   File exists: True, size: 117328\n",
      "‚è© SKIPPING EXPERIMENT 4: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 4 GNEURALUCB          : Reward=1236.00, Efficiency=069.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=400, Threshold=0.582]\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=1251.00, Efficiency=069.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=400, Threshold=0.628]\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=1236.00, Efficiency=069.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=400, Threshold=0.634]\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=1404.00, Efficiency=078.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=400, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP4 Winner:iCPursuitNeuralUCB  (Gap:021.5%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:200, SCapacity=400, Alloc=Default]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 250 frames  <>  SCALED-CAPACITY: 500 frames (CAPACITY:250 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=4 ‚Üí allocation=(5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 5: (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 5: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:250, QubitAlloc=Default, SC:500 (Scale=2 x Cap=250), Seed: 14950\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_5\n",
      "\t‚úì QuantumExperimentRunner_5 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_500-Default_Adversarial_Adaptive-250_5_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_500-Default_Adversarial_Adaptive-250_5_paper7.pkl\n",
      "\t   File exists: True, size: 143937\n",
      "‚è© SKIPPING EXPERIMENT 5: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 5 GNEURALUCB          : Reward=1531.00, Efficiency=068.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=500, Threshold=0.582]\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=1650.00, Efficiency=073.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=500, Threshold=0.628]\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=1531.00, Efficiency=068.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=500, Threshold=0.634]\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=1683.00, Efficiency=075.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=500, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP5 Winner:iCPursuitNeuralUCB  (Gap:024.6%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:250, SCapacity=500, Alloc=Default]\n",
      "\n",
      "Total experiment time: 013.9s\n",
      "Experiments completed for adaptive\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: ONLINE ADAPTIVE ATTACK\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: ONLINEADAPTIVE\n",
      "Category: Online Adaptive (Real-time Strategic)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 50 frames  <>  SCALED-CAPACITY: 100 frames (CAPACITY:50 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=0 ‚Üí allocation=(5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 1: (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:50, QubitAlloc=Default, SC:100 (Scale=2 x Cap=50), Seed: 14732\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_1\n",
      "\t‚úì QuantumExperimentRunner_1 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_100-Default_Adversarial_OnlineAdaptive-50_1_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_100-Default_Adversarial_OnlineAdaptive-50_1_paper7.pkl\n",
      "\t   File exists: True, size: 37501\n",
      "‚è© SKIPPING EXPERIMENT 1: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 1 GNEURALUCB          : Reward=0292.00, Efficiency=065.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=100, Threshold=0.582]\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=0328.00, Efficiency=073.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=100, Threshold=0.628]\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=0292.00, Efficiency=065.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=100, Threshold=0.634]\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=0320.00, Efficiency=071.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=100, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP1 Winner:EXPNeuralUCB        (Gap:026.9%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:50, SCapacity=100, Alloc=Default]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 100 frames  <>  SCALED-CAPACITY: 200 frames (CAPACITY:100 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=1 ‚Üí allocation=(5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 2: (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:100, QubitAlloc=Default, SC:200 (Scale=2 x Cap=100), Seed: 14647\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_2\n",
      "\t‚úì QuantumExperimentRunner_2 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_200-Default_Adversarial_OnlineAdaptive-100_2_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_200-Default_Adversarial_OnlineAdaptive-100_2_paper7.pkl\n",
      "\t   File exists: True, size: 64136\n",
      "‚è© SKIPPING EXPERIMENT 2: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 2 GNEURALUCB          : Reward=0584.00, Efficiency=065.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=200, Threshold=0.582]\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=0591.00, Efficiency=066.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=200, Threshold=0.628]\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=0584.00, Efficiency=065.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=200, Threshold=0.634]\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=0693.00, Efficiency=077.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=200, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP2 Winner:iCPursuitNeuralUCB  (Gap:022.6%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:100, SCapacity=200, Alloc=Default]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 150 frames  <>  SCALED-CAPACITY: 300 frames (CAPACITY:150 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=2 ‚Üí allocation=(5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 3: (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:150, QubitAlloc=Default, SC:300 (Scale=2 x Cap=150), Seed: 21138\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_3\n",
      "\t‚úì QuantumExperimentRunner_3 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_300-Default_Adversarial_OnlineAdaptive-150_3_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_300-Default_Adversarial_OnlineAdaptive-150_3_paper7.pkl\n",
      "\t   File exists: True, size: 90746\n",
      "‚è© SKIPPING EXPERIMENT 3: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 3 GNEURALUCB          : Reward=0862.00, Efficiency=064.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=300, Threshold=0.582]\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=0932.00, Efficiency=069.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=300, Threshold=0.628]\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=0862.00, Efficiency=064.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=300, Threshold=0.634]\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=1035.00, Efficiency=077.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=300, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP3 Winner:iCPursuitNeuralUCB  (Gap:022.8%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:150, SCapacity=300, Alloc=Default]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 200 frames  <>  SCALED-CAPACITY: 400 frames (CAPACITY:200 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=3 ‚Üí allocation=(5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 4: (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:200, QubitAlloc=Default, SC:400 (Scale=2 x Cap=200), Seed: 16677\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_4\n",
      "\t‚úì QuantumExperimentRunner_4 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_400-Default_Adversarial_OnlineAdaptive-200_4_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_400-Default_Adversarial_OnlineAdaptive-200_4_paper7.pkl\n",
      "\t   File exists: True, size: 117346\n",
      "‚è© SKIPPING EXPERIMENT 4: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 4 GNEURALUCB          : Reward=1156.00, Efficiency=064.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=400, Threshold=0.582]\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=1198.00, Efficiency=067.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=400, Threshold=0.628]\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=1156.00, Efficiency=064.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=400, Threshold=0.634]\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=1404.00, Efficiency=078.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=400, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP4 Winner:iCPursuitNeuralUCB  (Gap:021.5%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:200, SCapacity=400, Alloc=Default]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 250 frames  <>  SCALED-CAPACITY: 500 frames (CAPACITY:250 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[QubitAllocator] timestep=4 ‚Üí allocation=(5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 5: (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "üîÑ Default Dynamic Allocation (Initial): (5, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:250, QubitAlloc=Default, SC:500 (Scale=2 x Cap=250), Seed: 22447\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_5\n",
      "\t‚úì QuantumExperimentRunner_5 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_500-Default_Adversarial_OnlineAdaptive-250_5_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_500-Default_Adversarial_OnlineAdaptive-250_5_paper7.pkl\n",
      "\t   File exists: True, size: 143955\n",
      "‚è© SKIPPING EXPERIMENT 5: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 5 GNEURALUCB          : Reward=1544.00, Efficiency=069.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=500, Threshold=0.582]\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=1442.00, Efficiency=064.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=500, Threshold=0.628]\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=1544.00, Efficiency=069.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=500, Threshold=0.634]\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=1683.00, Efficiency=075.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=500, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP5 Winner:iCPursuitNeuralUCB  (Gap:024.8%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:250, SCapacity=500, Alloc=Default]\n",
      "\n",
      "Total experiment time: 014.1s\n",
      "Experiments completed for onlineadaptive\n",
      "‚úì Scenario 'none' evaluation completed.\n",
      "‚úì Scenario 'stochastic' evaluation completed.\n",
      "‚úì Scenario 'markov' evaluation completed.\n",
      "‚úì Scenario 'adaptive' evaluation completed.\n",
      "‚úì Scenario 'onlineadaptive' evaluation completed.\n",
      "\n",
      "======================================================================\n",
      "COMPREHENSIVE SCENARIO PERFORMANCE ANALYSIS\n",
      "======================================================================\n",
      "SCENARIO: NONE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 1350.00\n",
      "\t‚Ä¢ Winner Avg Gap: 0000.00%\n",
      "\t‚Ä¢ Winner Avg Reward: 1350.00\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0100.00%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 5 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: NONE\n",
      "======================================================================\n",
      "SCENARIO: \tBASELINE (OPTIMAL CONDITIONS)\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 5/5 experiments)\n",
      "\tWinner Avg Gap: \t000.0%\n",
      "\tWinner Avg Efficiency: \t100.0%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t100.0% Efficiency \t(Won 5/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t088.9% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t088.1% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t088.1% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: STOCHASTIC\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 1349.60\n",
      "\t‚Ä¢ Winner Avg Gap: 0006.13%\n",
      "\t‚Ä¢ Winner Avg Reward: 1269.00\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0093.87%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 5 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: STOCHASTIC\n",
      "======================================================================\n",
      "SCENARIO: \tSTOCHASTIC RANDOM FAILURES\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 5/5 experiments)\n",
      "\tWinner Avg Gap: \t006.1%\n",
      "\tWinner Avg Efficiency: \t093.9%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t093.9% Efficiency \t(Won 5/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t083.3% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t083.3% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t080.7% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: MARKOV\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: GNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 1308.40\n",
      "\t‚Ä¢ Winner Avg Gap: 0048.23%\n",
      "\t‚Ä¢ Winner Avg Reward: 0674.60\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0051.77%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 3 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 2 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: MARKOV\n",
      "======================================================================\n",
      "SCENARIO: \tMARKOV ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tGNeuralUCB (Won 3/5 experiments)\n",
      "\tWinner Avg Gap: \t048.2%\n",
      "\tWinner Avg Efficiency: \t051.8%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ GNeuralUCB     : \t051.8% Efficiency \t(Won 3/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t051.8% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t050.3% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t042.0% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 1340.20\n",
      "\t‚Ä¢ Winner Avg Gap: 0027.08%\n",
      "\t‚Ä¢ Winner Avg Reward: 0999.20\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0072.92%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 5 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tADAPTIVE ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 5/5 experiments)\n",
      "\tWinner Avg Gap: \t027.1%\n",
      "\tWinner Avg Efficiency: \t072.9%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t072.9% Efficiency \t(Won 5/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t067.2% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t067.2% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t065.8% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ONLINEADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 1342.40\n",
      "\t‚Ä¢ Winner Avg Gap: 0024.08%\n",
      "\t‚Ä¢ Winner Avg Reward: 1027.00\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0075.92%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 1 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 4 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ONLINEADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tONLINE ADAPTIVE ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 4/5 experiments)\n",
      "\tWinner Avg Gap: \t024.1%\n",
      "\tWinner Avg Efficiency: \t075.9%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t075.9% Efficiency \t(Won 4/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t068.0% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t065.6% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t065.6% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "KEY INSIGHTS:\n",
      "Best Performing Model Analysis (iCPursuitNeuralUCB):\n",
      "\t‚Ä¢ Stochastic Performance:    \t1269.000\n",
      "\t‚Ä¢ Baseline Performance:      \t1350.000\n",
      "\t‚Ä¢ Performance Retention:     \t094.0%\n",
      "\tGOOD:               \tAcceptable performance under stochastic conditions\n",
      "Statistical Analysis:\n",
      "\t‚Ä¢ Total models evaluated:     \t5\n",
      "\t‚Ä¢ Experiments per environment:\t5\n",
      "\t‚Ä¢ Quantum network simulation: \tComprehensive stochastic modeling\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "COMPREHENSIVE SCENARIO PERFORMANCE ANALYSIS\n",
      "======================================================================\n",
      "SCENARIO: NONE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 1350.00\n",
      "\t‚Ä¢ Winner Avg Gap: 0000.00%\n",
      "\t‚Ä¢ Winner Avg Reward: 1350.00\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0100.00%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 5 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: NONE\n",
      "======================================================================\n",
      "SCENARIO: \tBASELINE (OPTIMAL CONDITIONS)\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 5/5 experiments)\n",
      "\tWinner Avg Gap: \t000.0%\n",
      "\tWinner Avg Efficiency: \t100.0%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t100.0% Efficiency \t(Won 5/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t088.9% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t088.1% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t088.1% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: STOCHASTIC\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 1349.60\n",
      "\t‚Ä¢ Winner Avg Gap: 0006.13%\n",
      "\t‚Ä¢ Winner Avg Reward: 1269.00\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0093.87%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 5 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: STOCHASTIC\n",
      "======================================================================\n",
      "SCENARIO: \tSTOCHASTIC RANDOM FAILURES\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 5/5 experiments)\n",
      "\tWinner Avg Gap: \t006.1%\n",
      "\tWinner Avg Efficiency: \t093.9%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t093.9% Efficiency \t(Won 5/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t083.3% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t083.3% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t080.7% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: MARKOV\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: GNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 1308.40\n",
      "\t‚Ä¢ Winner Avg Gap: 0048.23%\n",
      "\t‚Ä¢ Winner Avg Reward: 0674.60\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0051.77%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 3 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 2 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: MARKOV\n",
      "======================================================================\n",
      "SCENARIO: \tMARKOV ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tGNeuralUCB (Won 3/5 experiments)\n",
      "\tWinner Avg Gap: \t048.2%\n",
      "\tWinner Avg Efficiency: \t051.8%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ GNeuralUCB     : \t051.8% Efficiency \t(Won 3/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t051.8% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t050.3% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t042.0% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 1340.20\n",
      "\t‚Ä¢ Winner Avg Gap: 0027.08%\n",
      "\t‚Ä¢ Winner Avg Reward: 0999.20\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0072.92%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 5 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tADAPTIVE ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 5/5 experiments)\n",
      "\tWinner Avg Gap: \t027.1%\n",
      "\tWinner Avg Efficiency: \t072.9%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t072.9% Efficiency \t(Won 5/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t067.2% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t067.2% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t065.8% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ONLINEADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 1342.40\n",
      "\t‚Ä¢ Winner Avg Gap: 0024.08%\n",
      "\t‚Ä¢ Winner Avg Reward: 1027.00\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0075.92%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 1 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 4 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ONLINEADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tONLINE ADAPTIVE ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 4/5 experiments)\n",
      "\tWinner Avg Gap: \t024.1%\n",
      "\tWinner Avg Efficiency: \t075.9%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t075.9% Efficiency \t(Won 4/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t068.0% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t065.6% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t065.6% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "‚úÖ Evaluation completed!\n",
      "[Logging Redirect Stopped]\n",
      "\n",
      "üßπ Final cleanup for Default\n",
      "\n",
      "======================================================================\n",
      "‚úÖ COMPLETED: Default\n",
      "======================================================================\n",
      "\n",
      "Default COMPLETED SUCCESSFULLY\n",
      "\n",
      "======================================================================\n",
      "ALL ALLOCATORS COMPLETE!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Cell 2: Allocator + ExperimentConfiguration for Paper #7\n",
    "# ============================================================\n",
    "importlib.reload(qubit_allocator)\n",
    "importlib.reload(experiment_config)\n",
    "importlib.reload(multi_run_evaluator)\n",
    "\n",
    "from daqr.core.quantum_physics              import *\n",
    "from daqr.evaluation.allocator_runner       import AllocatorRunner\n",
    "from daqr.evaluation.multi_run_evaluator    import MultiRunEvaluator\n",
    "from daqr.config.experiment_config          import ExperimentConfiguration\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"PAPER #7 (QBGP) QUANTUM ROUTING EVALUATION - SINGLE ALLOCATOR TEST\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1) Single Allocator Selection\n",
    "# ------------------------------------------------------------\n",
    "allocator_type = \"Default\"  # Options: \"Random\", \"DynamicUCB\", \"ThompsonSampling\"\n",
    "ALLOCATORS = [allocator_type]\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2) Run Parameters\n",
    "# ------------------------------------------------------------\n",
    "attack_intensity    = FRAMEWORK_CONFIG['intensity']\n",
    "current_frames      = 50\n",
    "frame_step          = 50\n",
    "current_experiments = 5\n",
    "last_backup         = True\n",
    "base_cap            = False\n",
    "overwrite           = True\n",
    "\n",
    "FRAMEWORK_CONFIG['exp_num']        = current_experiments\n",
    "FRAMEWORK_CONFIG['base_frames']    = current_frames\n",
    "FRAMEWORK_CONFIG['frame_step']     = frame_step\n",
    "\n",
    "\n",
    "# Testbed Configuration\n",
    "PHYSICS_MODELS = ['paper7']  # Paper 7 (QBGP)\n",
    "ATTACK_SCENARIOS = ['stochastic']  # Start simple\n",
    "SCALES = [1, 1.5, 2]\n",
    "RUNS = [5]\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üéØ PAPER 7 ALLOCATOR EVALUATION\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Allocator:                  {allocator_type}\")\n",
    "print(f\"Physics Model:              {PHYSICS_MODELS[0]}\")\n",
    "print(f\"Attack Scenarios:           {ATTACK_SCENARIOS}\")\n",
    "print(f\"Scales:                     {SCALES}\")\n",
    "print(f\"Runs per Scale:             {RUNS}\")\n",
    "print(f\"Total Frames:               {current_frames}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Run allocators over scales and physics models\n",
    "for allocator_type in ALLOCATORS:\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"RUNNING: {allocator_type} on Paper 7 (QBGP)\")\n",
    "    print('='*70)\n",
    "\n",
    "    for scale in SCALES:\n",
    "        print(f\"\\n{'-'*70}\")\n",
    "        print(f\"Preparing: {allocator_type} at scale {scale}\")\n",
    "        print(f\"{'-'*70}\")\n",
    "\n",
    "        for physics_model in PHYSICS_MODELS:\n",
    "            print(f\"\\nüîß Generating physics parameters for model: {physics_model}\") \n",
    "            try:\n",
    "                # Create isolated runner instance\n",
    "                custom_config = ExperimentConfiguration(\n",
    "                    env_type=FRAMEWORK_CONFIG['main_env'],\n",
    "                    scenarios=test_scenarios,\n",
    "                    use_last_backup=last_backup,\n",
    "                    models=models,\n",
    "                    attack_intensity=attack_intensity,\n",
    "                    scale=scale,\n",
    "                    base_capacity=base_cap,\n",
    "                    overwrite=overwrite\n",
    "                )\n",
    "\n",
    "                alloc_runner = AllocatorRunner(\n",
    "                    allocator_type=allocator_type,\n",
    "                    physics_models=[physics_model],\n",
    "                    framework_config=FRAMEWORK_CONFIG,\n",
    "                    scales=[scale],\n",
    "                    runs=RUNS,\n",
    "                    models=models,\n",
    "                    test_scenarios=test_scenarios,\n",
    "                    config=custom_config\n",
    "                )\n",
    "\n",
    "                # Run with Paper 12 physics\n",
    "                alloc_runner.run(get_physics_params_func=get_physics_params)\n",
    "                print(f\"\\n{allocator_type} COMPLETED SUCCESSFULLY\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"\\n{allocator_type} FAILED: {e}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ALL ALLOCATORS COMPLETE!\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "PAPER #7 (QBGP) QUANTUM ROUTING EVALUATION - SINGLE ALLOCATOR TEST\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "üéØ PAPER 7 ALLOCATOR EVALUATION\n",
      "======================================================================\n",
      "Allocator:                  Dynamic\n",
      "Physics Model:              paper7\n",
      "Attack Scenarios:           ['stochastic']\n",
      "Scales:                     [1, 1.5, 2]\n",
      "Runs per Scale:             [5]\n",
      "Total Frames:               50\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "RUNNING: Dynamic on Paper 7 (QBGP)\n",
      "======================================================================\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Preparing: Dynamic at scale 1\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üîß Generating physics parameters for model: paper7\n",
      "\n",
      "===================== GET LOCAL REGISTRY =====================\n",
      "‚Üí Skipping local cache (force=True or file missing)\n",
      "\n",
      "===================== BUILD LOCAL REGISTRY =====================\n",
      "\n",
      "================================================================================\n",
      "üîç SCANNING LOCAL FILES\n",
      "================================================================================\n",
      "Parameters: load_to_drive=False, force=False\n",
      "\n",
      "üìÇ Checking DRIVE mode: /content/drive/Shareddrives/ai_quantum_computing/quantum_data_lake\n",
      "   ‚ö†Ô∏è  Path does not exist, skipping\n",
      "\n",
      "üìÇ Checking LOCAL mode: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config\n",
      "   ‚úÖ Path exists, starting walk...\n",
      "   üö∂ Walking directory tree: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config\n",
      "\n",
      "   üìÅ Directory: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201\n",
      "      Relative: framework_state/day_20260201\n",
      "      Component: framework_state\n",
      "      Date: day_20260201\n",
      "      üìÑ Processing 2514 files in framework_state/day_20260201\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "      üìä framework_state/day_20260201: 2488/2514 files processed\n",
      "      üìä framework_state/day_20260201: 0/2514 files skipped\n",
      "      üìä framework_state/day_20260201: 26/2514 files conflicted\n",
      "\n",
      "   üìÅ Directory: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/model_state/day_20260201\n",
      "      Relative: model_state/day_20260201\n",
      "      Component: model_state\n",
      "      Date: day_20260201\n",
      "      üìÑ Processing 8842 files in model_state/day_20260201\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "      üìä model_state/day_20260201: 8842/8842 files processed\n",
      "      üìä model_state/day_20260201: 0/8842 files skipped\n",
      "      üìä model_state/day_20260201: 0/8842 files conflicted\n",
      "\n",
      "   üìä Processed 2 directories\n",
      "\n",
      "================================================================================\n",
      "üì¶ BUILDING FINAL REGISTRY\n",
      "================================================================================\n",
      "Components found: ['framework_state', 'model_state']\n",
      "  ‚Ä¢ framework_state: 2488 files\n",
      "  ‚Ä¢ model_state: 8842 files\n",
      "\n",
      "‚úÖ SCAN COMPLETE\n",
      "Modes scanned: 1\n",
      "Total files in registry: 11330\n",
      "================================================================================\n",
      "\n",
      "\t‚Üí Filesystem scan found 11330 files\n",
      "\n",
      "===================== GET DRIVE REGISTRY =====================\n",
      "===================== REGISTRY BUILD COMPLETE =====================\n",
      "\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "\tüì¶ LocalBackupManager Registry Saved Locally in LOCAL\n",
      "BUILDING REGISTRY WITH 0 EXPECTED COMPONENTS KEYS\n",
      "\n",
      "===================== GET LOCAL REGISTRY =====================\n",
      "‚Üí Skipping local cache (force=True or file missing)\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "\tüì¶ LocalBackupManager Registry Saved Locally in LOCAL\n",
      "\n",
      "======================================================================\n",
      "üéØ AllocatorRunner initialized: Dynamic\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "üöÄ STARTING ALLOCATOR: Dynamic\n",
      "======================================================================\n",
      "\n",
      "üìä Physics Model: paper7\n",
      "\n",
      "üìã Allocator Config:\n",
      "   Type: Dynamic\n",
      "   Testbed: default\n",
      "   Paths: 15\n",
      "   Total Qubits: 75\n",
      "   Min per route: 2\n",
      "   Seed: 42\n",
      "   Exploration bonus: 2.0\n",
      "‚úÖ Allocator created: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "‚úì Allocator: DynamicQubitAllocator (15 paths)\n",
      "   Initial allocation: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üìä Paper7 Topology: Real AS (as20000101.txt)\n",
      "üìä Paper7 Paths: 15 paths from 5-shortest between 3 ISPs\n",
      "üìä Paper7 Contexts: 15 context vectors generated\n",
      "üìä Paper7 Rewards: Context-aware (mode=neg_hop)\n",
      "‚è±Ô∏è  get_physics_params_paper7() time: 2.2 ms\n",
      "\n",
      "======================================================================\n",
      "RUN 1 | Scale: 1 | Exp: 5\n",
      "======================================================================\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "\n",
      "\tüîÑ Resume: MultiRunEvaluator\n",
      "\n",
      "=====================================================\n",
      "üîç GENERATING EXPECTED KEYS FROM EVALUATOR\n",
      "=====================================================\n",
      "  ‚Ä¢ Evaluator filename: MultiRunEvaluator_50-Dynamic_All_All-50_50_5_S1T_paper7.pkl\n",
      "\n",
      "üß© PARSED COMPONENTS\n",
      "  ‚Ä¢ cap_id:        50\n",
      "  ‚Ä¢ allocator_id:  Dynamic\n",
      "  ‚Ä¢ env_id:        All\n",
      "  ‚Ä¢ attack_id:     All\n",
      "  ‚Ä¢ base_frames:   50\n",
      "  ‚Ä¢ frame_step:    50\n",
      "  ‚Ä¢ runs_id:       5\n",
      "\n",
      "=====================================================\n",
      "üß™ GENERATING KEYS FOR EACH RUN\n",
      "=====================================================\n",
      "\n",
      "--- Run 1/5 -----------------------\n",
      "\n",
      "=====================================================\n",
      "üì¶ FINAL EXPECTED KEYS\n",
      "=====================================================\n",
      "  ‚Ä¢ Runner keys: 11\n",
      "\n",
      "  ‚Ä¢ Model keys: 50\n",
      "\n",
      "--- Run 2/5 -----------------------\n",
      "\n",
      "=====================================================\n",
      "üì¶ FINAL EXPECTED KEYS\n",
      "=====================================================\n",
      "  ‚Ä¢ Runner keys: 21\n",
      "\n",
      "  ‚Ä¢ Model keys: 100\n",
      "\n",
      "--- Run 3/5 -----------------------\n",
      "\n",
      "=====================================================\n",
      "üì¶ FINAL EXPECTED KEYS\n",
      "=====================================================\n",
      "  ‚Ä¢ Runner keys: 31\n",
      "\n",
      "  ‚Ä¢ Model keys: 150\n",
      "\n",
      "--- Run 4/5 -----------------------\n",
      "\n",
      "=====================================================\n",
      "üì¶ FINAL EXPECTED KEYS\n",
      "=====================================================\n",
      "  ‚Ä¢ Runner keys: 41\n",
      "\n",
      "  ‚Ä¢ Model keys: 200\n",
      "\n",
      "--- Run 5/5 -----------------------\n",
      "\n",
      "=====================================================\n",
      "üì¶ FINAL EXPECTED KEYS\n",
      "=====================================================\n",
      "  ‚Ä¢ Runner keys: 51\n",
      "\n",
      "  ‚Ä¢ Model keys: 250\n",
      "\n",
      "EXPECTED KEY GENERATION COMPLETE\n",
      "\n",
      "RESTORING FROM DRIVE 1\n",
      "RESTORING FROM DRIVE 2\n",
      "\t‚ö†Ô∏è Registry exists ‚Üí aborting restore\n",
      "\t‚òÅÔ∏è Attempting Drive download: framework_state/MultiRunEvaluator_50-Dynamic_All_All-50_50_5_S1T_paper7.pkl\n",
      "\t‚ùå Not found anywhere: framework_state/MultiRunEvaluator_50-Dynamic_All_All-50_50_5_S1T_paper7.pkl\n",
      "\t‚ùå Not found in registry or fallback locations\n",
      "\t‚òÅÔ∏è Attempting Drive download: framework_state/MultiRunEvaluator_50-Dynamic_All_All-50_50_5_S1T_paper7.pkl\n",
      "\t‚ùå Not found anywhere: framework_state/MultiRunEvaluator_50-Dynamic_All_All-50_50_5_S1T_paper7.pkl\n",
      "\t‚ùå Not found in registry or fallback locations\n",
      "[Resume] exact failed ‚Üí Looking for supersets\n",
      "[Resume-Supersets] target_runs=5, backups=dict_keys([])\n",
      "[Resume-Supersets] Trying horizons in size order (largest first): []\n",
      "[Resume-Supersets] ‚ùå No valid supersets found for resume\n",
      "No state found for MultiRunEvaluator, disabling resume for Experiment Runners\n",
      "Multi-Run Evaluator Initialized\n",
      "Environment Type: None\n",
      "Frame Range: 50 -> 250 (step: 50)\n",
      "quantum_exps-Dynamic(paper7)_alloc-all_envs-5_attacks-50_50-5_runs-S1T\n",
      "[Logging Redirect Initialized]\n",
      "Log File: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/quantum_logs/quantum_exps-Dynamic(paper7)_alloc-all_envs-5_attacks-50_50-5_runs-S1T_20260201_log.txt\n",
      "‚öô Running evaluation...\n",
      "======================================================================\n",
      "SCENARIOS MODEL EVALUATION\n",
      "======================================================================\n",
      "Testing algorithm performance against:\n",
      "\t‚Ä¢ Stochastic:  \tNatural quantum decoherence and network failures\n",
      "\t‚Ä¢ Baseline:    \tOptimal conditions for validation\n",
      "======================================================================\n",
      "Models to Test:             \tOracle, GNeuralUCB, EXPNeuralUCB, CPursuitNeuralUCB, iCPursuitNeuralUCB\n",
      "Experiments per Scenario:   \t5\n",
      "======================================================================\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: BASELINE (OPTIMAL CONDITIONS)\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: NONE\n",
      "Category: Baseline (No Attacks)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 50 frames  <>  SCALED-CAPACITY: 50 frames (CAPACITY:50 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=0 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for NONE Exp 1: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 1: Env:Baseline (None), Attack:No, Rate:0.0, Frames:50, QubitAlloc=Dynamic, SC:50 (Scale=1 x Cap=50), Seed: 15373\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 15\n",
      "\t   First reward: [9.0], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 1: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 GNEURALUCB          : Reward=0396.00, Efficiency=088.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=50, Threshold=0.582]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 1: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=0396.00, Efficiency=088.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=50, Threshold=0.628]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 1: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=0396.00, Efficiency=088.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=50, Threshold=0.634]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 1: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=0450.00, Efficiency=100.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=50, Threshold=0.712]\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 1: Env:Baseline (None), Attack:No, Rate:0.0, Frames:50, QubitAlloc=Dynamic, SC:50 (Scale=1 x Cap=50), Seed: 15373\n",
      "\t-->üèÜ EXP1 Winner:iCPursuitNeuralUCB  (Gap:000.0%) [Env:Baseline (None), Attack:No X Rate:0.0, Frames:50, SCapacity=50, Alloc=Dynamic]\n",
      "‚úì Experiment 1 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 100 frames  <>  SCALED-CAPACITY: 100 frames (CAPACITY:100 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=1 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for NONE Exp 2: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 2: Env:Baseline (None), Attack:No, Rate:0.0, Frames:100, QubitAlloc=Dynamic, SC:100 (Scale=1 x Cap=100), Seed: 12644\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 15\n",
      "\t   First reward: [9.0], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 2: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 GNEURALUCB          : Reward=0794.00, Efficiency=088.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=100, Threshold=0.582]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 2: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=0830.00, Efficiency=092.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=100, Threshold=0.628]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 2: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=0794.00, Efficiency=088.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=100, Threshold=0.634]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 2: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=0900.00, Efficiency=100.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=100, Threshold=0.712]\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 2: Env:Baseline (None), Attack:No, Rate:0.0, Frames:100, QubitAlloc=Dynamic, SC:100 (Scale=1 x Cap=100), Seed: 12644\n",
      "\t-->üèÜ EXP2 Winner:iCPursuitNeuralUCB  (Gap:000.0%) [Env:Baseline (None), Attack:No X Rate:0.0, Frames:100, SCapacity=100, Alloc=Dynamic]\n",
      "‚úì Experiment 2 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 150 frames  <>  SCALED-CAPACITY: 150 frames (CAPACITY:150 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=2 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for NONE Exp 3: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 3: Env:Baseline (None), Attack:No, Rate:0.0, Frames:150, QubitAlloc=Dynamic, SC:150 (Scale=1 x Cap=150), Seed: 20257\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 15\n",
      "\t   First reward: [9.0], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 3: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 GNEURALUCB          : Reward=1190.00, Efficiency=088.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=150, Threshold=0.582]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 3: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=1229.00, Efficiency=091.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=150, Threshold=0.628]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 3: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=1190.00, Efficiency=088.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=150, Threshold=0.634]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 3: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=1350.00, Efficiency=100.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=150, Threshold=0.712]\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 3: Env:Baseline (None), Attack:No, Rate:0.0, Frames:150, QubitAlloc=Dynamic, SC:150 (Scale=1 x Cap=150), Seed: 20257\n",
      "\t-->üèÜ EXP3 Winner:iCPursuitNeuralUCB  (Gap:000.0%) [Env:Baseline (None), Attack:No X Rate:0.0, Frames:150, SCapacity=150, Alloc=Dynamic]\n",
      "‚úì Experiment 3 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 200 frames  <>  SCALED-CAPACITY: 200 frames (CAPACITY:200 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=3 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for NONE Exp 4: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 4: Env:Baseline (None), Attack:No, Rate:0.0, Frames:200, QubitAlloc=Dynamic, SC:200 (Scale=1 x Cap=200), Seed: 20031\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 15\n",
      "\t   First reward: [9.0], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 4: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 GNEURALUCB          : Reward=1586.00, Efficiency=088.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=200, Threshold=0.582]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 4: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=1567.00, Efficiency=087.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=200, Threshold=0.628]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 4: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=1586.00, Efficiency=088.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=200, Threshold=0.634]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 4: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=1800.00, Efficiency=100.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=200, Threshold=0.712]\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 4: Env:Baseline (None), Attack:No, Rate:0.0, Frames:200, QubitAlloc=Dynamic, SC:200 (Scale=1 x Cap=200), Seed: 20031\n",
      "\t-->üèÜ EXP4 Winner:iCPursuitNeuralUCB  (Gap:000.0%) [Env:Baseline (None), Attack:No X Rate:0.0, Frames:200, SCapacity=200, Alloc=Dynamic]\n",
      "‚úì Experiment 4 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 250 frames  <>  SCALED-CAPACITY: 250 frames (CAPACITY:250 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=4 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for NONE Exp 5: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 5: Env:Baseline (None), Attack:No, Rate:0.0, Frames:250, QubitAlloc=Dynamic, SC:250 (Scale=1 x Cap=250), Seed: 17303\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 15\n",
      "\t   First reward: [9.0], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 5: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 GNEURALUCB          : Reward=1984.00, Efficiency=088.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=250, Threshold=0.582]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 5: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=1879.00, Efficiency=083.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=250, Threshold=0.628]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 5: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=1984.00, Efficiency=088.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=250, Threshold=0.634]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 5: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=2250.00, Efficiency=100.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=250, Threshold=0.712]\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 5: Env:Baseline (None), Attack:No, Rate:0.0, Frames:250, QubitAlloc=Dynamic, SC:250 (Scale=1 x Cap=250), Seed: 17303\n",
      "\t-->üèÜ EXP5 Winner:iCPursuitNeuralUCB  (Gap:000.0%) [Env:Baseline (None), Attack:No X Rate:0.0, Frames:250, SCapacity=250, Alloc=Dynamic]\n",
      "‚úì Experiment 5 completed successfully.\n",
      "Total experiment time: 1212.1s\n",
      "Experiments completed for none\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: STOCHASTIC RANDOM FAILURES\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: STOCHASTIC\n",
      "Category: Stochastic (Natural Random Failures)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 50 frames  <>  SCALED-CAPACITY: 50 frames (CAPACITY:50 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=0 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 1: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 1: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:50, QubitAlloc=Dynamic, SC:50 (Scale=1 x Cap=50), Seed: 15729\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 15\n",
      "\t   First reward: [9.0], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 1: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 GNEURALUCB          : Reward=0381.00, Efficiency=084.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=50, Threshold=0.582]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 1: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=0389.00, Efficiency=086.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=50, Threshold=0.628]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 1: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=0381.00, Efficiency=084.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=50, Threshold=0.634]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 1: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=0423.00, Efficiency=094.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=50, Threshold=0.712]\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 1: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:50, QubitAlloc=Dynamic, SC:50 (Scale=1 x Cap=50), Seed: 15729\n",
      "\t-->üèÜ EXP1 Winner:iCPursuitNeuralUCB  (Gap:005.8%) [Env:Stochastic, Attack:Random X Rate:0.0625, Frames:50, SCapacity=50, Alloc=Dynamic]\n",
      "‚úì Experiment 1 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 100 frames  <>  SCALED-CAPACITY: 100 frames (CAPACITY:100 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=1 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 2: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 2: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:100, QubitAlloc=Dynamic, SC:100 (Scale=1 x Cap=100), Seed: 19894\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 15\n",
      "\t   First reward: [9.0], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 2: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 GNEURALUCB          : Reward=0726.00, Efficiency=080.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=100, Threshold=0.582]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 2: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=0692.00, Efficiency=076.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=100, Threshold=0.628]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 2: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=0726.00, Efficiency=080.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=100, Threshold=0.634]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 2: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=0828.00, Efficiency=092.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=100, Threshold=0.712]\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 2: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:100, QubitAlloc=Dynamic, SC:100 (Scale=1 x Cap=100), Seed: 19894\n",
      "\t-->üèÜ EXP2 Winner:iCPursuitNeuralUCB  (Gap:008.0%) [Env:Stochastic, Attack:Random X Rate:0.0625, Frames:100, SCapacity=100, Alloc=Dynamic]\n",
      "‚úì Experiment 2 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 150 frames  <>  SCALED-CAPACITY: 150 frames (CAPACITY:150 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=2 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 3: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 3: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:150, QubitAlloc=Dynamic, SC:150 (Scale=1 x Cap=150), Seed: 16736\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 15\n",
      "\t   First reward: [9.0], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 3: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 GNEURALUCB          : Reward=1142.00, Efficiency=084.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=150, Threshold=0.582]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 3: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=1156.00, Efficiency=085.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=150, Threshold=0.628]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 3: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=1142.00, Efficiency=084.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=150, Threshold=0.634]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 3: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=1260.00, Efficiency=093.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=150, Threshold=0.712]\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 3: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:150, QubitAlloc=Dynamic, SC:150 (Scale=1 x Cap=150), Seed: 16736\n",
      "\t-->üèÜ EXP3 Winner:iCPursuitNeuralUCB  (Gap:006.7%) [Env:Stochastic, Attack:Random X Rate:0.0625, Frames:150, SCapacity=150, Alloc=Dynamic]\n",
      "‚úì Experiment 3 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 200 frames  <>  SCALED-CAPACITY: 200 frames (CAPACITY:200 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=3 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 4: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 4: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:200, QubitAlloc=Dynamic, SC:200 (Scale=1 x Cap=200), Seed: 12981\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 15\n",
      "\t   First reward: [9.0], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 4: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 GNEURALUCB          : Reward=1488.00, Efficiency=082.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=200, Threshold=0.582]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 4: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=1524.00, Efficiency=084.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=200, Threshold=0.628]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 4: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=1488.00, Efficiency=082.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=200, Threshold=0.634]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 4: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=1674.00, Efficiency=093.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=200, Threshold=0.712]\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 4: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:200, QubitAlloc=Dynamic, SC:200 (Scale=1 x Cap=200), Seed: 12981\n",
      "\t-->üèÜ EXP4 Winner:iCPursuitNeuralUCB  (Gap:006.8%) [Env:Stochastic, Attack:Random X Rate:0.0625, Frames:200, SCapacity=200, Alloc=Dynamic]\n",
      "‚úì Experiment 4 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 250 frames  <>  SCALED-CAPACITY: 250 frames (CAPACITY:250 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=4 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 5: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 5: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:250, QubitAlloc=Dynamic, SC:250 (Scale=1 x Cap=250), Seed: 17091\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 15\n",
      "\t   First reward: [9.0], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 5: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 GNEURALUCB          : Reward=1843.00, Efficiency=081.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=250, Threshold=0.582]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 5: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=1915.00, Efficiency=085.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=250, Threshold=0.628]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 5: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=1843.00, Efficiency=081.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=250, Threshold=0.634]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 5: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=2115.00, Efficiency=094.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=250, Threshold=0.712]\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 5: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:250, QubitAlloc=Dynamic, SC:250 (Scale=1 x Cap=250), Seed: 17091\n",
      "\t-->üèÜ EXP5 Winner:iCPursuitNeuralUCB  (Gap:006.0%) [Env:Stochastic, Attack:Random X Rate:0.0625, Frames:250, SCapacity=250, Alloc=Dynamic]\n",
      "‚úì Experiment 5 completed successfully.\n",
      "Total experiment time: 1044.3s\n",
      "Experiments completed for stochastic\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: MARKOV ADVERSARIAL ATTACK\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: MARKOV\n",
      "Category: Structured (Markov Chain Based)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 50 frames  <>  SCALED-CAPACITY: 50 frames (CAPACITY:50 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=0 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for MARKOV Exp 1: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 1: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:50, QubitAlloc=Dynamic, SC:50 (Scale=1 x Cap=50), Seed: 14132\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 15\n",
      "\t   First reward: [9.0], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 1: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 GNEURALUCB          : Reward=0194.00, Efficiency=044.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=50, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 1: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=0173.00, Efficiency=039.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=50, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 1: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=0194.00, Efficiency=044.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=50, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 1: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=0261.00, Efficiency=059.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=50, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 1: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:50, QubitAlloc=Dynamic, SC:50 (Scale=1 x Cap=50), Seed: 14132\n",
      "\t-->üèÜ EXP1 Winner:iCPursuitNeuralUCB  (Gap:040.7%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:50, SCapacity=50, Alloc=Dynamic]\n",
      "‚úì Experiment 1 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 100 frames  <>  SCALED-CAPACITY: 100 frames (CAPACITY:100 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=1 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for MARKOV Exp 2: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 2: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:100, QubitAlloc=Dynamic, SC:100 (Scale=1 x Cap=100), Seed: 22231\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 15\n",
      "\t   First reward: [9.0], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 2: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 GNEURALUCB          : Reward=0402.00, Efficiency=045.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=100, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 2: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=0354.00, Efficiency=040.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=100, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 2: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=0402.00, Efficiency=045.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=100, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 2: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=0441.00, Efficiency=050.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=100, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 2: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:100, QubitAlloc=Dynamic, SC:100 (Scale=1 x Cap=100), Seed: 22231\n",
      "\t-->üèÜ EXP2 Winner:iCPursuitNeuralUCB  (Gap:049.6%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:100, SCapacity=100, Alloc=Dynamic]\n",
      "‚úì Experiment 2 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 150 frames  <>  SCALED-CAPACITY: 150 frames (CAPACITY:150 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=2 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for MARKOV Exp 3: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 3: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:150, QubitAlloc=Dynamic, SC:150 (Scale=1 x Cap=150), Seed: 20747\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 15\n",
      "\t   First reward: [9.0], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 3: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 GNEURALUCB          : Reward=0640.00, Efficiency=048.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=150, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 3: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=0479.00, Efficiency=036.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=150, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 3: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=0640.00, Efficiency=048.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=150, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 3: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=0747.00, Efficiency=056.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=150, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 3: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:150, QubitAlloc=Dynamic, SC:150 (Scale=1 x Cap=150), Seed: 20747\n",
      "\t-->üèÜ EXP3 Winner:iCPursuitNeuralUCB  (Gap:043.1%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:150, SCapacity=150, Alloc=Dynamic]\n",
      "‚úì Experiment 3 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 200 frames  <>  SCALED-CAPACITY: 200 frames (CAPACITY:200 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=3 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for MARKOV Exp 4: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 4: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:200, QubitAlloc=Dynamic, SC:200 (Scale=1 x Cap=200), Seed: 15410\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 15\n",
      "\t   First reward: [9.0], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 4: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 GNEURALUCB          : Reward=0931.00, Efficiency=053.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=200, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 4: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=0814.00, Efficiency=046.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=200, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 4: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=0931.00, Efficiency=053.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=200, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 4: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=0963.00, Efficiency=054.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=200, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 4: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:200, QubitAlloc=Dynamic, SC:200 (Scale=1 x Cap=200), Seed: 15410\n",
      "\t-->üèÜ EXP4 Winner:iCPursuitNeuralUCB  (Gap:045.1%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:200, SCapacity=200, Alloc=Dynamic]\n",
      "‚úì Experiment 4 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 250 frames  <>  SCALED-CAPACITY: 250 frames (CAPACITY:250 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=4 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for MARKOV Exp 5: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 5: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:250, QubitAlloc=Dynamic, SC:250 (Scale=1 x Cap=250), Seed: 22674\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 15\n",
      "\t   First reward: [9.0], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 5: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 GNEURALUCB          : Reward=1092.00, Efficiency=049.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=250, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 5: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=0971.00, Efficiency=044.2% [Retries=3, Failed=0, < Threshold=3, SCapacity=250, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 5: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=1092.00, Efficiency=049.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=250, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 5: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=0898.00, Efficiency=040.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=250, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 5: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:250, QubitAlloc=Dynamic, SC:250 (Scale=1 x Cap=250), Seed: 22674\n",
      "\t-->üèÜ EXP5 Winner:GNeuralUCB          (Gap:050.3%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:250, SCapacity=250, Alloc=Dynamic]\n",
      "‚úì Experiment 5 completed successfully.\n",
      "Total experiment time: 832.5s\n",
      "Experiments completed for markov\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: ADAPTIVE ADVERSARIAL ATTACK\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: ADAPTIVE\n",
      "Category: Adaptive (Reactive Strategic)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 50 frames  <>  SCALED-CAPACITY: 50 frames (CAPACITY:50 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=0 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 1: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 1: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:50, QubitAlloc=Dynamic, SC:50 (Scale=1 x Cap=50), Seed: 21427\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 15\n",
      "\t   First reward: [9.0], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 1: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 GNEURALUCB          : Reward=0335.00, Efficiency=074.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=50, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 1: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=0262.00, Efficiency=058.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=50, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 1: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=0335.00, Efficiency=074.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=50, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 1: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=0288.00, Efficiency=064.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=50, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 1: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:50, QubitAlloc=Dynamic, SC:50 (Scale=1 x Cap=50), Seed: 21427\n",
      "\t-->üèÜ EXP1 Winner:GNeuralUCB          (Gap:025.2%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:50, SCapacity=50, Alloc=Dynamic]\n",
      "‚úì Experiment 1 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 100 frames  <>  SCALED-CAPACITY: 100 frames (CAPACITY:100 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=1 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 2: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 2: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:100, QubitAlloc=Dynamic, SC:100 (Scale=1 x Cap=100), Seed: 13200\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 15\n",
      "\t   First reward: [9.0], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 2: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 GNEURALUCB          : Reward=0569.00, Efficiency=063.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=100, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 2: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=0560.00, Efficiency=062.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=100, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 2: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=0569.00, Efficiency=063.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=100, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 2: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=0666.00, Efficiency=074.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=100, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 2: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:100, QubitAlloc=Dynamic, SC:100 (Scale=1 x Cap=100), Seed: 13200\n",
      "\t-->üèÜ EXP2 Winner:iCPursuitNeuralUCB  (Gap:025.3%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:100, SCapacity=100, Alloc=Dynamic]\n",
      "‚úì Experiment 2 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 150 frames  <>  SCALED-CAPACITY: 150 frames (CAPACITY:150 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=2 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 3: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 3: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:150, QubitAlloc=Dynamic, SC:150 (Scale=1 x Cap=150), Seed: 18005\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 15\n",
      "\t   First reward: [9.0], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 3: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 GNEURALUCB          : Reward=0837.00, Efficiency=062.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=150, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 3: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=0900.00, Efficiency=067.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=150, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 3: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=0837.00, Efficiency=062.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=150, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 3: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=1044.00, Efficiency=077.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=150, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 3: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:150, QubitAlloc=Dynamic, SC:150 (Scale=1 x Cap=150), Seed: 18005\n",
      "\t-->üèÜ EXP3 Winner:iCPursuitNeuralUCB  (Gap:022.3%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:150, SCapacity=150, Alloc=Dynamic]\n",
      "‚úì Experiment 3 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 200 frames  <>  SCALED-CAPACITY: 200 frames (CAPACITY:200 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=3 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 4: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 4: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:200, QubitAlloc=Dynamic, SC:200 (Scale=1 x Cap=200), Seed: 12955\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 15\n",
      "\t   First reward: [9.0], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 4: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 GNEURALUCB          : Reward=1159.00, Efficiency=064.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=200, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 4: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=1199.00, Efficiency=066.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=200, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 4: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=1159.00, Efficiency=064.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=200, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 4: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=1431.00, Efficiency=079.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=200, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 4: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:200, QubitAlloc=Dynamic, SC:200 (Scale=1 x Cap=200), Seed: 12955\n",
      "\t-->üèÜ EXP4 Winner:iCPursuitNeuralUCB  (Gap:020.1%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:200, SCapacity=200, Alloc=Dynamic]\n",
      "‚úì Experiment 4 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 250 frames  <>  SCALED-CAPACITY: 250 frames (CAPACITY:250 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=4 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 5: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 5: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:250, QubitAlloc=Dynamic, SC:250 (Scale=1 x Cap=250), Seed: 14950\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 15\n",
      "\t   First reward: [9.0], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 5: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 GNEURALUCB          : Reward=1564.00, Efficiency=069.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=250, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 5: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=1566.00, Efficiency=069.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=250, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 5: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=1564.00, Efficiency=069.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=250, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 5: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=1755.00, Efficiency=078.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=250, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 5: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:250, QubitAlloc=Dynamic, SC:250 (Scale=1 x Cap=250), Seed: 14950\n",
      "\t-->üèÜ EXP5 Winner:iCPursuitNeuralUCB  (Gap:021.7%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:250, SCapacity=250, Alloc=Dynamic]\n",
      "‚úì Experiment 5 completed successfully.\n",
      "Total experiment time: 835.6s\n",
      "Experiments completed for adaptive\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: ONLINE ADAPTIVE ATTACK\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: ONLINEADAPTIVE\n",
      "Category: Online Adaptive (Real-time Strategic)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 50 frames  <>  SCALED-CAPACITY: 50 frames (CAPACITY:50 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=0 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 1: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:50, QubitAlloc=Dynamic, SC:50 (Scale=1 x Cap=50), Seed: 14732\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 15\n",
      "\t   First reward: [9.0], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 GNEURALUCB          : Reward=0303.00, Efficiency=067.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=50, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=0340.00, Efficiency=076.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=50, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=0303.00, Efficiency=067.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=50, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=0360.00, Efficiency=080.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=50, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:50, QubitAlloc=Dynamic, SC:50 (Scale=1 x Cap=50), Seed: 14732\n",
      "\t-->üèÜ EXP1 Winner:iCPursuitNeuralUCB  (Gap:019.3%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:50, SCapacity=50, Alloc=Dynamic]\n",
      "‚úì Experiment 1 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 100 frames  <>  SCALED-CAPACITY: 100 frames (CAPACITY:100 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=1 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 2: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:100, QubitAlloc=Dynamic, SC:100 (Scale=1 x Cap=100), Seed: 14647\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 15\n",
      "\t   First reward: [9.0], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 GNEURALUCB          : Reward=0625.00, Efficiency=070.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=100, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=0573.00, Efficiency=064.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=100, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=0625.00, Efficiency=070.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=100, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=0585.00, Efficiency=065.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=100, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:100, QubitAlloc=Dynamic, SC:100 (Scale=1 x Cap=100), Seed: 14647\n",
      "\t-->üèÜ EXP2 Winner:GNeuralUCB          (Gap:029.9%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:100, SCapacity=100, Alloc=Dynamic]\n",
      "‚úì Experiment 2 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 150 frames  <>  SCALED-CAPACITY: 150 frames (CAPACITY:150 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=2 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 3: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:150, QubitAlloc=Dynamic, SC:150 (Scale=1 x Cap=150), Seed: 21138\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 15\n",
      "\t   First reward: [9.0], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 GNEURALUCB          : Reward=0892.00, Efficiency=066.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=150, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=0884.00, Efficiency=065.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=150, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=0892.00, Efficiency=066.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=150, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=1071.00, Efficiency=079.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=150, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:150, QubitAlloc=Dynamic, SC:150 (Scale=1 x Cap=150), Seed: 21138\n",
      "\t-->üèÜ EXP3 Winner:iCPursuitNeuralUCB  (Gap:020.2%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:150, SCapacity=150, Alloc=Dynamic]\n",
      "‚úì Experiment 3 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 200 frames  <>  SCALED-CAPACITY: 200 frames (CAPACITY:200 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=3 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 4: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:200, QubitAlloc=Dynamic, SC:200 (Scale=1 x Cap=200), Seed: 16677\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 15\n",
      "\t   First reward: [9.0], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 GNEURALUCB          : Reward=1209.00, Efficiency=067.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=200, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=1203.00, Efficiency=067.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=200, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=1209.00, Efficiency=067.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=200, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=1359.00, Efficiency=076.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=200, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:200, QubitAlloc=Dynamic, SC:200 (Scale=1 x Cap=200), Seed: 16677\n",
      "\t-->üèÜ EXP4 Winner:iCPursuitNeuralUCB  (Gap:023.9%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:200, SCapacity=200, Alloc=Dynamic]\n",
      "‚úì Experiment 4 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 250 frames  <>  SCALED-CAPACITY: 250 frames (CAPACITY:250 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=4 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 5: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:250, QubitAlloc=Dynamic, SC:250 (Scale=1 x Cap=250), Seed: 22447\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 15\n",
      "\t   First reward: [9.0], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 GNEURALUCB          : Reward=1413.00, Efficiency=063.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=250, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=1509.00, Efficiency=067.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=250, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=1413.00, Efficiency=063.2% [Retries=3, Failed=0, < Threshold=3, SCapacity=250, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=1737.00, Efficiency=077.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=250, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:250, QubitAlloc=Dynamic, SC:250 (Scale=1 x Cap=250), Seed: 22447\n",
      "\t-->üèÜ EXP5 Winner:iCPursuitNeuralUCB  (Gap:022.2%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:250, SCapacity=250, Alloc=Dynamic]\n",
      "‚úì Experiment 5 completed successfully.\n",
      "Total experiment time: 806.1s\n",
      "Experiments completed for onlineadaptive\n",
      "‚úì Scenario 'none' evaluation completed.\n",
      "‚úì Scenario 'stochastic' evaluation completed.\n",
      "‚úì Scenario 'markov' evaluation completed.\n",
      "‚úì Scenario 'adaptive' evaluation completed.\n",
      "‚úì Scenario 'onlineadaptive' evaluation completed.\n",
      "\n",
      "======================================================================\n",
      "COMPREHENSIVE SCENARIO PERFORMANCE ANALYSIS\n",
      "======================================================================\n",
      "SCENARIO: NONE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 1350.00\n",
      "\t‚Ä¢ Winner Avg Gap: 0000.00%\n",
      "\t‚Ä¢ Winner Avg Reward: 1350.00\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0100.00%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 5 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: NONE\n",
      "======================================================================\n",
      "SCENARIO: \tBASELINE (OPTIMAL CONDITIONS)\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 5/5 experiments)\n",
      "\tWinner Avg Gap: \t000.0%\n",
      "\tWinner Avg Efficiency: \t100.0%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t100.0% Efficiency \t(Won 5/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t088.4% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t088.1% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t088.1% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: STOCHASTIC\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 1349.20\n",
      "\t‚Ä¢ Winner Avg Gap: 0006.66%\n",
      "\t‚Ä¢ Winner Avg Reward: 1260.00\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0093.34%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 5 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: STOCHASTIC\n",
      "======================================================================\n",
      "SCENARIO: \tSTOCHASTIC RANDOM FAILURES\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 5/5 experiments)\n",
      "\tWinner Avg Gap: \t006.7%\n",
      "\tWinner Avg Efficiency: \t093.3%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t093.3% Efficiency \t(Won 5/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t083.8% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t083.0% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t083.0% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: MARKOV\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 1315.20\n",
      "\t‚Ä¢ Winner Avg Gap: 0047.50%\n",
      "\t‚Ä¢ Winner Avg Reward: 0662.00\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0052.50%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 1 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 4 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: MARKOV\n",
      "======================================================================\n",
      "SCENARIO: \tMARKOV ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 4/5 experiments)\n",
      "\tWinner Avg Gap: \t047.5%\n",
      "\tWinner Avg Efficiency: \t052.5%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t052.5% Efficiency \t(Won 4/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t048.3% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t048.3% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t041.4% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 1343.40\n",
      "\t‚Ä¢ Winner Avg Gap: 0025.04%\n",
      "\t‚Ä¢ Winner Avg Reward: 1036.80\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0074.96%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 1 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 4 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tADAPTIVE ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 4/5 experiments)\n",
      "\tWinner Avg Gap: \t025.0%\n",
      "\tWinner Avg Efficiency: \t075.0%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t075.0% Efficiency \t(Won 4/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t067.1% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t067.1% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t065.0% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ONLINEADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 1339.80\n",
      "\t‚Ä¢ Winner Avg Gap: 0023.99%\n",
      "\t‚Ä¢ Winner Avg Reward: 1022.40\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0076.01%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 1 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 4 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ONLINEADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tONLINE ADAPTIVE ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 4/5 experiments)\n",
      "\tWinner Avg Gap: \t024.0%\n",
      "\tWinner Avg Efficiency: \t076.0%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t076.0% Efficiency \t(Won 4/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t068.3% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t067.1% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t067.1% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "KEY INSIGHTS:\n",
      "Best Performing Model Analysis (iCPursuitNeuralUCB):\n",
      "\t‚Ä¢ Stochastic Performance:    \t1260.000\n",
      "\t‚Ä¢ Baseline Performance:      \t1350.000\n",
      "\t‚Ä¢ Performance Retention:     \t093.3%\n",
      "\tGOOD:               \tAcceptable performance under stochastic conditions\n",
      "Statistical Analysis:\n",
      "\t‚Ä¢ Total models evaluated:     \t5\n",
      "\t‚Ä¢ Experiments per environment:\t5\n",
      "\t‚Ä¢ Quantum network simulation: \tComprehensive stochastic modeling\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "COMPREHENSIVE SCENARIO PERFORMANCE ANALYSIS\n",
      "======================================================================\n",
      "SCENARIO: NONE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 1350.00\n",
      "\t‚Ä¢ Winner Avg Gap: 0000.00%\n",
      "\t‚Ä¢ Winner Avg Reward: 1350.00\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0100.00%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 5 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: NONE\n",
      "======================================================================\n",
      "SCENARIO: \tBASELINE (OPTIMAL CONDITIONS)\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 5/5 experiments)\n",
      "\tWinner Avg Gap: \t000.0%\n",
      "\tWinner Avg Efficiency: \t100.0%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t100.0% Efficiency \t(Won 5/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t088.4% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t088.1% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t088.1% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: STOCHASTIC\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 1349.20\n",
      "\t‚Ä¢ Winner Avg Gap: 0006.66%\n",
      "\t‚Ä¢ Winner Avg Reward: 1260.00\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0093.34%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 5 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: STOCHASTIC\n",
      "======================================================================\n",
      "SCENARIO: \tSTOCHASTIC RANDOM FAILURES\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 5/5 experiments)\n",
      "\tWinner Avg Gap: \t006.7%\n",
      "\tWinner Avg Efficiency: \t093.3%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t093.3% Efficiency \t(Won 5/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t083.8% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t083.0% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t083.0% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: MARKOV\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 1315.20\n",
      "\t‚Ä¢ Winner Avg Gap: 0047.50%\n",
      "\t‚Ä¢ Winner Avg Reward: 0662.00\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0052.50%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 1 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 4 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: MARKOV\n",
      "======================================================================\n",
      "SCENARIO: \tMARKOV ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 4/5 experiments)\n",
      "\tWinner Avg Gap: \t047.5%\n",
      "\tWinner Avg Efficiency: \t052.5%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t052.5% Efficiency \t(Won 4/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t048.3% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t048.3% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t041.4% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 1343.40\n",
      "\t‚Ä¢ Winner Avg Gap: 0025.04%\n",
      "\t‚Ä¢ Winner Avg Reward: 1036.80\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0074.96%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 1 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 4 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tADAPTIVE ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 4/5 experiments)\n",
      "\tWinner Avg Gap: \t025.0%\n",
      "\tWinner Avg Efficiency: \t075.0%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t075.0% Efficiency \t(Won 4/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t067.1% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t067.1% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t065.0% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ONLINEADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 1339.80\n",
      "\t‚Ä¢ Winner Avg Gap: 0023.99%\n",
      "\t‚Ä¢ Winner Avg Reward: 1022.40\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0076.01%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 1 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 4 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ONLINEADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tONLINE ADAPTIVE ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 4/5 experiments)\n",
      "\tWinner Avg Gap: \t024.0%\n",
      "\tWinner Avg Efficiency: \t076.0%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t076.0% Efficiency \t(Won 4/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t068.3% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t067.1% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t067.1% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "‚úÖ Evaluation completed!\n",
      "[Logging Redirect Stopped]\n",
      "\n",
      "üßπ Final cleanup for Dynamic\n",
      "\n",
      "======================================================================\n",
      "‚úÖ COMPLETED: Dynamic\n",
      "======================================================================\n",
      "\n",
      "Dynamic COMPLETED SUCCESSFULLY\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Preparing: Dynamic at scale 1.5\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üîß Generating physics parameters for model: paper7\n",
      "\n",
      "===================== GET LOCAL REGISTRY =====================\n",
      "‚Üí Skipping local cache (force=True or file missing)\n",
      "\n",
      "===================== BUILD LOCAL REGISTRY =====================\n",
      "\n",
      "================================================================================\n",
      "üîç SCANNING LOCAL FILES\n",
      "================================================================================\n",
      "Parameters: load_to_drive=False, force=False\n",
      "\n",
      "üìÇ Checking DRIVE mode: /content/drive/Shareddrives/ai_quantum_computing/quantum_data_lake\n",
      "   ‚ö†Ô∏è  Path does not exist, skipping\n",
      "\n",
      "üìÇ Checking LOCAL mode: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config\n",
      "   ‚úÖ Path exists, starting walk...\n",
      "   üö∂ Walking directory tree: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config\n",
      "\n",
      "   üìÅ Directory: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201\n",
      "      Relative: framework_state/day_20260201\n",
      "      Component: framework_state\n",
      "      Date: day_20260201\n",
      "      üìÑ Processing 2540 files in framework_state/day_20260201\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "      üìä framework_state/day_20260201: 2514/2540 files processed\n",
      "      üìä framework_state/day_20260201: 0/2540 files skipped\n",
      "      üìä framework_state/day_20260201: 26/2540 files conflicted\n",
      "\n",
      "   üìÅ Directory: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/model_state/day_20260201\n",
      "      Relative: model_state/day_20260201\n",
      "      Component: model_state\n",
      "      Date: day_20260201\n",
      "      üìÑ Processing 9000 files in model_state/day_20260201\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "      üìä model_state/day_20260201: 9000/9000 files processed\n",
      "      üìä model_state/day_20260201: 0/9000 files skipped\n",
      "      üìä model_state/day_20260201: 0/9000 files conflicted\n",
      "\n",
      "   üìä Processed 2 directories\n",
      "\n",
      "================================================================================\n",
      "üì¶ BUILDING FINAL REGISTRY\n",
      "================================================================================\n",
      "Components found: ['framework_state', 'model_state']\n",
      "  ‚Ä¢ framework_state: 2514 files\n",
      "  ‚Ä¢ model_state: 9000 files\n",
      "\n",
      "‚úÖ SCAN COMPLETE\n",
      "Modes scanned: 1\n",
      "Total files in registry: 11514\n",
      "================================================================================\n",
      "\n",
      "\t‚Üí Filesystem scan found 11514 files\n",
      "\n",
      "===================== GET DRIVE REGISTRY =====================\n",
      "===================== REGISTRY BUILD COMPLETE =====================\n",
      "\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "\tüì¶ LocalBackupManager Registry Saved Locally in LOCAL\n",
      "BUILDING REGISTRY WITH 0 EXPECTED COMPONENTS KEYS\n",
      "\n",
      "===================== GET LOCAL REGISTRY =====================\n",
      "‚Üí Skipping local cache (force=True or file missing)\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "\tüì¶ LocalBackupManager Registry Saved Locally in LOCAL\n",
      "\n",
      "======================================================================\n",
      "üéØ AllocatorRunner initialized: Dynamic\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "üöÄ STARTING ALLOCATOR: Dynamic\n",
      "======================================================================\n",
      "\n",
      "üìä Physics Model: paper7\n",
      "\n",
      "üìã Allocator Config:\n",
      "   Type: Dynamic\n",
      "   Testbed: default\n",
      "   Paths: 15\n",
      "   Total Qubits: 75\n",
      "   Min per route: 2\n",
      "   Seed: 42\n",
      "   Exploration bonus: 2.0\n",
      "‚úÖ Allocator created: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "‚úì Allocator: DynamicQubitAllocator (15 paths)\n",
      "   Initial allocation: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üìä Paper7 Topology: Real AS (as20000101.txt)\n",
      "üìä Paper7 Paths: 15 paths from 5-shortest between 3 ISPs\n",
      "üìä Paper7 Contexts: 15 context vectors generated\n",
      "üìä Paper7 Rewards: Context-aware (mode=neg_hop)\n",
      "‚è±Ô∏è  get_physics_params_paper7() time: 2.1 ms\n",
      "\n",
      "======================================================================\n",
      "RUN 1 | Scale: 1.5 | Exp: 5\n",
      "======================================================================\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "\n",
      "\tüîÑ Resume: MultiRunEvaluator\n",
      "\n",
      "=====================================================\n",
      "üîç GENERATING EXPECTED KEYS FROM EVALUATOR\n",
      "=====================================================\n",
      "  ‚Ä¢ Evaluator filename: MultiRunEvaluator_75-Dynamic_All_All-50_50_5_S1_5T_paper7.pkl\n",
      "\n",
      "üß© PARSED COMPONENTS\n",
      "  ‚Ä¢ cap_id:        75\n",
      "  ‚Ä¢ allocator_id:  Dynamic\n",
      "  ‚Ä¢ env_id:        All\n",
      "  ‚Ä¢ attack_id:     All\n",
      "  ‚Ä¢ base_frames:   50\n",
      "  ‚Ä¢ frame_step:    50\n",
      "  ‚Ä¢ runs_id:       5\n",
      "\n",
      "=====================================================\n",
      "üß™ GENERATING KEYS FOR EACH RUN\n",
      "=====================================================\n",
      "\n",
      "--- Run 1/5 -----------------------\n",
      "\n",
      "=====================================================\n",
      "üì¶ FINAL EXPECTED KEYS\n",
      "=====================================================\n",
      "  ‚Ä¢ Runner keys: 11\n",
      "\n",
      "  ‚Ä¢ Model keys: 50\n",
      "\n",
      "--- Run 2/5 -----------------------\n",
      "\n",
      "=====================================================\n",
      "üì¶ FINAL EXPECTED KEYS\n",
      "=====================================================\n",
      "  ‚Ä¢ Runner keys: 21\n",
      "\n",
      "  ‚Ä¢ Model keys: 100\n",
      "\n",
      "--- Run 3/5 -----------------------\n",
      "\n",
      "=====================================================\n",
      "üì¶ FINAL EXPECTED KEYS\n",
      "=====================================================\n",
      "  ‚Ä¢ Runner keys: 31\n",
      "\n",
      "  ‚Ä¢ Model keys: 150\n",
      "\n",
      "--- Run 4/5 -----------------------\n",
      "\n",
      "=====================================================\n",
      "üì¶ FINAL EXPECTED KEYS\n",
      "=====================================================\n",
      "  ‚Ä¢ Runner keys: 41\n",
      "\n",
      "  ‚Ä¢ Model keys: 200\n",
      "\n",
      "--- Run 5/5 -----------------------\n",
      "\n",
      "=====================================================\n",
      "üì¶ FINAL EXPECTED KEYS\n",
      "=====================================================\n",
      "  ‚Ä¢ Runner keys: 51\n",
      "\n",
      "  ‚Ä¢ Model keys: 250\n",
      "\n",
      "EXPECTED KEY GENERATION COMPLETE\n",
      "\n",
      "RESTORING FROM DRIVE 1\n",
      "RESTORING FROM DRIVE 2\n",
      "\t‚ö†Ô∏è Registry exists ‚Üí aborting restore\n",
      "\t‚úì MultiRunEvaluator Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/MultiRunEvaluator_75-Dynamic_All_All-50_50_5_S1_5T_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/MultiRunEvaluator_75-Dynamic_All_All-50_50_5_S1_5T_paper7.pkl\n",
      "\t   File exists: True, size: 4159463\n",
      "EQUAL METHOD\n",
      "Multi-Run Evaluator Initialized\n",
      "Environment Type: None\n",
      "Frame Range: 50 -> 250 (step: 50)\n",
      "quantum_exps-Dynamic(paper7)_alloc-all_envs-5_attacks-50_50-5_runs-S1.5T\n",
      "[Logging Redirect Initialized]\n",
      "Log File: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/quantum_logs/quantum_exps-Dynamic(paper7)_alloc-all_envs-5_attacks-50_50-5_runs-S1.5T_20260201_log.txt\n",
      "‚öô Running evaluation...\n",
      "======================================================================\n",
      "SCENARIOS MODEL EVALUATION\n",
      "======================================================================\n",
      "Testing algorithm performance against:\n",
      "\t‚Ä¢ Stochastic:  \tNatural quantum decoherence and network failures\n",
      "\t‚Ä¢ Baseline:    \tOptimal conditions for validation\n",
      "======================================================================\n",
      "Models to Test:             \tOracle, GNeuralUCB, EXPNeuralUCB, CPursuitNeuralUCB, iCPursuitNeuralUCB\n",
      "Experiments per Scenario:   \t5\n",
      "======================================================================\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: BASELINE (OPTIMAL CONDITIONS)\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: NONE\n",
      "Category: Baseline (No Attacks)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 50 frames  <>  SCALED-CAPACITY: 75.0 frames (CAPACITY:50 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=0 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for NONE Exp 1: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 1: Env:Baseline (None), Attack:No, Rate:0.0, Frames:50, QubitAlloc=Dynamic, SC:75 (Scale=1.5 x Cap=50), Seed: 15373\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_1\n",
      "\t‚úì QuantumExperimentRunner_1 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_75-Dynamic_Baseline (None)_No-50_1_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_75-Dynamic_Baseline (None)_No-50_1_paper7.pkl\n",
      "\t   File exists: True, size: 37479\n",
      "‚è© SKIPPING EXPERIMENT 1: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 1 GNEURALUCB          : Reward=0396.00, Efficiency=088.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=75.0, Threshold=0.582]\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=0418.00, Efficiency=092.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=75.0, Threshold=0.628]\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=0396.00, Efficiency=088.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=75.0, Threshold=0.634]\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=0450.00, Efficiency=100.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=75.0, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP1 Winner:iCPursuitNeuralUCB  (Gap:000.0%) [Env:Baseline (None), Attack:No X Rate:0.25, Frames:50, SCapacity=75.0, Alloc=Dynamic]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 100 frames  <>  SCALED-CAPACITY: 150.0 frames (CAPACITY:100 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=1 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for NONE Exp 2: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 2: Env:Baseline (None), Attack:No, Rate:0.0, Frames:100, QubitAlloc=Dynamic, SC:150 (Scale=1.5 x Cap=100), Seed: 12644\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_2\n",
      "\t‚úì QuantumExperimentRunner_2 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_150-Dynamic_Baseline (None)_No-100_2_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_150-Dynamic_Baseline (None)_No-100_2_paper7.pkl\n",
      "\t   File exists: True, size: 64115\n",
      "‚è© SKIPPING EXPERIMENT 2: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 2 GNEURALUCB          : Reward=0794.00, Efficiency=088.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=150.0, Threshold=0.582]\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=0831.00, Efficiency=092.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=150.0, Threshold=0.628]\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=0794.00, Efficiency=088.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=150.0, Threshold=0.634]\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=0900.00, Efficiency=100.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=150.0, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP2 Winner:iCPursuitNeuralUCB  (Gap:000.0%) [Env:Baseline (None), Attack:No X Rate:0.25, Frames:100, SCapacity=150.0, Alloc=Dynamic]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 150 frames  <>  SCALED-CAPACITY: 225.0 frames (CAPACITY:150 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=2 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for NONE Exp 3: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 3: Env:Baseline (None), Attack:No, Rate:0.0, Frames:150, QubitAlloc=Dynamic, SC:225 (Scale=1.5 x Cap=150), Seed: 20257\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_3\n",
      "\t‚úì QuantumExperimentRunner_3 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_225-Dynamic_Baseline (None)_No-150_3_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_225-Dynamic_Baseline (None)_No-150_3_paper7.pkl\n",
      "\t   File exists: True, size: 90724\n",
      "‚è© SKIPPING EXPERIMENT 3: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 3 GNEURALUCB          : Reward=1190.00, Efficiency=088.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=225.0, Threshold=0.582]\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=1275.00, Efficiency=094.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=225.0, Threshold=0.628]\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=1190.00, Efficiency=088.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=225.0, Threshold=0.634]\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=1350.00, Efficiency=100.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=225.0, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP3 Winner:iCPursuitNeuralUCB  (Gap:000.0%) [Env:Baseline (None), Attack:No X Rate:0.25, Frames:150, SCapacity=225.0, Alloc=Dynamic]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 200 frames  <>  SCALED-CAPACITY: 300.0 frames (CAPACITY:200 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=3 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for NONE Exp 4: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 4: Env:Baseline (None), Attack:No, Rate:0.0, Frames:200, QubitAlloc=Dynamic, SC:300 (Scale=1.5 x Cap=200), Seed: 20031\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_4\n",
      "\t‚úì QuantumExperimentRunner_4 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_300-Dynamic_Baseline (None)_No-200_4_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_300-Dynamic_Baseline (None)_No-200_4_paper7.pkl\n",
      "\t   File exists: True, size: 117325\n",
      "‚è© SKIPPING EXPERIMENT 4: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 4 GNEURALUCB          : Reward=1586.00, Efficiency=088.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=300.0, Threshold=0.582]\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=1566.00, Efficiency=087.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=300.0, Threshold=0.628]\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=1586.00, Efficiency=088.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=300.0, Threshold=0.634]\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=1800.00, Efficiency=100.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=300.0, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP4 Winner:iCPursuitNeuralUCB  (Gap:000.0%) [Env:Baseline (None), Attack:No X Rate:0.25, Frames:200, SCapacity=300.0, Alloc=Dynamic]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 250 frames  <>  SCALED-CAPACITY: 375.0 frames (CAPACITY:250 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=4 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for NONE Exp 5: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 5: Env:Baseline (None), Attack:No, Rate:0.0, Frames:250, QubitAlloc=Dynamic, SC:375 (Scale=1.5 x Cap=250), Seed: 17303\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_5\n",
      "\t‚úì QuantumExperimentRunner_5 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_375-Dynamic_Baseline (None)_No-250_5_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_375-Dynamic_Baseline (None)_No-250_5_paper7.pkl\n",
      "\t   File exists: True, size: 143934\n",
      "‚è© SKIPPING EXPERIMENT 5: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 5 GNEURALUCB          : Reward=1984.00, Efficiency=088.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=375.0, Threshold=0.582]\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=1990.00, Efficiency=088.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=375.0, Threshold=0.628]\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=1984.00, Efficiency=088.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=375.0, Threshold=0.634]\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=2250.00, Efficiency=100.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=375.0, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP5 Winner:iCPursuitNeuralUCB  (Gap:000.0%) [Env:Baseline (None), Attack:No X Rate:0.25, Frames:250, SCapacity=375.0, Alloc=Dynamic]\n",
      "\n",
      "Total experiment time: 012.5s\n",
      "Experiments completed for none\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: STOCHASTIC RANDOM FAILURES\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: STOCHASTIC\n",
      "Category: Stochastic (Natural Random Failures)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 50 frames  <>  SCALED-CAPACITY: 75.0 frames (CAPACITY:50 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=0 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 1: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 1: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:50, QubitAlloc=Dynamic, SC:75 (Scale=1.5 x Cap=50), Seed: 15729\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_1\n",
      "\t‚úì QuantumExperimentRunner_1 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_75-Dynamic_Stochastic_Random-50_1_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_75-Dynamic_Stochastic_Random-50_1_paper7.pkl\n",
      "\t   File exists: True, size: 37483\n",
      "‚è© SKIPPING EXPERIMENT 1: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 1 GNEURALUCB          : Reward=0389.00, Efficiency=086.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=75.0, Threshold=0.582]\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=0381.00, Efficiency=084.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=75.0, Threshold=0.628]\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=0389.00, Efficiency=086.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=75.0, Threshold=0.634]\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=0432.00, Efficiency=096.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=75.0, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP1 Winner:iCPursuitNeuralUCB  (Gap:003.8%) [Env:Stochastic, Attack:Random X Rate:0.25, Frames:50, SCapacity=75.0, Alloc=Dynamic]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 100 frames  <>  SCALED-CAPACITY: 150.0 frames (CAPACITY:100 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=1 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 2: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 2: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:100, QubitAlloc=Dynamic, SC:150 (Scale=1.5 x Cap=100), Seed: 19894\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_2\n",
      "\t‚úì QuantumExperimentRunner_2 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_150-Dynamic_Stochastic_Random-100_2_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_150-Dynamic_Stochastic_Random-100_2_paper7.pkl\n",
      "\t   File exists: True, size: 64119\n",
      "‚è© SKIPPING EXPERIMENT 2: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 2 GNEURALUCB          : Reward=0752.00, Efficiency=083.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=150.0, Threshold=0.582]\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=0755.00, Efficiency=083.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=150.0, Threshold=0.628]\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=0752.00, Efficiency=083.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=150.0, Threshold=0.634]\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=0837.00, Efficiency=093.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=150.0, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP2 Winner:iCPursuitNeuralUCB  (Gap:007.0%) [Env:Stochastic, Attack:Random X Rate:0.25, Frames:100, SCapacity=150.0, Alloc=Dynamic]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 150 frames  <>  SCALED-CAPACITY: 225.0 frames (CAPACITY:150 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=2 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 3: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 3: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:150, QubitAlloc=Dynamic, SC:225 (Scale=1.5 x Cap=150), Seed: 16736\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_3\n",
      "\t‚úì QuantumExperimentRunner_3 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_225-Dynamic_Stochastic_Random-150_3_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_225-Dynamic_Stochastic_Random-150_3_paper7.pkl\n",
      "\t   File exists: True, size: 90728\n",
      "‚è© SKIPPING EXPERIMENT 3: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 3 GNEURALUCB          : Reward=1089.00, Efficiency=080.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=225.0, Threshold=0.582]\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=1113.00, Efficiency=082.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=225.0, Threshold=0.628]\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=1089.00, Efficiency=080.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=225.0, Threshold=0.634]\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=1269.00, Efficiency=094.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=225.0, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP3 Winner:iCPursuitNeuralUCB  (Gap:006.0%) [Env:Stochastic, Attack:Random X Rate:0.25, Frames:150, SCapacity=225.0, Alloc=Dynamic]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 200 frames  <>  SCALED-CAPACITY: 300.0 frames (CAPACITY:200 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=3 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 4: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 4: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:200, QubitAlloc=Dynamic, SC:300 (Scale=1.5 x Cap=200), Seed: 12981\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_4\n",
      "\t‚úì QuantumExperimentRunner_4 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_300-Dynamic_Stochastic_Random-200_4_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_300-Dynamic_Stochastic_Random-200_4_paper7.pkl\n",
      "\t   File exists: True, size: 117329\n",
      "‚è© SKIPPING EXPERIMENT 4: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 4 GNEURALUCB          : Reward=1437.00, Efficiency=079.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=300.0, Threshold=0.582]\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=1457.00, Efficiency=080.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=300.0, Threshold=0.628]\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=1437.00, Efficiency=079.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=300.0, Threshold=0.634]\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=1692.00, Efficiency=094.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=300.0, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP4 Winner:iCPursuitNeuralUCB  (Gap:006.0%) [Env:Stochastic, Attack:Random X Rate:0.25, Frames:200, SCapacity=300.0, Alloc=Dynamic]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 250 frames  <>  SCALED-CAPACITY: 375.0 frames (CAPACITY:250 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=4 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 5: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 5: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:250, QubitAlloc=Dynamic, SC:375 (Scale=1.5 x Cap=250), Seed: 17091\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_5\n",
      "\t‚úì QuantumExperimentRunner_5 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_375-Dynamic_Stochastic_Random-250_5_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_375-Dynamic_Stochastic_Random-250_5_paper7.pkl\n",
      "\t   File exists: True, size: 143938\n",
      "‚è© SKIPPING EXPERIMENT 5: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 5 GNEURALUCB          : Reward=1859.00, Efficiency=082.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=375.0, Threshold=0.582]\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=1893.00, Efficiency=084.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=375.0, Threshold=0.628]\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=1859.00, Efficiency=082.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=375.0, Threshold=0.634]\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=2142.00, Efficiency=095.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=375.0, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP5 Winner:iCPursuitNeuralUCB  (Gap:004.8%) [Env:Stochastic, Attack:Random X Rate:0.25, Frames:250, SCapacity=375.0, Alloc=Dynamic]\n",
      "\n",
      "Total experiment time: 013.3s\n",
      "Experiments completed for stochastic\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: MARKOV ADVERSARIAL ATTACK\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: MARKOV\n",
      "Category: Structured (Markov Chain Based)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 50 frames  <>  SCALED-CAPACITY: 75.0 frames (CAPACITY:50 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=0 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for MARKOV Exp 1: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 1: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:50, QubitAlloc=Dynamic, SC:75 (Scale=1.5 x Cap=50), Seed: 14132\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_1\n",
      "\t‚úì QuantumExperimentRunner_1 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_75-Dynamic_Adversarial_Markov-50_1_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_75-Dynamic_Adversarial_Markov-50_1_paper7.pkl\n",
      "\t   File exists: True, size: 37481\n",
      "‚è© SKIPPING EXPERIMENT 1: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 1 GNEURALUCB          : Reward=0200.00, Efficiency=045.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=75.0, Threshold=0.582]\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=0218.00, Efficiency=050.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=75.0, Threshold=0.628]\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=0200.00, Efficiency=045.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=75.0, Threshold=0.634]\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=0125.00, Efficiency=028.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=75.0, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP1 Winner:EXPNeuralUCB        (Gap:050.0%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:50, SCapacity=75.0, Alloc=Dynamic]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 100 frames  <>  SCALED-CAPACITY: 150.0 frames (CAPACITY:100 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=1 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for MARKOV Exp 2: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 2: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:100, QubitAlloc=Dynamic, SC:150 (Scale=1.5 x Cap=100), Seed: 22231\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_2\n",
      "\t‚úì QuantumExperimentRunner_2 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_150-Dynamic_Adversarial_Markov-100_2_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_150-Dynamic_Adversarial_Markov-100_2_paper7.pkl\n",
      "\t   File exists: True, size: 64117\n",
      "‚è© SKIPPING EXPERIMENT 2: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 2 GNEURALUCB          : Reward=0366.00, Efficiency=041.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=150.0, Threshold=0.582]\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=0490.00, Efficiency=055.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=150.0, Threshold=0.628]\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=0366.00, Efficiency=041.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=150.0, Threshold=0.634]\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=0540.00, Efficiency=061.2% [Retries=3, Failed=0, < Threshold=3, SCapacity=150.0, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP2 Winner:iCPursuitNeuralUCB  (Gap:038.8%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:100, SCapacity=150.0, Alloc=Dynamic]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 150 frames  <>  SCALED-CAPACITY: 225.0 frames (CAPACITY:150 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=2 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for MARKOV Exp 3: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 3: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:150, QubitAlloc=Dynamic, SC:225 (Scale=1.5 x Cap=150), Seed: 20747\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_3\n",
      "\t‚úì QuantumExperimentRunner_3 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_225-Dynamic_Adversarial_Markov-150_3_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_225-Dynamic_Adversarial_Markov-150_3_paper7.pkl\n",
      "\t   File exists: True, size: 90726\n",
      "‚è© SKIPPING EXPERIMENT 3: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 3 GNEURALUCB          : Reward=0555.00, Efficiency=042.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=225.0, Threshold=0.582]\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=0555.00, Efficiency=042.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=225.0, Threshold=0.628]\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=0555.00, Efficiency=042.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=225.0, Threshold=0.634]\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=0574.00, Efficiency=043.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=225.0, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP3 Winner:iCPursuitNeuralUCB  (Gap:056.2%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:150, SCapacity=225.0, Alloc=Dynamic]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 200 frames  <>  SCALED-CAPACITY: 300.0 frames (CAPACITY:200 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=3 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for MARKOV Exp 4: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 4: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:200, QubitAlloc=Dynamic, SC:300 (Scale=1.5 x Cap=200), Seed: 15410\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_4\n",
      "\t‚úì QuantumExperimentRunner_4 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_300-Dynamic_Adversarial_Markov-200_4_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_300-Dynamic_Adversarial_Markov-200_4_paper7.pkl\n",
      "\t   File exists: True, size: 117327\n",
      "‚è© SKIPPING EXPERIMENT 4: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 4 GNEURALUCB          : Reward=0907.00, Efficiency=051.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=300.0, Threshold=0.582]\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=0882.00, Efficiency=050.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=300.0, Threshold=0.628]\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=0907.00, Efficiency=051.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=300.0, Threshold=0.634]\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=0801.00, Efficiency=045.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=300.0, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP4 Winner:GNeuralUCB          (Gap:048.2%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:200, SCapacity=300.0, Alloc=Dynamic]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 250 frames  <>  SCALED-CAPACITY: 375.0 frames (CAPACITY:250 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=4 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for MARKOV Exp 5: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 5: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:250, QubitAlloc=Dynamic, SC:375 (Scale=1.5 x Cap=250), Seed: 22674\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_5\n",
      "\t‚úì QuantumExperimentRunner_5 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_375-Dynamic_Adversarial_Markov-250_5_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_375-Dynamic_Adversarial_Markov-250_5_paper7.pkl\n",
      "\t   File exists: True, size: 143936\n",
      "‚è© SKIPPING EXPERIMENT 5: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 5 GNEURALUCB          : Reward=1035.00, Efficiency=047.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=375.0, Threshold=0.582]\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=0872.00, Efficiency=040.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=375.0, Threshold=0.628]\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=1035.00, Efficiency=047.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=375.0, Threshold=0.634]\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=0936.00, Efficiency=043.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=375.0, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP5 Winner:GNeuralUCB          (Gap:052.4%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:250, SCapacity=375.0, Alloc=Dynamic]\n",
      "\n",
      "Total experiment time: 013.8s\n",
      "Experiments completed for markov\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: ADAPTIVE ADVERSARIAL ATTACK\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: ADAPTIVE\n",
      "Category: Adaptive (Reactive Strategic)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 50 frames  <>  SCALED-CAPACITY: 75.0 frames (CAPACITY:50 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=0 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 1: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 1: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:50, QubitAlloc=Dynamic, SC:75 (Scale=1.5 x Cap=50), Seed: 21427\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_1\n",
      "\t‚úì QuantumExperimentRunner_1 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_75-Dynamic_Adversarial_Adaptive-50_1_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_75-Dynamic_Adversarial_Adaptive-50_1_paper7.pkl\n",
      "\t   File exists: True, size: 37487\n",
      "‚è© SKIPPING EXPERIMENT 1: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 1 GNEURALUCB          : Reward=0319.00, Efficiency=071.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=75.0, Threshold=0.582]\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=0264.00, Efficiency=059.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=75.0, Threshold=0.628]\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=0319.00, Efficiency=071.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=75.0, Threshold=0.634]\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=0333.00, Efficiency=074.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=75.0, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP1 Winner:iCPursuitNeuralUCB  (Gap:025.5%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:50, SCapacity=75.0, Alloc=Dynamic]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 100 frames  <>  SCALED-CAPACITY: 150.0 frames (CAPACITY:100 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=1 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 2: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 2: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:100, QubitAlloc=Dynamic, SC:150 (Scale=1.5 x Cap=100), Seed: 13200\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_2\n",
      "\t‚úì QuantumExperimentRunner_2 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_150-Dynamic_Adversarial_Adaptive-100_2_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_150-Dynamic_Adversarial_Adaptive-100_2_paper7.pkl\n",
      "\t   File exists: True, size: 64123\n",
      "‚è© SKIPPING EXPERIMENT 2: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 2 GNEURALUCB          : Reward=0591.00, Efficiency=066.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=150.0, Threshold=0.582]\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=0588.00, Efficiency=065.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=150.0, Threshold=0.628]\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=0591.00, Efficiency=066.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=150.0, Threshold=0.634]\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=0576.00, Efficiency=064.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=150.0, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP2 Winner:GNeuralUCB          (Gap:033.8%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:100, SCapacity=150.0, Alloc=Dynamic]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 150 frames  <>  SCALED-CAPACITY: 225.0 frames (CAPACITY:150 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=2 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 3: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 3: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:150, QubitAlloc=Dynamic, SC:225 (Scale=1.5 x Cap=150), Seed: 18005\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_3\n",
      "\t‚úì QuantumExperimentRunner_3 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_225-Dynamic_Adversarial_Adaptive-150_3_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_225-Dynamic_Adversarial_Adaptive-150_3_paper7.pkl\n",
      "\t   File exists: True, size: 90732\n",
      "‚è© SKIPPING EXPERIMENT 3: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 3 GNEURALUCB          : Reward=0903.00, Efficiency=067.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=225.0, Threshold=0.582]\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=0911.00, Efficiency=067.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=225.0, Threshold=0.628]\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=0903.00, Efficiency=067.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=225.0, Threshold=0.634]\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=0928.00, Efficiency=069.2% [Retries=3, Failed=0, < Threshold=3, SCapacity=225.0, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP3 Winner:iCPursuitNeuralUCB  (Gap:030.8%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:150, SCapacity=225.0, Alloc=Dynamic]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 200 frames  <>  SCALED-CAPACITY: 300.0 frames (CAPACITY:200 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=3 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 4: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 4: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:200, QubitAlloc=Dynamic, SC:300 (Scale=1.5 x Cap=200), Seed: 12955\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_4\n",
      "\t‚úì QuantumExperimentRunner_4 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_300-Dynamic_Adversarial_Adaptive-200_4_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_300-Dynamic_Adversarial_Adaptive-200_4_paper7.pkl\n",
      "\t   File exists: True, size: 117333\n",
      "‚è© SKIPPING EXPERIMENT 4: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 4 GNEURALUCB          : Reward=1240.00, Efficiency=069.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=300.0, Threshold=0.582]\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=1142.00, Efficiency=063.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=300.0, Threshold=0.628]\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=1240.00, Efficiency=069.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=300.0, Threshold=0.634]\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=1050.00, Efficiency=058.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=300.0, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP4 Winner:GNeuralUCB          (Gap:030.8%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:200, SCapacity=300.0, Alloc=Dynamic]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 250 frames  <>  SCALED-CAPACITY: 375.0 frames (CAPACITY:250 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=4 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 5: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 5: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:250, QubitAlloc=Dynamic, SC:375 (Scale=1.5 x Cap=250), Seed: 14950\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_5\n",
      "\t‚úì QuantumExperimentRunner_5 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_375-Dynamic_Adversarial_Adaptive-250_5_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_375-Dynamic_Adversarial_Adaptive-250_5_paper7.pkl\n",
      "\t   File exists: True, size: 143942\n",
      "‚è© SKIPPING EXPERIMENT 5: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 5 GNEURALUCB          : Reward=1481.00, Efficiency=066.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=375.0, Threshold=0.582]\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=1424.00, Efficiency=063.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=375.0, Threshold=0.628]\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=1481.00, Efficiency=066.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=375.0, Threshold=0.634]\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=1674.00, Efficiency=075.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=375.0, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP5 Winner:iCPursuitNeuralUCB  (Gap:024.9%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:250, SCapacity=375.0, Alloc=Dynamic]\n",
      "\n",
      "Total experiment time: 014.0s\n",
      "Experiments completed for adaptive\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: ONLINE ADAPTIVE ATTACK\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: ONLINEADAPTIVE\n",
      "Category: Online Adaptive (Real-time Strategic)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 50 frames  <>  SCALED-CAPACITY: 75.0 frames (CAPACITY:50 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=0 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 1: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:50, QubitAlloc=Dynamic, SC:75 (Scale=1.5 x Cap=50), Seed: 14732\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_1\n",
      "\t‚úì QuantumExperimentRunner_1 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_75-Dynamic_Adversarial_OnlineAdaptive-50_1_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_75-Dynamic_Adversarial_OnlineAdaptive-50_1_paper7.pkl\n",
      "\t   File exists: True, size: 37505\n",
      "‚è© SKIPPING EXPERIMENT 1: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 1 GNEURALUCB          : Reward=0303.00, Efficiency=067.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=75.0, Threshold=0.582]\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=0316.00, Efficiency=070.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=75.0, Threshold=0.628]\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=0303.00, Efficiency=067.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=75.0, Threshold=0.634]\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=0256.00, Efficiency=057.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=75.0, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP1 Winner:EXPNeuralUCB        (Gap:029.5%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:50, SCapacity=75.0, Alloc=Dynamic]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 100 frames  <>  SCALED-CAPACITY: 150.0 frames (CAPACITY:100 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=1 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 2: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:100, QubitAlloc=Dynamic, SC:150 (Scale=1.5 x Cap=100), Seed: 14647\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_2\n",
      "\t‚úì QuantumExperimentRunner_2 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_150-Dynamic_Adversarial_OnlineAdaptive-100_2_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_150-Dynamic_Adversarial_OnlineAdaptive-100_2_paper7.pkl\n",
      "\t   File exists: True, size: 64141\n",
      "‚è© SKIPPING EXPERIMENT 2: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 2 GNEURALUCB          : Reward=0603.00, Efficiency=067.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=150.0, Threshold=0.582]\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=0569.00, Efficiency=063.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=150.0, Threshold=0.628]\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=0603.00, Efficiency=067.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=150.0, Threshold=0.634]\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=0666.00, Efficiency=074.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=150.0, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP2 Winner:iCPursuitNeuralUCB  (Gap:025.3%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:100, SCapacity=150.0, Alloc=Dynamic]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 150 frames  <>  SCALED-CAPACITY: 225.0 frames (CAPACITY:150 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=2 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 3: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:150, QubitAlloc=Dynamic, SC:225 (Scale=1.5 x Cap=150), Seed: 21138\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_3\n",
      "\t‚úì QuantumExperimentRunner_3 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_225-Dynamic_Adversarial_OnlineAdaptive-150_3_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_225-Dynamic_Adversarial_OnlineAdaptive-150_3_paper7.pkl\n",
      "\t   File exists: True, size: 90750\n",
      "‚è© SKIPPING EXPERIMENT 3: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 3 GNEURALUCB          : Reward=0886.00, Efficiency=066.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=225.0, Threshold=0.582]\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=0894.00, Efficiency=066.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=225.0, Threshold=0.628]\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=0886.00, Efficiency=066.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=225.0, Threshold=0.634]\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=0888.00, Efficiency=066.2% [Retries=3, Failed=0, < Threshold=3, SCapacity=225.0, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP3 Winner:EXPNeuralUCB        (Gap:033.3%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:150, SCapacity=225.0, Alloc=Dynamic]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 200 frames  <>  SCALED-CAPACITY: 300.0 frames (CAPACITY:200 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=3 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 4: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:200, QubitAlloc=Dynamic, SC:300 (Scale=1.5 x Cap=200), Seed: 16677\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_4\n",
      "\t‚úì QuantumExperimentRunner_4 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_300-Dynamic_Adversarial_OnlineAdaptive-200_4_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_300-Dynamic_Adversarial_OnlineAdaptive-200_4_paper7.pkl\n",
      "\t   File exists: True, size: 117351\n",
      "‚è© SKIPPING EXPERIMENT 4: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 4 GNEURALUCB          : Reward=1259.00, Efficiency=070.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=300.0, Threshold=0.582]\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=1256.00, Efficiency=070.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=300.0, Threshold=0.628]\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=1259.00, Efficiency=070.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=300.0, Threshold=0.634]\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=1413.00, Efficiency=079.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=300.0, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP4 Winner:iCPursuitNeuralUCB  (Gap:020.9%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:200, SCapacity=300.0, Alloc=Dynamic]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 250 frames  <>  SCALED-CAPACITY: 375.0 frames (CAPACITY:250 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=4 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 5: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:250, QubitAlloc=Dynamic, SC:375 (Scale=1.5 x Cap=250), Seed: 22447\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_5\n",
      "\t‚úì QuantumExperimentRunner_5 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_375-Dynamic_Adversarial_OnlineAdaptive-250_5_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_375-Dynamic_Adversarial_OnlineAdaptive-250_5_paper7.pkl\n",
      "\t   File exists: True, size: 143960\n",
      "‚è© SKIPPING EXPERIMENT 5: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 5 GNEURALUCB          : Reward=1389.00, Efficiency=062.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=375.0, Threshold=0.582]\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=1518.00, Efficiency=068.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=375.0, Threshold=0.628]\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=1389.00, Efficiency=062.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=375.0, Threshold=0.634]\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=1528.00, Efficiency=068.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=375.0, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP5 Winner:iCPursuitNeuralUCB  (Gap:031.4%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:250, SCapacity=375.0, Alloc=Dynamic]\n",
      "\n",
      "Total experiment time: 014.5s\n",
      "Experiments completed for onlineadaptive\n",
      "‚úì Scenario 'none' evaluation completed.\n",
      "‚úì Scenario 'stochastic' evaluation completed.\n",
      "‚úì Scenario 'markov' evaluation completed.\n",
      "‚úì Scenario 'adaptive' evaluation completed.\n",
      "‚úì Scenario 'onlineadaptive' evaluation completed.\n",
      "\n",
      "======================================================================\n",
      "COMPREHENSIVE SCENARIO PERFORMANCE ANALYSIS\n",
      "======================================================================\n",
      "SCENARIO: NONE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 1350.00\n",
      "\t‚Ä¢ Winner Avg Gap: 0000.00%\n",
      "\t‚Ä¢ Winner Avg Reward: 1350.00\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0100.00%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 5 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: NONE\n",
      "======================================================================\n",
      "SCENARIO: \tBASELINE (OPTIMAL CONDITIONS)\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 5/5 experiments)\n",
      "\tWinner Avg Gap: \t000.0%\n",
      "\tWinner Avg Efficiency: \t100.0%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t100.0% Efficiency \t(Won 5/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t091.0% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t088.1% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t088.1% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: STOCHASTIC\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 1349.80\n",
      "\t‚Ä¢ Winner Avg Gap: 0005.52%\n",
      "\t‚Ä¢ Winner Avg Reward: 1274.40\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0094.48%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 5 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: STOCHASTIC\n",
      "======================================================================\n",
      "SCENARIO: \tSTOCHASTIC RANDOM FAILURES\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 5/5 experiments)\n",
      "\tWinner Avg Gap: \t005.5%\n",
      "\tWinner Avg Efficiency: \t094.5%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t094.5% Efficiency \t(Won 5/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t083.3% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t082.7% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t082.7% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: MARKOV\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: EXPNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 1310.80\n",
      "\t‚Ä¢ Winner Avg Gap: 0052.33%\n",
      "\t‚Ä¢ Winner Avg Reward: 0603.40\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0047.67%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 2 wins\n",
      "\t\t- EXPNeuralUCB: 1 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 2 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: MARKOV\n",
      "======================================================================\n",
      "SCENARIO: \tMARKOV ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tEXPNeuralUCB (Won 1/5 experiments)\n",
      "\tWinner Avg Gap: \t052.3%\n",
      "\tWinner Avg Efficiency: \t047.7%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t047.7% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t045.8% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t045.8% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t044.5% Efficiency \t(Won 2/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 1340.40\n",
      "\t‚Ä¢ Winner Avg Gap: 0031.62%\n",
      "\t‚Ä¢ Winner Avg Reward: 0912.20\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0068.38%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 2 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 3 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tADAPTIVE ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 3/5 experiments)\n",
      "\tWinner Avg Gap: \t031.6%\n",
      "\tWinner Avg Efficiency: \t068.4%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t068.4% Efficiency \t(Won 3/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t068.1% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t068.1% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t064.1% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ONLINEADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 1339.20\n",
      "\t‚Ä¢ Winner Avg Gap: 0030.85%\n",
      "\t‚Ä¢ Winner Avg Reward: 0950.20\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0069.15%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 2 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 3 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ONLINEADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tONLINE ADAPTIVE ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 3/5 experiments)\n",
      "\tWinner Avg Gap: \t030.9%\n",
      "\tWinner Avg Efficiency: \t069.1%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t069.1% Efficiency \t(Won 3/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t067.9% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t066.8% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t066.8% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "KEY INSIGHTS:\n",
      "Best Performing Model Analysis (iCPursuitNeuralUCB):\n",
      "\t‚Ä¢ Stochastic Performance:    \t1274.400\n",
      "\t‚Ä¢ Baseline Performance:      \t1350.000\n",
      "\t‚Ä¢ Performance Retention:     \t094.4%\n",
      "\tGOOD:               \tAcceptable performance under stochastic conditions\n",
      "Statistical Analysis:\n",
      "\t‚Ä¢ Total models evaluated:     \t5\n",
      "\t‚Ä¢ Experiments per environment:\t5\n",
      "\t‚Ä¢ Quantum network simulation: \tComprehensive stochastic modeling\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "COMPREHENSIVE SCENARIO PERFORMANCE ANALYSIS\n",
      "======================================================================\n",
      "SCENARIO: NONE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 1350.00\n",
      "\t‚Ä¢ Winner Avg Gap: 0000.00%\n",
      "\t‚Ä¢ Winner Avg Reward: 1350.00\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0100.00%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 5 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: NONE\n",
      "======================================================================\n",
      "SCENARIO: \tBASELINE (OPTIMAL CONDITIONS)\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 5/5 experiments)\n",
      "\tWinner Avg Gap: \t000.0%\n",
      "\tWinner Avg Efficiency: \t100.0%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t100.0% Efficiency \t(Won 5/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t091.0% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t088.1% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t088.1% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: STOCHASTIC\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 1349.80\n",
      "\t‚Ä¢ Winner Avg Gap: 0005.52%\n",
      "\t‚Ä¢ Winner Avg Reward: 1274.40\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0094.48%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 5 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: STOCHASTIC\n",
      "======================================================================\n",
      "SCENARIO: \tSTOCHASTIC RANDOM FAILURES\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 5/5 experiments)\n",
      "\tWinner Avg Gap: \t005.5%\n",
      "\tWinner Avg Efficiency: \t094.5%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t094.5% Efficiency \t(Won 5/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t083.3% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t082.7% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t082.7% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: MARKOV\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: EXPNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 1310.80\n",
      "\t‚Ä¢ Winner Avg Gap: 0052.33%\n",
      "\t‚Ä¢ Winner Avg Reward: 0603.40\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0047.67%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 2 wins\n",
      "\t\t- EXPNeuralUCB: 1 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 2 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: MARKOV\n",
      "======================================================================\n",
      "SCENARIO: \tMARKOV ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tEXPNeuralUCB (Won 1/5 experiments)\n",
      "\tWinner Avg Gap: \t052.3%\n",
      "\tWinner Avg Efficiency: \t047.7%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t047.7% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t045.8% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t045.8% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t044.5% Efficiency \t(Won 2/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 1340.40\n",
      "\t‚Ä¢ Winner Avg Gap: 0031.62%\n",
      "\t‚Ä¢ Winner Avg Reward: 0912.20\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0068.38%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 2 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 3 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tADAPTIVE ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 3/5 experiments)\n",
      "\tWinner Avg Gap: \t031.6%\n",
      "\tWinner Avg Efficiency: \t068.4%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t068.4% Efficiency \t(Won 3/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t068.1% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t068.1% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t064.1% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ONLINEADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 1339.20\n",
      "\t‚Ä¢ Winner Avg Gap: 0030.85%\n",
      "\t‚Ä¢ Winner Avg Reward: 0950.20\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0069.15%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 2 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 3 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ONLINEADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tONLINE ADAPTIVE ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 3/5 experiments)\n",
      "\tWinner Avg Gap: \t030.9%\n",
      "\tWinner Avg Efficiency: \t069.1%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t069.1% Efficiency \t(Won 3/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t067.9% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t066.8% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t066.8% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "‚úÖ Evaluation completed!\n",
      "[Logging Redirect Stopped]\n",
      "\n",
      "üßπ Final cleanup for Dynamic\n",
      "\n",
      "======================================================================\n",
      "‚úÖ COMPLETED: Dynamic\n",
      "======================================================================\n",
      "\n",
      "Dynamic COMPLETED SUCCESSFULLY\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Preparing: Dynamic at scale 2\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üîß Generating physics parameters for model: paper7\n",
      "\n",
      "===================== GET LOCAL REGISTRY =====================\n",
      "‚Üí Skipping local cache (force=True or file missing)\n",
      "\n",
      "===================== BUILD LOCAL REGISTRY =====================\n",
      "\n",
      "================================================================================\n",
      "üîç SCANNING LOCAL FILES\n",
      "================================================================================\n",
      "Parameters: load_to_drive=False, force=False\n",
      "\n",
      "üìÇ Checking DRIVE mode: /content/drive/Shareddrives/ai_quantum_computing/quantum_data_lake\n",
      "   ‚ö†Ô∏è  Path does not exist, skipping\n",
      "\n",
      "üìÇ Checking LOCAL mode: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config\n",
      "   ‚úÖ Path exists, starting walk...\n",
      "   üö∂ Walking directory tree: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config\n",
      "\n",
      "   üìÅ Directory: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201\n",
      "      Relative: framework_state/day_20260201\n",
      "      Component: framework_state\n",
      "      Date: day_20260201\n",
      "      üìÑ Processing 2540 files in framework_state/day_20260201\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "      üìä framework_state/day_20260201: 2514/2540 files processed\n",
      "      üìä framework_state/day_20260201: 0/2540 files skipped\n",
      "      üìä framework_state/day_20260201: 26/2540 files conflicted\n",
      "\n",
      "   üìÅ Directory: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/model_state/day_20260201\n",
      "      Relative: model_state/day_20260201\n",
      "      Component: model_state\n",
      "      Date: day_20260201\n",
      "      üìÑ Processing 9000 files in model_state/day_20260201\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "      üìä model_state/day_20260201: 9000/9000 files processed\n",
      "      üìä model_state/day_20260201: 0/9000 files skipped\n",
      "      üìä model_state/day_20260201: 0/9000 files conflicted\n",
      "\n",
      "   üìä Processed 2 directories\n",
      "\n",
      "================================================================================\n",
      "üì¶ BUILDING FINAL REGISTRY\n",
      "================================================================================\n",
      "Components found: ['framework_state', 'model_state']\n",
      "  ‚Ä¢ framework_state: 2514 files\n",
      "  ‚Ä¢ model_state: 9000 files\n",
      "\n",
      "‚úÖ SCAN COMPLETE\n",
      "Modes scanned: 1\n",
      "Total files in registry: 11514\n",
      "================================================================================\n",
      "\n",
      "\t‚Üí Filesystem scan found 11514 files\n",
      "\n",
      "===================== GET DRIVE REGISTRY =====================\n",
      "===================== REGISTRY BUILD COMPLETE =====================\n",
      "\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "\tüì¶ LocalBackupManager Registry Saved Locally in LOCAL\n",
      "BUILDING REGISTRY WITH 0 EXPECTED COMPONENTS KEYS\n",
      "\n",
      "===================== GET LOCAL REGISTRY =====================\n",
      "‚Üí Skipping local cache (force=True or file missing)\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "\tüì¶ LocalBackupManager Registry Saved Locally in LOCAL\n",
      "\n",
      "======================================================================\n",
      "üéØ AllocatorRunner initialized: Dynamic\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "üöÄ STARTING ALLOCATOR: Dynamic\n",
      "======================================================================\n",
      "\n",
      "üìä Physics Model: paper7\n",
      "\n",
      "üìã Allocator Config:\n",
      "   Type: Dynamic\n",
      "   Testbed: default\n",
      "   Paths: 15\n",
      "   Total Qubits: 75\n",
      "   Min per route: 2\n",
      "   Seed: 42\n",
      "   Exploration bonus: 2.0\n",
      "‚úÖ Allocator created: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "‚úì Allocator: DynamicQubitAllocator (15 paths)\n",
      "   Initial allocation: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üìä Paper7 Topology: Real AS (as20000101.txt)\n",
      "üìä Paper7 Paths: 15 paths from 5-shortest between 3 ISPs\n",
      "üìä Paper7 Contexts: 15 context vectors generated\n",
      "üìä Paper7 Rewards: Context-aware (mode=neg_hop)\n",
      "‚è±Ô∏è  get_physics_params_paper7() time: 2.3 ms\n",
      "\n",
      "======================================================================\n",
      "RUN 1 | Scale: 2 | Exp: 5\n",
      "======================================================================\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "\n",
      "\tüîÑ Resume: MultiRunEvaluator\n",
      "\n",
      "=====================================================\n",
      "üîç GENERATING EXPECTED KEYS FROM EVALUATOR\n",
      "=====================================================\n",
      "  ‚Ä¢ Evaluator filename: MultiRunEvaluator_100-Dynamic_All_All-50_50_5_S2T_paper7.pkl\n",
      "\n",
      "üß© PARSED COMPONENTS\n",
      "  ‚Ä¢ cap_id:        100\n",
      "  ‚Ä¢ allocator_id:  Dynamic\n",
      "  ‚Ä¢ env_id:        All\n",
      "  ‚Ä¢ attack_id:     All\n",
      "  ‚Ä¢ base_frames:   50\n",
      "  ‚Ä¢ frame_step:    50\n",
      "  ‚Ä¢ runs_id:       5\n",
      "\n",
      "=====================================================\n",
      "üß™ GENERATING KEYS FOR EACH RUN\n",
      "=====================================================\n",
      "\n",
      "--- Run 1/5 -----------------------\n",
      "\n",
      "=====================================================\n",
      "üì¶ FINAL EXPECTED KEYS\n",
      "=====================================================\n",
      "  ‚Ä¢ Runner keys: 11\n",
      "\n",
      "  ‚Ä¢ Model keys: 50\n",
      "\n",
      "--- Run 2/5 -----------------------\n",
      "\n",
      "=====================================================\n",
      "üì¶ FINAL EXPECTED KEYS\n",
      "=====================================================\n",
      "  ‚Ä¢ Runner keys: 21\n",
      "\n",
      "  ‚Ä¢ Model keys: 100\n",
      "\n",
      "--- Run 3/5 -----------------------\n",
      "\n",
      "=====================================================\n",
      "üì¶ FINAL EXPECTED KEYS\n",
      "=====================================================\n",
      "  ‚Ä¢ Runner keys: 31\n",
      "\n",
      "  ‚Ä¢ Model keys: 150\n",
      "\n",
      "--- Run 4/5 -----------------------\n",
      "\n",
      "=====================================================\n",
      "üì¶ FINAL EXPECTED KEYS\n",
      "=====================================================\n",
      "  ‚Ä¢ Runner keys: 41\n",
      "\n",
      "  ‚Ä¢ Model keys: 200\n",
      "\n",
      "--- Run 5/5 -----------------------\n",
      "\n",
      "=====================================================\n",
      "üì¶ FINAL EXPECTED KEYS\n",
      "=====================================================\n",
      "  ‚Ä¢ Runner keys: 51\n",
      "\n",
      "  ‚Ä¢ Model keys: 250\n",
      "\n",
      "EXPECTED KEY GENERATION COMPLETE\n",
      "\n",
      "RESTORING FROM DRIVE 1\n",
      "RESTORING FROM DRIVE 2\n",
      "\t‚ö†Ô∏è Registry exists ‚Üí aborting restore\n",
      "\t‚úì MultiRunEvaluator Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/MultiRunEvaluator_100-Dynamic_All_All-50_50_5_S2T_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/MultiRunEvaluator_100-Dynamic_All_All-50_50_5_S2T_paper7.pkl\n",
      "\t   File exists: True, size: 4183632\n",
      "EQUAL METHOD\n",
      "Multi-Run Evaluator Initialized\n",
      "Environment Type: None\n",
      "Frame Range: 50 -> 250 (step: 50)\n",
      "quantum_exps-Dynamic(paper7)_alloc-all_envs-5_attacks-50_50-5_runs-S2T\n",
      "[Logging Redirect Initialized]\n",
      "Log File: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/quantum_logs/quantum_exps-Dynamic(paper7)_alloc-all_envs-5_attacks-50_50-5_runs-S2T_20260201_log.txt\n",
      "‚öô Running evaluation...\n",
      "======================================================================\n",
      "SCENARIOS MODEL EVALUATION\n",
      "======================================================================\n",
      "Testing algorithm performance against:\n",
      "\t‚Ä¢ Stochastic:  \tNatural quantum decoherence and network failures\n",
      "\t‚Ä¢ Baseline:    \tOptimal conditions for validation\n",
      "======================================================================\n",
      "Models to Test:             \tOracle, GNeuralUCB, EXPNeuralUCB, CPursuitNeuralUCB, iCPursuitNeuralUCB\n",
      "Experiments per Scenario:   \t5\n",
      "======================================================================\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: BASELINE (OPTIMAL CONDITIONS)\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: NONE\n",
      "Category: Baseline (No Attacks)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 50 frames  <>  SCALED-CAPACITY: 100 frames (CAPACITY:50 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=0 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for NONE Exp 1: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 1: Env:Baseline (None), Attack:No, Rate:0.0, Frames:50, QubitAlloc=Dynamic, SC:100 (Scale=2 x Cap=50), Seed: 15373\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_1\n",
      "\t‚úì QuantumExperimentRunner_1 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_100-Dynamic_Baseline (None)_No-50_1_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_100-Dynamic_Baseline (None)_No-50_1_paper7.pkl\n",
      "\t   File exists: True, size: 35461\n",
      "‚è© SKIPPING EXPERIMENT 1: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 1 GNEURALUCB          : Reward=0396.00, Efficiency=088.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=100, Threshold=0.582]\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=0391.00, Efficiency=086.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=100, Threshold=0.628]\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=0396.00, Efficiency=088.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=100, Threshold=0.634]\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=0450.00, Efficiency=100.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=100, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP1 Winner:iCPursuitNeuralUCB  (Gap:000.0%) [Env:Baseline (None), Attack:No X Rate:0.25, Frames:50, SCapacity=100, Alloc=Dynamic]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 100 frames  <>  SCALED-CAPACITY: 200 frames (CAPACITY:100 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=1 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for NONE Exp 2: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 2: Env:Baseline (None), Attack:No, Rate:0.0, Frames:100, QubitAlloc=Dynamic, SC:200 (Scale=2 x Cap=100), Seed: 12644\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_2\n",
      "\t‚úì QuantumExperimentRunner_2 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_200-Dynamic_Baseline (None)_No-100_2_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_200-Dynamic_Baseline (None)_No-100_2_paper7.pkl\n",
      "\t   File exists: True, size: 62090\n",
      "‚è© SKIPPING EXPERIMENT 2: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 2 GNEURALUCB          : Reward=0794.00, Efficiency=088.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=200, Threshold=0.582]\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=0830.00, Efficiency=092.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=200, Threshold=0.628]\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=0794.00, Efficiency=088.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=200, Threshold=0.634]\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=0900.00, Efficiency=100.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=200, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP2 Winner:iCPursuitNeuralUCB  (Gap:000.0%) [Env:Baseline (None), Attack:No X Rate:0.25, Frames:100, SCapacity=200, Alloc=Dynamic]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 150 frames  <>  SCALED-CAPACITY: 300 frames (CAPACITY:150 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=2 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for NONE Exp 3: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 3: Env:Baseline (None), Attack:No, Rate:0.0, Frames:150, QubitAlloc=Dynamic, SC:300 (Scale=2 x Cap=150), Seed: 20257\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_3\n",
      "\t‚úì QuantumExperimentRunner_3 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_300-Dynamic_Baseline (None)_No-150_3_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_300-Dynamic_Baseline (None)_No-150_3_paper7.pkl\n",
      "\t   File exists: True, size: 88700\n",
      "‚è© SKIPPING EXPERIMENT 3: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 3 GNEURALUCB          : Reward=1190.00, Efficiency=088.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=300, Threshold=0.582]\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=1184.00, Efficiency=087.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=300, Threshold=0.628]\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=1190.00, Efficiency=088.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=300, Threshold=0.634]\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=1350.00, Efficiency=100.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=300, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP3 Winner:iCPursuitNeuralUCB  (Gap:000.0%) [Env:Baseline (None), Attack:No X Rate:0.25, Frames:150, SCapacity=300, Alloc=Dynamic]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 200 frames  <>  SCALED-CAPACITY: 400 frames (CAPACITY:200 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=3 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for NONE Exp 4: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 4: Env:Baseline (None), Attack:No, Rate:0.0, Frames:200, QubitAlloc=Dynamic, SC:400 (Scale=2 x Cap=200), Seed: 20031\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_4\n",
      "\t‚úì QuantumExperimentRunner_4 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_400-Dynamic_Baseline (None)_No-200_4_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_400-Dynamic_Baseline (None)_No-200_4_paper7.pkl\n",
      "\t   File exists: True, size: 115300\n",
      "‚è© SKIPPING EXPERIMENT 4: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 4 GNEURALUCB          : Reward=1586.00, Efficiency=088.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=400, Threshold=0.582]\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=1600.00, Efficiency=088.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=400, Threshold=0.628]\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=1586.00, Efficiency=088.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=400, Threshold=0.634]\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=1800.00, Efficiency=100.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=400, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP4 Winner:iCPursuitNeuralUCB  (Gap:000.0%) [Env:Baseline (None), Attack:No X Rate:0.25, Frames:200, SCapacity=400, Alloc=Dynamic]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 250 frames  <>  SCALED-CAPACITY: 500 frames (CAPACITY:250 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=4 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for NONE Exp 5: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 5: Env:Baseline (None), Attack:No, Rate:0.0, Frames:250, QubitAlloc=Dynamic, SC:500 (Scale=2 x Cap=250), Seed: 17303\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_5\n",
      "\t‚úì QuantumExperimentRunner_5 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_500-Dynamic_Baseline (None)_No-250_5_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_500-Dynamic_Baseline (None)_No-250_5_paper7.pkl\n",
      "\t   File exists: True, size: 141909\n",
      "‚è© SKIPPING EXPERIMENT 5: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 5 GNEURALUCB          : Reward=1984.00, Efficiency=088.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=500, Threshold=0.582]\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=1993.00, Efficiency=088.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=500, Threshold=0.628]\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=1984.00, Efficiency=088.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=500, Threshold=0.634]\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=2250.00, Efficiency=100.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=500, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP5 Winner:iCPursuitNeuralUCB  (Gap:000.0%) [Env:Baseline (None), Attack:No X Rate:0.25, Frames:250, SCapacity=500, Alloc=Dynamic]\n",
      "\n",
      "Total experiment time: 013.0s\n",
      "Experiments completed for none\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: STOCHASTIC RANDOM FAILURES\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: STOCHASTIC\n",
      "Category: Stochastic (Natural Random Failures)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 50 frames  <>  SCALED-CAPACITY: 100 frames (CAPACITY:50 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=0 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 1: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 1: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:50, QubitAlloc=Dynamic, SC:100 (Scale=2 x Cap=50), Seed: 15729\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_1\n",
      "\t‚úì QuantumExperimentRunner_1 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_100-Dynamic_Stochastic_Random-50_1_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_100-Dynamic_Stochastic_Random-50_1_paper7.pkl\n",
      "\t   File exists: True, size: 35465\n",
      "‚è© SKIPPING EXPERIMENT 1: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 1 GNEURALUCB          : Reward=0381.00, Efficiency=084.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=100, Threshold=0.582]\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=0356.00, Efficiency=079.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=100, Threshold=0.628]\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=0381.00, Efficiency=084.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=100, Threshold=0.634]\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=0441.00, Efficiency=098.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=100, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP1 Winner:iCPursuitNeuralUCB  (Gap:002.0%) [Env:Stochastic, Attack:Random X Rate:0.25, Frames:50, SCapacity=100, Alloc=Dynamic]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 100 frames  <>  SCALED-CAPACITY: 200 frames (CAPACITY:100 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=1 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 2: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 2: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:100, QubitAlloc=Dynamic, SC:200 (Scale=2 x Cap=100), Seed: 19894\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_2\n",
      "\t‚úì QuantumExperimentRunner_2 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_200-Dynamic_Stochastic_Random-100_2_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_200-Dynamic_Stochastic_Random-100_2_paper7.pkl\n",
      "\t   File exists: True, size: 62094\n",
      "‚è© SKIPPING EXPERIMENT 2: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 2 GNEURALUCB          : Reward=0749.00, Efficiency=083.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=200, Threshold=0.582]\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=0671.00, Efficiency=074.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=200, Threshold=0.628]\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=0749.00, Efficiency=083.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=200, Threshold=0.634]\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=0801.00, Efficiency=089.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=200, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP2 Winner:iCPursuitNeuralUCB  (Gap:011.0%) [Env:Stochastic, Attack:Random X Rate:0.25, Frames:100, SCapacity=200, Alloc=Dynamic]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 150 frames  <>  SCALED-CAPACITY: 300 frames (CAPACITY:150 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=2 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 3: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 3: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:150, QubitAlloc=Dynamic, SC:300 (Scale=2 x Cap=150), Seed: 16736\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_3\n",
      "\t‚úì QuantumExperimentRunner_3 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_300-Dynamic_Stochastic_Random-150_3_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_300-Dynamic_Stochastic_Random-150_3_paper7.pkl\n",
      "\t   File exists: True, size: 88704\n",
      "‚è© SKIPPING EXPERIMENT 3: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 3 GNEURALUCB          : Reward=1121.00, Efficiency=083.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=300, Threshold=0.582]\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=1176.00, Efficiency=087.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=300, Threshold=0.628]\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=1121.00, Efficiency=083.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=300, Threshold=0.634]\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=1242.00, Efficiency=092.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=300, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP3 Winner:iCPursuitNeuralUCB  (Gap:007.9%) [Env:Stochastic, Attack:Random X Rate:0.25, Frames:150, SCapacity=300, Alloc=Dynamic]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 200 frames  <>  SCALED-CAPACITY: 400 frames (CAPACITY:200 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=3 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 4: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 4: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:200, QubitAlloc=Dynamic, SC:400 (Scale=2 x Cap=200), Seed: 12981\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_4\n",
      "\t‚úì QuantumExperimentRunner_4 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_400-Dynamic_Stochastic_Random-200_4_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_400-Dynamic_Stochastic_Random-200_4_paper7.pkl\n",
      "\t   File exists: True, size: 115304\n",
      "‚è© SKIPPING EXPERIMENT 4: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 4 GNEURALUCB          : Reward=1473.00, Efficiency=081.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=400, Threshold=0.582]\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=1588.00, Efficiency=088.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=400, Threshold=0.628]\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=1473.00, Efficiency=081.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=400, Threshold=0.634]\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=1674.00, Efficiency=093.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=400, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP4 Winner:iCPursuitNeuralUCB  (Gap:007.0%) [Env:Stochastic, Attack:Random X Rate:0.25, Frames:200, SCapacity=400, Alloc=Dynamic]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 250 frames  <>  SCALED-CAPACITY: 500 frames (CAPACITY:250 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=4 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 5: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 5: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:250, QubitAlloc=Dynamic, SC:500 (Scale=2 x Cap=250), Seed: 17091\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_5\n",
      "\t‚úì QuantumExperimentRunner_5 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_500-Dynamic_Stochastic_Random-250_5_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_500-Dynamic_Stochastic_Random-250_5_paper7.pkl\n",
      "\t   File exists: True, size: 141913\n",
      "‚è© SKIPPING EXPERIMENT 5: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 5 GNEURALUCB          : Reward=1876.00, Efficiency=083.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=500, Threshold=0.582]\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=1676.00, Efficiency=074.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=500, Threshold=0.628]\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=1876.00, Efficiency=083.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=500, Threshold=0.634]\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=2187.00, Efficiency=097.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=500, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP5 Winner:iCPursuitNeuralUCB  (Gap:002.8%) [Env:Stochastic, Attack:Random X Rate:0.25, Frames:250, SCapacity=500, Alloc=Dynamic]\n",
      "\n",
      "Total experiment time: 012.7s\n",
      "Experiments completed for stochastic\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: MARKOV ADVERSARIAL ATTACK\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: MARKOV\n",
      "Category: Structured (Markov Chain Based)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 50 frames  <>  SCALED-CAPACITY: 100 frames (CAPACITY:50 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=0 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for MARKOV Exp 1: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 1: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:50, QubitAlloc=Dynamic, SC:100 (Scale=2 x Cap=50), Seed: 14132\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_1\n",
      "\t‚úì QuantumExperimentRunner_1 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_100-Dynamic_Adversarial_Markov-50_1_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_100-Dynamic_Adversarial_Markov-50_1_paper7.pkl\n",
      "\t   File exists: True, size: 35460\n",
      "‚è© SKIPPING EXPERIMENT 1: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 1 GNEURALUCB          : Reward=0239.00, Efficiency=055.2% [Retries=3, Failed=0, < Threshold=3, SCapacity=100, Threshold=0.582]\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=0143.00, Efficiency=033.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=100, Threshold=0.628]\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=0239.00, Efficiency=055.2% [Retries=3, Failed=0, < Threshold=3, SCapacity=100, Threshold=0.634]\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=0198.00, Efficiency=045.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=100, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP1 Winner:GNeuralUCB          (Gap:044.8%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:50, SCapacity=100, Alloc=Dynamic]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 100 frames  <>  SCALED-CAPACITY: 200 frames (CAPACITY:100 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=1 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for MARKOV Exp 2: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 2: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:100, QubitAlloc=Dynamic, SC:200 (Scale=2 x Cap=100), Seed: 22231\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_2\n",
      "\t‚úì QuantumExperimentRunner_2 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_200-Dynamic_Adversarial_Markov-100_2_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_200-Dynamic_Adversarial_Markov-100_2_paper7.pkl\n",
      "\t   File exists: True, size: 62092\n",
      "‚è© SKIPPING EXPERIMENT 2: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 2 GNEURALUCB          : Reward=0434.00, Efficiency=049.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=200, Threshold=0.582]\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=0330.00, Efficiency=037.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=200, Threshold=0.628]\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=0434.00, Efficiency=049.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=200, Threshold=0.634]\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=0408.00, Efficiency=046.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=200, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP2 Winner:GNeuralUCB          (Gap:050.5%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:100, SCapacity=200, Alloc=Dynamic]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 150 frames  <>  SCALED-CAPACITY: 300 frames (CAPACITY:150 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=2 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for MARKOV Exp 3: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 3: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:150, QubitAlloc=Dynamic, SC:300 (Scale=2 x Cap=150), Seed: 20747\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_3\n",
      "\t‚úì QuantumExperimentRunner_3 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_300-Dynamic_Adversarial_Markov-150_3_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_300-Dynamic_Adversarial_Markov-150_3_paper7.pkl\n",
      "\t   File exists: True, size: 88702\n",
      "‚è© SKIPPING EXPERIMENT 3: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 3 GNEURALUCB          : Reward=0654.00, Efficiency=050.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=300, Threshold=0.582]\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=0553.00, Efficiency=042.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=300, Threshold=0.628]\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=0654.00, Efficiency=050.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=300, Threshold=0.634]\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=0752.00, Efficiency=057.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=300, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP3 Winner:iCPursuitNeuralUCB  (Gap:042.5%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:150, SCapacity=300, Alloc=Dynamic]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 200 frames  <>  SCALED-CAPACITY: 400 frames (CAPACITY:200 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=3 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for MARKOV Exp 4: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 4: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:200, QubitAlloc=Dynamic, SC:400 (Scale=2 x Cap=200), Seed: 15410\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_4\n",
      "\t‚úì QuantumExperimentRunner_4 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_400-Dynamic_Adversarial_Markov-200_4_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_400-Dynamic_Adversarial_Markov-200_4_paper7.pkl\n",
      "\t   File exists: True, size: 115302\n",
      "‚è© SKIPPING EXPERIMENT 4: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 4 GNEURALUCB          : Reward=0896.00, Efficiency=051.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=400, Threshold=0.582]\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=0870.00, Efficiency=050.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=400, Threshold=0.628]\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=0896.00, Efficiency=051.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=400, Threshold=0.634]\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=0918.00, Efficiency=052.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=400, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP4 Winner:iCPursuitNeuralUCB  (Gap:047.3%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:200, SCapacity=400, Alloc=Dynamic]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 250 frames  <>  SCALED-CAPACITY: 500 frames (CAPACITY:250 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=4 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for MARKOV Exp 5: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 5: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:250, QubitAlloc=Dynamic, SC:500 (Scale=2 x Cap=250), Seed: 22674\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_5\n",
      "\t‚úì QuantumExperimentRunner_5 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_500-Dynamic_Adversarial_Markov-250_5_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_500-Dynamic_Adversarial_Markov-250_5_paper7.pkl\n",
      "\t   File exists: True, size: 141911\n",
      "‚è© SKIPPING EXPERIMENT 5: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 5 GNEURALUCB          : Reward=1150.00, Efficiency=052.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=500, Threshold=0.582]\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=1028.00, Efficiency=047.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=500, Threshold=0.628]\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=1150.00, Efficiency=052.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=500, Threshold=0.634]\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=1071.00, Efficiency=049.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=500, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP5 Winner:GNeuralUCB          (Gap:047.4%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:250, SCapacity=500, Alloc=Dynamic]\n",
      "\n",
      "Total experiment time: 013.5s\n",
      "Experiments completed for markov\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: ADAPTIVE ADVERSARIAL ATTACK\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: ADAPTIVE\n",
      "Category: Adaptive (Reactive Strategic)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 50 frames  <>  SCALED-CAPACITY: 100 frames (CAPACITY:50 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=0 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 1: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 1: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:50, QubitAlloc=Dynamic, SC:100 (Scale=2 x Cap=50), Seed: 21427\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_1\n",
      "\t‚úì QuantumExperimentRunner_1 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_100-Dynamic_Adversarial_Adaptive-50_1_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_100-Dynamic_Adversarial_Adaptive-50_1_paper7.pkl\n",
      "\t   File exists: True, size: 35469\n",
      "‚è© SKIPPING EXPERIMENT 1: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 1 GNEURALUCB          : Reward=0271.00, Efficiency=060.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=100, Threshold=0.582]\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=0269.00, Efficiency=060.2% [Retries=3, Failed=0, < Threshold=3, SCapacity=100, Threshold=0.628]\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=0271.00, Efficiency=060.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=100, Threshold=0.634]\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=0280.00, Efficiency=062.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=100, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP1 Winner:iCPursuitNeuralUCB  (Gap:037.4%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:50, SCapacity=100, Alloc=Dynamic]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 100 frames  <>  SCALED-CAPACITY: 200 frames (CAPACITY:100 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=1 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 2: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 2: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:100, QubitAlloc=Dynamic, SC:200 (Scale=2 x Cap=100), Seed: 13200\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_2\n",
      "\t‚úì QuantumExperimentRunner_2 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_200-Dynamic_Adversarial_Adaptive-100_2_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_200-Dynamic_Adversarial_Adaptive-100_2_paper7.pkl\n",
      "\t   File exists: True, size: 62098\n",
      "‚è© SKIPPING EXPERIMENT 2: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 2 GNEURALUCB          : Reward=0625.00, Efficiency=069.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=200, Threshold=0.582]\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=0555.00, Efficiency=062.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=200, Threshold=0.628]\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=0625.00, Efficiency=069.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=200, Threshold=0.634]\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=0711.00, Efficiency=079.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=200, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP2 Winner:iCPursuitNeuralUCB  (Gap:020.6%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:100, SCapacity=200, Alloc=Dynamic]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 150 frames  <>  SCALED-CAPACITY: 300 frames (CAPACITY:150 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=2 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 3: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 3: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:150, QubitAlloc=Dynamic, SC:300 (Scale=2 x Cap=150), Seed: 18005\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_3\n",
      "\t‚úì QuantumExperimentRunner_3 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_300-Dynamic_Adversarial_Adaptive-150_3_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_300-Dynamic_Adversarial_Adaptive-150_3_paper7.pkl\n",
      "\t   File exists: True, size: 88708\n",
      "‚è© SKIPPING EXPERIMENT 3: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 3 GNEURALUCB          : Reward=0911.00, Efficiency=068.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=300, Threshold=0.582]\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=0843.00, Efficiency=063.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=300, Threshold=0.628]\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=0911.00, Efficiency=068.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=300, Threshold=0.634]\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=0918.00, Efficiency=068.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=300, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP3 Winner:iCPursuitNeuralUCB  (Gap:031.3%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:150, SCapacity=300, Alloc=Dynamic]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 200 frames  <>  SCALED-CAPACITY: 400 frames (CAPACITY:200 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=3 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 4: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 4: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:200, QubitAlloc=Dynamic, SC:400 (Scale=2 x Cap=200), Seed: 12955\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_4\n",
      "\t‚úì QuantumExperimentRunner_4 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_400-Dynamic_Adversarial_Adaptive-200_4_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_400-Dynamic_Adversarial_Adaptive-200_4_paper7.pkl\n",
      "\t   File exists: True, size: 115308\n",
      "‚è© SKIPPING EXPERIMENT 4: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 4 GNEURALUCB          : Reward=1236.00, Efficiency=069.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=400, Threshold=0.582]\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=1251.00, Efficiency=069.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=400, Threshold=0.628]\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=1236.00, Efficiency=069.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=400, Threshold=0.634]\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=1404.00, Efficiency=078.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=400, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP4 Winner:iCPursuitNeuralUCB  (Gap:021.5%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:200, SCapacity=400, Alloc=Dynamic]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 250 frames  <>  SCALED-CAPACITY: 500 frames (CAPACITY:250 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=4 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 5: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 5: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:250, QubitAlloc=Dynamic, SC:500 (Scale=2 x Cap=250), Seed: 14950\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_5\n",
      "\t‚úì QuantumExperimentRunner_5 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_500-Dynamic_Adversarial_Adaptive-250_5_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_500-Dynamic_Adversarial_Adaptive-250_5_paper7.pkl\n",
      "\t   File exists: True, size: 141917\n",
      "‚è© SKIPPING EXPERIMENT 5: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 5 GNEURALUCB          : Reward=1531.00, Efficiency=068.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=500, Threshold=0.582]\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=1650.00, Efficiency=073.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=500, Threshold=0.628]\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=1531.00, Efficiency=068.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=500, Threshold=0.634]\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=1683.00, Efficiency=075.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=500, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP5 Winner:iCPursuitNeuralUCB  (Gap:024.6%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:250, SCapacity=500, Alloc=Dynamic]\n",
      "\n",
      "Total experiment time: 014.3s\n",
      "Experiments completed for adaptive\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: ONLINE ADAPTIVE ATTACK\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: ONLINEADAPTIVE\n",
      "Category: Online Adaptive (Real-time Strategic)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 50 frames  <>  SCALED-CAPACITY: 100 frames (CAPACITY:50 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=0 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 1: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:50, QubitAlloc=Dynamic, SC:100 (Scale=2 x Cap=50), Seed: 14732\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_1\n",
      "\t‚úì QuantumExperimentRunner_1 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_100-Dynamic_Adversarial_OnlineAdaptive-50_1_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_100-Dynamic_Adversarial_OnlineAdaptive-50_1_paper7.pkl\n",
      "\t   File exists: True, size: 35487\n",
      "‚è© SKIPPING EXPERIMENT 1: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 1 GNEURALUCB          : Reward=0292.00, Efficiency=065.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=100, Threshold=0.582]\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=0328.00, Efficiency=073.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=100, Threshold=0.628]\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=0292.00, Efficiency=065.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=100, Threshold=0.634]\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=0320.00, Efficiency=071.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=100, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP1 Winner:EXPNeuralUCB        (Gap:026.9%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:50, SCapacity=100, Alloc=Dynamic]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 100 frames  <>  SCALED-CAPACITY: 200 frames (CAPACITY:100 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=1 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 2: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:100, QubitAlloc=Dynamic, SC:200 (Scale=2 x Cap=100), Seed: 14647\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_2\n",
      "\t‚úì QuantumExperimentRunner_2 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_200-Dynamic_Adversarial_OnlineAdaptive-100_2_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_200-Dynamic_Adversarial_OnlineAdaptive-100_2_paper7.pkl\n",
      "\t   File exists: True, size: 62116\n",
      "‚è© SKIPPING EXPERIMENT 2: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 2 GNEURALUCB          : Reward=0584.00, Efficiency=065.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=200, Threshold=0.582]\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=0591.00, Efficiency=066.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=200, Threshold=0.628]\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=0584.00, Efficiency=065.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=200, Threshold=0.634]\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=0693.00, Efficiency=077.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=200, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP2 Winner:iCPursuitNeuralUCB  (Gap:022.6%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:100, SCapacity=200, Alloc=Dynamic]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 150 frames  <>  SCALED-CAPACITY: 300 frames (CAPACITY:150 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=2 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 3: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:150, QubitAlloc=Dynamic, SC:300 (Scale=2 x Cap=150), Seed: 21138\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_3\n",
      "\t‚úì QuantumExperimentRunner_3 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_300-Dynamic_Adversarial_OnlineAdaptive-150_3_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_300-Dynamic_Adversarial_OnlineAdaptive-150_3_paper7.pkl\n",
      "\t   File exists: True, size: 88726\n",
      "‚è© SKIPPING EXPERIMENT 3: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 3 GNEURALUCB          : Reward=0862.00, Efficiency=064.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=300, Threshold=0.582]\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=0932.00, Efficiency=069.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=300, Threshold=0.628]\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=0862.00, Efficiency=064.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=300, Threshold=0.634]\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=1035.00, Efficiency=077.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=300, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP3 Winner:iCPursuitNeuralUCB  (Gap:022.8%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:150, SCapacity=300, Alloc=Dynamic]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 200 frames  <>  SCALED-CAPACITY: 400 frames (CAPACITY:200 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=3 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 4: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:200, QubitAlloc=Dynamic, SC:400 (Scale=2 x Cap=200), Seed: 16677\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_4\n",
      "\t‚úì QuantumExperimentRunner_4 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_400-Dynamic_Adversarial_OnlineAdaptive-200_4_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_400-Dynamic_Adversarial_OnlineAdaptive-200_4_paper7.pkl\n",
      "\t   File exists: True, size: 115326\n",
      "‚è© SKIPPING EXPERIMENT 4: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 4 GNEURALUCB          : Reward=1156.00, Efficiency=064.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=400, Threshold=0.582]\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=1198.00, Efficiency=067.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=400, Threshold=0.628]\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=1156.00, Efficiency=064.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=400, Threshold=0.634]\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=1404.00, Efficiency=078.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=400, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP4 Winner:iCPursuitNeuralUCB  (Gap:021.5%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:200, SCapacity=400, Alloc=Dynamic]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 250 frames  <>  SCALED-CAPACITY: 500 frames (CAPACITY:250 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[DynamicAllocator] timestep=4 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 5: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ Dynamic Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:250, QubitAlloc=Dynamic, SC:500 (Scale=2 x Cap=250), Seed: 22447\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_5\n",
      "\t‚úì QuantumExperimentRunner_5 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_500-Dynamic_Adversarial_OnlineAdaptive-250_5_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_500-Dynamic_Adversarial_OnlineAdaptive-250_5_paper7.pkl\n",
      "\t   File exists: True, size: 141935\n",
      "‚è© SKIPPING EXPERIMENT 5: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 5 GNEURALUCB          : Reward=1544.00, Efficiency=069.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=500, Threshold=0.582]\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=1442.00, Efficiency=064.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=500, Threshold=0.628]\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=1544.00, Efficiency=069.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=500, Threshold=0.634]\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=1683.00, Efficiency=075.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=500, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP5 Winner:iCPursuitNeuralUCB  (Gap:024.8%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:250, SCapacity=500, Alloc=Dynamic]\n",
      "\n",
      "Total experiment time: 014.1s\n",
      "Experiments completed for onlineadaptive\n",
      "‚úì Scenario 'none' evaluation completed.\n",
      "‚úì Scenario 'stochastic' evaluation completed.\n",
      "‚úì Scenario 'markov' evaluation completed.\n",
      "‚úì Scenario 'adaptive' evaluation completed.\n",
      "‚úì Scenario 'onlineadaptive' evaluation completed.\n",
      "\n",
      "======================================================================\n",
      "COMPREHENSIVE SCENARIO PERFORMANCE ANALYSIS\n",
      "======================================================================\n",
      "SCENARIO: NONE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 1350.00\n",
      "\t‚Ä¢ Winner Avg Gap: 0000.00%\n",
      "\t‚Ä¢ Winner Avg Reward: 1350.00\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0100.00%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 5 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: NONE\n",
      "======================================================================\n",
      "SCENARIO: \tBASELINE (OPTIMAL CONDITIONS)\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 5/5 experiments)\n",
      "\tWinner Avg Gap: \t000.0%\n",
      "\tWinner Avg Efficiency: \t100.0%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t100.0% Efficiency \t(Won 5/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t088.9% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t088.1% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t088.1% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: STOCHASTIC\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 1349.60\n",
      "\t‚Ä¢ Winner Avg Gap: 0006.13%\n",
      "\t‚Ä¢ Winner Avg Reward: 1269.00\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0093.87%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 5 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: STOCHASTIC\n",
      "======================================================================\n",
      "SCENARIO: \tSTOCHASTIC RANDOM FAILURES\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 5/5 experiments)\n",
      "\tWinner Avg Gap: \t006.1%\n",
      "\tWinner Avg Efficiency: \t093.9%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t093.9% Efficiency \t(Won 5/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t083.3% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t083.3% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t080.7% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: MARKOV\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: GNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 1308.40\n",
      "\t‚Ä¢ Winner Avg Gap: 0048.23%\n",
      "\t‚Ä¢ Winner Avg Reward: 0674.60\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0051.77%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 3 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 2 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: MARKOV\n",
      "======================================================================\n",
      "SCENARIO: \tMARKOV ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tGNeuralUCB (Won 3/5 experiments)\n",
      "\tWinner Avg Gap: \t048.2%\n",
      "\tWinner Avg Efficiency: \t051.8%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ GNeuralUCB     : \t051.8% Efficiency \t(Won 3/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t051.8% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t050.3% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t042.0% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 1340.20\n",
      "\t‚Ä¢ Winner Avg Gap: 0027.08%\n",
      "\t‚Ä¢ Winner Avg Reward: 0999.20\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0072.92%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 5 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tADAPTIVE ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 5/5 experiments)\n",
      "\tWinner Avg Gap: \t027.1%\n",
      "\tWinner Avg Efficiency: \t072.9%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t072.9% Efficiency \t(Won 5/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t067.2% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t067.2% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t065.8% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ONLINEADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 1342.40\n",
      "\t‚Ä¢ Winner Avg Gap: 0024.08%\n",
      "\t‚Ä¢ Winner Avg Reward: 1027.00\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0075.92%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 1 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 4 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ONLINEADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tONLINE ADAPTIVE ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 4/5 experiments)\n",
      "\tWinner Avg Gap: \t024.1%\n",
      "\tWinner Avg Efficiency: \t075.9%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t075.9% Efficiency \t(Won 4/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t068.0% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t065.6% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t065.6% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "KEY INSIGHTS:\n",
      "Best Performing Model Analysis (iCPursuitNeuralUCB):\n",
      "\t‚Ä¢ Stochastic Performance:    \t1269.000\n",
      "\t‚Ä¢ Baseline Performance:      \t1350.000\n",
      "\t‚Ä¢ Performance Retention:     \t094.0%\n",
      "\tGOOD:               \tAcceptable performance under stochastic conditions\n",
      "Statistical Analysis:\n",
      "\t‚Ä¢ Total models evaluated:     \t5\n",
      "\t‚Ä¢ Experiments per environment:\t5\n",
      "\t‚Ä¢ Quantum network simulation: \tComprehensive stochastic modeling\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "COMPREHENSIVE SCENARIO PERFORMANCE ANALYSIS\n",
      "======================================================================\n",
      "SCENARIO: NONE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 1350.00\n",
      "\t‚Ä¢ Winner Avg Gap: 0000.00%\n",
      "\t‚Ä¢ Winner Avg Reward: 1350.00\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0100.00%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 5 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: NONE\n",
      "======================================================================\n",
      "SCENARIO: \tBASELINE (OPTIMAL CONDITIONS)\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 5/5 experiments)\n",
      "\tWinner Avg Gap: \t000.0%\n",
      "\tWinner Avg Efficiency: \t100.0%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t100.0% Efficiency \t(Won 5/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t088.9% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t088.1% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t088.1% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: STOCHASTIC\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 1349.60\n",
      "\t‚Ä¢ Winner Avg Gap: 0006.13%\n",
      "\t‚Ä¢ Winner Avg Reward: 1269.00\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0093.87%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 5 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: STOCHASTIC\n",
      "======================================================================\n",
      "SCENARIO: \tSTOCHASTIC RANDOM FAILURES\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 5/5 experiments)\n",
      "\tWinner Avg Gap: \t006.1%\n",
      "\tWinner Avg Efficiency: \t093.9%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t093.9% Efficiency \t(Won 5/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t083.3% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t083.3% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t080.7% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: MARKOV\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: GNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 1308.40\n",
      "\t‚Ä¢ Winner Avg Gap: 0048.23%\n",
      "\t‚Ä¢ Winner Avg Reward: 0674.60\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0051.77%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 3 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 2 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: MARKOV\n",
      "======================================================================\n",
      "SCENARIO: \tMARKOV ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tGNeuralUCB (Won 3/5 experiments)\n",
      "\tWinner Avg Gap: \t048.2%\n",
      "\tWinner Avg Efficiency: \t051.8%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ GNeuralUCB     : \t051.8% Efficiency \t(Won 3/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t051.8% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t050.3% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t042.0% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 1340.20\n",
      "\t‚Ä¢ Winner Avg Gap: 0027.08%\n",
      "\t‚Ä¢ Winner Avg Reward: 0999.20\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0072.92%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 5 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tADAPTIVE ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 5/5 experiments)\n",
      "\tWinner Avg Gap: \t027.1%\n",
      "\tWinner Avg Efficiency: \t072.9%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t072.9% Efficiency \t(Won 5/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t067.2% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t067.2% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t065.8% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ONLINEADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 1342.40\n",
      "\t‚Ä¢ Winner Avg Gap: 0024.08%\n",
      "\t‚Ä¢ Winner Avg Reward: 1027.00\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0075.92%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 1 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 4 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ONLINEADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tONLINE ADAPTIVE ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 4/5 experiments)\n",
      "\tWinner Avg Gap: \t024.1%\n",
      "\tWinner Avg Efficiency: \t075.9%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t075.9% Efficiency \t(Won 4/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t068.0% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t065.6% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t065.6% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "‚úÖ Evaluation completed!\n",
      "[Logging Redirect Stopped]\n",
      "\n",
      "üßπ Final cleanup for Dynamic\n",
      "\n",
      "======================================================================\n",
      "‚úÖ COMPLETED: Dynamic\n",
      "======================================================================\n",
      "\n",
      "Dynamic COMPLETED SUCCESSFULLY\n",
      "\n",
      "======================================================================\n",
      "ALL ALLOCATORS COMPLETE!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Cell 2: Allocator + ExperimentConfiguration for Paper #7\n",
    "# ============================================================\n",
    "importlib.reload(qubit_allocator)\n",
    "importlib.reload(experiment_config)\n",
    "importlib.reload(multi_run_evaluator)\n",
    "\n",
    "from daqr.core.quantum_physics              import *\n",
    "from daqr.evaluation.allocator_runner       import AllocatorRunner\n",
    "from daqr.evaluation.multi_run_evaluator    import MultiRunEvaluator\n",
    "from daqr.config.experiment_config          import ExperimentConfiguration\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"PAPER #7 (QBGP) QUANTUM ROUTING EVALUATION - SINGLE ALLOCATOR TEST\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1) Single Allocator Selection\n",
    "# ------------------------------------------------------------\n",
    "allocator_type = \"Dynamic\"  # Options: \"Random\", \"Dynamic\", \"ThompsonSampling\"\n",
    "ALLOCATORS = [allocator_type]\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2) Run Parameters\n",
    "# ------------------------------------------------------------\n",
    "attack_intensity    = FRAMEWORK_CONFIG['intensity']\n",
    "current_frames      = 50\n",
    "frame_step          = 50\n",
    "current_experiments = 5\n",
    "last_backup         = True\n",
    "base_cap            = False\n",
    "overwrite           = True\n",
    "\n",
    "FRAMEWORK_CONFIG['exp_num']        = current_experiments\n",
    "FRAMEWORK_CONFIG['base_frames']    = current_frames\n",
    "FRAMEWORK_CONFIG['frame_step']     = frame_step\n",
    "\n",
    "\n",
    "# Testbed Configuration\n",
    "PHYSICS_MODELS = ['paper7']  # Paper 7 (QBGP)\n",
    "ATTACK_SCENARIOS = ['stochastic']  # Start simple\n",
    "SCALES = [1, 1.5, 2]\n",
    "RUNS = [5]\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üéØ PAPER 7 ALLOCATOR EVALUATION\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Allocator:                  {allocator_type}\")\n",
    "print(f\"Physics Model:              {PHYSICS_MODELS[0]}\")\n",
    "print(f\"Attack Scenarios:           {ATTACK_SCENARIOS}\")\n",
    "print(f\"Scales:                     {SCALES}\")\n",
    "print(f\"Runs per Scale:             {RUNS}\")\n",
    "print(f\"Total Frames:               {current_frames}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Run allocators over scales and physics models\n",
    "for allocator_type in ALLOCATORS:\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"RUNNING: {allocator_type} on Paper 7 (QBGP)\")\n",
    "    print('='*70)\n",
    "\n",
    "    for scale in SCALES:\n",
    "        print(f\"\\n{'-'*70}\")\n",
    "        print(f\"Preparing: {allocator_type} at scale {scale}\")\n",
    "        print(f\"{'-'*70}\")\n",
    "\n",
    "        for physics_model in PHYSICS_MODELS:\n",
    "            print(f\"\\nüîß Generating physics parameters for model: {physics_model}\") \n",
    "            try:\n",
    "                # Create isolated runner instance\n",
    "                custom_config = ExperimentConfiguration(\n",
    "                    env_type=FRAMEWORK_CONFIG['main_env'],\n",
    "                    scenarios=test_scenarios,\n",
    "                    use_last_backup=last_backup,\n",
    "                    models=models,\n",
    "                    attack_intensity=attack_intensity,\n",
    "                    scale=scale,\n",
    "                    base_capacity=base_cap,\n",
    "                    overwrite=overwrite\n",
    "                )\n",
    "\n",
    "                alloc_runner = AllocatorRunner(\n",
    "                    allocator_type=allocator_type,\n",
    "                    physics_models=[physics_model],\n",
    "                    framework_config=FRAMEWORK_CONFIG,\n",
    "                    scales=[scale],\n",
    "                    runs=RUNS,\n",
    "                    models=models,\n",
    "                    test_scenarios=test_scenarios,\n",
    "                    config=custom_config\n",
    "                )\n",
    "\n",
    "                # Run with Paper 12 physics\n",
    "                alloc_runner.run(get_physics_params_func=get_physics_params)\n",
    "                print(f\"\\n{allocator_type} COMPLETED SUCCESSFULLY\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"\\n{allocator_type} FAILED: {e}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ALL ALLOCATORS COMPLETE!\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "PAPER #7 (QBGP) QUANTUM ROUTING EVALUATION - SINGLE ALLOCATOR TEST\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "üéØ PAPER 7 ALLOCATOR EVALUATION\n",
      "======================================================================\n",
      "Allocator:                  ThompsonSampling\n",
      "Physics Model:              paper7\n",
      "Attack Scenarios:           ['stochastic']\n",
      "Scales:                     [1, 1.5, 2]\n",
      "Runs per Scale:             [5]\n",
      "Total Frames:               50\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "RUNNING: ThompsonSampling on Paper 7 (QBGP)\n",
      "======================================================================\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Preparing: ThompsonSampling at scale 1\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üîß Generating physics parameters for model: paper7\n",
      "\n",
      "===================== GET LOCAL REGISTRY =====================\n",
      "‚Üí Skipping local cache (force=True or file missing)\n",
      "\n",
      "===================== BUILD LOCAL REGISTRY =====================\n",
      "\n",
      "================================================================================\n",
      "üîç SCANNING LOCAL FILES\n",
      "================================================================================\n",
      "Parameters: load_to_drive=False, force=False\n",
      "\n",
      "üìÇ Checking DRIVE mode: /content/drive/Shareddrives/ai_quantum_computing/quantum_data_lake\n",
      "   ‚ö†Ô∏è  Path does not exist, skipping\n",
      "\n",
      "üìÇ Checking LOCAL mode: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config\n",
      "   ‚úÖ Path exists, starting walk...\n",
      "   üö∂ Walking directory tree: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config\n",
      "\n",
      "   üìÅ Directory: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201\n",
      "      Relative: framework_state/day_20260201\n",
      "      Component: framework_state\n",
      "      Date: day_20260201\n",
      "      üìÑ Processing 2540 files in framework_state/day_20260201\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "      üìä framework_state/day_20260201: 2514/2540 files processed\n",
      "      üìä framework_state/day_20260201: 0/2540 files skipped\n",
      "      üìä framework_state/day_20260201: 26/2540 files conflicted\n",
      "\n",
      "   üìÅ Directory: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/model_state/day_20260201\n",
      "      Relative: model_state/day_20260201\n",
      "      Component: model_state\n",
      "      Date: day_20260201\n",
      "      üìÑ Processing 9120 files in model_state/day_20260201\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "      üìä model_state/day_20260201: 9120/9120 files processed\n",
      "      üìä model_state/day_20260201: 0/9120 files skipped\n",
      "      üìä model_state/day_20260201: 0/9120 files conflicted\n",
      "\n",
      "   üìä Processed 2 directories\n",
      "\n",
      "================================================================================\n",
      "üì¶ BUILDING FINAL REGISTRY\n",
      "================================================================================\n",
      "Components found: ['framework_state', 'model_state']\n",
      "  ‚Ä¢ framework_state: 2514 files\n",
      "  ‚Ä¢ model_state: 9120 files\n",
      "\n",
      "‚úÖ SCAN COMPLETE\n",
      "Modes scanned: 1\n",
      "Total files in registry: 11634\n",
      "================================================================================\n",
      "\n",
      "\t‚Üí Filesystem scan found 11634 files\n",
      "\n",
      "===================== GET DRIVE REGISTRY =====================\n",
      "===================== REGISTRY BUILD COMPLETE =====================\n",
      "\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "\tüì¶ LocalBackupManager Registry Saved Locally in LOCAL\n",
      "BUILDING REGISTRY WITH 0 EXPECTED COMPONENTS KEYS\n",
      "\n",
      "===================== GET LOCAL REGISTRY =====================\n",
      "‚Üí Skipping local cache (force=True or file missing)\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "\tüì¶ LocalBackupManager Registry Saved Locally in LOCAL\n",
      "\n",
      "======================================================================\n",
      "üéØ AllocatorRunner initialized: ThompsonSampling\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "üöÄ STARTING ALLOCATOR: ThompsonSampling\n",
      "======================================================================\n",
      "\n",
      "üìä Physics Model: paper7\n",
      "\n",
      "üìã Allocator Config:\n",
      "   Type: ThompsonSampling\n",
      "   Testbed: default\n",
      "   Paths: 15\n",
      "   Total Qubits: 75\n",
      "   Min per route: 2\n",
      "   Seed: 42\n",
      "   Priors: Œ±=1.0, Œ≤=1.0\n",
      "‚úÖ Allocator created: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "‚úì Allocator: ThompsonSamplingAllocator (15 paths)\n",
      "   Initial allocation: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üìä Paper7 Topology: Real AS (as20000101.txt)\n",
      "üìä Paper7 Paths: 15 paths from 5-shortest between 3 ISPs\n",
      "üìä Paper7 Contexts: 15 context vectors generated\n",
      "üìä Paper7 Rewards: Context-aware (mode=neg_hop)\n",
      "‚è±Ô∏è  get_physics_params_paper7() time: 2.3 ms\n",
      "\n",
      "======================================================================\n",
      "RUN 1 | Scale: 1 | Exp: 5\n",
      "======================================================================\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "\n",
      "\tüîÑ Resume: MultiRunEvaluator\n",
      "\n",
      "=====================================================\n",
      "üîç GENERATING EXPECTED KEYS FROM EVALUATOR\n",
      "=====================================================\n",
      "  ‚Ä¢ Evaluator filename: MultiRunEvaluator_50-ThompsonSampling_All_All-50_50_5_S1T_paper7.pkl\n",
      "\n",
      "üß© PARSED COMPONENTS\n",
      "  ‚Ä¢ cap_id:        50\n",
      "  ‚Ä¢ allocator_id:  ThompsonSampling\n",
      "  ‚Ä¢ env_id:        All\n",
      "  ‚Ä¢ attack_id:     All\n",
      "  ‚Ä¢ base_frames:   50\n",
      "  ‚Ä¢ frame_step:    50\n",
      "  ‚Ä¢ runs_id:       5\n",
      "\n",
      "=====================================================\n",
      "üß™ GENERATING KEYS FOR EACH RUN\n",
      "=====================================================\n",
      "\n",
      "--- Run 1/5 -----------------------\n",
      "\n",
      "=====================================================\n",
      "üì¶ FINAL EXPECTED KEYS\n",
      "=====================================================\n",
      "  ‚Ä¢ Runner keys: 11\n",
      "\n",
      "  ‚Ä¢ Model keys: 50\n",
      "\n",
      "--- Run 2/5 -----------------------\n",
      "\n",
      "=====================================================\n",
      "üì¶ FINAL EXPECTED KEYS\n",
      "=====================================================\n",
      "  ‚Ä¢ Runner keys: 21\n",
      "\n",
      "  ‚Ä¢ Model keys: 100\n",
      "\n",
      "--- Run 3/5 -----------------------\n",
      "\n",
      "=====================================================\n",
      "üì¶ FINAL EXPECTED KEYS\n",
      "=====================================================\n",
      "  ‚Ä¢ Runner keys: 31\n",
      "\n",
      "  ‚Ä¢ Model keys: 150\n",
      "\n",
      "--- Run 4/5 -----------------------\n",
      "\n",
      "=====================================================\n",
      "üì¶ FINAL EXPECTED KEYS\n",
      "=====================================================\n",
      "  ‚Ä¢ Runner keys: 41\n",
      "\n",
      "  ‚Ä¢ Model keys: 200\n",
      "\n",
      "--- Run 5/5 -----------------------\n",
      "\n",
      "=====================================================\n",
      "üì¶ FINAL EXPECTED KEYS\n",
      "=====================================================\n",
      "  ‚Ä¢ Runner keys: 51\n",
      "\n",
      "  ‚Ä¢ Model keys: 250\n",
      "\n",
      "EXPECTED KEY GENERATION COMPLETE\n",
      "\n",
      "RESTORING FROM DRIVE 1\n",
      "RESTORING FROM DRIVE 2\n",
      "\t‚ö†Ô∏è Registry exists ‚Üí aborting restore\n",
      "\t‚òÅÔ∏è Attempting Drive download: framework_state/MultiRunEvaluator_50-ThompsonSampling_All_All-50_50_5_S1T_paper7.pkl\n",
      "\t‚ùå Not found anywhere: framework_state/MultiRunEvaluator_50-ThompsonSampling_All_All-50_50_5_S1T_paper7.pkl\n",
      "\t‚ùå Not found in registry or fallback locations\n",
      "\t‚òÅÔ∏è Attempting Drive download: framework_state/MultiRunEvaluator_50-ThompsonSampling_All_All-50_50_5_S1T_paper7.pkl\n",
      "\t‚ùå Not found anywhere: framework_state/MultiRunEvaluator_50-ThompsonSampling_All_All-50_50_5_S1T_paper7.pkl\n",
      "\t‚ùå Not found in registry or fallback locations\n",
      "[Resume] exact failed ‚Üí Looking for supersets\n",
      "[Resume-Supersets] target_runs=5, backups=dict_keys([])\n",
      "[Resume-Supersets] Trying horizons in size order (largest first): []\n",
      "[Resume-Supersets] ‚ùå No valid supersets found for resume\n",
      "No state found for MultiRunEvaluator, disabling resume for Experiment Runners\n",
      "Multi-Run Evaluator Initialized\n",
      "Environment Type: None\n",
      "Frame Range: 50 -> 250 (step: 50)\n",
      "quantum_exps-ThompsonSampling(paper7)_alloc-all_envs-5_attacks-50_50-5_runs-S1T\n",
      "[Logging Redirect Initialized]\n",
      "Log File: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/quantum_logs/quantum_exps-ThompsonSampling(paper7)_alloc-all_envs-5_attacks-50_50-5_runs-S1T_20260201_log.txt\n",
      "‚öô Running evaluation...\n",
      "======================================================================\n",
      "SCENARIOS MODEL EVALUATION\n",
      "======================================================================\n",
      "Testing algorithm performance against:\n",
      "\t‚Ä¢ Stochastic:  \tNatural quantum decoherence and network failures\n",
      "\t‚Ä¢ Baseline:    \tOptimal conditions for validation\n",
      "======================================================================\n",
      "Models to Test:             \tOracle, GNeuralUCB, EXPNeuralUCB, CPursuitNeuralUCB, iCPursuitNeuralUCB\n",
      "Experiments per Scenario:   \t5\n",
      "======================================================================\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: BASELINE (OPTIMAL CONDITIONS)\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: NONE\n",
      "Category: Baseline (No Attacks)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 50 frames  <>  SCALED-CAPACITY: 50 frames (CAPACITY:50 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=0 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for NONE Exp 1: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 1: Env:Baseline (None), Attack:No, Rate:0.0, Frames:50, QubitAlloc=ThompsonSampling, SC:50 (Scale=1 x Cap=50), Seed: 15373\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 15\n",
      "\t   First reward: [9.0], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 1: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 GNEURALUCB          : Reward=0396.00, Efficiency=088.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=50, Threshold=0.582]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 1: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=0396.00, Efficiency=088.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=50, Threshold=0.628]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 1: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=0396.00, Efficiency=088.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=50, Threshold=0.634]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 1: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=0450.00, Efficiency=100.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=50, Threshold=0.712]\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 1: Env:Baseline (None), Attack:No, Rate:0.0, Frames:50, QubitAlloc=ThompsonSampling, SC:50 (Scale=1 x Cap=50), Seed: 15373\n",
      "\t-->üèÜ EXP1 Winner:iCPursuitNeuralUCB  (Gap:000.0%) [Env:Baseline (None), Attack:No X Rate:0.0, Frames:50, SCapacity=50, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 1 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 100 frames  <>  SCALED-CAPACITY: 100 frames (CAPACITY:100 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=1 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for NONE Exp 2: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 2: Env:Baseline (None), Attack:No, Rate:0.0, Frames:100, QubitAlloc=ThompsonSampling, SC:100 (Scale=1 x Cap=100), Seed: 12644\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 15\n",
      "\t   First reward: [9.0], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 2: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 GNEURALUCB          : Reward=0794.00, Efficiency=088.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=100, Threshold=0.582]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 2: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=0830.00, Efficiency=092.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=100, Threshold=0.628]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 2: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=0794.00, Efficiency=088.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=100, Threshold=0.634]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 2: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=0900.00, Efficiency=100.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=100, Threshold=0.712]\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 2: Env:Baseline (None), Attack:No, Rate:0.0, Frames:100, QubitAlloc=ThompsonSampling, SC:100 (Scale=1 x Cap=100), Seed: 12644\n",
      "\t-->üèÜ EXP2 Winner:iCPursuitNeuralUCB  (Gap:000.0%) [Env:Baseline (None), Attack:No X Rate:0.0, Frames:100, SCapacity=100, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 2 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 150 frames  <>  SCALED-CAPACITY: 150 frames (CAPACITY:150 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=2 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for NONE Exp 3: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 3: Env:Baseline (None), Attack:No, Rate:0.0, Frames:150, QubitAlloc=ThompsonSampling, SC:150 (Scale=1 x Cap=150), Seed: 20257\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 15\n",
      "\t   First reward: [9.0], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 3: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 GNEURALUCB          : Reward=1190.00, Efficiency=088.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=150, Threshold=0.582]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 3: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=1229.00, Efficiency=091.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=150, Threshold=0.628]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 3: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=1190.00, Efficiency=088.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=150, Threshold=0.634]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 3: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=1350.00, Efficiency=100.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=150, Threshold=0.712]\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 3: Env:Baseline (None), Attack:No, Rate:0.0, Frames:150, QubitAlloc=ThompsonSampling, SC:150 (Scale=1 x Cap=150), Seed: 20257\n",
      "\t-->üèÜ EXP3 Winner:iCPursuitNeuralUCB  (Gap:000.0%) [Env:Baseline (None), Attack:No X Rate:0.0, Frames:150, SCapacity=150, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 3 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 200 frames  <>  SCALED-CAPACITY: 200 frames (CAPACITY:200 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=3 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for NONE Exp 4: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 4: Env:Baseline (None), Attack:No, Rate:0.0, Frames:200, QubitAlloc=ThompsonSampling, SC:200 (Scale=1 x Cap=200), Seed: 20031\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 15\n",
      "\t   First reward: [9.0], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 4: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 GNEURALUCB          : Reward=1586.00, Efficiency=088.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=200, Threshold=0.582]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 4: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=1567.00, Efficiency=087.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=200, Threshold=0.628]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 4: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=1586.00, Efficiency=088.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=200, Threshold=0.634]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 4: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=1800.00, Efficiency=100.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=200, Threshold=0.712]\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 4: Env:Baseline (None), Attack:No, Rate:0.0, Frames:200, QubitAlloc=ThompsonSampling, SC:200 (Scale=1 x Cap=200), Seed: 20031\n",
      "\t-->üèÜ EXP4 Winner:iCPursuitNeuralUCB  (Gap:000.0%) [Env:Baseline (None), Attack:No X Rate:0.0, Frames:200, SCapacity=200, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 4 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 250 frames  <>  SCALED-CAPACITY: 250 frames (CAPACITY:250 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=4 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for NONE Exp 5: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 5: Env:Baseline (None), Attack:No, Rate:0.0, Frames:250, QubitAlloc=ThompsonSampling, SC:250 (Scale=1 x Cap=250), Seed: 17303\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 15\n",
      "\t   First reward: [9.0], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 5: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 GNEURALUCB          : Reward=1984.00, Efficiency=088.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=250, Threshold=0.582]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 5: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=1879.00, Efficiency=083.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=250, Threshold=0.628]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 5: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=1984.00, Efficiency=088.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=250, Threshold=0.634]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 5: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=2250.00, Efficiency=100.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=250, Threshold=0.712]\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 5: Env:Baseline (None), Attack:No, Rate:0.0, Frames:250, QubitAlloc=ThompsonSampling, SC:250 (Scale=1 x Cap=250), Seed: 17303\n",
      "\t-->üèÜ EXP5 Winner:iCPursuitNeuralUCB  (Gap:000.0%) [Env:Baseline (None), Attack:No X Rate:0.0, Frames:250, SCapacity=250, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 5 completed successfully.\n",
      "Total experiment time: 937.3s\n",
      "Experiments completed for none\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: STOCHASTIC RANDOM FAILURES\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: STOCHASTIC\n",
      "Category: Stochastic (Natural Random Failures)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 50 frames  <>  SCALED-CAPACITY: 50 frames (CAPACITY:50 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=0 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 1: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 1: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:50, QubitAlloc=ThompsonSampling, SC:50 (Scale=1 x Cap=50), Seed: 15729\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 15\n",
      "\t   First reward: [9.0], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 1: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 GNEURALUCB          : Reward=0381.00, Efficiency=084.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=50, Threshold=0.582]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 1: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=0389.00, Efficiency=086.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=50, Threshold=0.628]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 1: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=0381.00, Efficiency=084.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=50, Threshold=0.634]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 1: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=0423.00, Efficiency=094.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=50, Threshold=0.712]\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 1: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:50, QubitAlloc=ThompsonSampling, SC:50 (Scale=1 x Cap=50), Seed: 15729\n",
      "\t-->üèÜ EXP1 Winner:iCPursuitNeuralUCB  (Gap:005.8%) [Env:Stochastic, Attack:Random X Rate:0.0625, Frames:50, SCapacity=50, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 1 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 100 frames  <>  SCALED-CAPACITY: 100 frames (CAPACITY:100 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=1 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 2: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 2: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:100, QubitAlloc=ThompsonSampling, SC:100 (Scale=1 x Cap=100), Seed: 19894\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 15\n",
      "\t   First reward: [9.0], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 2: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 GNEURALUCB          : Reward=0726.00, Efficiency=080.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=100, Threshold=0.582]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 2: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=0692.00, Efficiency=076.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=100, Threshold=0.628]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 2: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=0726.00, Efficiency=080.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=100, Threshold=0.634]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 2: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=0828.00, Efficiency=092.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=100, Threshold=0.712]\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 2: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:100, QubitAlloc=ThompsonSampling, SC:100 (Scale=1 x Cap=100), Seed: 19894\n",
      "\t-->üèÜ EXP2 Winner:iCPursuitNeuralUCB  (Gap:008.0%) [Env:Stochastic, Attack:Random X Rate:0.0625, Frames:100, SCapacity=100, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 2 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 150 frames  <>  SCALED-CAPACITY: 150 frames (CAPACITY:150 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=2 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 3: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 3: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:150, QubitAlloc=ThompsonSampling, SC:150 (Scale=1 x Cap=150), Seed: 16736\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 15\n",
      "\t   First reward: [9.0], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 3: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 GNEURALUCB          : Reward=1142.00, Efficiency=084.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=150, Threshold=0.582]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 3: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=1156.00, Efficiency=085.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=150, Threshold=0.628]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 3: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=1142.00, Efficiency=084.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=150, Threshold=0.634]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 3: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=1260.00, Efficiency=093.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=150, Threshold=0.712]\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 3: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:150, QubitAlloc=ThompsonSampling, SC:150 (Scale=1 x Cap=150), Seed: 16736\n",
      "\t-->üèÜ EXP3 Winner:iCPursuitNeuralUCB  (Gap:006.7%) [Env:Stochastic, Attack:Random X Rate:0.0625, Frames:150, SCapacity=150, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 3 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 200 frames  <>  SCALED-CAPACITY: 200 frames (CAPACITY:200 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=3 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 4: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 4: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:200, QubitAlloc=ThompsonSampling, SC:200 (Scale=1 x Cap=200), Seed: 12981\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 15\n",
      "\t   First reward: [9.0], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 4: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 GNEURALUCB          : Reward=1488.00, Efficiency=082.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=200, Threshold=0.582]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 4: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=1524.00, Efficiency=084.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=200, Threshold=0.628]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 4: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=1488.00, Efficiency=082.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=200, Threshold=0.634]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 4: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=1674.00, Efficiency=093.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=200, Threshold=0.712]\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 4: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:200, QubitAlloc=ThompsonSampling, SC:200 (Scale=1 x Cap=200), Seed: 12981\n",
      "\t-->üèÜ EXP4 Winner:iCPursuitNeuralUCB  (Gap:006.8%) [Env:Stochastic, Attack:Random X Rate:0.0625, Frames:200, SCapacity=200, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 4 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 250 frames  <>  SCALED-CAPACITY: 250 frames (CAPACITY:250 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=4 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 5: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 5: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:250, QubitAlloc=ThompsonSampling, SC:250 (Scale=1 x Cap=250), Seed: 17091\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 15\n",
      "\t   First reward: [9.0], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 5: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 GNEURALUCB          : Reward=1843.00, Efficiency=081.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=250, Threshold=0.582]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 5: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=1915.00, Efficiency=085.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=250, Threshold=0.628]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 5: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=1843.00, Efficiency=081.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=250, Threshold=0.634]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 5: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=2115.00, Efficiency=094.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=250, Threshold=0.712]\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 5: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:250, QubitAlloc=ThompsonSampling, SC:250 (Scale=1 x Cap=250), Seed: 17091\n",
      "\t-->üèÜ EXP5 Winner:iCPursuitNeuralUCB  (Gap:006.0%) [Env:Stochastic, Attack:Random X Rate:0.0625, Frames:250, SCapacity=250, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 5 completed successfully.\n",
      "Total experiment time: 870.5s\n",
      "Experiments completed for stochastic\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: MARKOV ADVERSARIAL ATTACK\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: MARKOV\n",
      "Category: Structured (Markov Chain Based)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 50 frames  <>  SCALED-CAPACITY: 50 frames (CAPACITY:50 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=0 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for MARKOV Exp 1: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 1: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:50, QubitAlloc=ThompsonSampling, SC:50 (Scale=1 x Cap=50), Seed: 14132\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 15\n",
      "\t   First reward: [9.0], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 1: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 GNEURALUCB          : Reward=0194.00, Efficiency=044.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=50, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 1: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=0173.00, Efficiency=039.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=50, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 1: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=0194.00, Efficiency=044.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=50, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 1: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=0261.00, Efficiency=059.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=50, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 1: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:50, QubitAlloc=ThompsonSampling, SC:50 (Scale=1 x Cap=50), Seed: 14132\n",
      "\t-->üèÜ EXP1 Winner:iCPursuitNeuralUCB  (Gap:040.7%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:50, SCapacity=50, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 1 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 100 frames  <>  SCALED-CAPACITY: 100 frames (CAPACITY:100 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=1 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for MARKOV Exp 2: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 2: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:100, QubitAlloc=ThompsonSampling, SC:100 (Scale=1 x Cap=100), Seed: 22231\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 15\n",
      "\t   First reward: [9.0], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 2: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 GNEURALUCB          : Reward=0402.00, Efficiency=045.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=100, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 2: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=0354.00, Efficiency=040.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=100, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 2: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=0402.00, Efficiency=045.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=100, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 2: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=0441.00, Efficiency=050.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=100, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 2: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:100, QubitAlloc=ThompsonSampling, SC:100 (Scale=1 x Cap=100), Seed: 22231\n",
      "\t-->üèÜ EXP2 Winner:iCPursuitNeuralUCB  (Gap:049.6%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:100, SCapacity=100, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 2 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 150 frames  <>  SCALED-CAPACITY: 150 frames (CAPACITY:150 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=2 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for MARKOV Exp 3: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 3: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:150, QubitAlloc=ThompsonSampling, SC:150 (Scale=1 x Cap=150), Seed: 20747\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 15\n",
      "\t   First reward: [9.0], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 3: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 GNEURALUCB          : Reward=0640.00, Efficiency=048.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=150, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 3: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=0479.00, Efficiency=036.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=150, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 3: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=0640.00, Efficiency=048.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=150, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 3: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=0747.00, Efficiency=056.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=150, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 3: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:150, QubitAlloc=ThompsonSampling, SC:150 (Scale=1 x Cap=150), Seed: 20747\n",
      "\t-->üèÜ EXP3 Winner:iCPursuitNeuralUCB  (Gap:043.1%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:150, SCapacity=150, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 3 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 200 frames  <>  SCALED-CAPACITY: 200 frames (CAPACITY:200 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=3 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for MARKOV Exp 4: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 4: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:200, QubitAlloc=ThompsonSampling, SC:200 (Scale=1 x Cap=200), Seed: 15410\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 15\n",
      "\t   First reward: [9.0], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 4: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 GNEURALUCB          : Reward=0931.00, Efficiency=053.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=200, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 4: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=0814.00, Efficiency=046.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=200, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 4: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=0931.00, Efficiency=053.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=200, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 4: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=0963.00, Efficiency=054.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=200, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 4: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:200, QubitAlloc=ThompsonSampling, SC:200 (Scale=1 x Cap=200), Seed: 15410\n",
      "\t-->üèÜ EXP4 Winner:iCPursuitNeuralUCB  (Gap:045.1%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:200, SCapacity=200, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 4 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 250 frames  <>  SCALED-CAPACITY: 250 frames (CAPACITY:250 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=4 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for MARKOV Exp 5: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 5: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:250, QubitAlloc=ThompsonSampling, SC:250 (Scale=1 x Cap=250), Seed: 22674\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 15\n",
      "\t   First reward: [9.0], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 5: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 GNEURALUCB          : Reward=1092.00, Efficiency=049.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=250, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 5: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=0971.00, Efficiency=044.2% [Retries=3, Failed=0, < Threshold=3, SCapacity=250, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 5: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=1092.00, Efficiency=049.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=250, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 5: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=0898.00, Efficiency=040.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=250, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 5: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:250, QubitAlloc=ThompsonSampling, SC:250 (Scale=1 x Cap=250), Seed: 22674\n",
      "\t-->üèÜ EXP5 Winner:GNeuralUCB          (Gap:050.3%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:250, SCapacity=250, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 5 completed successfully.\n",
      "Total experiment time: 831.2s\n",
      "Experiments completed for markov\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: ADAPTIVE ADVERSARIAL ATTACK\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: ADAPTIVE\n",
      "Category: Adaptive (Reactive Strategic)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 50 frames  <>  SCALED-CAPACITY: 50 frames (CAPACITY:50 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=0 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 1: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 1: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:50, QubitAlloc=ThompsonSampling, SC:50 (Scale=1 x Cap=50), Seed: 21427\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 15\n",
      "\t   First reward: [9.0], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 1: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 GNEURALUCB          : Reward=0335.00, Efficiency=074.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=50, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 1: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=0262.00, Efficiency=058.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=50, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 1: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=0335.00, Efficiency=074.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=50, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 1: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=0288.00, Efficiency=064.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=50, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 1: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:50, QubitAlloc=ThompsonSampling, SC:50 (Scale=1 x Cap=50), Seed: 21427\n",
      "\t-->üèÜ EXP1 Winner:GNeuralUCB          (Gap:025.2%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:50, SCapacity=50, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 1 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 100 frames  <>  SCALED-CAPACITY: 100 frames (CAPACITY:100 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=1 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 2: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 2: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:100, QubitAlloc=ThompsonSampling, SC:100 (Scale=1 x Cap=100), Seed: 13200\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 15\n",
      "\t   First reward: [9.0], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 2: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 GNEURALUCB          : Reward=0569.00, Efficiency=063.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=100, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 2: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=0560.00, Efficiency=062.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=100, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 2: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=0569.00, Efficiency=063.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=100, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 2: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=0666.00, Efficiency=074.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=100, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 2: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:100, QubitAlloc=ThompsonSampling, SC:100 (Scale=1 x Cap=100), Seed: 13200\n",
      "\t-->üèÜ EXP2 Winner:iCPursuitNeuralUCB  (Gap:025.3%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:100, SCapacity=100, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 2 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 150 frames  <>  SCALED-CAPACITY: 150 frames (CAPACITY:150 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=2 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 3: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 3: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:150, QubitAlloc=ThompsonSampling, SC:150 (Scale=1 x Cap=150), Seed: 18005\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 15\n",
      "\t   First reward: [9.0], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 3: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 GNEURALUCB          : Reward=0837.00, Efficiency=062.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=150, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 3: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=0900.00, Efficiency=067.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=150, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 3: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=0837.00, Efficiency=062.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=150, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 3: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=1044.00, Efficiency=077.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=150, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 3: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:150, QubitAlloc=ThompsonSampling, SC:150 (Scale=1 x Cap=150), Seed: 18005\n",
      "\t-->üèÜ EXP3 Winner:iCPursuitNeuralUCB  (Gap:022.3%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:150, SCapacity=150, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 3 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 200 frames  <>  SCALED-CAPACITY: 200 frames (CAPACITY:200 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=3 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 4: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 4: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:200, QubitAlloc=ThompsonSampling, SC:200 (Scale=1 x Cap=200), Seed: 12955\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 15\n",
      "\t   First reward: [9.0], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 4: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 GNEURALUCB          : Reward=1159.00, Efficiency=064.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=200, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 4: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=1199.00, Efficiency=066.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=200, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 4: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=1159.00, Efficiency=064.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=200, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 4: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=1431.00, Efficiency=079.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=200, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 4: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:200, QubitAlloc=ThompsonSampling, SC:200 (Scale=1 x Cap=200), Seed: 12955\n",
      "\t-->üèÜ EXP4 Winner:iCPursuitNeuralUCB  (Gap:020.1%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:200, SCapacity=200, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 4 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 250 frames  <>  SCALED-CAPACITY: 250 frames (CAPACITY:250 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=4 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 5: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 5: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:250, QubitAlloc=ThompsonSampling, SC:250 (Scale=1 x Cap=250), Seed: 14950\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 15\n",
      "\t   First reward: [9.0], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 5: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 GNEURALUCB          : Reward=1564.00, Efficiency=069.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=250, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 5: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=1566.00, Efficiency=069.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=250, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 5: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=1564.00, Efficiency=069.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=250, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 5: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=1755.00, Efficiency=078.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=250, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 5: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:250, QubitAlloc=ThompsonSampling, SC:250 (Scale=1 x Cap=250), Seed: 14950\n",
      "\t-->üèÜ EXP5 Winner:iCPursuitNeuralUCB  (Gap:021.7%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:250, SCapacity=250, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 5 completed successfully.\n",
      "Total experiment time: 823.5s\n",
      "Experiments completed for adaptive\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: ONLINE ADAPTIVE ATTACK\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: ONLINEADAPTIVE\n",
      "Category: Online Adaptive (Real-time Strategic)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 50 frames  <>  SCALED-CAPACITY: 50 frames (CAPACITY:50 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=0 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 1: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:50, QubitAlloc=ThompsonSampling, SC:50 (Scale=1 x Cap=50), Seed: 14732\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 15\n",
      "\t   First reward: [9.0], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 GNEURALUCB          : Reward=0303.00, Efficiency=067.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=50, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=0340.00, Efficiency=076.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=50, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=0303.00, Efficiency=067.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=50, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=0360.00, Efficiency=080.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=50, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:50, QubitAlloc=ThompsonSampling, SC:50 (Scale=1 x Cap=50), Seed: 14732\n",
      "\t-->üèÜ EXP1 Winner:iCPursuitNeuralUCB  (Gap:019.3%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:50, SCapacity=50, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 1 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 100 frames  <>  SCALED-CAPACITY: 100 frames (CAPACITY:100 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=1 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 2: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:100, QubitAlloc=ThompsonSampling, SC:100 (Scale=1 x Cap=100), Seed: 14647\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 15\n",
      "\t   First reward: [9.0], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 GNEURALUCB          : Reward=0625.00, Efficiency=070.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=100, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=0573.00, Efficiency=064.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=100, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=0625.00, Efficiency=070.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=100, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=0585.00, Efficiency=065.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=100, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:100, QubitAlloc=ThompsonSampling, SC:100 (Scale=1 x Cap=100), Seed: 14647\n",
      "\t-->üèÜ EXP2 Winner:GNeuralUCB          (Gap:029.9%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:100, SCapacity=100, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 2 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 150 frames  <>  SCALED-CAPACITY: 150 frames (CAPACITY:150 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=2 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 3: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:150, QubitAlloc=ThompsonSampling, SC:150 (Scale=1 x Cap=150), Seed: 21138\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 15\n",
      "\t   First reward: [9.0], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 GNEURALUCB          : Reward=0892.00, Efficiency=066.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=150, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=0884.00, Efficiency=065.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=150, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=0892.00, Efficiency=066.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=150, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=1071.00, Efficiency=079.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=150, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:150, QubitAlloc=ThompsonSampling, SC:150 (Scale=1 x Cap=150), Seed: 21138\n",
      "\t-->üèÜ EXP3 Winner:iCPursuitNeuralUCB  (Gap:020.2%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:150, SCapacity=150, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 3 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 200 frames  <>  SCALED-CAPACITY: 200 frames (CAPACITY:200 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=3 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 4: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:200, QubitAlloc=ThompsonSampling, SC:200 (Scale=1 x Cap=200), Seed: 16677\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 15\n",
      "\t   First reward: [9.0], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 GNEURALUCB          : Reward=1209.00, Efficiency=067.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=200, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=1203.00, Efficiency=067.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=200, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=1209.00, Efficiency=067.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=200, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=1359.00, Efficiency=076.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=200, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:200, QubitAlloc=ThompsonSampling, SC:200 (Scale=1 x Cap=200), Seed: 16677\n",
      "\t-->üèÜ EXP4 Winner:iCPursuitNeuralUCB  (Gap:023.9%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:200, SCapacity=200, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 4 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 250 frames  <>  SCALED-CAPACITY: 250 frames (CAPACITY:250 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=4 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 5: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:250, QubitAlloc=ThompsonSampling, SC:250 (Scale=1 x Cap=250), Seed: 22447\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 15\n",
      "\t   First reward: [9.0], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 GNEURALUCB          : Reward=1413.00, Efficiency=063.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=250, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=1509.00, Efficiency=067.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=250, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=1413.00, Efficiency=063.2% [Retries=3, Failed=0, < Threshold=3, SCapacity=250, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=1737.00, Efficiency=077.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=250, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:250, QubitAlloc=ThompsonSampling, SC:250 (Scale=1 x Cap=250), Seed: 22447\n",
      "\t-->üèÜ EXP5 Winner:iCPursuitNeuralUCB  (Gap:022.2%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:250, SCapacity=250, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 5 completed successfully.\n",
      "Total experiment time: 804.7s\n",
      "Experiments completed for onlineadaptive\n",
      "‚úì Scenario 'none' evaluation completed.\n",
      "‚úì Scenario 'stochastic' evaluation completed.\n",
      "‚úì Scenario 'markov' evaluation completed.\n",
      "‚úì Scenario 'adaptive' evaluation completed.\n",
      "‚úì Scenario 'onlineadaptive' evaluation completed.\n",
      "\n",
      "======================================================================\n",
      "COMPREHENSIVE SCENARIO PERFORMANCE ANALYSIS\n",
      "======================================================================\n",
      "SCENARIO: NONE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 1350.00\n",
      "\t‚Ä¢ Winner Avg Gap: 0000.00%\n",
      "\t‚Ä¢ Winner Avg Reward: 1350.00\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0100.00%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 5 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: NONE\n",
      "======================================================================\n",
      "SCENARIO: \tBASELINE (OPTIMAL CONDITIONS)\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 5/5 experiments)\n",
      "\tWinner Avg Gap: \t000.0%\n",
      "\tWinner Avg Efficiency: \t100.0%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t100.0% Efficiency \t(Won 5/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t088.4% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t088.1% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t088.1% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: STOCHASTIC\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 1349.20\n",
      "\t‚Ä¢ Winner Avg Gap: 0006.66%\n",
      "\t‚Ä¢ Winner Avg Reward: 1260.00\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0093.34%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 5 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: STOCHASTIC\n",
      "======================================================================\n",
      "SCENARIO: \tSTOCHASTIC RANDOM FAILURES\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 5/5 experiments)\n",
      "\tWinner Avg Gap: \t006.7%\n",
      "\tWinner Avg Efficiency: \t093.3%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t093.3% Efficiency \t(Won 5/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t083.8% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t083.0% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t083.0% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: MARKOV\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 1315.20\n",
      "\t‚Ä¢ Winner Avg Gap: 0047.50%\n",
      "\t‚Ä¢ Winner Avg Reward: 0662.00\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0052.50%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 1 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 4 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: MARKOV\n",
      "======================================================================\n",
      "SCENARIO: \tMARKOV ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 4/5 experiments)\n",
      "\tWinner Avg Gap: \t047.5%\n",
      "\tWinner Avg Efficiency: \t052.5%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t052.5% Efficiency \t(Won 4/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t048.3% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t048.3% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t041.4% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 1343.40\n",
      "\t‚Ä¢ Winner Avg Gap: 0025.04%\n",
      "\t‚Ä¢ Winner Avg Reward: 1036.80\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0074.96%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 1 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 4 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tADAPTIVE ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 4/5 experiments)\n",
      "\tWinner Avg Gap: \t025.0%\n",
      "\tWinner Avg Efficiency: \t075.0%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t075.0% Efficiency \t(Won 4/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t067.1% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t067.1% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t065.0% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ONLINEADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 1339.80\n",
      "\t‚Ä¢ Winner Avg Gap: 0023.99%\n",
      "\t‚Ä¢ Winner Avg Reward: 1022.40\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0076.01%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 1 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 4 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ONLINEADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tONLINE ADAPTIVE ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 4/5 experiments)\n",
      "\tWinner Avg Gap: \t024.0%\n",
      "\tWinner Avg Efficiency: \t076.0%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t076.0% Efficiency \t(Won 4/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t068.3% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t067.1% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t067.1% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "KEY INSIGHTS:\n",
      "Best Performing Model Analysis (iCPursuitNeuralUCB):\n",
      "\t‚Ä¢ Stochastic Performance:    \t1260.000\n",
      "\t‚Ä¢ Baseline Performance:      \t1350.000\n",
      "\t‚Ä¢ Performance Retention:     \t093.3%\n",
      "\tGOOD:               \tAcceptable performance under stochastic conditions\n",
      "Statistical Analysis:\n",
      "\t‚Ä¢ Total models evaluated:     \t5\n",
      "\t‚Ä¢ Experiments per environment:\t5\n",
      "\t‚Ä¢ Quantum network simulation: \tComprehensive stochastic modeling\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "COMPREHENSIVE SCENARIO PERFORMANCE ANALYSIS\n",
      "======================================================================\n",
      "SCENARIO: NONE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 1350.00\n",
      "\t‚Ä¢ Winner Avg Gap: 0000.00%\n",
      "\t‚Ä¢ Winner Avg Reward: 1350.00\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0100.00%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 5 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: NONE\n",
      "======================================================================\n",
      "SCENARIO: \tBASELINE (OPTIMAL CONDITIONS)\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 5/5 experiments)\n",
      "\tWinner Avg Gap: \t000.0%\n",
      "\tWinner Avg Efficiency: \t100.0%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t100.0% Efficiency \t(Won 5/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t088.4% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t088.1% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t088.1% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: STOCHASTIC\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 1349.20\n",
      "\t‚Ä¢ Winner Avg Gap: 0006.66%\n",
      "\t‚Ä¢ Winner Avg Reward: 1260.00\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0093.34%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 5 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: STOCHASTIC\n",
      "======================================================================\n",
      "SCENARIO: \tSTOCHASTIC RANDOM FAILURES\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 5/5 experiments)\n",
      "\tWinner Avg Gap: \t006.7%\n",
      "\tWinner Avg Efficiency: \t093.3%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t093.3% Efficiency \t(Won 5/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t083.8% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t083.0% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t083.0% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: MARKOV\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 1315.20\n",
      "\t‚Ä¢ Winner Avg Gap: 0047.50%\n",
      "\t‚Ä¢ Winner Avg Reward: 0662.00\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0052.50%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 1 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 4 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: MARKOV\n",
      "======================================================================\n",
      "SCENARIO: \tMARKOV ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 4/5 experiments)\n",
      "\tWinner Avg Gap: \t047.5%\n",
      "\tWinner Avg Efficiency: \t052.5%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t052.5% Efficiency \t(Won 4/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t048.3% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t048.3% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t041.4% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 1343.40\n",
      "\t‚Ä¢ Winner Avg Gap: 0025.04%\n",
      "\t‚Ä¢ Winner Avg Reward: 1036.80\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0074.96%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 1 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 4 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tADAPTIVE ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 4/5 experiments)\n",
      "\tWinner Avg Gap: \t025.0%\n",
      "\tWinner Avg Efficiency: \t075.0%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t075.0% Efficiency \t(Won 4/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t067.1% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t067.1% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t065.0% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ONLINEADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 1339.80\n",
      "\t‚Ä¢ Winner Avg Gap: 0023.99%\n",
      "\t‚Ä¢ Winner Avg Reward: 1022.40\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0076.01%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 1 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 4 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ONLINEADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tONLINE ADAPTIVE ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 4/5 experiments)\n",
      "\tWinner Avg Gap: \t024.0%\n",
      "\tWinner Avg Efficiency: \t076.0%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t076.0% Efficiency \t(Won 4/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t068.3% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t067.1% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t067.1% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "‚úÖ Evaluation completed!\n",
      "[Logging Redirect Stopped]\n",
      "\n",
      "üßπ Final cleanup for ThompsonSampling\n",
      "\n",
      "======================================================================\n",
      "‚úÖ COMPLETED: ThompsonSampling\n",
      "======================================================================\n",
      "\n",
      "ThompsonSampling COMPLETED SUCCESSFULLY\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Preparing: ThompsonSampling at scale 1.5\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üîß Generating physics parameters for model: paper7\n",
      "\n",
      "===================== GET LOCAL REGISTRY =====================\n",
      "‚Üí Skipping local cache (force=True or file missing)\n",
      "\n",
      "===================== BUILD LOCAL REGISTRY =====================\n",
      "\n",
      "================================================================================\n",
      "üîç SCANNING LOCAL FILES\n",
      "================================================================================\n",
      "Parameters: load_to_drive=False, force=False\n",
      "\n",
      "üìÇ Checking DRIVE mode: /content/drive/Shareddrives/ai_quantum_computing/quantum_data_lake\n",
      "   ‚ö†Ô∏è  Path does not exist, skipping\n",
      "\n",
      "üìÇ Checking LOCAL mode: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config\n",
      "   ‚úÖ Path exists, starting walk...\n",
      "   üö∂ Walking directory tree: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config\n",
      "\n",
      "   üìÅ Directory: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201\n",
      "      Relative: framework_state/day_20260201\n",
      "      Component: framework_state\n",
      "      Date: day_20260201\n",
      "      üìÑ Processing 2567 files in framework_state/day_20260201\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "      üìä framework_state/day_20260201: 2541/2567 files processed\n",
      "      üìä framework_state/day_20260201: 0/2567 files skipped\n",
      "      üìä framework_state/day_20260201: 26/2567 files conflicted\n",
      "\n",
      "   üìÅ Directory: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/model_state/day_20260201\n",
      "      Relative: model_state/day_20260201\n",
      "      Component: model_state\n",
      "      Date: day_20260201\n",
      "      üìÑ Processing 9282 files in model_state/day_20260201\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "      üìä model_state/day_20260201: 9282/9282 files processed\n",
      "      üìä model_state/day_20260201: 0/9282 files skipped\n",
      "      üìä model_state/day_20260201: 0/9282 files conflicted\n",
      "\n",
      "   üìä Processed 2 directories\n",
      "\n",
      "================================================================================\n",
      "üì¶ BUILDING FINAL REGISTRY\n",
      "================================================================================\n",
      "Components found: ['framework_state', 'model_state']\n",
      "  ‚Ä¢ framework_state: 2541 files\n",
      "  ‚Ä¢ model_state: 9282 files\n",
      "\n",
      "‚úÖ SCAN COMPLETE\n",
      "Modes scanned: 1\n",
      "Total files in registry: 11823\n",
      "================================================================================\n",
      "\n",
      "\t‚Üí Filesystem scan found 11823 files\n",
      "\n",
      "===================== GET DRIVE REGISTRY =====================\n",
      "===================== REGISTRY BUILD COMPLETE =====================\n",
      "\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "\tüì¶ LocalBackupManager Registry Saved Locally in LOCAL\n",
      "BUILDING REGISTRY WITH 0 EXPECTED COMPONENTS KEYS\n",
      "\n",
      "===================== GET LOCAL REGISTRY =====================\n",
      "‚Üí Skipping local cache (force=True or file missing)\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "\tüì¶ LocalBackupManager Registry Saved Locally in LOCAL\n",
      "\n",
      "======================================================================\n",
      "üéØ AllocatorRunner initialized: ThompsonSampling\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "üöÄ STARTING ALLOCATOR: ThompsonSampling\n",
      "======================================================================\n",
      "\n",
      "üìä Physics Model: paper7\n",
      "\n",
      "üìã Allocator Config:\n",
      "   Type: ThompsonSampling\n",
      "   Testbed: default\n",
      "   Paths: 15\n",
      "   Total Qubits: 75\n",
      "   Min per route: 2\n",
      "   Seed: 42\n",
      "   Priors: Œ±=1.0, Œ≤=1.0\n",
      "‚úÖ Allocator created: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "‚úì Allocator: ThompsonSamplingAllocator (15 paths)\n",
      "   Initial allocation: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üìä Paper7 Topology: Real AS (as20000101.txt)\n",
      "üìä Paper7 Paths: 15 paths from 5-shortest between 3 ISPs\n",
      "üìä Paper7 Contexts: 15 context vectors generated\n",
      "üìä Paper7 Rewards: Context-aware (mode=neg_hop)\n",
      "‚è±Ô∏è  get_physics_params_paper7() time: 4.5 ms\n",
      "\n",
      "======================================================================\n",
      "RUN 1 | Scale: 1.5 | Exp: 5\n",
      "======================================================================\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "\n",
      "\tüîÑ Resume: MultiRunEvaluator\n",
      "\n",
      "=====================================================\n",
      "üîç GENERATING EXPECTED KEYS FROM EVALUATOR\n",
      "=====================================================\n",
      "  ‚Ä¢ Evaluator filename: MultiRunEvaluator_75-ThompsonSampling_All_All-50_50_5_S1_5T_paper7.pkl\n",
      "\n",
      "üß© PARSED COMPONENTS\n",
      "  ‚Ä¢ cap_id:        75\n",
      "  ‚Ä¢ allocator_id:  ThompsonSampling\n",
      "  ‚Ä¢ env_id:        All\n",
      "  ‚Ä¢ attack_id:     All\n",
      "  ‚Ä¢ base_frames:   50\n",
      "  ‚Ä¢ frame_step:    50\n",
      "  ‚Ä¢ runs_id:       5\n",
      "\n",
      "=====================================================\n",
      "üß™ GENERATING KEYS FOR EACH RUN\n",
      "=====================================================\n",
      "\n",
      "--- Run 1/5 -----------------------\n",
      "\n",
      "=====================================================\n",
      "üì¶ FINAL EXPECTED KEYS\n",
      "=====================================================\n",
      "  ‚Ä¢ Runner keys: 11\n",
      "\n",
      "  ‚Ä¢ Model keys: 50\n",
      "\n",
      "--- Run 2/5 -----------------------\n",
      "\n",
      "=====================================================\n",
      "üì¶ FINAL EXPECTED KEYS\n",
      "=====================================================\n",
      "  ‚Ä¢ Runner keys: 21\n",
      "\n",
      "  ‚Ä¢ Model keys: 100\n",
      "\n",
      "--- Run 3/5 -----------------------\n",
      "\n",
      "=====================================================\n",
      "üì¶ FINAL EXPECTED KEYS\n",
      "=====================================================\n",
      "  ‚Ä¢ Runner keys: 31\n",
      "\n",
      "  ‚Ä¢ Model keys: 150\n",
      "\n",
      "--- Run 4/5 -----------------------\n",
      "\n",
      "=====================================================\n",
      "üì¶ FINAL EXPECTED KEYS\n",
      "=====================================================\n",
      "  ‚Ä¢ Runner keys: 41\n",
      "\n",
      "  ‚Ä¢ Model keys: 200\n",
      "\n",
      "--- Run 5/5 -----------------------\n",
      "\n",
      "=====================================================\n",
      "üì¶ FINAL EXPECTED KEYS\n",
      "=====================================================\n",
      "  ‚Ä¢ Runner keys: 51\n",
      "\n",
      "  ‚Ä¢ Model keys: 250\n",
      "\n",
      "EXPECTED KEY GENERATION COMPLETE\n",
      "\n",
      "RESTORING FROM DRIVE 1\n",
      "RESTORING FROM DRIVE 2\n",
      "\t‚ö†Ô∏è Registry exists ‚Üí aborting restore\n",
      "\t‚òÅÔ∏è Attempting Drive download: framework_state/MultiRunEvaluator_75-ThompsonSampling_All_All-50_50_5_S1_5T_paper7.pkl\n",
      "\t‚ùå Not found anywhere: framework_state/MultiRunEvaluator_75-ThompsonSampling_All_All-50_50_5_S1_5T_paper7.pkl\n",
      "\t‚ùå Not found in registry or fallback locations\n",
      "\t‚òÅÔ∏è Attempting Drive download: framework_state/MultiRunEvaluator_75-ThompsonSampling_All_All-50_50_5_S1_5T_paper7.pkl\n",
      "\t‚ùå Not found anywhere: framework_state/MultiRunEvaluator_75-ThompsonSampling_All_All-50_50_5_S1_5T_paper7.pkl\n",
      "\t‚ùå Not found in registry or fallback locations\n",
      "[Resume] exact failed ‚Üí Looking for supersets\n",
      "[Resume-Supersets] target_runs=5, backups=dict_keys([])\n",
      "[Resume-Supersets] Trying horizons in size order (largest first): []\n",
      "[Resume-Supersets] ‚ùå No valid supersets found for resume\n",
      "No state found for MultiRunEvaluator, disabling resume for Experiment Runners\n",
      "Multi-Run Evaluator Initialized\n",
      "Environment Type: None\n",
      "Frame Range: 50 -> 250 (step: 50)\n",
      "quantum_exps-ThompsonSampling(paper7)_alloc-all_envs-5_attacks-50_50-5_runs-S1.5T\n",
      "[Logging Redirect Initialized]\n",
      "Log File: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/quantum_logs/quantum_exps-ThompsonSampling(paper7)_alloc-all_envs-5_attacks-50_50-5_runs-S1.5T_20260201_log.txt\n",
      "‚öô Running evaluation...\n",
      "======================================================================\n",
      "SCENARIOS MODEL EVALUATION\n",
      "======================================================================\n",
      "Testing algorithm performance against:\n",
      "\t‚Ä¢ Stochastic:  \tNatural quantum decoherence and network failures\n",
      "\t‚Ä¢ Baseline:    \tOptimal conditions for validation\n",
      "======================================================================\n",
      "Models to Test:             \tOracle, GNeuralUCB, EXPNeuralUCB, CPursuitNeuralUCB, iCPursuitNeuralUCB\n",
      "Experiments per Scenario:   \t5\n",
      "======================================================================\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: BASELINE (OPTIMAL CONDITIONS)\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: NONE\n",
      "Category: Baseline (No Attacks)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 50 frames  <>  SCALED-CAPACITY: 75.0 frames (CAPACITY:50 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=0 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for NONE Exp 1: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 1: Env:Baseline (None), Attack:No, Rate:0.0, Frames:50, QubitAlloc=ThompsonSampling, SC:75 (Scale=1.5 x Cap=50), Seed: 15373\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 15\n",
      "\t   First reward: [9.0], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 1: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 GNEURALUCB          : Reward=0396.00, Efficiency=088.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=75, Threshold=0.582]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 1: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=0396.00, Efficiency=088.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=75, Threshold=0.628]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 1: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=0396.00, Efficiency=088.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=75, Threshold=0.634]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 1: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=0450.00, Efficiency=100.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=75, Threshold=0.712]\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 1: Env:Baseline (None), Attack:No, Rate:0.0, Frames:50, QubitAlloc=ThompsonSampling, SC:75 (Scale=1.5 x Cap=50), Seed: 15373\n",
      "\t-->üèÜ EXP1 Winner:iCPursuitNeuralUCB  (Gap:000.0%) [Env:Baseline (None), Attack:No X Rate:0.0, Frames:50, SCapacity=75, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 1 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 100 frames  <>  SCALED-CAPACITY: 150.0 frames (CAPACITY:100 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=1 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for NONE Exp 2: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 2: Env:Baseline (None), Attack:No, Rate:0.0, Frames:100, QubitAlloc=ThompsonSampling, SC:150 (Scale=1.5 x Cap=100), Seed: 12644\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 15\n",
      "\t   First reward: [9.0], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 2: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 GNEURALUCB          : Reward=0794.00, Efficiency=088.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=150, Threshold=0.582]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 2: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=0830.00, Efficiency=092.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=150, Threshold=0.628]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 2: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=0794.00, Efficiency=088.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=150, Threshold=0.634]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 2: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=0900.00, Efficiency=100.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=150, Threshold=0.712]\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 2: Env:Baseline (None), Attack:No, Rate:0.0, Frames:100, QubitAlloc=ThompsonSampling, SC:150 (Scale=1.5 x Cap=100), Seed: 12644\n",
      "\t-->üèÜ EXP2 Winner:iCPursuitNeuralUCB  (Gap:000.0%) [Env:Baseline (None), Attack:No X Rate:0.0, Frames:100, SCapacity=150, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 2 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 150 frames  <>  SCALED-CAPACITY: 225.0 frames (CAPACITY:150 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=2 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for NONE Exp 3: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 3: Env:Baseline (None), Attack:No, Rate:0.0, Frames:150, QubitAlloc=ThompsonSampling, SC:225 (Scale=1.5 x Cap=150), Seed: 20257\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 15\n",
      "\t   First reward: [9.0], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 3: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 GNEURALUCB          : Reward=1190.00, Efficiency=088.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=225, Threshold=0.582]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 3: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=1229.00, Efficiency=091.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=225, Threshold=0.628]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 3: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=1190.00, Efficiency=088.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=225, Threshold=0.634]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 3: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=1350.00, Efficiency=100.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=225, Threshold=0.712]\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 3: Env:Baseline (None), Attack:No, Rate:0.0, Frames:150, QubitAlloc=ThompsonSampling, SC:225 (Scale=1.5 x Cap=150), Seed: 20257\n",
      "\t-->üèÜ EXP3 Winner:iCPursuitNeuralUCB  (Gap:000.0%) [Env:Baseline (None), Attack:No X Rate:0.0, Frames:150, SCapacity=225, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 3 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 200 frames  <>  SCALED-CAPACITY: 300.0 frames (CAPACITY:200 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=3 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for NONE Exp 4: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 4: Env:Baseline (None), Attack:No, Rate:0.0, Frames:200, QubitAlloc=ThompsonSampling, SC:300 (Scale=1.5 x Cap=200), Seed: 20031\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 15\n",
      "\t   First reward: [9.0], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 4: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 GNEURALUCB          : Reward=1586.00, Efficiency=088.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=300, Threshold=0.582]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 4: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=1567.00, Efficiency=087.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=300, Threshold=0.628]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 4: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=1586.00, Efficiency=088.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=300, Threshold=0.634]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 4: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=1800.00, Efficiency=100.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=300, Threshold=0.712]\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 4: Env:Baseline (None), Attack:No, Rate:0.0, Frames:200, QubitAlloc=ThompsonSampling, SC:300 (Scale=1.5 x Cap=200), Seed: 20031\n",
      "\t-->üèÜ EXP4 Winner:iCPursuitNeuralUCB  (Gap:000.0%) [Env:Baseline (None), Attack:No X Rate:0.0, Frames:200, SCapacity=300, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 4 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 250 frames  <>  SCALED-CAPACITY: 375.0 frames (CAPACITY:250 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=4 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for NONE Exp 5: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 5: Env:Baseline (None), Attack:No, Rate:0.0, Frames:250, QubitAlloc=ThompsonSampling, SC:375 (Scale=1.5 x Cap=250), Seed: 17303\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 15\n",
      "\t   First reward: [9.0], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 5: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 GNEURALUCB          : Reward=1984.00, Efficiency=088.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=375, Threshold=0.582]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 5: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=1879.00, Efficiency=083.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=375, Threshold=0.628]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 5: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=1984.00, Efficiency=088.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=375, Threshold=0.634]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 5: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=2250.00, Efficiency=100.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=375, Threshold=0.712]\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 5: Env:Baseline (None), Attack:No, Rate:0.0, Frames:250, QubitAlloc=ThompsonSampling, SC:375 (Scale=1.5 x Cap=250), Seed: 17303\n",
      "\t-->üèÜ EXP5 Winner:iCPursuitNeuralUCB  (Gap:000.0%) [Env:Baseline (None), Attack:No X Rate:0.0, Frames:250, SCapacity=375, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 5 completed successfully.\n",
      "Total experiment time: 902.2s\n",
      "Experiments completed for none\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: STOCHASTIC RANDOM FAILURES\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: STOCHASTIC\n",
      "Category: Stochastic (Natural Random Failures)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 50 frames  <>  SCALED-CAPACITY: 75.0 frames (CAPACITY:50 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=0 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 1: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 1: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:50, QubitAlloc=ThompsonSampling, SC:75 (Scale=1.5 x Cap=50), Seed: 15729\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 15\n",
      "\t   First reward: [9.0], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 1: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 GNEURALUCB          : Reward=0381.00, Efficiency=084.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=75, Threshold=0.582]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 1: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=0389.00, Efficiency=086.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=75, Threshold=0.628]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 1: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=0381.00, Efficiency=084.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=75, Threshold=0.634]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 1: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=0423.00, Efficiency=094.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=75, Threshold=0.712]\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 1: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:50, QubitAlloc=ThompsonSampling, SC:75 (Scale=1.5 x Cap=50), Seed: 15729\n",
      "\t-->üèÜ EXP1 Winner:iCPursuitNeuralUCB  (Gap:005.8%) [Env:Stochastic, Attack:Random X Rate:0.0625, Frames:50, SCapacity=75, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 1 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 100 frames  <>  SCALED-CAPACITY: 150.0 frames (CAPACITY:100 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=1 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 2: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 2: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:100, QubitAlloc=ThompsonSampling, SC:150 (Scale=1.5 x Cap=100), Seed: 19894\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 15\n",
      "\t   First reward: [9.0], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 2: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 GNEURALUCB          : Reward=0726.00, Efficiency=080.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=150, Threshold=0.582]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 2: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=0692.00, Efficiency=076.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=150, Threshold=0.628]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 2: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=0726.00, Efficiency=080.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=150, Threshold=0.634]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 2: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=0828.00, Efficiency=092.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=150, Threshold=0.712]\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 2: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:100, QubitAlloc=ThompsonSampling, SC:150 (Scale=1.5 x Cap=100), Seed: 19894\n",
      "\t-->üèÜ EXP2 Winner:iCPursuitNeuralUCB  (Gap:008.0%) [Env:Stochastic, Attack:Random X Rate:0.0625, Frames:100, SCapacity=150, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 2 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 150 frames  <>  SCALED-CAPACITY: 225.0 frames (CAPACITY:150 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=2 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 3: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 3: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:150, QubitAlloc=ThompsonSampling, SC:225 (Scale=1.5 x Cap=150), Seed: 16736\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 15\n",
      "\t   First reward: [9.0], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 3: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 GNEURALUCB          : Reward=1142.00, Efficiency=084.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=225, Threshold=0.582]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 3: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=1156.00, Efficiency=085.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=225, Threshold=0.628]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 3: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=1142.00, Efficiency=084.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=225, Threshold=0.634]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 3: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=1260.00, Efficiency=093.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=225, Threshold=0.712]\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 3: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:150, QubitAlloc=ThompsonSampling, SC:225 (Scale=1.5 x Cap=150), Seed: 16736\n",
      "\t-->üèÜ EXP3 Winner:iCPursuitNeuralUCB  (Gap:006.7%) [Env:Stochastic, Attack:Random X Rate:0.0625, Frames:150, SCapacity=225, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 3 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 200 frames  <>  SCALED-CAPACITY: 300.0 frames (CAPACITY:200 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=3 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 4: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 4: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:200, QubitAlloc=ThompsonSampling, SC:300 (Scale=1.5 x Cap=200), Seed: 12981\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 15\n",
      "\t   First reward: [9.0], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 4: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 GNEURALUCB          : Reward=1488.00, Efficiency=082.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=300, Threshold=0.582]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 4: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=1524.00, Efficiency=084.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=300, Threshold=0.628]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 4: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=1488.00, Efficiency=082.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=300, Threshold=0.634]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 4: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=1674.00, Efficiency=093.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=300, Threshold=0.712]\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 4: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:200, QubitAlloc=ThompsonSampling, SC:300 (Scale=1.5 x Cap=200), Seed: 12981\n",
      "\t-->üèÜ EXP4 Winner:iCPursuitNeuralUCB  (Gap:006.8%) [Env:Stochastic, Attack:Random X Rate:0.0625, Frames:200, SCapacity=300, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 4 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 250 frames  <>  SCALED-CAPACITY: 375.0 frames (CAPACITY:250 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=4 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 5: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 5: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:250, QubitAlloc=ThompsonSampling, SC:375 (Scale=1.5 x Cap=250), Seed: 17091\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 15\n",
      "\t   First reward: [9.0], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 5: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 GNEURALUCB          : Reward=1843.00, Efficiency=081.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=375, Threshold=0.582]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 5: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=1915.00, Efficiency=085.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=375, Threshold=0.628]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 5: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=1843.00, Efficiency=081.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=375, Threshold=0.634]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 5: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=2115.00, Efficiency=094.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=375, Threshold=0.712]\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 5: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:250, QubitAlloc=ThompsonSampling, SC:375 (Scale=1.5 x Cap=250), Seed: 17091\n",
      "\t-->üèÜ EXP5 Winner:iCPursuitNeuralUCB  (Gap:006.0%) [Env:Stochastic, Attack:Random X Rate:0.0625, Frames:250, SCapacity=375, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 5 completed successfully.\n",
      "Total experiment time: 824.2s\n",
      "Experiments completed for stochastic\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: MARKOV ADVERSARIAL ATTACK\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: MARKOV\n",
      "Category: Structured (Markov Chain Based)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 50 frames  <>  SCALED-CAPACITY: 75.0 frames (CAPACITY:50 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=0 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for MARKOV Exp 1: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 1: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:50, QubitAlloc=ThompsonSampling, SC:75 (Scale=1.5 x Cap=50), Seed: 14132\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 15\n",
      "\t   First reward: [9.0], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 1: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 GNEURALUCB          : Reward=0194.00, Efficiency=044.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=75, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 1: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=0173.00, Efficiency=039.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=75, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 1: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=0194.00, Efficiency=044.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=75, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 1: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=0261.00, Efficiency=059.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=75, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 1: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:50, QubitAlloc=ThompsonSampling, SC:75 (Scale=1.5 x Cap=50), Seed: 14132\n",
      "\t-->üèÜ EXP1 Winner:iCPursuitNeuralUCB  (Gap:040.7%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:50, SCapacity=75, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 1 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 100 frames  <>  SCALED-CAPACITY: 150.0 frames (CAPACITY:100 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=1 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for MARKOV Exp 2: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 2: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:100, QubitAlloc=ThompsonSampling, SC:150 (Scale=1.5 x Cap=100), Seed: 22231\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 15\n",
      "\t   First reward: [9.0], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 2: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 GNEURALUCB          : Reward=0402.00, Efficiency=045.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=150, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 2: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=0354.00, Efficiency=040.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=150, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 2: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=0402.00, Efficiency=045.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=150, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 2: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=0441.00, Efficiency=050.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=150, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 2: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:100, QubitAlloc=ThompsonSampling, SC:150 (Scale=1.5 x Cap=100), Seed: 22231\n",
      "\t-->üèÜ EXP2 Winner:iCPursuitNeuralUCB  (Gap:049.6%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:100, SCapacity=150, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 2 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 150 frames  <>  SCALED-CAPACITY: 225.0 frames (CAPACITY:150 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=2 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for MARKOV Exp 3: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 3: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:150, QubitAlloc=ThompsonSampling, SC:225 (Scale=1.5 x Cap=150), Seed: 20747\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 15\n",
      "\t   First reward: [9.0], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 3: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 GNEURALUCB          : Reward=0640.00, Efficiency=048.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=225, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 3: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=0479.00, Efficiency=036.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=225, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 3: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=0640.00, Efficiency=048.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=225, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 3: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=0747.00, Efficiency=056.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=225, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 3: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:150, QubitAlloc=ThompsonSampling, SC:225 (Scale=1.5 x Cap=150), Seed: 20747\n",
      "\t-->üèÜ EXP3 Winner:iCPursuitNeuralUCB  (Gap:043.1%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:150, SCapacity=225, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 3 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 200 frames  <>  SCALED-CAPACITY: 300.0 frames (CAPACITY:200 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=3 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for MARKOV Exp 4: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 4: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:200, QubitAlloc=ThompsonSampling, SC:300 (Scale=1.5 x Cap=200), Seed: 15410\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 15\n",
      "\t   First reward: [9.0], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 4: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 GNEURALUCB          : Reward=0931.00, Efficiency=053.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=300, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 4: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=0814.00, Efficiency=046.4% [Retries=3, Failed=0, < Threshold=3, SCapacity=300, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 4: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=0931.00, Efficiency=053.1% [Retries=3, Failed=0, < Threshold=3, SCapacity=300, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 4: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=0963.00, Efficiency=054.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=300, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 4: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:200, QubitAlloc=ThompsonSampling, SC:300 (Scale=1.5 x Cap=200), Seed: 15410\n",
      "\t-->üèÜ EXP4 Winner:iCPursuitNeuralUCB  (Gap:045.1%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:200, SCapacity=300, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 4 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 250 frames  <>  SCALED-CAPACITY: 375.0 frames (CAPACITY:250 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=4 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for MARKOV Exp 5: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 5: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:250, QubitAlloc=ThompsonSampling, SC:375 (Scale=1.5 x Cap=250), Seed: 22674\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 15\n",
      "\t   First reward: [9.0], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 5: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 GNEURALUCB          : Reward=1092.00, Efficiency=049.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=375, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 5: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=0971.00, Efficiency=044.2% [Retries=3, Failed=0, < Threshold=3, SCapacity=375, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 5: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=1092.00, Efficiency=049.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=375, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (MARKOV) EXP 5: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=0898.00, Efficiency=040.9% [Retries=3, Failed=0, < Threshold=3, SCapacity=375, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 5: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:250, QubitAlloc=ThompsonSampling, SC:375 (Scale=1.5 x Cap=250), Seed: 22674\n",
      "\t-->üèÜ EXP5 Winner:GNeuralUCB          (Gap:050.3%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:250, SCapacity=375, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 5 completed successfully.\n",
      "Total experiment time: 763.8s\n",
      "Experiments completed for markov\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: ADAPTIVE ADVERSARIAL ATTACK\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: ADAPTIVE\n",
      "Category: Adaptive (Reactive Strategic)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 50 frames  <>  SCALED-CAPACITY: 75.0 frames (CAPACITY:50 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=0 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 1: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 1: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:50, QubitAlloc=ThompsonSampling, SC:75 (Scale=1.5 x Cap=50), Seed: 21427\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 15\n",
      "\t   First reward: [9.0], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 1: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 GNEURALUCB          : Reward=0335.00, Efficiency=074.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=75, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 1: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=0262.00, Efficiency=058.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=75, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 1: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=0335.00, Efficiency=074.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=75, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 1: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=0288.00, Efficiency=064.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=75, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 1: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:50, QubitAlloc=ThompsonSampling, SC:75 (Scale=1.5 x Cap=50), Seed: 21427\n",
      "\t-->üèÜ EXP1 Winner:GNeuralUCB          (Gap:025.2%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:50, SCapacity=75, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 1 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 100 frames  <>  SCALED-CAPACITY: 150.0 frames (CAPACITY:100 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=1 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 2: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 2: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:100, QubitAlloc=ThompsonSampling, SC:150 (Scale=1.5 x Cap=100), Seed: 13200\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 15\n",
      "\t   First reward: [9.0], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 2: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 GNEURALUCB          : Reward=0569.00, Efficiency=063.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=150, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 2: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=0560.00, Efficiency=062.8% [Retries=3, Failed=0, < Threshold=3, SCapacity=150, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 2: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=0569.00, Efficiency=063.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=150, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 2: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=0666.00, Efficiency=074.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=150, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 2: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:100, QubitAlloc=ThompsonSampling, SC:150 (Scale=1.5 x Cap=100), Seed: 13200\n",
      "\t-->üèÜ EXP2 Winner:iCPursuitNeuralUCB  (Gap:025.3%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:100, SCapacity=150, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 2 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 150 frames  <>  SCALED-CAPACITY: 225.0 frames (CAPACITY:150 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=2 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 3: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 3: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:150, QubitAlloc=ThompsonSampling, SC:225 (Scale=1.5 x Cap=150), Seed: 18005\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 15\n",
      "\t   First reward: [9.0], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 3: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 GNEURALUCB          : Reward=0837.00, Efficiency=062.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=225, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 3: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=0900.00, Efficiency=067.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=225, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 3: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=0837.00, Efficiency=062.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=225, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 3: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=1044.00, Efficiency=077.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=225, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 3: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:150, QubitAlloc=ThompsonSampling, SC:225 (Scale=1.5 x Cap=150), Seed: 18005\n",
      "\t-->üèÜ EXP3 Winner:iCPursuitNeuralUCB  (Gap:022.3%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:150, SCapacity=225, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 3 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 200 frames  <>  SCALED-CAPACITY: 300.0 frames (CAPACITY:200 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=3 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 4: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 4: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:200, QubitAlloc=ThompsonSampling, SC:300 (Scale=1.5 x Cap=200), Seed: 12955\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 15\n",
      "\t   First reward: [9.0], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 4: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 GNEURALUCB          : Reward=1159.00, Efficiency=064.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=300, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 4: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=1199.00, Efficiency=066.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=300, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 4: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=1159.00, Efficiency=064.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=300, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 4: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=1431.00, Efficiency=079.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=300, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 4: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:200, QubitAlloc=ThompsonSampling, SC:300 (Scale=1.5 x Cap=200), Seed: 12955\n",
      "\t-->üèÜ EXP4 Winner:iCPursuitNeuralUCB  (Gap:020.1%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:200, SCapacity=300, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 4 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 250 frames  <>  SCALED-CAPACITY: 375.0 frames (CAPACITY:250 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=4 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 5: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 5: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:250, QubitAlloc=ThompsonSampling, SC:375 (Scale=1.5 x Cap=250), Seed: 14950\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 15\n",
      "\t   First reward: [9.0], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 5: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 GNEURALUCB          : Reward=1564.00, Efficiency=069.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=375, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 5: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=1566.00, Efficiency=069.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=375, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 5: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=1564.00, Efficiency=069.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=375, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ADAPTIVE) EXP 5: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=1755.00, Efficiency=078.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=375, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 5: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:250, QubitAlloc=ThompsonSampling, SC:375 (Scale=1.5 x Cap=250), Seed: 14950\n",
      "\t-->üèÜ EXP5 Winner:iCPursuitNeuralUCB  (Gap:021.7%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:250, SCapacity=375, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 5 completed successfully.\n",
      "Total experiment time: 808.5s\n",
      "Experiments completed for adaptive\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: ONLINE ADAPTIVE ATTACK\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: ONLINEADAPTIVE\n",
      "Category: Online Adaptive (Real-time Strategic)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 50 frames  <>  SCALED-CAPACITY: 75.0 frames (CAPACITY:50 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=0 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 1: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:50, QubitAlloc=ThompsonSampling, SC:75 (Scale=1.5 x Cap=50), Seed: 14732\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 15\n",
      "\t   First reward: [9.0], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 GNEURALUCB          : Reward=0303.00, Efficiency=067.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=75, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=0340.00, Efficiency=076.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=75, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=0303.00, Efficiency=067.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=75, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=0360.00, Efficiency=080.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=75, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:50, QubitAlloc=ThompsonSampling, SC:75 (Scale=1.5 x Cap=50), Seed: 14732\n",
      "\t-->üèÜ EXP1 Winner:iCPursuitNeuralUCB  (Gap:019.3%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:50, SCapacity=75, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 1 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 100 frames  <>  SCALED-CAPACITY: 150.0 frames (CAPACITY:100 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=1 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 2: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:100, QubitAlloc=ThompsonSampling, SC:150 (Scale=1.5 x Cap=100), Seed: 14647\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 15\n",
      "\t   First reward: [9.0], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 GNEURALUCB          : Reward=0625.00, Efficiency=070.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=150, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=0573.00, Efficiency=064.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=150, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=0625.00, Efficiency=070.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=150, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=0585.00, Efficiency=065.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=150, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:100, QubitAlloc=ThompsonSampling, SC:150 (Scale=1.5 x Cap=100), Seed: 14647\n",
      "\t-->üèÜ EXP2 Winner:GNeuralUCB          (Gap:029.9%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:100, SCapacity=150, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 2 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 150 frames  <>  SCALED-CAPACITY: 225.0 frames (CAPACITY:150 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=2 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 3: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:150, QubitAlloc=ThompsonSampling, SC:225 (Scale=1.5 x Cap=150), Seed: 21138\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 15\n",
      "\t   First reward: [9.0], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 GNEURALUCB          : Reward=0892.00, Efficiency=066.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=225, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=0884.00, Efficiency=065.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=225, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=0892.00, Efficiency=066.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=225, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=1071.00, Efficiency=079.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=225, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:150, QubitAlloc=ThompsonSampling, SC:225 (Scale=1.5 x Cap=150), Seed: 21138\n",
      "\t-->üèÜ EXP3 Winner:iCPursuitNeuralUCB  (Gap:020.2%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:150, SCapacity=225, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 3 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 200 frames  <>  SCALED-CAPACITY: 300.0 frames (CAPACITY:200 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=3 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 4: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:200, QubitAlloc=ThompsonSampling, SC:300 (Scale=1.5 x Cap=200), Seed: 16677\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 15\n",
      "\t   First reward: [9.0], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 GNEURALUCB          : Reward=1209.00, Efficiency=067.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=300, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=1203.00, Efficiency=067.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=300, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=1209.00, Efficiency=067.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=300, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=1359.00, Efficiency=076.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=300, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:200, QubitAlloc=ThompsonSampling, SC:300 (Scale=1.5 x Cap=200), Seed: 16677\n",
      "\t-->üèÜ EXP4 Winner:iCPursuitNeuralUCB  (Gap:023.9%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:200, SCapacity=300, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 4 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 250 frames  <>  SCALED-CAPACITY: 375.0 frames (CAPACITY:250 X SCALE:1.5)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=4 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 5: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:250, QubitAlloc=ThompsonSampling, SC:375 (Scale=1.5 x Cap=250), Seed: 22447\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 15\n",
      "\t   First reward: [9.0], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 GNEURALUCB          : Reward=1413.00, Efficiency=063.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=375, Threshold=0.582]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=1509.00, Efficiency=067.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=375, Threshold=0.628]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=1413.00, Efficiency=063.2% [Retries=3, Failed=0, < Threshold=3, SCapacity=375, Threshold=0.634]\n",
      "\n",
      "\tüîÑ ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=1737.00, Efficiency=077.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=375, Threshold=0.712]\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:250, QubitAlloc=ThompsonSampling, SC:375 (Scale=1.5 x Cap=250), Seed: 22447\n",
      "\t-->üèÜ EXP5 Winner:iCPursuitNeuralUCB  (Gap:022.2%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:250, SCapacity=375, Alloc=ThompsonSampling]\n",
      "‚úì Experiment 5 completed successfully.\n",
      "Total experiment time: 826.9s\n",
      "Experiments completed for onlineadaptive\n",
      "‚úì Scenario 'none' evaluation completed.\n",
      "‚úì Scenario 'stochastic' evaluation completed.\n",
      "‚úì Scenario 'markov' evaluation completed.\n",
      "‚úì Scenario 'adaptive' evaluation completed.\n",
      "‚úì Scenario 'onlineadaptive' evaluation completed.\n",
      "\n",
      "======================================================================\n",
      "COMPREHENSIVE SCENARIO PERFORMANCE ANALYSIS\n",
      "======================================================================\n",
      "SCENARIO: NONE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 1350.00\n",
      "\t‚Ä¢ Winner Avg Gap: 0000.00%\n",
      "\t‚Ä¢ Winner Avg Reward: 1350.00\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0100.00%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 5 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: NONE\n",
      "======================================================================\n",
      "SCENARIO: \tBASELINE (OPTIMAL CONDITIONS)\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 5/5 experiments)\n",
      "\tWinner Avg Gap: \t000.0%\n",
      "\tWinner Avg Efficiency: \t100.0%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t100.0% Efficiency \t(Won 5/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t088.4% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t088.1% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t088.1% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: STOCHASTIC\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 1349.20\n",
      "\t‚Ä¢ Winner Avg Gap: 0006.66%\n",
      "\t‚Ä¢ Winner Avg Reward: 1260.00\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0093.34%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 5 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: STOCHASTIC\n",
      "======================================================================\n",
      "SCENARIO: \tSTOCHASTIC RANDOM FAILURES\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 5/5 experiments)\n",
      "\tWinner Avg Gap: \t006.7%\n",
      "\tWinner Avg Efficiency: \t093.3%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t093.3% Efficiency \t(Won 5/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t083.8% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t083.0% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t083.0% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: MARKOV\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 1315.20\n",
      "\t‚Ä¢ Winner Avg Gap: 0047.50%\n",
      "\t‚Ä¢ Winner Avg Reward: 0662.00\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0052.50%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 1 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 4 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: MARKOV\n",
      "======================================================================\n",
      "SCENARIO: \tMARKOV ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 4/5 experiments)\n",
      "\tWinner Avg Gap: \t047.5%\n",
      "\tWinner Avg Efficiency: \t052.5%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t052.5% Efficiency \t(Won 4/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t048.3% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t048.3% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t041.4% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 1343.40\n",
      "\t‚Ä¢ Winner Avg Gap: 0025.04%\n",
      "\t‚Ä¢ Winner Avg Reward: 1036.80\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0074.96%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 1 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 4 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tADAPTIVE ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 4/5 experiments)\n",
      "\tWinner Avg Gap: \t025.0%\n",
      "\tWinner Avg Efficiency: \t075.0%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t075.0% Efficiency \t(Won 4/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t067.1% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t067.1% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t065.0% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ONLINEADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 1339.80\n",
      "\t‚Ä¢ Winner Avg Gap: 0023.99%\n",
      "\t‚Ä¢ Winner Avg Reward: 1022.40\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0076.01%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 1 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 4 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ONLINEADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tONLINE ADAPTIVE ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 4/5 experiments)\n",
      "\tWinner Avg Gap: \t024.0%\n",
      "\tWinner Avg Efficiency: \t076.0%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t076.0% Efficiency \t(Won 4/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t068.3% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t067.1% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t067.1% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "KEY INSIGHTS:\n",
      "Best Performing Model Analysis (iCPursuitNeuralUCB):\n",
      "\t‚Ä¢ Stochastic Performance:    \t1260.000\n",
      "\t‚Ä¢ Baseline Performance:      \t1350.000\n",
      "\t‚Ä¢ Performance Retention:     \t093.3%\n",
      "\tGOOD:               \tAcceptable performance under stochastic conditions\n",
      "Statistical Analysis:\n",
      "\t‚Ä¢ Total models evaluated:     \t5\n",
      "\t‚Ä¢ Experiments per environment:\t5\n",
      "\t‚Ä¢ Quantum network simulation: \tComprehensive stochastic modeling\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "COMPREHENSIVE SCENARIO PERFORMANCE ANALYSIS\n",
      "======================================================================\n",
      "SCENARIO: NONE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 1350.00\n",
      "\t‚Ä¢ Winner Avg Gap: 0000.00%\n",
      "\t‚Ä¢ Winner Avg Reward: 1350.00\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0100.00%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 5 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: NONE\n",
      "======================================================================\n",
      "SCENARIO: \tBASELINE (OPTIMAL CONDITIONS)\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 5/5 experiments)\n",
      "\tWinner Avg Gap: \t000.0%\n",
      "\tWinner Avg Efficiency: \t100.0%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t100.0% Efficiency \t(Won 5/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t088.4% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t088.1% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t088.1% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: STOCHASTIC\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 1349.20\n",
      "\t‚Ä¢ Winner Avg Gap: 0006.66%\n",
      "\t‚Ä¢ Winner Avg Reward: 1260.00\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0093.34%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 5 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: STOCHASTIC\n",
      "======================================================================\n",
      "SCENARIO: \tSTOCHASTIC RANDOM FAILURES\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 5/5 experiments)\n",
      "\tWinner Avg Gap: \t006.7%\n",
      "\tWinner Avg Efficiency: \t093.3%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t093.3% Efficiency \t(Won 5/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t083.8% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t083.0% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t083.0% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: MARKOV\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 1315.20\n",
      "\t‚Ä¢ Winner Avg Gap: 0047.50%\n",
      "\t‚Ä¢ Winner Avg Reward: 0662.00\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0052.50%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 1 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 4 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: MARKOV\n",
      "======================================================================\n",
      "SCENARIO: \tMARKOV ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 4/5 experiments)\n",
      "\tWinner Avg Gap: \t047.5%\n",
      "\tWinner Avg Efficiency: \t052.5%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t052.5% Efficiency \t(Won 4/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t048.3% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t048.3% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t041.4% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 1343.40\n",
      "\t‚Ä¢ Winner Avg Gap: 0025.04%\n",
      "\t‚Ä¢ Winner Avg Reward: 1036.80\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0074.96%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 1 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 4 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tADAPTIVE ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 4/5 experiments)\n",
      "\tWinner Avg Gap: \t025.0%\n",
      "\tWinner Avg Efficiency: \t075.0%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t075.0% Efficiency \t(Won 4/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t067.1% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t067.1% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t065.0% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ONLINEADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 1339.80\n",
      "\t‚Ä¢ Winner Avg Gap: 0023.99%\n",
      "\t‚Ä¢ Winner Avg Reward: 1022.40\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0076.01%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 1 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 4 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ONLINEADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tONLINE ADAPTIVE ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 4/5 experiments)\n",
      "\tWinner Avg Gap: \t024.0%\n",
      "\tWinner Avg Efficiency: \t076.0%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t076.0% Efficiency \t(Won 4/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t068.3% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t067.1% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t067.1% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "‚úÖ Evaluation completed!\n",
      "[Logging Redirect Stopped]\n",
      "\n",
      "üßπ Final cleanup for ThompsonSampling\n",
      "\n",
      "======================================================================\n",
      "‚úÖ COMPLETED: ThompsonSampling\n",
      "======================================================================\n",
      "\n",
      "ThompsonSampling COMPLETED SUCCESSFULLY\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Preparing: ThompsonSampling at scale 2\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üîß Generating physics parameters for model: paper7\n",
      "\n",
      "===================== GET LOCAL REGISTRY =====================\n",
      "‚Üí Skipping local cache (force=True or file missing)\n",
      "\n",
      "===================== BUILD LOCAL REGISTRY =====================\n",
      "\n",
      "================================================================================\n",
      "üîç SCANNING LOCAL FILES\n",
      "================================================================================\n",
      "Parameters: load_to_drive=False, force=False\n",
      "\n",
      "üìÇ Checking DRIVE mode: /content/drive/Shareddrives/ai_quantum_computing/quantum_data_lake\n",
      "   ‚ö†Ô∏è  Path does not exist, skipping\n",
      "\n",
      "üìÇ Checking LOCAL mode: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config\n",
      "   ‚úÖ Path exists, starting walk...\n",
      "   üö∂ Walking directory tree: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config\n",
      "\n",
      "   üìÅ Directory: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201\n",
      "      Relative: framework_state/day_20260201\n",
      "      Component: framework_state\n",
      "      Date: day_20260201\n",
      "      üìÑ Processing 2568 files in framework_state/day_20260201\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "      üìä framework_state/day_20260201: 2542/2568 files processed\n",
      "      üìä framework_state/day_20260201: 0/2568 files skipped\n",
      "      üìä framework_state/day_20260201: 26/2568 files conflicted\n",
      "\n",
      "   üìÅ Directory: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/model_state/day_20260201\n",
      "      Relative: model_state/day_20260201\n",
      "      Component: model_state\n",
      "      Date: day_20260201\n",
      "      üìÑ Processing 9304 files in model_state/day_20260201\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "      üìä model_state/day_20260201: 9304/9304 files processed\n",
      "      üìä model_state/day_20260201: 0/9304 files skipped\n",
      "      üìä model_state/day_20260201: 0/9304 files conflicted\n",
      "\n",
      "   üìä Processed 2 directories\n",
      "\n",
      "================================================================================\n",
      "üì¶ BUILDING FINAL REGISTRY\n",
      "================================================================================\n",
      "Components found: ['framework_state', 'model_state']\n",
      "  ‚Ä¢ framework_state: 2542 files\n",
      "  ‚Ä¢ model_state: 9304 files\n",
      "\n",
      "‚úÖ SCAN COMPLETE\n",
      "Modes scanned: 1\n",
      "Total files in registry: 11846\n",
      "================================================================================\n",
      "\n",
      "\t‚Üí Filesystem scan found 11846 files\n",
      "\n",
      "===================== GET DRIVE REGISTRY =====================\n",
      "===================== REGISTRY BUILD COMPLETE =====================\n",
      "\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "\tüì¶ LocalBackupManager Registry Saved Locally in LOCAL\n",
      "BUILDING REGISTRY WITH 0 EXPECTED COMPONENTS KEYS\n",
      "\n",
      "===================== GET LOCAL REGISTRY =====================\n",
      "‚Üí Skipping local cache (force=True or file missing)\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "\tüì¶ LocalBackupManager Registry Saved Locally in LOCAL\n",
      "\n",
      "======================================================================\n",
      "üéØ AllocatorRunner initialized: ThompsonSampling\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "üöÄ STARTING ALLOCATOR: ThompsonSampling\n",
      "======================================================================\n",
      "\n",
      "üìä Physics Model: paper7\n",
      "\n",
      "üìã Allocator Config:\n",
      "   Type: ThompsonSampling\n",
      "   Testbed: default\n",
      "   Paths: 15\n",
      "   Total Qubits: 75\n",
      "   Min per route: 2\n",
      "   Seed: 42\n",
      "   Priors: Œ±=1.0, Œ≤=1.0\n",
      "‚úÖ Allocator created: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "‚úì Allocator: ThompsonSamplingAllocator (15 paths)\n",
      "   Initial allocation: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üìä Paper7 Topology: Real AS (as20000101.txt)\n",
      "üìä Paper7 Paths: 15 paths from 5-shortest between 3 ISPs\n",
      "üìä Paper7 Contexts: 15 context vectors generated\n",
      "üìä Paper7 Rewards: Context-aware (mode=neg_hop)\n",
      "‚è±Ô∏è  get_physics_params_paper7() time: 4.3 ms\n",
      "\n",
      "======================================================================\n",
      "RUN 1 | Scale: 2 | Exp: 5\n",
      "======================================================================\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "\n",
      "\tüîÑ Resume: MultiRunEvaluator\n",
      "\n",
      "=====================================================\n",
      "üîç GENERATING EXPECTED KEYS FROM EVALUATOR\n",
      "=====================================================\n",
      "  ‚Ä¢ Evaluator filename: MultiRunEvaluator_100-ThompsonSampling_All_All-50_50_5_S2T_paper7.pkl\n",
      "\n",
      "üß© PARSED COMPONENTS\n",
      "  ‚Ä¢ cap_id:        100\n",
      "  ‚Ä¢ allocator_id:  ThompsonSampling\n",
      "  ‚Ä¢ env_id:        All\n",
      "  ‚Ä¢ attack_id:     All\n",
      "  ‚Ä¢ base_frames:   50\n",
      "  ‚Ä¢ frame_step:    50\n",
      "  ‚Ä¢ runs_id:       5\n",
      "\n",
      "=====================================================\n",
      "üß™ GENERATING KEYS FOR EACH RUN\n",
      "=====================================================\n",
      "\n",
      "--- Run 1/5 -----------------------\n",
      "\n",
      "=====================================================\n",
      "üì¶ FINAL EXPECTED KEYS\n",
      "=====================================================\n",
      "  ‚Ä¢ Runner keys: 11\n",
      "\n",
      "  ‚Ä¢ Model keys: 50\n",
      "\n",
      "--- Run 2/5 -----------------------\n",
      "\n",
      "=====================================================\n",
      "üì¶ FINAL EXPECTED KEYS\n",
      "=====================================================\n",
      "  ‚Ä¢ Runner keys: 21\n",
      "\n",
      "  ‚Ä¢ Model keys: 100\n",
      "\n",
      "--- Run 3/5 -----------------------\n",
      "\n",
      "=====================================================\n",
      "üì¶ FINAL EXPECTED KEYS\n",
      "=====================================================\n",
      "  ‚Ä¢ Runner keys: 31\n",
      "\n",
      "  ‚Ä¢ Model keys: 150\n",
      "\n",
      "--- Run 4/5 -----------------------\n",
      "\n",
      "=====================================================\n",
      "üì¶ FINAL EXPECTED KEYS\n",
      "=====================================================\n",
      "  ‚Ä¢ Runner keys: 41\n",
      "\n",
      "  ‚Ä¢ Model keys: 200\n",
      "\n",
      "--- Run 5/5 -----------------------\n",
      "\n",
      "=====================================================\n",
      "üì¶ FINAL EXPECTED KEYS\n",
      "=====================================================\n",
      "  ‚Ä¢ Runner keys: 51\n",
      "\n",
      "  ‚Ä¢ Model keys: 250\n",
      "\n",
      "EXPECTED KEY GENERATION COMPLETE\n",
      "\n",
      "RESTORING FROM DRIVE 1\n",
      "RESTORING FROM DRIVE 2\n",
      "\t‚ö†Ô∏è Registry exists ‚Üí aborting restore\n",
      "\t‚úì MultiRunEvaluator Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/MultiRunEvaluator_100-ThompsonSampling_All_All-50_50_5_S2T_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/MultiRunEvaluator_100-ThompsonSampling_All_All-50_50_5_S2T_paper7.pkl\n",
      "\t   File exists: True, size: 4183659\n",
      "EQUAL METHOD\n",
      "Multi-Run Evaluator Initialized\n",
      "Environment Type: None\n",
      "Frame Range: 50 -> 250 (step: 50)\n",
      "quantum_exps-ThompsonSampling(paper7)_alloc-all_envs-5_attacks-50_50-5_runs-S2T\n",
      "[Logging Redirect Initialized]\n",
      "Log File: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/quantum_logs/quantum_exps-ThompsonSampling(paper7)_alloc-all_envs-5_attacks-50_50-5_runs-S2T_20260201_log.txt\n",
      "‚öô Running evaluation...\n",
      "======================================================================\n",
      "SCENARIOS MODEL EVALUATION\n",
      "======================================================================\n",
      "Testing algorithm performance against:\n",
      "\t‚Ä¢ Stochastic:  \tNatural quantum decoherence and network failures\n",
      "\t‚Ä¢ Baseline:    \tOptimal conditions for validation\n",
      "======================================================================\n",
      "Models to Test:             \tOracle, GNeuralUCB, EXPNeuralUCB, CPursuitNeuralUCB, iCPursuitNeuralUCB\n",
      "Experiments per Scenario:   \t5\n",
      "======================================================================\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: BASELINE (OPTIMAL CONDITIONS)\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: NONE\n",
      "Category: Baseline (No Attacks)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 50 frames  <>  SCALED-CAPACITY: 100 frames (CAPACITY:50 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=0 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for NONE Exp 1: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 1: Env:Baseline (None), Attack:No, Rate:0.0, Frames:50, QubitAlloc=ThompsonSampling, SC:100 (Scale=2 x Cap=50), Seed: 15373\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_1\n",
      "\t‚úì QuantumExperimentRunner_1 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_100-ThompsonSampling_Baseline (None)_No-50_1_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_100-ThompsonSampling_Baseline (None)_No-50_1_paper7.pkl\n",
      "\t   File exists: True, size: 35488\n",
      "‚è© SKIPPING EXPERIMENT 1: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 1 GNEURALUCB          : Reward=0396.00, Efficiency=088.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=100, Threshold=0.582]\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=0391.00, Efficiency=086.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=100, Threshold=0.628]\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=0396.00, Efficiency=088.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=100, Threshold=0.634]\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=0450.00, Efficiency=100.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=100, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP1 Winner:iCPursuitNeuralUCB  (Gap:000.0%) [Env:Baseline (None), Attack:No X Rate:0.25, Frames:50, SCapacity=100, Alloc=ThompsonSampling]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 100 frames  <>  SCALED-CAPACITY: 200 frames (CAPACITY:100 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=1 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for NONE Exp 2: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 2: Env:Baseline (None), Attack:No, Rate:0.0, Frames:100, QubitAlloc=ThompsonSampling, SC:200 (Scale=2 x Cap=100), Seed: 12644\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_2\n",
      "\t‚úì QuantumExperimentRunner_2 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_200-ThompsonSampling_Baseline (None)_No-100_2_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_200-ThompsonSampling_Baseline (None)_No-100_2_paper7.pkl\n",
      "\t   File exists: True, size: 62117\n",
      "‚è© SKIPPING EXPERIMENT 2: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 2 GNEURALUCB          : Reward=0794.00, Efficiency=088.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=200, Threshold=0.582]\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=0830.00, Efficiency=092.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=200, Threshold=0.628]\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=0794.00, Efficiency=088.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=200, Threshold=0.634]\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=0900.00, Efficiency=100.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=200, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP2 Winner:iCPursuitNeuralUCB  (Gap:000.0%) [Env:Baseline (None), Attack:No X Rate:0.25, Frames:100, SCapacity=200, Alloc=ThompsonSampling]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 150 frames  <>  SCALED-CAPACITY: 300 frames (CAPACITY:150 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=2 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for NONE Exp 3: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 3: Env:Baseline (None), Attack:No, Rate:0.0, Frames:150, QubitAlloc=ThompsonSampling, SC:300 (Scale=2 x Cap=150), Seed: 20257\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_3\n",
      "\t‚úì QuantumExperimentRunner_3 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_300-ThompsonSampling_Baseline (None)_No-150_3_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_300-ThompsonSampling_Baseline (None)_No-150_3_paper7.pkl\n",
      "\t   File exists: True, size: 88727\n",
      "‚è© SKIPPING EXPERIMENT 3: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 3 GNEURALUCB          : Reward=1190.00, Efficiency=088.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=300, Threshold=0.582]\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=1184.00, Efficiency=087.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=300, Threshold=0.628]\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=1190.00, Efficiency=088.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=300, Threshold=0.634]\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=1350.00, Efficiency=100.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=300, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP3 Winner:iCPursuitNeuralUCB  (Gap:000.0%) [Env:Baseline (None), Attack:No X Rate:0.25, Frames:150, SCapacity=300, Alloc=ThompsonSampling]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 200 frames  <>  SCALED-CAPACITY: 400 frames (CAPACITY:200 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=3 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for NONE Exp 4: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 4: Env:Baseline (None), Attack:No, Rate:0.0, Frames:200, QubitAlloc=ThompsonSampling, SC:400 (Scale=2 x Cap=200), Seed: 20031\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_4\n",
      "\t‚úì QuantumExperimentRunner_4 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_400-ThompsonSampling_Baseline (None)_No-200_4_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_400-ThompsonSampling_Baseline (None)_No-200_4_paper7.pkl\n",
      "\t   File exists: True, size: 115327\n",
      "‚è© SKIPPING EXPERIMENT 4: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 4 GNEURALUCB          : Reward=1586.00, Efficiency=088.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=400, Threshold=0.582]\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=1600.00, Efficiency=088.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=400, Threshold=0.628]\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=1586.00, Efficiency=088.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=400, Threshold=0.634]\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=1800.00, Efficiency=100.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=400, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP4 Winner:iCPursuitNeuralUCB  (Gap:000.0%) [Env:Baseline (None), Attack:No X Rate:0.25, Frames:200, SCapacity=400, Alloc=ThompsonSampling]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 250 frames  <>  SCALED-CAPACITY: 500 frames (CAPACITY:250 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=4 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for NONE Exp 5: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 5: Env:Baseline (None), Attack:No, Rate:0.0, Frames:250, QubitAlloc=ThompsonSampling, SC:500 (Scale=2 x Cap=250), Seed: 17303\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_5\n",
      "\t‚úì QuantumExperimentRunner_5 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_500-ThompsonSampling_Baseline (None)_No-250_5_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_500-ThompsonSampling_Baseline (None)_No-250_5_paper7.pkl\n",
      "\t   File exists: True, size: 141936\n",
      "‚è© SKIPPING EXPERIMENT 5: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 5 GNEURALUCB          : Reward=1984.00, Efficiency=088.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=500, Threshold=0.582]\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=1993.00, Efficiency=088.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=500, Threshold=0.628]\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=1984.00, Efficiency=088.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=500, Threshold=0.634]\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=2250.00, Efficiency=100.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=500, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP5 Winner:iCPursuitNeuralUCB  (Gap:000.0%) [Env:Baseline (None), Attack:No X Rate:0.25, Frames:250, SCapacity=500, Alloc=ThompsonSampling]\n",
      "\n",
      "Total experiment time: 013.0s\n",
      "Experiments completed for none\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: STOCHASTIC RANDOM FAILURES\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: STOCHASTIC\n",
      "Category: Stochastic (Natural Random Failures)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 50 frames  <>  SCALED-CAPACITY: 100 frames (CAPACITY:50 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=0 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 1: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 1: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:50, QubitAlloc=ThompsonSampling, SC:100 (Scale=2 x Cap=50), Seed: 15729\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_1\n",
      "\t‚úì QuantumExperimentRunner_1 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_100-ThompsonSampling_Stochastic_Random-50_1_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_100-ThompsonSampling_Stochastic_Random-50_1_paper7.pkl\n",
      "\t   File exists: True, size: 35492\n",
      "‚è© SKIPPING EXPERIMENT 1: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 1 GNEURALUCB          : Reward=0381.00, Efficiency=084.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=100, Threshold=0.582]\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=0356.00, Efficiency=079.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=100, Threshold=0.628]\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=0381.00, Efficiency=084.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=100, Threshold=0.634]\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=0441.00, Efficiency=098.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=100, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP1 Winner:iCPursuitNeuralUCB  (Gap:002.0%) [Env:Stochastic, Attack:Random X Rate:0.25, Frames:50, SCapacity=100, Alloc=ThompsonSampling]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 100 frames  <>  SCALED-CAPACITY: 200 frames (CAPACITY:100 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=1 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 2: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 2: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:100, QubitAlloc=ThompsonSampling, SC:200 (Scale=2 x Cap=100), Seed: 19894\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_2\n",
      "\t‚úì QuantumExperimentRunner_2 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_200-ThompsonSampling_Stochastic_Random-100_2_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_200-ThompsonSampling_Stochastic_Random-100_2_paper7.pkl\n",
      "\t   File exists: True, size: 62121\n",
      "‚è© SKIPPING EXPERIMENT 2: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 2 GNEURALUCB          : Reward=0749.00, Efficiency=083.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=200, Threshold=0.582]\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=0671.00, Efficiency=074.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=200, Threshold=0.628]\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=0749.00, Efficiency=083.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=200, Threshold=0.634]\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=0801.00, Efficiency=089.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=200, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP2 Winner:iCPursuitNeuralUCB  (Gap:011.0%) [Env:Stochastic, Attack:Random X Rate:0.25, Frames:100, SCapacity=200, Alloc=ThompsonSampling]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 150 frames  <>  SCALED-CAPACITY: 300 frames (CAPACITY:150 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=2 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 3: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 3: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:150, QubitAlloc=ThompsonSampling, SC:300 (Scale=2 x Cap=150), Seed: 16736\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_3\n",
      "\t‚úì QuantumExperimentRunner_3 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_300-ThompsonSampling_Stochastic_Random-150_3_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_300-ThompsonSampling_Stochastic_Random-150_3_paper7.pkl\n",
      "\t   File exists: True, size: 88731\n",
      "‚è© SKIPPING EXPERIMENT 3: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 3 GNEURALUCB          : Reward=1121.00, Efficiency=083.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=300, Threshold=0.582]\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=1176.00, Efficiency=087.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=300, Threshold=0.628]\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=1121.00, Efficiency=083.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=300, Threshold=0.634]\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=1242.00, Efficiency=092.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=300, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP3 Winner:iCPursuitNeuralUCB  (Gap:007.9%) [Env:Stochastic, Attack:Random X Rate:0.25, Frames:150, SCapacity=300, Alloc=ThompsonSampling]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 200 frames  <>  SCALED-CAPACITY: 400 frames (CAPACITY:200 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=3 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 4: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 4: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:200, QubitAlloc=ThompsonSampling, SC:400 (Scale=2 x Cap=200), Seed: 12981\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_4\n",
      "\t‚úì QuantumExperimentRunner_4 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_400-ThompsonSampling_Stochastic_Random-200_4_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_400-ThompsonSampling_Stochastic_Random-200_4_paper7.pkl\n",
      "\t   File exists: True, size: 115331\n",
      "‚è© SKIPPING EXPERIMENT 4: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 4 GNEURALUCB          : Reward=1473.00, Efficiency=081.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=400, Threshold=0.582]\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=1588.00, Efficiency=088.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=400, Threshold=0.628]\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=1473.00, Efficiency=081.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=400, Threshold=0.634]\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=1674.00, Efficiency=093.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=400, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP4 Winner:iCPursuitNeuralUCB  (Gap:007.0%) [Env:Stochastic, Attack:Random X Rate:0.25, Frames:200, SCapacity=400, Alloc=ThompsonSampling]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 250 frames  <>  SCALED-CAPACITY: 500 frames (CAPACITY:250 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=4 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 5: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 5: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:250, QubitAlloc=ThompsonSampling, SC:500 (Scale=2 x Cap=250), Seed: 17091\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_5\n",
      "\t‚úì QuantumExperimentRunner_5 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_500-ThompsonSampling_Stochastic_Random-250_5_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_500-ThompsonSampling_Stochastic_Random-250_5_paper7.pkl\n",
      "\t   File exists: True, size: 141940\n",
      "‚è© SKIPPING EXPERIMENT 5: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 5 GNEURALUCB          : Reward=1876.00, Efficiency=083.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=500, Threshold=0.582]\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=1676.00, Efficiency=074.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=500, Threshold=0.628]\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=1876.00, Efficiency=083.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=500, Threshold=0.634]\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=2187.00, Efficiency=097.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=500, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP5 Winner:iCPursuitNeuralUCB  (Gap:002.8%) [Env:Stochastic, Attack:Random X Rate:0.25, Frames:250, SCapacity=500, Alloc=ThompsonSampling]\n",
      "\n",
      "Total experiment time: 012.8s\n",
      "Experiments completed for stochastic\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: MARKOV ADVERSARIAL ATTACK\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: MARKOV\n",
      "Category: Structured (Markov Chain Based)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 50 frames  <>  SCALED-CAPACITY: 100 frames (CAPACITY:50 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=0 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for MARKOV Exp 1: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 1: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:50, QubitAlloc=ThompsonSampling, SC:100 (Scale=2 x Cap=50), Seed: 14132\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_1\n",
      "\t‚úì QuantumExperimentRunner_1 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_100-ThompsonSampling_Adversarial_Markov-50_1_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_100-ThompsonSampling_Adversarial_Markov-50_1_paper7.pkl\n",
      "\t   File exists: True, size: 35487\n",
      "‚è© SKIPPING EXPERIMENT 1: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 1 GNEURALUCB          : Reward=0239.00, Efficiency=055.2% [Retries=3, Failed=0, < Threshold=3, SCapacity=100, Threshold=0.582]\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=0143.00, Efficiency=033.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=100, Threshold=0.628]\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=0239.00, Efficiency=055.2% [Retries=3, Failed=0, < Threshold=3, SCapacity=100, Threshold=0.634]\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=0198.00, Efficiency=045.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=100, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP1 Winner:GNeuralUCB          (Gap:044.8%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:50, SCapacity=100, Alloc=ThompsonSampling]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 100 frames  <>  SCALED-CAPACITY: 200 frames (CAPACITY:100 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=1 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for MARKOV Exp 2: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 2: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:100, QubitAlloc=ThompsonSampling, SC:200 (Scale=2 x Cap=100), Seed: 22231\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_2\n",
      "\t‚úì QuantumExperimentRunner_2 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_200-ThompsonSampling_Adversarial_Markov-100_2_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_200-ThompsonSampling_Adversarial_Markov-100_2_paper7.pkl\n",
      "\t   File exists: True, size: 62119\n",
      "‚è© SKIPPING EXPERIMENT 2: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 2 GNEURALUCB          : Reward=0434.00, Efficiency=049.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=200, Threshold=0.582]\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=0330.00, Efficiency=037.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=200, Threshold=0.628]\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=0434.00, Efficiency=049.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=200, Threshold=0.634]\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=0408.00, Efficiency=046.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=200, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP2 Winner:GNeuralUCB          (Gap:050.5%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:100, SCapacity=200, Alloc=ThompsonSampling]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 150 frames  <>  SCALED-CAPACITY: 300 frames (CAPACITY:150 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=2 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for MARKOV Exp 3: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 3: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:150, QubitAlloc=ThompsonSampling, SC:300 (Scale=2 x Cap=150), Seed: 20747\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_3\n",
      "\t‚úì QuantumExperimentRunner_3 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_300-ThompsonSampling_Adversarial_Markov-150_3_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_300-ThompsonSampling_Adversarial_Markov-150_3_paper7.pkl\n",
      "\t   File exists: True, size: 88729\n",
      "‚è© SKIPPING EXPERIMENT 3: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 3 GNEURALUCB          : Reward=0654.00, Efficiency=050.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=300, Threshold=0.582]\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=0553.00, Efficiency=042.3% [Retries=3, Failed=0, < Threshold=3, SCapacity=300, Threshold=0.628]\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=0654.00, Efficiency=050.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=300, Threshold=0.634]\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=0752.00, Efficiency=057.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=300, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP3 Winner:iCPursuitNeuralUCB  (Gap:042.5%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:150, SCapacity=300, Alloc=ThompsonSampling]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 200 frames  <>  SCALED-CAPACITY: 400 frames (CAPACITY:200 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=3 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for MARKOV Exp 4: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 4: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:200, QubitAlloc=ThompsonSampling, SC:400 (Scale=2 x Cap=200), Seed: 15410\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_4\n",
      "\t‚úì QuantumExperimentRunner_4 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_400-ThompsonSampling_Adversarial_Markov-200_4_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_400-ThompsonSampling_Adversarial_Markov-200_4_paper7.pkl\n",
      "\t   File exists: True, size: 115329\n",
      "‚è© SKIPPING EXPERIMENT 4: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 4 GNEURALUCB          : Reward=0896.00, Efficiency=051.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=400, Threshold=0.582]\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=0870.00, Efficiency=050.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=400, Threshold=0.628]\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=0896.00, Efficiency=051.5% [Retries=3, Failed=0, < Threshold=3, SCapacity=400, Threshold=0.634]\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=0918.00, Efficiency=052.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=400, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP4 Winner:iCPursuitNeuralUCB  (Gap:047.3%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:200, SCapacity=400, Alloc=ThompsonSampling]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 250 frames  <>  SCALED-CAPACITY: 500 frames (CAPACITY:250 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=4 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for MARKOV Exp 5: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (MARKOV) EXP 5: Env:Adversarial, Attack:Markov, Rate:0.25, Frames:250, QubitAlloc=ThompsonSampling, SC:500 (Scale=2 x Cap=250), Seed: 22674\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_5\n",
      "\t‚úì QuantumExperimentRunner_5 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_500-ThompsonSampling_Adversarial_Markov-250_5_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_500-ThompsonSampling_Adversarial_Markov-250_5_paper7.pkl\n",
      "\t   File exists: True, size: 141938\n",
      "‚è© SKIPPING EXPERIMENT 5: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 5 GNEURALUCB          : Reward=1150.00, Efficiency=052.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=500, Threshold=0.582]\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=1028.00, Efficiency=047.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=500, Threshold=0.628]\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=1150.00, Efficiency=052.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=500, Threshold=0.634]\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=1071.00, Efficiency=049.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=500, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP5 Winner:GNeuralUCB          (Gap:047.4%) [Env:Adversarial, Attack:Markov X Rate:0.25, Frames:250, SCapacity=500, Alloc=ThompsonSampling]\n",
      "\n",
      "Total experiment time: 014.0s\n",
      "Experiments completed for markov\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: ADAPTIVE ADVERSARIAL ATTACK\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: ADAPTIVE\n",
      "Category: Adaptive (Reactive Strategic)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 50 frames  <>  SCALED-CAPACITY: 100 frames (CAPACITY:50 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=0 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 1: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 1: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:50, QubitAlloc=ThompsonSampling, SC:100 (Scale=2 x Cap=50), Seed: 21427\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_1\n",
      "\t‚úì QuantumExperimentRunner_1 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_100-ThompsonSampling_Adversarial_Adaptive-50_1_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_100-ThompsonSampling_Adversarial_Adaptive-50_1_paper7.pkl\n",
      "\t   File exists: True, size: 35496\n",
      "‚è© SKIPPING EXPERIMENT 1: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 1 GNEURALUCB          : Reward=0271.00, Efficiency=060.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=100, Threshold=0.582]\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=0269.00, Efficiency=060.2% [Retries=3, Failed=0, < Threshold=3, SCapacity=100, Threshold=0.628]\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=0271.00, Efficiency=060.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=100, Threshold=0.634]\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=0280.00, Efficiency=062.6% [Retries=3, Failed=0, < Threshold=3, SCapacity=100, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP1 Winner:iCPursuitNeuralUCB  (Gap:037.4%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:50, SCapacity=100, Alloc=ThompsonSampling]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 100 frames  <>  SCALED-CAPACITY: 200 frames (CAPACITY:100 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=1 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 2: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 2: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:100, QubitAlloc=ThompsonSampling, SC:200 (Scale=2 x Cap=100), Seed: 13200\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_2\n",
      "\t‚úì QuantumExperimentRunner_2 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_200-ThompsonSampling_Adversarial_Adaptive-100_2_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_200-ThompsonSampling_Adversarial_Adaptive-100_2_paper7.pkl\n",
      "\t   File exists: True, size: 62125\n",
      "‚è© SKIPPING EXPERIMENT 2: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 2 GNEURALUCB          : Reward=0625.00, Efficiency=069.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=200, Threshold=0.582]\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=0555.00, Efficiency=062.0% [Retries=3, Failed=0, < Threshold=3, SCapacity=200, Threshold=0.628]\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=0625.00, Efficiency=069.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=200, Threshold=0.634]\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=0711.00, Efficiency=079.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=200, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP2 Winner:iCPursuitNeuralUCB  (Gap:020.6%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:100, SCapacity=200, Alloc=ThompsonSampling]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 150 frames  <>  SCALED-CAPACITY: 300 frames (CAPACITY:150 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=2 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 3: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 3: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:150, QubitAlloc=ThompsonSampling, SC:300 (Scale=2 x Cap=150), Seed: 18005\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_3\n",
      "\t‚úì QuantumExperimentRunner_3 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_300-ThompsonSampling_Adversarial_Adaptive-150_3_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_300-ThompsonSampling_Adversarial_Adaptive-150_3_paper7.pkl\n",
      "\t   File exists: True, size: 88735\n",
      "‚è© SKIPPING EXPERIMENT 3: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 3 GNEURALUCB          : Reward=0911.00, Efficiency=068.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=300, Threshold=0.582]\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=0843.00, Efficiency=063.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=300, Threshold=0.628]\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=0911.00, Efficiency=068.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=300, Threshold=0.634]\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=0918.00, Efficiency=068.7% [Retries=3, Failed=0, < Threshold=3, SCapacity=300, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP3 Winner:iCPursuitNeuralUCB  (Gap:031.3%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:150, SCapacity=300, Alloc=ThompsonSampling]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 200 frames  <>  SCALED-CAPACITY: 400 frames (CAPACITY:200 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=3 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 4: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 4: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:200, QubitAlloc=ThompsonSampling, SC:400 (Scale=2 x Cap=200), Seed: 12955\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_4\n",
      "\t‚úì QuantumExperimentRunner_4 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_400-ThompsonSampling_Adversarial_Adaptive-200_4_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_400-ThompsonSampling_Adversarial_Adaptive-200_4_paper7.pkl\n",
      "\t   File exists: True, size: 115335\n",
      "‚è© SKIPPING EXPERIMENT 4: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 4 GNEURALUCB          : Reward=1236.00, Efficiency=069.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=400, Threshold=0.582]\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=1251.00, Efficiency=069.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=400, Threshold=0.628]\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=1236.00, Efficiency=069.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=400, Threshold=0.634]\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=1404.00, Efficiency=078.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=400, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP4 Winner:iCPursuitNeuralUCB  (Gap:021.5%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:200, SCapacity=400, Alloc=ThompsonSampling]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 250 frames  <>  SCALED-CAPACITY: 500 frames (CAPACITY:250 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=4 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for ADAPTIVE Exp 5: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ADAPTIVE) EXP 5: Env:Adversarial, Attack:Adaptive, Rate:0.25, Frames:250, QubitAlloc=ThompsonSampling, SC:500 (Scale=2 x Cap=250), Seed: 14950\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_5\n",
      "\t‚úì QuantumExperimentRunner_5 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_500-ThompsonSampling_Adversarial_Adaptive-250_5_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_500-ThompsonSampling_Adversarial_Adaptive-250_5_paper7.pkl\n",
      "\t   File exists: True, size: 141944\n",
      "‚è© SKIPPING EXPERIMENT 5: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 5 GNEURALUCB          : Reward=1531.00, Efficiency=068.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=500, Threshold=0.582]\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=1650.00, Efficiency=073.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=500, Threshold=0.628]\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=1531.00, Efficiency=068.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=500, Threshold=0.634]\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=1683.00, Efficiency=075.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=500, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP5 Winner:iCPursuitNeuralUCB  (Gap:024.6%) [Env:Adversarial, Attack:Adaptive X Rate:0.25, Frames:250, SCapacity=500, Alloc=ThompsonSampling]\n",
      "\n",
      "Total experiment time: 014.1s\n",
      "Experiments completed for adaptive\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: ONLINE ADAPTIVE ATTACK\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: ONLINEADAPTIVE\n",
      "Category: Online Adaptive (Real-time Strategic)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 50 frames  <>  SCALED-CAPACITY: 100 frames (CAPACITY:50 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=0 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 1: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 1: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:50, QubitAlloc=ThompsonSampling, SC:100 (Scale=2 x Cap=50), Seed: 14732\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_1\n",
      "\t‚úì QuantumExperimentRunner_1 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_100-ThompsonSampling_Adversarial_OnlineAdaptive-50_1_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_1_100-ThompsonSampling_Adversarial_OnlineAdaptive-50_1_paper7.pkl\n",
      "\t   File exists: True, size: 35514\n",
      "‚è© SKIPPING EXPERIMENT 1: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 1 GNEURALUCB          : Reward=0292.00, Efficiency=065.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=100, Threshold=0.582]\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=0328.00, Efficiency=073.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=100, Threshold=0.628]\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=0292.00, Efficiency=065.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=100, Threshold=0.634]\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=0320.00, Efficiency=071.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=100, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP1 Winner:EXPNeuralUCB        (Gap:026.9%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:50, SCapacity=100, Alloc=ThompsonSampling]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 100 frames  <>  SCALED-CAPACITY: 200 frames (CAPACITY:100 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=1 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 2: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 2: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:100, QubitAlloc=ThompsonSampling, SC:200 (Scale=2 x Cap=100), Seed: 14647\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_2\n",
      "\t‚úì QuantumExperimentRunner_2 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_200-ThompsonSampling_Adversarial_OnlineAdaptive-100_2_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_2_200-ThompsonSampling_Adversarial_OnlineAdaptive-100_2_paper7.pkl\n",
      "\t   File exists: True, size: 62143\n",
      "‚è© SKIPPING EXPERIMENT 2: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 2 GNEURALUCB          : Reward=0584.00, Efficiency=065.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=200, Threshold=0.582]\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=0591.00, Efficiency=066.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=200, Threshold=0.628]\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=0584.00, Efficiency=065.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=200, Threshold=0.634]\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=0693.00, Efficiency=077.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=200, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP2 Winner:iCPursuitNeuralUCB  (Gap:022.6%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:100, SCapacity=200, Alloc=ThompsonSampling]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 150 frames  <>  SCALED-CAPACITY: 300 frames (CAPACITY:150 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=2 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 3: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 3: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:150, QubitAlloc=ThompsonSampling, SC:300 (Scale=2 x Cap=150), Seed: 21138\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_3\n",
      "\t‚úì QuantumExperimentRunner_3 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_300-ThompsonSampling_Adversarial_OnlineAdaptive-150_3_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_3_300-ThompsonSampling_Adversarial_OnlineAdaptive-150_3_paper7.pkl\n",
      "\t   File exists: True, size: 88753\n",
      "‚è© SKIPPING EXPERIMENT 3: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 3 GNEURALUCB          : Reward=0862.00, Efficiency=064.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=300, Threshold=0.582]\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=0932.00, Efficiency=069.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=300, Threshold=0.628]\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=0862.00, Efficiency=064.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=300, Threshold=0.634]\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=1035.00, Efficiency=077.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=300, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP3 Winner:iCPursuitNeuralUCB  (Gap:022.8%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:150, SCapacity=300, Alloc=ThompsonSampling]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 200 frames  <>  SCALED-CAPACITY: 400 frames (CAPACITY:200 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=3 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 4: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 4: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:200, QubitAlloc=ThompsonSampling, SC:400 (Scale=2 x Cap=200), Seed: 16677\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_4\n",
      "\t‚úì QuantumExperimentRunner_4 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_400-ThompsonSampling_Adversarial_OnlineAdaptive-200_4_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_4_400-ThompsonSampling_Adversarial_OnlineAdaptive-200_4_paper7.pkl\n",
      "\t   File exists: True, size: 115353\n",
      "‚è© SKIPPING EXPERIMENT 4: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 4 GNEURALUCB          : Reward=1156.00, Efficiency=064.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=400, Threshold=0.582]\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=1198.00, Efficiency=067.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=400, Threshold=0.628]\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=1156.00, Efficiency=064.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=400, Threshold=0.634]\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=1404.00, Efficiency=078.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=400, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP4 Winner:iCPursuitNeuralUCB  (Gap:021.5%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:200, SCapacity=400, Alloc=ThompsonSampling]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 250 frames  <>  SCALED-CAPACITY: 500 frames (CAPACITY:250 X SCALE:2)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[ThompsonAllocator] timestep=4 (uniform init) ‚Üí allocation=(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîß Allocated qubits for ONLINEADAPTIVE Exp 5: (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "üîÑ ThompsonSampling Dynamic Allocation (Initial): (5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)\n",
      "======================================================================================================================================================\n",
      "\n",
      "ADVERSARIAL (ONLINEADAPTIVE) EXP 5: Env:Adversarial, Attack:OnlineAdaptive, Rate:0.25, Frames:250, QubitAlloc=ThompsonSampling, SC:500 (Scale=2 x Cap=250), Seed: 22447\n",
      "======================================================================================================================================================\n",
      "\n",
      "\tüîÑ Resume: QuantumExperimentRunner_5\n",
      "\t‚úì QuantumExperimentRunner_5 Path validated: '/Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_500-ThompsonSampling_Adversarial_OnlineAdaptive-250_5_paper7.pkl'\n",
      "\t   Loading from: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201/QuantumExperimentRunner_5_500-ThompsonSampling_Adversarial_OnlineAdaptive-250_5_paper7.pkl\n",
      "\t   File exists: True, size: 141962\n",
      "‚è© SKIPPING EXPERIMENT 5: ALREADY COMPLETED AND STORED\n",
      "\n",
      "\tüìä EXPERIMENT RESULTS SUMMARY\n",
      "\t========================================================================================================================\n",
      "\tEXP 5 GNEURALUCB          : Reward=1544.00, Efficiency=069.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=500, Threshold=0.582]\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=1442.00, Efficiency=064.4% [Retries=0, Failed=0, < Threshold=0, SCapacity=500, Threshold=0.628]\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=1544.00, Efficiency=069.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=500, Threshold=0.634]\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=1683.00, Efficiency=075.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=500, Threshold=0.712]\n",
      "\t========================================================================================================================\n",
      "\t-->üèÜ EXP5 Winner:iCPursuitNeuralUCB  (Gap:024.8%) [Env:Adversarial, Attack:OnlineAdaptive X Rate:0.25, Frames:250, SCapacity=500, Alloc=ThompsonSampling]\n",
      "\n",
      "Total experiment time: 014.1s\n",
      "Experiments completed for onlineadaptive\n",
      "‚úì Scenario 'none' evaluation completed.\n",
      "‚úì Scenario 'stochastic' evaluation completed.\n",
      "‚úì Scenario 'markov' evaluation completed.\n",
      "‚úì Scenario 'adaptive' evaluation completed.\n",
      "‚úì Scenario 'onlineadaptive' evaluation completed.\n",
      "\n",
      "======================================================================\n",
      "COMPREHENSIVE SCENARIO PERFORMANCE ANALYSIS\n",
      "======================================================================\n",
      "SCENARIO: NONE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 1350.00\n",
      "\t‚Ä¢ Winner Avg Gap: 0000.00%\n",
      "\t‚Ä¢ Winner Avg Reward: 1350.00\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0100.00%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 5 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: NONE\n",
      "======================================================================\n",
      "SCENARIO: \tBASELINE (OPTIMAL CONDITIONS)\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 5/5 experiments)\n",
      "\tWinner Avg Gap: \t000.0%\n",
      "\tWinner Avg Efficiency: \t100.0%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t100.0% Efficiency \t(Won 5/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t088.9% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t088.1% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t088.1% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: STOCHASTIC\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 1349.60\n",
      "\t‚Ä¢ Winner Avg Gap: 0006.13%\n",
      "\t‚Ä¢ Winner Avg Reward: 1269.00\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0093.87%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 5 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: STOCHASTIC\n",
      "======================================================================\n",
      "SCENARIO: \tSTOCHASTIC RANDOM FAILURES\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 5/5 experiments)\n",
      "\tWinner Avg Gap: \t006.1%\n",
      "\tWinner Avg Efficiency: \t093.9%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t093.9% Efficiency \t(Won 5/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t083.3% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t083.3% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t080.7% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: MARKOV\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: GNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 1308.40\n",
      "\t‚Ä¢ Winner Avg Gap: 0048.23%\n",
      "\t‚Ä¢ Winner Avg Reward: 0674.60\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0051.77%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 3 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 2 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: MARKOV\n",
      "======================================================================\n",
      "SCENARIO: \tMARKOV ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tGNeuralUCB (Won 3/5 experiments)\n",
      "\tWinner Avg Gap: \t048.2%\n",
      "\tWinner Avg Efficiency: \t051.8%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ GNeuralUCB     : \t051.8% Efficiency \t(Won 3/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t051.8% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t050.3% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t042.0% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 1340.20\n",
      "\t‚Ä¢ Winner Avg Gap: 0027.08%\n",
      "\t‚Ä¢ Winner Avg Reward: 0999.20\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0072.92%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 5 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tADAPTIVE ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 5/5 experiments)\n",
      "\tWinner Avg Gap: \t027.1%\n",
      "\tWinner Avg Efficiency: \t072.9%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t072.9% Efficiency \t(Won 5/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t067.2% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t067.2% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t065.8% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ONLINEADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 1342.40\n",
      "\t‚Ä¢ Winner Avg Gap: 0024.08%\n",
      "\t‚Ä¢ Winner Avg Reward: 1027.00\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0075.92%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 1 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 4 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ONLINEADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tONLINE ADAPTIVE ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 4/5 experiments)\n",
      "\tWinner Avg Gap: \t024.1%\n",
      "\tWinner Avg Efficiency: \t075.9%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t075.9% Efficiency \t(Won 4/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t068.0% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t065.6% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t065.6% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "KEY INSIGHTS:\n",
      "Best Performing Model Analysis (iCPursuitNeuralUCB):\n",
      "\t‚Ä¢ Stochastic Performance:    \t1269.000\n",
      "\t‚Ä¢ Baseline Performance:      \t1350.000\n",
      "\t‚Ä¢ Performance Retention:     \t094.0%\n",
      "\tGOOD:               \tAcceptable performance under stochastic conditions\n",
      "Statistical Analysis:\n",
      "\t‚Ä¢ Total models evaluated:     \t5\n",
      "\t‚Ä¢ Experiments per environment:\t5\n",
      "\t‚Ä¢ Quantum network simulation: \tComprehensive stochastic modeling\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "COMPREHENSIVE SCENARIO PERFORMANCE ANALYSIS\n",
      "======================================================================\n",
      "SCENARIO: NONE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 1350.00\n",
      "\t‚Ä¢ Winner Avg Gap: 0000.00%\n",
      "\t‚Ä¢ Winner Avg Reward: 1350.00\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0100.00%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 5 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: NONE\n",
      "======================================================================\n",
      "SCENARIO: \tBASELINE (OPTIMAL CONDITIONS)\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 5/5 experiments)\n",
      "\tWinner Avg Gap: \t000.0%\n",
      "\tWinner Avg Efficiency: \t100.0%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t100.0% Efficiency \t(Won 5/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t088.9% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t088.1% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t088.1% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: STOCHASTIC\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 1349.60\n",
      "\t‚Ä¢ Winner Avg Gap: 0006.13%\n",
      "\t‚Ä¢ Winner Avg Reward: 1269.00\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0093.87%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 5 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: STOCHASTIC\n",
      "======================================================================\n",
      "SCENARIO: \tSTOCHASTIC RANDOM FAILURES\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 5/5 experiments)\n",
      "\tWinner Avg Gap: \t006.1%\n",
      "\tWinner Avg Efficiency: \t093.9%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t093.9% Efficiency \t(Won 5/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t083.3% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t083.3% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t080.7% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: MARKOV\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: GNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 1308.40\n",
      "\t‚Ä¢ Winner Avg Gap: 0048.23%\n",
      "\t‚Ä¢ Winner Avg Reward: 0674.60\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0051.77%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 3 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 2 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: MARKOV\n",
      "======================================================================\n",
      "SCENARIO: \tMARKOV ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tGNeuralUCB (Won 3/5 experiments)\n",
      "\tWinner Avg Gap: \t048.2%\n",
      "\tWinner Avg Efficiency: \t051.8%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ GNeuralUCB     : \t051.8% Efficiency \t(Won 3/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t051.8% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t050.3% Efficiency \t(Won 2/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t042.0% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 1340.20\n",
      "\t‚Ä¢ Winner Avg Gap: 0027.08%\n",
      "\t‚Ä¢ Winner Avg Reward: 0999.20\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0072.92%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 0 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 5 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tADAPTIVE ADVERSARIAL ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 5/5 experiments)\n",
      "\tWinner Avg Gap: \t027.1%\n",
      "\tWinner Avg Efficiency: \t072.9%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t072.9% Efficiency \t(Won 5/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t067.2% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t067.2% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t065.8% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "SCENARIO: ONLINEADAPTIVE\n",
      "\t‚Ä¢ Total Experiments: 5\n",
      "\t‚Ä¢ Overall Winner: iCPursuitNeuralUCB\n",
      "\t‚Ä¢ Oracle Avg Reward: 1342.40\n",
      "\t‚Ä¢ Winner Avg Gap: 0024.08%\n",
      "\t‚Ä¢ Winner Avg Reward: 1027.00\n",
      "\t‚Ä¢ Winner Avg Efficiency: 0075.92%\n",
      "\t‚Ä¢ Win Counts:\n",
      "\t\t- Oracle: 0 wins\n",
      "\t\t- GNeuralUCB: 0 wins\n",
      "\t\t- EXPNeuralUCB: 1 wins\n",
      "\t\t- CPursuitNeuralUCB: 0 wins\n",
      "\t\t- iCPursuitNeuralUCB: 4 wins\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "DETAILED SCENARIO PERFORMANCE: ONLINEADAPTIVE\n",
      "======================================================================\n",
      "SCENARIO: \tONLINE ADAPTIVE ATTACK\n",
      "----------------------------------------\n",
      "Recommended Model: \tiCPursuitNeuralUCB (Won 4/5 experiments)\n",
      "\tWinner Avg Gap: \t024.1%\n",
      "\tWinner Avg Efficiency: \t075.9%\n",
      "\n",
      "Overall Models Performance:\n",
      "\t‚Ä¢ iCPursuitNeuralUCB: \t075.9% Efficiency \t(Won 4/5 experiments)\n",
      "\t‚Ä¢ EXPNeuralUCB   : \t068.0% Efficiency \t(Won 1/5 experiments)\n",
      "\t‚Ä¢ GNeuralUCB     : \t065.6% Efficiency \t(Won 0/5 experiments)\n",
      "\t‚Ä¢ CPursuitNeuralUCB: \t065.6% Efficiency \t(Won 0/5 experiments)\n",
      "======================================================================\n",
      "‚úÖ Evaluation completed!\n",
      "[Logging Redirect Stopped]\n",
      "\n",
      "üßπ Final cleanup for ThompsonSampling\n",
      "\n",
      "======================================================================\n",
      "‚úÖ COMPLETED: ThompsonSampling\n",
      "======================================================================\n",
      "\n",
      "ThompsonSampling COMPLETED SUCCESSFULLY\n",
      "\n",
      "======================================================================\n",
      "ALL ALLOCATORS COMPLETE!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Cell 2: Allocator + ExperimentConfiguration for Paper #7\n",
    "# ============================================================\n",
    "importlib.reload(qubit_allocator)\n",
    "importlib.reload(experiment_config)\n",
    "importlib.reload(multi_run_evaluator)\n",
    "\n",
    "from daqr.core.quantum_physics              import *\n",
    "from daqr.evaluation.allocator_runner       import AllocatorRunner\n",
    "from daqr.evaluation.multi_run_evaluator    import MultiRunEvaluator\n",
    "from daqr.config.experiment_config          import ExperimentConfiguration\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"PAPER #7 (QBGP) QUANTUM ROUTING EVALUATION - SINGLE ALLOCATOR TEST\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1) Single Allocator Selection\n",
    "# ------------------------------------------------------------\n",
    "allocator_type = \"ThompsonSampling\"  # Options: \"Random\", \"Dynamic\", \"ThompsonSampling\"\n",
    "ALLOCATORS = [allocator_type]\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2) Run Parameters\n",
    "# ------------------------------------------------------------\n",
    "attack_intensity    = FRAMEWORK_CONFIG['intensity']\n",
    "current_frames      = 50\n",
    "frame_step          = 50\n",
    "current_experiments = 5\n",
    "last_backup         = True\n",
    "base_cap            = False\n",
    "overwrite           = True\n",
    "\n",
    "FRAMEWORK_CONFIG['exp_num']        = current_experiments\n",
    "FRAMEWORK_CONFIG['base_frames']    = current_frames\n",
    "FRAMEWORK_CONFIG['frame_step']     = frame_step\n",
    "\n",
    "\n",
    "# Testbed Configuration\n",
    "PHYSICS_MODELS = ['paper7']  # Paper 7 (QBGP)\n",
    "ATTACK_SCENARIOS = ['stochastic']  # Start simple\n",
    "SCALES = [1, 1.5, 2]\n",
    "RUNS = [5]\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üéØ PAPER 7 ALLOCATOR EVALUATION\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Allocator:                  {allocator_type}\")\n",
    "print(f\"Physics Model:              {PHYSICS_MODELS[0]}\")\n",
    "print(f\"Attack Scenarios:           {ATTACK_SCENARIOS}\")\n",
    "print(f\"Scales:                     {SCALES}\")\n",
    "print(f\"Runs per Scale:             {RUNS}\")\n",
    "print(f\"Total Frames:               {current_frames}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Run allocators over scales and physics models\n",
    "for allocator_type in ALLOCATORS:\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"RUNNING: {allocator_type} on Paper 7 (QBGP)\")\n",
    "    print('='*70)\n",
    "\n",
    "    for scale in SCALES:\n",
    "        print(f\"\\n{'-'*70}\")\n",
    "        print(f\"Preparing: {allocator_type} at scale {scale}\")\n",
    "        print(f\"{'-'*70}\")\n",
    "\n",
    "        for physics_model in PHYSICS_MODELS:\n",
    "            print(f\"\\nüîß Generating physics parameters for model: {physics_model}\") \n",
    "            try:\n",
    "                # Create isolated runner instance\n",
    "                custom_config = ExperimentConfiguration(\n",
    "                    env_type=FRAMEWORK_CONFIG['main_env'],\n",
    "                    scenarios=test_scenarios,\n",
    "                    use_last_backup=last_backup,\n",
    "                    models=models,\n",
    "                    attack_intensity=attack_intensity,\n",
    "                    scale=scale,\n",
    "                    base_capacity=base_cap,\n",
    "                    overwrite=overwrite\n",
    "                )\n",
    "\n",
    "                alloc_runner = AllocatorRunner(\n",
    "                    allocator_type=allocator_type,\n",
    "                    physics_models=[physics_model],\n",
    "                    framework_config=FRAMEWORK_CONFIG,\n",
    "                    scales=[scale],\n",
    "                    runs=RUNS,\n",
    "                    models=models,\n",
    "                    test_scenarios=test_scenarios,\n",
    "                    config=custom_config\n",
    "                )\n",
    "\n",
    "                # Run with Paper 12 physics\n",
    "                alloc_runner.run(get_physics_params_func=get_physics_params)\n",
    "                print(f\"\\n{allocator_type} COMPLETED SUCCESSFULLY\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"\\n{allocator_type} FAILED: {e}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ALL ALLOCATORS COMPLETE!\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "robustness-analysis",
    "outputId": "d5bf77ec-ed26-474f-b68b-650ab683fece"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "PAPER #7 (QBGP) QUANTUM ROUTING EVALUATION - SINGLE ALLOCATOR TEST\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "üéØ PAPER 7 ALLOCATOR EVALUATION\n",
      "======================================================================\n",
      "Allocator:                  Random\n",
      "Physics Model:              paper7\n",
      "Attack Scenarios:           ['stochastic']\n",
      "Scales:                     [1, 1.5, 2]\n",
      "Runs per Scale:             [5]\n",
      "Total Frames:               50\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "RUNNING: Random on Paper 7 (QBGP)\n",
      "======================================================================\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Preparing: Random at scale 1\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üîß Generating physics parameters for model: paper7\n",
      "\n",
      "===================== GET LOCAL REGISTRY =====================\n",
      "‚Üí Skipping local cache (force=True or file missing)\n",
      "\n",
      "===================== BUILD LOCAL REGISTRY =====================\n",
      "\n",
      "================================================================================\n",
      "üîç SCANNING LOCAL FILES\n",
      "================================================================================\n",
      "Parameters: load_to_drive=False, force=False\n",
      "\n",
      "üìÇ Checking DRIVE mode: /content/drive/Shareddrives/ai_quantum_computing/quantum_data_lake\n",
      "   ‚ö†Ô∏è  Path does not exist, skipping\n",
      "\n",
      "üìÇ Checking LOCAL mode: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config\n",
      "   ‚úÖ Path exists, starting walk...\n",
      "   üö∂ Walking directory tree: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config\n",
      "\n",
      "   üìÅ Directory: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/framework_state/day_20260201\n",
      "      Relative: framework_state/day_20260201\n",
      "      Component: framework_state\n",
      "      Date: day_20260201\n",
      "      üìÑ Processing 2569 files in framework_state/day_20260201\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "      üìä framework_state/day_20260201: 2543/2569 files processed\n",
      "      üìä framework_state/day_20260201: 0/2569 files skipped\n",
      "      üìä framework_state/day_20260201: 26/2569 files conflicted\n",
      "\n",
      "   üìÅ Directory: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/model_state/day_20260201\n",
      "      Relative: model_state/day_20260201\n",
      "      Component: model_state\n",
      "      Date: day_20260201\n",
      "      üìÑ Processing 9316 files in model_state/day_20260201\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "      üìä model_state/day_20260201: 9316/9316 files processed\n",
      "      üìä model_state/day_20260201: 0/9316 files skipped\n",
      "      üìä model_state/day_20260201: 0/9316 files conflicted\n",
      "\n",
      "   üìä Processed 2 directories\n",
      "\n",
      "================================================================================\n",
      "üì¶ BUILDING FINAL REGISTRY\n",
      "================================================================================\n",
      "Components found: ['framework_state', 'model_state']\n",
      "  ‚Ä¢ framework_state: 2543 files\n",
      "  ‚Ä¢ model_state: 9316 files\n",
      "\n",
      "‚úÖ SCAN COMPLETE\n",
      "Modes scanned: 1\n",
      "Total files in registry: 11859\n",
      "================================================================================\n",
      "\n",
      "\t‚Üí Filesystem scan found 11859 files\n",
      "\n",
      "===================== GET DRIVE REGISTRY =====================\n",
      "===================== REGISTRY BUILD COMPLETE =====================\n",
      "\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "\tüì¶ LocalBackupManager Registry Saved Locally in LOCAL\n",
      "BUILDING REGISTRY WITH 0 EXPECTED COMPONENTS KEYS\n",
      "\n",
      "===================== GET LOCAL REGISTRY =====================\n",
      "‚Üí Skipping local cache (force=True or file missing)\n",
      "\n",
      "==================== FETCH FROM DRIVE START ====================\n",
      "‚Üí Looking for 'backup_registry.json' in Drive folder: 0APT9hcMpvuHYUk9PVA\n",
      "‚Üí No registry file found in Drive\n",
      "==================== FETCH FROM DRIVE END =====================\n",
      "\n",
      "\tüì¶ LocalBackupManager Registry Saved Locally in LOCAL\n",
      "\n",
      "======================================================================\n",
      "üéØ AllocatorRunner initialized: Random\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "üöÄ STARTING ALLOCATOR: Random\n",
      "======================================================================\n",
      "\n",
      "üìä Physics Model: paper7\n",
      "\n",
      "üìã Allocator Config:\n",
      "   Type: Random\n",
      "   Testbed: default\n",
      "   Paths: 15\n",
      "   Total Qubits: 75\n",
      "   Min per route: 2\n",
      "   Seed: 42\n",
      "   Epsilon: 1.0, Decay: 1.0\n",
      "‚úÖ Allocator created: (10, 6, 4, 2, 3, 2, 8, 5, 5, 2, 13, 7, 3, 3, 2)\n",
      "‚úì Allocator: RandomQubitAllocator (15 paths)\n",
      "   Initial allocation: (5, 2, 14, 5, 4, 2, 4, 4, 6, 5, 9, 3, 3, 2, 7)\n",
      "üìä Paper7 Topology: Real AS (as20000101.txt)\n",
      "üìä Paper7 Paths: 15 paths from 5-shortest between 3 ISPs\n",
      "üìä Paper7 Contexts: 15 context vectors generated\n",
      "üìä Paper7 Rewards: Context-aware (mode=neg_hop)\n",
      "‚è±Ô∏è  get_physics_params_paper7() time: 3.5 ms\n",
      "\n",
      "======================================================================\n",
      "RUN 1 | Scale: 1 | Exp: 5\n",
      "======================================================================\n",
      "üîÑ Random Dynamic Allocation (Initial): (9, 7, 3, 3, 4, 5, 4, 5, 2, 4, 3, 12, 6, 5, 3)\n",
      "\n",
      "\tüîÑ Resume: MultiRunEvaluator\n",
      "\n",
      "=====================================================\n",
      "üîç GENERATING EXPECTED KEYS FROM EVALUATOR\n",
      "=====================================================\n",
      "  ‚Ä¢ Evaluator filename: MultiRunEvaluator_50-Random_All_All-50_50_5_S1T_paper7.pkl\n",
      "\n",
      "üß© PARSED COMPONENTS\n",
      "  ‚Ä¢ cap_id:        50\n",
      "  ‚Ä¢ allocator_id:  Random\n",
      "  ‚Ä¢ env_id:        All\n",
      "  ‚Ä¢ attack_id:     All\n",
      "  ‚Ä¢ base_frames:   50\n",
      "  ‚Ä¢ frame_step:    50\n",
      "  ‚Ä¢ runs_id:       5\n",
      "\n",
      "=====================================================\n",
      "üß™ GENERATING KEYS FOR EACH RUN\n",
      "=====================================================\n",
      "\n",
      "--- Run 1/5 -----------------------\n",
      "\n",
      "=====================================================\n",
      "üì¶ FINAL EXPECTED KEYS\n",
      "=====================================================\n",
      "  ‚Ä¢ Runner keys: 11\n",
      "\n",
      "  ‚Ä¢ Model keys: 50\n",
      "\n",
      "--- Run 2/5 -----------------------\n",
      "\n",
      "=====================================================\n",
      "üì¶ FINAL EXPECTED KEYS\n",
      "=====================================================\n",
      "  ‚Ä¢ Runner keys: 21\n",
      "\n",
      "  ‚Ä¢ Model keys: 100\n",
      "\n",
      "--- Run 3/5 -----------------------\n",
      "\n",
      "=====================================================\n",
      "üì¶ FINAL EXPECTED KEYS\n",
      "=====================================================\n",
      "  ‚Ä¢ Runner keys: 31\n",
      "\n",
      "  ‚Ä¢ Model keys: 150\n",
      "\n",
      "--- Run 4/5 -----------------------\n",
      "\n",
      "=====================================================\n",
      "üì¶ FINAL EXPECTED KEYS\n",
      "=====================================================\n",
      "  ‚Ä¢ Runner keys: 41\n",
      "\n",
      "  ‚Ä¢ Model keys: 200\n",
      "\n",
      "--- Run 5/5 -----------------------\n",
      "\n",
      "=====================================================\n",
      "üì¶ FINAL EXPECTED KEYS\n",
      "=====================================================\n",
      "  ‚Ä¢ Runner keys: 51\n",
      "\n",
      "  ‚Ä¢ Model keys: 250\n",
      "\n",
      "EXPECTED KEY GENERATION COMPLETE\n",
      "\n",
      "RESTORING FROM DRIVE 1\n",
      "RESTORING FROM DRIVE 2\n",
      "\t‚ö†Ô∏è Registry exists ‚Üí aborting restore\n",
      "\t‚òÅÔ∏è Attempting Drive download: framework_state/MultiRunEvaluator_50-Random_All_All-50_50_5_S1T_paper7.pkl\n",
      "\t‚ùå Not found anywhere: framework_state/MultiRunEvaluator_50-Random_All_All-50_50_5_S1T_paper7.pkl\n",
      "\t‚ùå Not found in registry or fallback locations\n",
      "\t‚òÅÔ∏è Attempting Drive download: framework_state/MultiRunEvaluator_50-Random_All_All-50_50_5_S1T_paper7.pkl\n",
      "\t‚ùå Not found anywhere: framework_state/MultiRunEvaluator_50-Random_All_All-50_50_5_S1T_paper7.pkl\n",
      "\t‚ùå Not found in registry or fallback locations\n",
      "[Resume] exact failed ‚Üí Looking for supersets\n",
      "[Resume-Supersets] target_runs=5, backups=dict_keys([])\n",
      "[Resume-Supersets] Trying horizons in size order (largest first): []\n",
      "[Resume-Supersets] ‚ùå No valid supersets found for resume\n",
      "No state found for MultiRunEvaluator, disabling resume for Experiment Runners\n",
      "Multi-Run Evaluator Initialized\n",
      "Environment Type: None\n",
      "Frame Range: 50 -> 250 (step: 50)\n",
      "quantum_exps-Random(paper7)_alloc-all_envs-5_attacks-50_50-5_runs-S1T\n",
      "[Logging Redirect Initialized]\n",
      "Log File: /Users/pitergarcia/DataScience/Semester4/GA-Work/hybrid_variable_framework/Dynamic_Routing_Eval_Framework/daqr/config/quantum_logs/quantum_exps-Random(paper7)_alloc-all_envs-5_attacks-50_50-5_runs-S1T_20260201_log.txt\n",
      "‚öô Running evaluation...\n",
      "======================================================================\n",
      "SCENARIOS MODEL EVALUATION\n",
      "======================================================================\n",
      "Testing algorithm performance against:\n",
      "\t‚Ä¢ Stochastic:  \tNatural quantum decoherence and network failures\n",
      "\t‚Ä¢ Baseline:    \tOptimal conditions for validation\n",
      "======================================================================\n",
      "Models to Test:             \tOracle, GNeuralUCB, EXPNeuralUCB, CPursuitNeuralUCB, iCPursuitNeuralUCB\n",
      "Experiments per Scenario:   \t5\n",
      "======================================================================\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: BASELINE (OPTIMAL CONDITIONS)\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: NONE\n",
      "Category: Baseline (No Attacks)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 50 frames  <>  SCALED-CAPACITY: 50 frames (CAPACITY:50 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[RandomAllocator Œµ=1.000] timestep=0 mode=random ‚Üí allocation=(9, 7, 3, 3, 4, 5, 4, 5, 2, 4, 3, 12, 6, 5, 3)\n",
      "üîß Allocated qubits for NONE Exp 1: (9, 7, 3, 3, 4, 5, 4, 5, 2, 4, 3, 12, 6, 5, 3)\n",
      "üîÑ Random Dynamic Allocation (Initial): (4, 5, 4, 3, 3, 2, 4, 4, 3, 3, 2, 6, 6, 3, 23)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 1: Env:Baseline (None), Attack:No, Rate:0.0, Frames:50, QubitAlloc=Random, SC:50 (Scale=1 x Cap=50), Seed: 15373\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 15\n",
      "\t   First reward: [9.0], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 1: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 GNEURALUCB          : Reward=0396.00, Efficiency=088.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=50, Threshold=0.582]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 1: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=0396.00, Efficiency=088.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=50, Threshold=0.628]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 1: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=0396.00, Efficiency=088.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=50, Threshold=0.634]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 1: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=0450.00, Efficiency=100.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=50, Threshold=0.712]\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 1: Env:Baseline (None), Attack:No, Rate:0.0, Frames:50, QubitAlloc=Random, SC:50 (Scale=1 x Cap=50), Seed: 15373\n",
      "\t-->üèÜ EXP1 Winner:iCPursuitNeuralUCB  (Gap:000.0%) [Env:Baseline (None), Attack:No X Rate:0.0, Frames:50, SCapacity=50, Alloc=Random]\n",
      "‚úì Experiment 1 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 100 frames  <>  SCALED-CAPACITY: 100 frames (CAPACITY:100 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[RandomAllocator Œµ=1.000] timestep=1 mode=random ‚Üí allocation=(4, 5, 4, 3, 3, 2, 4, 4, 3, 3, 2, 6, 6, 3, 23)\n",
      "üîß Allocated qubits for NONE Exp 2: (4, 5, 4, 3, 3, 2, 4, 4, 3, 3, 2, 6, 6, 3, 23)\n",
      "üîÑ Random Dynamic Allocation (Initial): (10, 3, 3, 2, 9, 8, 2, 5, 6, 4, 3, 3, 2, 8, 7)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 2: Env:Baseline (None), Attack:No, Rate:0.0, Frames:100, QubitAlloc=Random, SC:100 (Scale=1 x Cap=100), Seed: 12644\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 15\n",
      "\t   First reward: [9.0], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 2: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 GNEURALUCB          : Reward=0794.00, Efficiency=088.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=100, Threshold=0.582]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 2: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=0830.00, Efficiency=092.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=100, Threshold=0.628]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 2: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=0794.00, Efficiency=088.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=100, Threshold=0.634]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 2: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=0900.00, Efficiency=100.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=100, Threshold=0.712]\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 2: Env:Baseline (None), Attack:No, Rate:0.0, Frames:100, QubitAlloc=Random, SC:100 (Scale=1 x Cap=100), Seed: 12644\n",
      "\t-->üèÜ EXP2 Winner:iCPursuitNeuralUCB  (Gap:000.0%) [Env:Baseline (None), Attack:No X Rate:0.0, Frames:100, SCapacity=100, Alloc=Random]\n",
      "‚úì Experiment 2 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 150 frames  <>  SCALED-CAPACITY: 150 frames (CAPACITY:150 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[RandomAllocator Œµ=1.000] timestep=2 mode=random ‚Üí allocation=(10, 3, 3, 2, 9, 8, 2, 5, 6, 4, 3, 3, 2, 8, 7)\n",
      "üîß Allocated qubits for NONE Exp 3: (10, 3, 3, 2, 9, 8, 2, 5, 6, 4, 3, 3, 2, 8, 7)\n",
      "üîÑ Random Dynamic Allocation (Initial): (6, 4, 4, 3, 2, 6, 3, 2, 5, 3, 11, 11, 9, 3, 3)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 3: Env:Baseline (None), Attack:No, Rate:0.0, Frames:150, QubitAlloc=Random, SC:150 (Scale=1 x Cap=150), Seed: 20257\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 15\n",
      "\t   First reward: [9.0], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 3: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 GNEURALUCB          : Reward=1190.00, Efficiency=088.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=150, Threshold=0.582]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 3: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=1229.00, Efficiency=091.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=150, Threshold=0.628]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 3: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=1190.00, Efficiency=088.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=150, Threshold=0.634]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 3: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=1350.00, Efficiency=100.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=150, Threshold=0.712]\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 3: Env:Baseline (None), Attack:No, Rate:0.0, Frames:150, QubitAlloc=Random, SC:150 (Scale=1 x Cap=150), Seed: 20257\n",
      "\t-->üèÜ EXP3 Winner:iCPursuitNeuralUCB  (Gap:000.0%) [Env:Baseline (None), Attack:No X Rate:0.0, Frames:150, SCapacity=150, Alloc=Random]\n",
      "‚úì Experiment 3 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 200 frames  <>  SCALED-CAPACITY: 200 frames (CAPACITY:200 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[RandomAllocator Œµ=1.000] timestep=3 mode=random ‚Üí allocation=(6, 4, 4, 3, 2, 6, 3, 2, 5, 3, 11, 11, 9, 3, 3)\n",
      "üîß Allocated qubits for NONE Exp 4: (6, 4, 4, 3, 2, 6, 3, 2, 5, 3, 11, 11, 9, 3, 3)\n",
      "üîÑ Random Dynamic Allocation (Initial): (9, 3, 5, 3, 5, 3, 2, 14, 8, 8, 2, 2, 3, 4, 4)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 4: Env:Baseline (None), Attack:No, Rate:0.0, Frames:200, QubitAlloc=Random, SC:200 (Scale=1 x Cap=200), Seed: 20031\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 15\n",
      "\t   First reward: [9.0], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 4: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 GNEURALUCB          : Reward=1586.00, Efficiency=088.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=200, Threshold=0.582]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 4: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=1567.00, Efficiency=087.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=200, Threshold=0.628]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 4: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=1586.00, Efficiency=088.1% [Retries=0, Failed=0, < Threshold=0, SCapacity=200, Threshold=0.634]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 4: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=1800.00, Efficiency=100.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=200, Threshold=0.712]\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 4: Env:Baseline (None), Attack:No, Rate:0.0, Frames:200, QubitAlloc=Random, SC:200 (Scale=1 x Cap=200), Seed: 20031\n",
      "\t-->üèÜ EXP4 Winner:iCPursuitNeuralUCB  (Gap:000.0%) [Env:Baseline (None), Attack:No X Rate:0.0, Frames:200, SCapacity=200, Alloc=Random]\n",
      "‚úì Experiment 4 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 250 frames  <>  SCALED-CAPACITY: 250 frames (CAPACITY:250 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[RandomAllocator Œµ=1.000] timestep=4 mode=random ‚Üí allocation=(9, 3, 5, 3, 5, 3, 2, 14, 8, 8, 2, 2, 3, 4, 4)\n",
      "üîß Allocated qubits for NONE Exp 5: (9, 3, 5, 3, 5, 3, 2, 14, 8, 8, 2, 2, 3, 4, 4)\n",
      "üîÑ Random Dynamic Allocation (Initial): (3, 3, 2, 3, 13, 3, 3, 6, 6, 3, 4, 6, 2, 10, 8)\n",
      "======================================================================================================================================================\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 5: Env:Baseline (None), Attack:No, Rate:0.0, Frames:250, QubitAlloc=Random, SC:250 (Scale=1 x Cap=250), Seed: 17303\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 15\n",
      "\t   First reward: [9.0], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 5: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 GNEURALUCB          : Reward=1984.00, Efficiency=088.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=250, Threshold=0.582]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 5: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 EXPNEURALUCB        : Reward=1879.00, Efficiency=083.5% [Retries=0, Failed=0, < Threshold=0, SCapacity=250, Threshold=0.628]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 5: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 CPURSUITNEURALUCB   : Reward=1984.00, Efficiency=088.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=250, Threshold=0.634]\n",
      "\n",
      "\tüîÑ BASELINE (NONE) (NO) EXP 5: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 ICPURSUITNEURALUCB  : Reward=2250.00, Efficiency=100.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=250, Threshold=0.712]\n",
      "\n",
      "BASELINE (NONE) (NO) EXP 5: Env:Baseline (None), Attack:No, Rate:0.0, Frames:250, QubitAlloc=Random, SC:250 (Scale=1 x Cap=250), Seed: 17303\n",
      "\t-->üèÜ EXP5 Winner:iCPursuitNeuralUCB  (Gap:000.0%) [Env:Baseline (None), Attack:No X Rate:0.0, Frames:250, SCapacity=250, Alloc=Random]\n",
      "‚úì Experiment 5 completed successfully.\n",
      "Total experiment time: 1105.7s\n",
      "Experiments completed for none\n",
      "\n",
      "\n",
      "\n",
      "TESTING ENVIRONMENT SCENARIO: STOCHASTIC RANDOM FAILURES\n",
      "==================================================\n",
      "\n",
      "STARTING EXPERIMENTS: STOCHASTIC\n",
      "Category: Stochastic (Natural Random Failures)\n",
      "============================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 1: 50 frames  <>  SCALED-CAPACITY: 50 frames (CAPACITY:50 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[RandomAllocator Œµ=1.000] timestep=0 mode=random ‚Üí allocation=(3, 3, 2, 3, 13, 3, 3, 6, 6, 3, 4, 6, 2, 10, 8)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 1: (3, 3, 2, 3, 13, 3, 3, 6, 6, 3, 4, 6, 2, 10, 8)\n",
      "üîÑ Random Dynamic Allocation (Initial): (2, 4, 13, 5, 4, 5, 4, 7, 2, 3, 4, 9, 5, 2, 6)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 1: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:50, QubitAlloc=Random, SC:50 (Scale=1 x Cap=50), Seed: 15729\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 15\n",
      "\t   First reward: [9.0], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 1: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 GNEURALUCB          : Reward=0381.00, Efficiency=084.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=50, Threshold=0.582]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 1: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 EXPNEURALUCB        : Reward=0389.00, Efficiency=086.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=50, Threshold=0.628]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 1: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 CPURSUITNEURALUCB   : Reward=0381.00, Efficiency=084.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=50, Threshold=0.634]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 1: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 1 ICPURSUITNEURALUCB  : Reward=0423.00, Efficiency=094.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=50, Threshold=0.712]\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 1: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:50, QubitAlloc=Random, SC:50 (Scale=1 x Cap=50), Seed: 15729\n",
      "\t-->üèÜ EXP1 Winner:iCPursuitNeuralUCB  (Gap:005.8%) [Env:Stochastic, Attack:Random X Rate:0.0625, Frames:50, SCapacity=50, Alloc=Random]\n",
      "‚úì Experiment 1 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 2: 100 frames  <>  SCALED-CAPACITY: 100 frames (CAPACITY:100 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[RandomAllocator Œµ=1.000] timestep=1 mode=random ‚Üí allocation=(2, 4, 13, 5, 4, 5, 4, 7, 2, 3, 4, 9, 5, 2, 6)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 2: (2, 4, 13, 5, 4, 5, 4, 7, 2, 3, 4, 9, 5, 2, 6)\n",
      "üîÑ Random Dynamic Allocation (Initial): (7, 8, 6, 3, 3, 3, 7, 3, 4, 3, 5, 6, 7, 2, 8)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 2: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:100, QubitAlloc=Random, SC:100 (Scale=1 x Cap=100), Seed: 19894\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 15\n",
      "\t   First reward: [9.0], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 2: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 GNEURALUCB          : Reward=0726.00, Efficiency=080.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=100, Threshold=0.582]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 2: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 EXPNEURALUCB        : Reward=0692.00, Efficiency=076.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=100, Threshold=0.628]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 2: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 CPURSUITNEURALUCB   : Reward=0726.00, Efficiency=080.7% [Retries=0, Failed=0, < Threshold=0, SCapacity=100, Threshold=0.634]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 2: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 2 ICPURSUITNEURALUCB  : Reward=0828.00, Efficiency=092.0% [Retries=0, Failed=0, < Threshold=0, SCapacity=100, Threshold=0.712]\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 2: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:100, QubitAlloc=Random, SC:100 (Scale=1 x Cap=100), Seed: 19894\n",
      "\t-->üèÜ EXP2 Winner:iCPursuitNeuralUCB  (Gap:008.0%) [Env:Stochastic, Attack:Random X Rate:0.0625, Frames:100, SCapacity=100, Alloc=Random]\n",
      "‚úì Experiment 2 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 3: 150 frames  <>  SCALED-CAPACITY: 150 frames (CAPACITY:150 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[RandomAllocator Œµ=1.000] timestep=2 mode=random ‚Üí allocation=(7, 8, 6, 3, 3, 3, 7, 3, 4, 3, 5, 6, 7, 2, 8)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 3: (7, 8, 6, 3, 3, 3, 7, 3, 4, 3, 5, 6, 7, 2, 8)\n",
      "üîÑ Random Dynamic Allocation (Initial): (2, 17, 6, 3, 5, 8, 11, 2, 3, 3, 4, 2, 4, 3, 2)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 3: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:150, QubitAlloc=Random, SC:150 (Scale=1 x Cap=150), Seed: 16736\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 15\n",
      "\t   First reward: [9.0], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 3: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 GNEURALUCB          : Reward=1142.00, Efficiency=084.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=150, Threshold=0.582]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 3: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 EXPNEURALUCB        : Reward=1156.00, Efficiency=085.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=150, Threshold=0.628]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 3: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 CPURSUITNEURALUCB   : Reward=1142.00, Efficiency=084.6% [Retries=0, Failed=0, < Threshold=0, SCapacity=150, Threshold=0.634]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 3: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 3 ICPURSUITNEURALUCB  : Reward=1260.00, Efficiency=093.3% [Retries=0, Failed=0, < Threshold=0, SCapacity=150, Threshold=0.712]\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 3: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:150, QubitAlloc=Random, SC:150 (Scale=1 x Cap=150), Seed: 16736\n",
      "\t-->üèÜ EXP3 Winner:iCPursuitNeuralUCB  (Gap:006.7%) [Env:Stochastic, Attack:Random X Rate:0.0625, Frames:150, SCapacity=150, Alloc=Random]\n",
      "‚úì Experiment 3 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 4: 200 frames  <>  SCALED-CAPACITY: 200 frames (CAPACITY:200 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[RandomAllocator Œµ=1.000] timestep=3 mode=random ‚Üí allocation=(2, 17, 6, 3, 5, 8, 11, 2, 3, 3, 4, 2, 4, 3, 2)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 4: (2, 17, 6, 3, 5, 8, 11, 2, 3, 3, 4, 2, 4, 3, 2)\n",
      "üîÑ Random Dynamic Allocation (Initial): (5, 6, 11, 5, 7, 7, 3, 2, 3, 2, 4, 2, 9, 7, 2)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 4: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:200, QubitAlloc=Random, SC:200 (Scale=1 x Cap=200), Seed: 12981\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 15\n",
      "\t   First reward: [9.0], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 4: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 GNEURALUCB          : Reward=1488.00, Efficiency=082.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=200, Threshold=0.582]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 4: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 EXPNEURALUCB        : Reward=1524.00, Efficiency=084.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=200, Threshold=0.628]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 4: Starting CPursuitNeuralUCB    in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 CPURSUITNEURALUCB   : Reward=1488.00, Efficiency=082.8% [Retries=0, Failed=0, < Threshold=0, SCapacity=200, Threshold=0.634]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 4: Starting iCPursuitNeuralUCB   in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 4 ICPURSUITNEURALUCB  : Reward=1674.00, Efficiency=093.2% [Retries=0, Failed=0, < Threshold=0, SCapacity=200, Threshold=0.712]\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 4: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:200, QubitAlloc=Random, SC:200 (Scale=1 x Cap=200), Seed: 12981\n",
      "\t-->üèÜ EXP4 Winner:iCPursuitNeuralUCB  (Gap:006.8%) [Env:Stochastic, Attack:Random X Rate:0.0625, Frames:200, SCapacity=200, Alloc=Random]\n",
      "‚úì Experiment 4 completed successfully.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EXPERIMENT 5: 250 frames  <>  SCALED-CAPACITY: 250 frames (CAPACITY:250 X SCALE:1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[RandomAllocator Œµ=1.000] timestep=4 mode=random ‚Üí allocation=(5, 6, 11, 5, 7, 7, 3, 2, 3, 2, 4, 2, 9, 7, 2)\n",
      "üîß Allocated qubits for STOCHASTIC Exp 5: (5, 6, 11, 5, 7, 7, 3, 2, 3, 2, 4, 2, 9, 7, 2)\n",
      "üîÑ Random Dynamic Allocation (Initial): (9, 2, 2, 7, 4, 4, 6, 4, 5, 4, 6, 5, 7, 2, 8)\n",
      "======================================================================================================================================================\n",
      "\n",
      "STOCHASTIC (RANDOM) EXP 5: Env:Stochastic, Attack:Random, Rate:0.0625, Frames:250, QubitAlloc=Random, SC:250 (Scale=1 x Cap=250), Seed: 17091\n",
      "======================================================================================================================================================\n",
      "\tGetting Oracle Rewards ...\n",
      "\tüìä Reward structure for Oracle:\n",
      "\t   Type: <class 'list'>\n",
      "\t   Length: 15\n",
      "\t   First reward: [9.0], type: <class 'list'>\n",
      "\t   First reward length: 1\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 5: Starting GNeuralUCB           in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n",
      "\tEXP 5 GNEURALUCB          : Reward=1843.00, Efficiency=081.9% [Retries=0, Failed=0, < Threshold=0, SCapacity=250, Threshold=0.582]\n",
      "\n",
      "\tüîÑ STOCHASTIC (RANDOM) EXP 5: Starting EXPNeuralUCB         in sequence...\n",
      "\t‚úì Oracle model loaded from configs: Oracle\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Cell 2: Allocator + ExperimentConfiguration for Paper #7\n",
    "# ============================================================\n",
    "importlib.reload(qubit_allocator)\n",
    "importlib.reload(experiment_config)\n",
    "importlib.reload(multi_run_evaluator)\n",
    "\n",
    "from daqr.core.quantum_physics              import *\n",
    "from daqr.evaluation.allocator_runner       import AllocatorRunner\n",
    "from daqr.evaluation.multi_run_evaluator    import MultiRunEvaluator\n",
    "from daqr.config.experiment_config          import ExperimentConfiguration\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"PAPER #7 (QBGP) QUANTUM ROUTING EVALUATION - SINGLE ALLOCATOR TEST\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1) Single Allocator Selection\n",
    "# ------------------------------------------------------------\n",
    "allocator_type = \"Random\"  # Options: \"Random\", \"Dynamic\", \"ThompsonSampling\"\n",
    "ALLOCATORS = [allocator_type]\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2) Run Parameters\n",
    "# ------------------------------------------------------------\n",
    "attack_intensity    = FRAMEWORK_CONFIG['intensity']\n",
    "current_frames      = 50\n",
    "frame_step          = 50\n",
    "current_experiments = 5\n",
    "last_backup         = True\n",
    "base_cap            = False\n",
    "overwrite           = False\n",
    "\n",
    "FRAMEWORK_CONFIG['exp_num']        = current_experiments\n",
    "FRAMEWORK_CONFIG['base_frames']    = current_frames\n",
    "FRAMEWORK_CONFIG['frame_step']     = frame_step\n",
    "\n",
    "\n",
    "# Testbed Configuration\n",
    "PHYSICS_MODELS = ['paper7']  # Paper 7 (QBGP)\n",
    "ATTACK_SCENARIOS = ['stochastic']  # Start simple\n",
    "SCALES = [1, 1.5, 2]\n",
    "RUNS = [5]\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üéØ PAPER 7 ALLOCATOR EVALUATION\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Allocator:                  {allocator_type}\")\n",
    "print(f\"Physics Model:              {PHYSICS_MODELS[0]}\")\n",
    "print(f\"Attack Scenarios:           {ATTACK_SCENARIOS}\")\n",
    "print(f\"Scales:                     {SCALES}\")\n",
    "print(f\"Runs per Scale:             {RUNS}\")\n",
    "print(f\"Total Frames:               {current_frames}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Run allocators over scales and physics models\n",
    "for allocator_type in ALLOCATORS:\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"RUNNING: {allocator_type} on Paper 7 (QBGP)\")\n",
    "    print('='*70)\n",
    "\n",
    "    for scale in SCALES:\n",
    "        print(f\"\\n{'-'*70}\")\n",
    "        print(f\"Preparing: {allocator_type} at scale {scale}\")\n",
    "        print(f\"{'-'*70}\")\n",
    "\n",
    "        for physics_model in PHYSICS_MODELS:\n",
    "            print(f\"\\nüîß Generating physics parameters for model: {physics_model}\") \n",
    "            try:\n",
    "                # Create isolated runner instance\n",
    "                custom_config = ExperimentConfiguration(\n",
    "                    env_type=FRAMEWORK_CONFIG['main_env'],\n",
    "                    scenarios=test_scenarios,\n",
    "                    use_last_backup=last_backup,\n",
    "                    models=models,\n",
    "                    attack_intensity=attack_intensity,\n",
    "                    scale=scale,\n",
    "                    base_capacity=base_cap,\n",
    "                    overwrite=overwrite\n",
    "                )\n",
    "\n",
    "                alloc_runner = AllocatorRunner(\n",
    "                    allocator_type=allocator_type,\n",
    "                    physics_models=[physics_model],\n",
    "                    framework_config=FRAMEWORK_CONFIG,\n",
    "                    scales=[scale],\n",
    "                    runs=RUNS,\n",
    "                    models=models,\n",
    "                    test_scenarios=test_scenarios,\n",
    "                    config=custom_config\n",
    "                )\n",
    "\n",
    "                # Run with Paper 12 physics\n",
    "                alloc_runner.run(get_physics_params_func=get_physics_params)\n",
    "                print(f\"\\n{allocator_type} COMPLETED SUCCESSFULLY\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"\\n{allocator_type} FAILED: {e}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ALL ALLOCATORS COMPLETE!\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # ------------------------------------------------------------\n",
    "# # 1) Allocator selection (Paper #2: start with fixed baseline)\n",
    "# # ------------------------------------------------------------\n",
    "# importlib.reload(qubit_allocator)\n",
    "# importlib.reload(experiment_config)\n",
    "# importlib.reload(multi_run_evaluator)\n",
    "\n",
    "# from daqr.core.quantum_physics              import *\n",
    "# from daqr.evaluation.allocator_runner       import AllocatorRunner\n",
    "# from daqr.evaluation.multi_run_evaluator    import MultiRunEvaluator\n",
    "# from daqr.config.experiment_config          import ExperimentConfiguration\n",
    "\n",
    "# print(\"=\" * 70)\n",
    "# print(\"PAPER #7 (QBGP) QUANTUM ROUTING EVALUATION - SINGLE ALLOCATOR TEST\")\n",
    "# print(\"=\" * 70)\n",
    "\n",
    "# allocator_type =    \"Random\" # Fixed allocator via environment (Paper #2 baseline)\n",
    "\n",
    "# # ------------------------------------------------------------\n",
    "# # 2) Derive run parameters from FRAMEWORK_CONFIG (Cell 1)\n",
    "# # ------------------------------------------------------------\n",
    "# # current_frames      = FRAMEWORK_CONFIG['base_frames'] \n",
    "# # frame_step          = FRAMEWORK_CONFIG['frame_step']\n",
    "# # attack_intensity    = FRAMEWORK_CONFIG['intensity']\n",
    "# # current_experiments = FRAMEWORK_CONFIG['exp_num']\n",
    "\n",
    "# attack_intensity    = FRAMEWORK_CONFIG['intensity']\n",
    "# current_frames      = 50\n",
    "# frame_step          = 50\n",
    "# current_experiments = 5\n",
    "# last_backup         = False\n",
    "# base_cap            = False\n",
    "# overwrite           = True\n",
    "\n",
    "# # PHYSICS_MODELS = ['paper2', 'default']  # Set to ['default', 'paper2'] to test both\n",
    "# ATTACK_SCENARIOS = ['stochastic']  # Start simple, expand later\n",
    "# PHYSICS_MODELS = ['paper7']\n",
    "# SCALES = [1, 1.5, 2]\n",
    "# RUNS = [5]\n",
    "\n",
    "\n",
    "# print(\"\\n\" + \"=\" * 70, \"\\nüéØ QUANTUM ROUTING ALLOCATOR EVALUATION\\n\", \"=\" * 70)\n",
    "# print(f\"Physics Models:             {PHYSICS_MODELS}\")\n",
    "# print(f\"Scales:                     {SCALES}\")\n",
    "# print(f\"Runs:                       {RUNS}\")\n",
    "# print(\"=\" * 70)\n",
    "\n",
    "# # Run each allocator in isolation\n",
    "# print(f\"\\n{'='*70}\")\n",
    "# print(f\"üöÄ ALLOCATOR: {allocator_type}\")\n",
    "# print('='*70)\n",
    "\n",
    "# try:\n",
    "#     # Create isolated runner instance for this allocator\n",
    "#     custom_config = ExperimentConfiguration(\n",
    "#         env_type=FRAMEWORK_CONFIG['main_env'], scenarios=test_scenarios, use_last_backup=last_backup,\n",
    "#         models=models, attack_intensity=attack_intensity, scale=2, base_capacity=base_cap, overwrite=overwrite)\n",
    "\n",
    "#     alloc_runner = AllocatorRunner(\n",
    "#         allocator_type=allocator_type, physics_models=PHYSICS_MODELS, framework_config=FRAMEWORK_CONFIG, \n",
    "#         scales=SCALES, runs=RUNS, models=models, test_scenarios=test_scenarios, config=custom_config)\n",
    "\n",
    "#     # Run this allocator with your existing get_physics_params function\n",
    "#     alloc_runner.run(get_physics_params_func=get_physics_params)\n",
    "#     print(f\"\\n‚úÖ {allocator_type} COMPLETED SUCCESSFULLY\")\n",
    "\n",
    "# except Exception as e:\n",
    "#     print(f\"\\n‚ùå {allocator_type} FAILED: {e}\")\n",
    "#     traceback.print_exc()\n",
    "\n",
    "# print(\"\\n\" + \"=\" * 70)\n",
    "# print(\"‚úÖ ALL ALLOCATORS COMPLETE!\")\n",
    "# print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ------------------------------------------------------------\n",
    "# # 1) Allocator selection (Paper #2: start with fixed baseline)\n",
    "# # ------------------------------------------------------------\n",
    "# importlib.reload(qubit_allocator)\n",
    "# importlib.reload(experiment_config)\n",
    "# importlib.reload(multi_run_evaluator)\n",
    "\n",
    "# from daqr.core.quantum_physics              import *\n",
    "# from daqr.evaluation.allocator_runner       import AllocatorRunner\n",
    "# from daqr.evaluation.multi_run_evaluator    import MultiRunEvaluator\n",
    "# from daqr.config.experiment_config          import ExperimentConfiguration\n",
    "\n",
    "# print(\"=\" * 70)\n",
    "# print(\"PAPER #7 (QBGP) QUANTUM ROUTING EVALUATION - SINGLE ALLOCATOR TEST\")\n",
    "# print(\"=\" * 70)\n",
    "\n",
    "# # ------------------------------------------------------------\n",
    "# # 1) Single Allocator Selection\n",
    "# # ------------------------------------------------------------\n",
    "# allocator_type = \"ThompsonSampling\"  # Options: \"Random\", \"DynamicUCB\", \"ThompsonSampling\"\n",
    "\n",
    "# # ------------------------------------------------------------\n",
    "# # 2) Run Parameters\n",
    "# # ------------------------------------------------------------\n",
    "# attack_intensity    = FRAMEWORK_CONFIG['intensity']\n",
    "# current_frames      = 50\n",
    "# frame_step          = 50\n",
    "# current_experiments = 5\n",
    "# last_backup         = False\n",
    "# base_cap            = False\n",
    "# overwrite           = True\n",
    "\n",
    "# # Testbed Configuration\n",
    "# PHYSICS_MODELS = ['paper7']  # Paper 7 (QBGP)\n",
    "# ATTACK_SCENARIOS = ['stochastic']  # Start simple\n",
    "# SCALES = [1, 1.5, 2]\n",
    "# RUNS = [5]\n",
    "\n",
    "# print(\"\\n\" + \"=\" * 70)\n",
    "# print(\"üéØ PAPER 7 ALLOCATOR EVALUATION\")\n",
    "# print(\"=\" * 70)\n",
    "# print(f\"Allocator:                  {allocator_type}\")\n",
    "# print(f\"Physics Model:              {PHYSICS_MODELS[0]}\")\n",
    "# print(f\"Attack Scenarios:           {ATTACK_SCENARIOS}\")\n",
    "# print(f\"Scales:                     {SCALES}\")\n",
    "# print(f\"Runs per Scale:             {RUNS}\")\n",
    "# print(f\"Total Frames:               {current_frames}\")\n",
    "# print(\"=\" * 70)\n",
    "\n",
    "# # Run allocator\n",
    "# print(f\"\\n{'='*70}\")\n",
    "# print(f\"üöÄ RUNNING: {allocator_type} on Paper 7 (QBGP)\")\n",
    "# print('='*70)\n",
    "\n",
    "# try:\n",
    "#     # Create isolated runner instance\n",
    "#     custom_config = ExperimentConfiguration(\n",
    "#         env_type=FRAMEWORK_CONFIG['main_env'],\n",
    "#         scenarios=test_scenarios,\n",
    "#         use_last_backup=last_backup,\n",
    "#         models=models,\n",
    "#         attack_intensity=attack_intensity,\n",
    "#         scale=1,\n",
    "#         base_capacity=base_cap,\n",
    "#         overwrite=overwrite\n",
    "#     )\n",
    "\n",
    "#     alloc_runner = AllocatorRunner(\n",
    "#         allocator_type=allocator_type,\n",
    "#         physics_models=PHYSICS_MODELS,\n",
    "#         framework_config=FRAMEWORK_CONFIG,\n",
    "#         scales=SCALES,\n",
    "#         runs=RUNS,\n",
    "#         models=models,\n",
    "#         test_scenarios=test_scenarios,\n",
    "#         config=custom_config\n",
    "#     )\n",
    "\n",
    "#     # Run with Paper 7 physics\n",
    "#     alloc_runner.run(get_physics_params_func=get_physics_params)\n",
    "#     print(f\"\\n‚úÖ {allocator_type} COMPLETED SUCCESSFULLY\")\n",
    "\n",
    "# except Exception as e:\n",
    "#     print(f\"\\n‚ùå {allocator_type} FAILED: {e}\")\n",
    "#     import traceback\n",
    "#     traceback.print_exc()\n",
    "\n",
    "# print(\"\\n\" + \"=\" * 70)\n",
    "# print(\"‚úÖ ALLOCATOR TEST COMPLETE!\")\n",
    "# print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "comprehensive-evaluation"
   },
   "source": [
    "## Multi-Environment Performance Analysis\n",
    "\n",
    "### Complete Evaluation Matrix\n",
    "\n",
    "This research extends beyond the primary stochastic-adversarial comparison to provide comprehensive algorithm assessment across the complete spectrum of operational environments, establishing a thorough empirical foundation for robustness evaluation.\n",
    "\n",
    "### Environmental Test Framework\n",
    "\n",
    "| Environment | Classification | Threat Characteristics | Analytical Purpose |\n",
    "|-------------|---------------|----------------------|-------------------|\n",
    "| `none` | Baseline | Deterministic optimal conditions | Theoretical performance ceiling |\n",
    "| `stochastic` | Probabilistic | Uniform random failures | Standard operational baseline |\n",
    "| `markov` | Adversarial | Memory-dependent strategic attacks | Oblivious adversarial model |\n",
    "| `adaptive` | Adversarial | Feedback-driven strategic attacks | Responsive adversarial model |\n",
    "| `onlineadaptive` | Adversarial | Real-time adaptive strategic attacks | Sophisticated adversarial model |\n",
    "\n",
    "### Research Contributions\n",
    "\n",
    "**Comprehensive Threat Model Coverage**\n",
    "The evaluation framework addresses the complete spectrum of operational conditions, from optimal deterministic environments through increasingly sophisticated adversarial scenarios, providing unprecedented coverage of realistic deployment conditions.\n",
    "\n",
    "**Graduated Adversarial Complexity Analysis**  \n",
    "The systematic progression from oblivious to sophisticated adversarial models enables precise quantification of algorithm performance degradation as threat sophistication increases, revealing critical robustness thresholds.\n",
    "\n",
    "**Cross-Environment Validation Protocol**\n",
    "Consistent algorithm ranking across multiple environments validates robustness claims and identifies algorithms with stable performance characteristics independent of operational conditions.\n",
    "\n",
    "**Empirical Robustness Quantification**\n",
    "The multi-environment approach enables precise measurement of performance degradation rates, establishing quantitative robustness metrics that support theoretical predictions and practical deployment decisions.\n",
    "\n",
    "### Methodological Significance\n",
    "\n",
    "This comprehensive evaluation protocol addresses limitations in existing literature where algorithm assessment often focuses on narrow operational scenarios, providing the empirical foundation necessary for robust algorithm deployment in practical quantum network environments."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1rknAIThhNzWIoGwNHJR_N0F6hBb7T3e-",
     "timestamp": 1759053280580
    }
   ]
  },
  "kernelspec": {
   "display_name": ".quantum (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
